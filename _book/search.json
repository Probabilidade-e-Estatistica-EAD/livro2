[{"path":"index.html","id":"prefácio","chapter":"Prefácio","heading":"Prefácio","text":"Este material é baseado livro desenvolvido pela OpenIntro, OpenIntro Statistics, que fornece uma introdução à estatística, nível de graduação. O material original está disponível github em formato TeX. Ao longo deste livro, é possível consultar o código de todos os gráficos e tabelas clicando botão “Mostrar código” correspondente. O código completo deste livro encontra-se github da disciplina.Tanto este material adaptado, quanto o original, estão sob mesma licença Creative Commons.","code":""},{"path":"ch1-intro.html","id":"ch1-intro","chapter":"1 Introdução aos Bancos de Dados","heading":"1 Introdução aos Bancos de Dados","text":"Os cientistas procuram responder perguntas usando métodos rigorosos e observações cuidadosas. Essas observações – coletadas partir de notas de campo, pesquisas e experimentos – formam espinha dorsal de uma investigação estatística e são chamadas de banco de dados. Estatística é o estudo de como melhor coletar, analisar e tirar conclusões dos dados. É útil colocar estatísticas contexto de um processo geral de investigação:Identifique uma questão ou problema.Identifique uma questão ou problema.Coletar dados relevantes sobre o tópico.Coletar dados relevantes sobre o tópico.Analise os dados.Analise os dados.Faça uma conclusão.Faça uma conclusão.Estatística como um assunto se concentra em tornar os estágios 2-4 objetivos, rigorosos e eficientes. Isto é, estatística tem três componentes principais: como melhor podemos coletar dados? Como deve ser analisado? E o que podemos inferir da análise?\r\nOs tópicos que os cientistas investigam são tão diversos quanto perguntas que fazem. entanto, muitas dessas investigações podem ser abordadas com um pequeno número de técnicas de coleta de dados, ferramentas analíticas e conceitos fundamentais em inferência estatística. Este capítulo fornece um vislumbre desses e de outros temas que encontraremos ao longo restante livro. Apresentamos os princípios básicos de cada ramo e aprendemos algumas ferramentas ao longo caminho. Nós vamos encontrar aplicações de outros campos, alguns dos quais não são tipicamente associados à ciência, mas, mesmo assim, podem se beneficiar estudo estatístico.","code":""},{"path":"ch1-intro.html","id":"basicExampleOfStentsAndStrokes","chapter":"1 Introdução aos Bancos de Dados","heading":"1.1 Estudo de caso: usando stents para evitar derrames","text":"Seção 1.1 introduz um desafio clássico na estatística: avaliar eficácia de um tratamento médico. Os termos nesta seção e, na verdade, em grande parte deste capítulo, serão revisitados posteriormente texto. O plano, por enquanto, é simplesmente ter uma noção papel que estatísticas podem desempenhar na prática.Nesta seção, vamos considerar um experimento que estuda eficácia dos stents tratamento de pacientes com risco de acidente vascular cerebral1. Os stents são dispositivos colocados dentro dos vasos sanguíneos que auxiliam na recuperação paciente após eventos cardíacos e reduzem o risco de um novo acidente ou morte. Muitos médicos esperavam que houvesse benefícios similares para pacientes com risco de derrame. Começamos escrevendo pergunta principal que os pesquisadores esperam responder:O uso de stents reduz o risco de acidente vascular cerebral?Os pesquisadores que fizeram essa pergunta coletaram dados de 451 pacientes em risco. Cada paciente voluntário foi aleatoriamente designado para um dos dois grupos:Grupo de tratamento: Os pacientes grupo de tratamento receberam stent e tratamento médico. O manejo médico incluiu medicamentos, gerenciamento de fatores de risco e ajuda na modificação estilo de vida.Grupo de tratamento: Os pacientes grupo de tratamento receberam stent e tratamento médico. O manejo médico incluiu medicamentos, gerenciamento de fatores de risco e ajuda na modificação estilo de vida.Grupo de controle: Os pacientes grupo controle receberam o mesmo tratamento médico grupo de tratamento, mas não receberam stents.Grupo de controle: Os pacientes grupo controle receberam o mesmo tratamento médico grupo de tratamento, mas não receberam stents.Os pesquisadores distribuíram aleatoriamente 224 pacientes para o grupo de tratamento e 227 para o grupo de controle. Neste estudo, o grupo controle fornece um ponto de referência contra o qual podemos medir o impacto médico dos stents grupo de tratamento.Os pesquisadores estudaram o efeito dos stents em dois momentos: 30 dias após inscrição e 365 dias após inscrição. Os resultados de 5 pacientes estão resumidos na Tabela 1.1. Os resultados dos pacientes são registrados como “acidente vascular cerebral” ou “nenhum evento,” representando se o paciente teve ou não um acidente vascular cerebral final de um período de tempo.Tabela 1.1:  Resultados para cinco pacientes estudo stentConsiderar os dados de cada paciente individualmente seria um caminho longo e complicado para responder à pergunta de pesquisa original. Em vez disso, executar uma análise estatística de dados nos permite considerar todos os dados de uma só vez. Tabela 1.2 resume os dados brutos de uma maneira mais útil. Nesta tabela, podemos ver rapidamente o que aconteceu durante todo o estudo. Por exemplo, para identificar o número de pacientes grupo de tratamento que tiveram um derrame dentro de 30 dias, olhamos lado esquerdo da mesa na intersecção tratamento com o derrame: 33.Tabela 1.2: Estatística descritiva para o estudo sobre stentPodemos calcular estatísticas através da tabela. Uma estatística é um único número que resume uma grande quantidade de dados.3 Por exemplo, os principais resultados estudo após um ano podem ser descritos por duas estatísticas resumidas: proporção de pessoas que tiveram um derrame nos grupos de tratamento e de controle.Proporção que teve um derrame grupo tratamento (stent):\r\n\\[\\frac{45}{224} = 0.20 = 20\\%\\]Proporção que teve um derrame grupo tratamento (stent):\r\n\\[\\frac{45}{224} = 0.20 = 20\\%\\]Proporção que teve um derrame grupo de controle:\r\n\\[\\frac{28}{227} = 0.12 = 12\\%\\]Proporção que teve um derrame grupo de controle:\r\n\\[\\frac{28}{227} = 0.12 = 12\\%\\]Estas duas estatísticas resumidas são úteis para procurar diferenças nos grupos, e temos uma surpresa: mais 8% de pacientes grupo de tratamento tiveram um derrame! Isto é importante por duas razões. Primeiro, é contrário ao que os médicos esperavam, que os stents reduziriam taxa de derrames. Segundo, leva uma questão estatística: os dados mostram uma diferença “real” entre os grupos?Essa segunda questão é sutil. Suponha que você jogue uma moeda 100 vezes. Embora chance de uma moeda cair cara em uma dada moeda seja de 50%, provavelmente não observaremos exatamente 50 caras. Esse tipo de flutuação faz parte de praticamente qualquer tipo de processo de geração de dados. É possível que diferença de 8% estudo stent se deva essa variação natural. entanto, quanto maior diferença que observamos (para um tamanho de amostra específico), menos crível é que diferença seja devida ao acaso. Então, o que estamos realmente perguntando é o seguinte: diferença é tão grande que devemos rejeitar noção de que isso se deve ao acaso?Embora ainda não tenhamos nossas ferramentas estatísticas para resolver totalmente essa questão por conta própria, podemos compreender conclusões da análise publicada: havia evidências convincentes de danos por stents neste estudo de pacientes com AVC.Seja cuidadoso: não generalizamos os resultados deste estudo para todos os pacientes e todos os stents. Este estudo analisou pacientes com características muito específicas que se voluntariaram para fazer parte deste estudo e que podem não ser representativos de todos os pacientes com AVC. Além disso, existem muitos tipos de stents e este estudo considerou apenas o stent Wingspan auto-expansível (Boston Scientific). entanto, este estudo nos deixa uma lição importante: devemos manter nossos olhos abertos para surpresas.","code":"\ntable1 <- data.frame(Paciente = c(1, 2, 3, 450, 451), Grupo = c('tratamento',                                                'tratamento','tratamento','controle','controle'),\n                     trinta_dias = c('sem evento','acidente','sem evento','sem evento',\n                                'sem evento'),\n                     trezentos_sessenta_cinco_dias = c('sem evento',\n                                                       'acidente','sem evento',\n                                                       'sem evento','sem evento'))\n\ncolnames(table1) <- c('Paciente','Grupo','0-30 dias','0-365 dias')\n\nknitr::kable(table1, caption = ' Resultados para cinco pacientes do estudo stent',\n             align = 'c')\ntable2 <- data.frame(rbind(c(33, 191, 45, 179), \n                           c(13, 214, 28, 199), \n                           c(46, 405, 73, 378)))\n\n#organiza~ção dos nomes\nrownames(table2) <- c('tratamento', 'controle','total')\ncolnames(table2) <- c('ataque cardíaco (0-30 dias)', 'sem evento (0-30 dias)',\n                      'ataque cardíaco (0-365 dias)', 'sem evento (0-365 dias)')\n\nknitr::kable(table2, align = 'c',\n             caption = 'Estatística descritiva para o estudo sobre stent')"},{"path":"ch1-intro.html","id":"dataBasics","chapter":"1 Introdução aos Bancos de Dados","heading":"1.2 Noções básicas de dados","text":"Apresentação eficaz e descrição dos dados é um primeiro passo na maioria das análises. Esta seção apresenta uma estrutura para organizar dados, bem como alguma terminologia que será usada ao longo deste livro.","code":""},{"path":"ch1-intro.html","id":"observationsVariableData","chapter":"1 Introdução aos Bancos de Dados","heading":"1.2.1 Observações, variáveis e matrizes de dados","text":"Tabela 1.3 exibe linhas 1, 2, 3 e 50 de um conjunto de dados referentes 50 e-mails recebidos durante o início de 2012. Essas observações serão chamadas de conjunto de dados email50 e são uma amostra aleatória de um conjunto de dados maior vamos ver na Seção 1.8.Tabela 1.3: Quatro linhas da matriz de dados email50.Cada linha na tabela representa um único e-mail ou caso.4 colunas representam características, chamadas variéveis, para cada um dos e-mails. Por exemplo, primeira linha representa o email 1, que não é spam, contém 21,705 caracteres, 551 quebras de linha, está escrito em formato HTML e contém apenas números pequenos.Na prática, é especialmente importante fazer perguntas esclarecedoras para garantir que aspectos importantes dos dados sejam compreendidos. Por exemplo, é sempre importante ter certeza de que sabemos o que cada variável significa e unidades de medida. descrições de todas cinco variáveis de e-mail são dadas na Tabela 1.4.Tabela 1.4:  Variáveis e suas descrições para o conjunto de dados email50Os dados na Tabela 1.3 representam matriz de dados, que é uma maneira comum de organizar dados. Cada linha de uma matriz de dados corresponde um caso único e cada coluna corresponde uma variável. Uma matriz de dados para o estudo de acidente vascular cerebral foi introduzida na Seção 1.1 é mostrado na Tabela 1.1, onde os casos eram pacientes e havia três variáveis registradas para cada paciente.matrizes de dados são uma maneira conveniente de registrar e armazenar dados. Se outro indivíduo ou caso adicionado ao conjunto de dados, uma linha adicional poderá ser facilmente adicionada. Da mesma forma, outra coluna pode ser adicionada para uma nova variável.Sete colunas conjunto de dados município são mostrados na Tabela 1.5, e variáveis estão resumidas na Tabela 1.6. Esses dados foram coletados site Censo dos EUA6.Tabela 1.5: Sete linhas conjunto de dados condado.Tabela 1.6: Variáveis e suas descrições para o banco de dados condado.","code":"\nlibrary(openintro)\ndata(\"email50\")\n\ntable3 <- email50[,c('spam', 'num_char', 'line_breaks', 'format', 'number')]\ntable3$spam <- ifelse(table3$spam  == '0', 'não', 'sim')\ntable3$format <- ifelse(table3$format  == '0', 'text', 'html')\n\n\nknitr::kable(table3[c(1:3,50),], align = 'c',\n             caption = 'Quatro linhas da matriz de dados email50.')\ntable4 <- data.frame(variavel = colnames(table3),\n                     descricao = c('Especifica se a mensagem eras spam',\n                                   'O número de caracteres no email',\n                                   'O número de quebras de linha no email (não incluindo quebras por figura)',\n                                   ' Indica se o email continha formatação especial, como negrito, tabelas, ou links, o que indicaria que a mensagem está no formato HTML',\n                                   'Indica se o email não tinha nenhum número, um pequeno número (menor que 1 milhão), ou um número grande'))\n\nknitr::kable(table4, align = 'r', \n             caption = ' Variáveis e suas descrições para o conjunto de dados email50')\ndata(county)\n\nknitr::kable(head(county, 7), align = 'c', \n             caption = 'Sete linhas do conjunto de dados condado.')\ntable6 <- data.frame(variavel = colnames(county), \n                     descricao = c('Nome do condado',\n                                   'Estado onde fica o condado (também incluso o distrito de Colúmbia)',\n                                   'População em 2000',\n                                   'População em 2010',\n                                   'Gasto federal per capita',\n                                   'Porcentagem da população na pobreza',\n                                   'Porcentagem da população que vive em sua própria casa ou vive com o dono (e.g. crianças vivendo com pais que são donos da casa)',\n                                   ' Percentagem de unidades habitacionais que fazem parte de estruturas multi unidade (e.g. apartamentos)',\n                                   'Renda per capita',\n                                   'Renda por habitação mediana para o condado, onde a renda por habitação é igual a renda total de todos ocupantes com mais de 15 anos de idade'))\n\nknitr::kable(table6, align = 'r', \n              caption = 'Variáveis e suas descrições para o banco de dados condado.')"},{"path":"ch1-intro.html","id":"typesVariables","chapter":"1 Introdução aos Bancos de Dados","heading":"1.2.2 Tipos de variáveis","text":"Examine variáveis fed_spend, pop2010, state, e med_income conjunto de dados condado. Cada uma dessas variáveis é inerentemente diferente das outras três, mas muitas delas compartilham certas características.Primeiro considere fed_spend, que é dito ser uma variável numérica, pois pode ter uma ampla gama de valores numéricos e é sensato adicionar, subtrair ou obter médias com esses valores. Por outro lado, não classificaríamos os códigos de área de telefone como numéricos, uma vez que sua média, soma e diferença não têm um significado claro.pop2010 variável também é numérica, embora pareça ser um pouco diferente de fed_spend. Esta variável da contagem da população só pode ter números inteiros não negativos (\\(1,2,3,\\dots\\)). Por essa razão, variável população é dita ser discreta já que só pode assumir valores numéricos com saltos. Por outro lado, diz-se que variável gasto federal é contínua.variável state pode levar até 51 valores, contabilizando Washington, DC: AL,\\(\\dots\\), e WY. Porque próprias respostas são categorias, state é chamada uma variável categórica, e os valores possíveis são chamados de níveis da variável.\r\nFigura 1.1: Repartição das variáveis em seus respectivos tipos.\r\nO número de irmãos e altura dos alunos representam variáveis numéricas. Como o número de irmãos é uma contagem, ele é discreto. Altura varia continuamente, por isso é uma variável numérica contínua. última variável classifica os alunos em duas categorias - aqueles que fizeram e aqueles que não fizeram um curso de estatística – o que torna essa variável categórica.","code":"\nvars <- data.frame(xmin = c(6, 0, 12.5, -3, 3, 9, 15),\n                   xmax = c(11, 5, 17.5, 2, 8, 14, 20),\n                   ymin = c(4, 2, 2, 0, 0, 0, 0), \n                   ymax = c(5, 3, 3, 1, 1, 1, 1), \n                   x = c(8.5, 2.5, 15, -0.5, 5.5, 11.5, 17.5), \n                   y = c(4.5, 2.5, 2.5, 0.5, 0.5, 0.5, 0.5),\n                   labs = c('todas \\n variáveis', 'numérica', 'categórica', 'contínua', \n                   'discreta', 'nominal \\n(cat. sem ordem)', 'ordinal \\n(cat. com ordem)'), \n                   size = c(3, 4, 4, 4, 4, 3, 3))\n\narrows <- data.frame(x = c(8, 9, 2, 3, 14.5, 15.5),\n                     y = c(3.9, 3.9, 1.9, 1.9, 1.9, 1.9),\n                     xend = c(5, 12.5, -0.5, 5.5, 11.5, 17.5),\n                     yend = c(3.2, 3.2, 1.2, 1.2, 1.2, 1.2))\n\nggplot(data = vars) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  geom_rect(mapping = aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), \n            alpha = 0.5, color = 'black', fill = 'skyblue3') + \n  annotate(geom = 'text', x = vars$x, y = vars$y, \n           label = paste0(vars$labs), size = vars$size) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), \n        axis.title = element_blank()) +\n  geom_segment(data = arrows, aes(x = x, xend = xend, y = y, yend = yend), \n               arrow = arrow(length = unit(0.2, \"cm\")))"},{"path":"ch1-intro.html","id":"variableRelations","chapter":"1 Introdução aos Bancos de Dados","heading":"1.2.3 Relações entre variáveis","text":"Muitas análises são motivadas por um pesquisador que procura uma relação entre duas ou mais variáveis. Um cientista social pode gostar de responder algumas das seguintes perguntas:Os gastos federais, em média, são maiores ou menores nos condados com altas taxas de pobreza?Os gastos federais, em média, são maiores ou menores nos condados com altas taxas de pobreza?Se variável casa própria menor que média nacional em um município, percentagem de estruturas de várias unidades naquele município provavelmente estará acima ou abaixo da média nacional?Se variável casa própria menor que média nacional em um município, percentagem de estruturas de várias unidades naquele município provavelmente estará acima ou abaixo da média nacional?Quais municípios têm uma renda média maior: aqueles que decretam uma ou mais proibições de fumar ou aqueles que não decretaram?Quais municípios têm uma renda média maior: aqueles que decretam uma ou mais proibições de fumar ou aqueles que não decretaram?Para responder essas perguntas, os dados devem ser coletados, como o conjunto de dados condado mostrado na Tabela 1.5. Examinar estatísticas-resumo poderia fornecer insights para cada uma das três perguntas sobre condados. Além disso, os gráficos podem ser usados para resumir visualmente os dados e são úteis para responder essas perguntas também. Gráficos de dispersão são um tipo de gráfico usado para estudar relação entre duas variáveis numéricas. Figura 1.2 compara variáveis fed_spend e poverty.Cada ponto representa um único condado. Por exemplo, o ponto realçado corresponde ao Condado 1088 conjunto de dados: Owsley County, Kentucky, que tinha uma taxa de pobreza de 41,5% e gastos federais de $21,50 per capita. O gráfico de dispersão sugere uma relação entre duas variáveis: os municípios com alta taxa de pobreza também tendem ter um pouco mais de gastos federais. Podemos pensar em por que essa relação existe e investigar cada ideia para determinar qual é explicação mais razoável.\r\nFigura 1.2: Um gráfico de dispersão mostrando fed_spend contra poverty.\r\nDiz-se que duas variáveis estão associadas porque o gráfico mostra um padrão discernível. Quando duas variáveis mostram alguma conexão umas com outras, elas são chamadas variáveis associadas. Variáveis associadas também podem ser chamadas variáveis dependentes e vice-versa.\r\nFigura 1.3: Gráfico de dispersão entre proporção de casa própria e porcentagem de unidades eem estruturas de multi-unidades\r\nParece que quanto maior fração de unidades em estruturas com várias unidades, menor taxa de casa própria. Como existe alguma relação entre variáveis, elas estão associadas.Porque há uma tendência de queda na Figura 1.3 – municípios com mais unidades em estruturas de várias unidades estão associados uma menor casa própria – essas variáveis são consideradas associadas negativamente. Uma associação positiva é mostrada na relação entre variáveis poverty e fed_spend representadas na Figura 1.2, onde os municípios com maiores taxas de pobreza tendem receber mais gastos federais per capita.\r\nSe duas variáveis não estão associadas, então elas são independentes. Ou seja, duas variáveis são independentes se não houver relação evidente entre duas.Associado ou independente, não ambos: Um par de variáveis estão relacionadas de alguma forma (associadas) ou não (independentes). Nenhum par de variáveis são associadas e independentes.","code":"\nggplot(data = county, mapping = aes(x = poverty, y = fed_spend)) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Pobreza', y = 'Gasto federal per capita') + \n  geom_point() + \n  ylim(0, 30) + \n  scale_x_continuous(breaks = seq(0, 50, 10)) +\n  geom_segment(aes(x = 0, y = 21.5, xend = 41.5, yend = 21.5), \n               linetype = \"dashed\", color = 'red') + \n  geom_segment(aes(x = 41.5, y = 0, xend = 41.5, yend = 21.5), \n               linetype = \"dashed\", color = 'red')\nggplot(data = countyComplete, \n       mapping = aes(x = housing_multi_unit, y = home_ownership)) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Porcentagem de Unidades em Estruturas de Multi-Unidades', \n       y = 'Proporção de Casa Própria') + \n  geom_point()"},{"path":"ch1-intro.html","id":"overviewOfDataCollectionPrinciples","chapter":"1 Introdução aos Bancos de Dados","heading":"1.3 Visão geral dos princípios de coleta de dados","text":"O primeiro passo na condução de pesquisas é identificar tópicos ou questões que devem ser investigados. Uma pergunta de pesquisa claramente apresentada é útil para identificar quais assuntos ou casos devem ser estudados e quais variáveis são importantes. Também é importante considerar como os dados são coletados para que sejam confiáveis e ajudem atingir metas de pesquisa.","code":""},{"path":"ch1-intro.html","id":"populationsAndSamples","chapter":"1 Introdução aos Bancos de Dados","heading":"1.3.1 Populações e amostras","text":"Considere três perguntas de pesquisa seguir:Qual é o teor médio de mercúrio peixe-espada Oceano Atlântico?Qual é o teor médio de mercúrio peixe-espada Oceano Atlântico?Nos últimos 5 anos, qual é o tempo médio para concluir um curso para alunos de graduação da Duke?Nos últimos 5 anos, qual é o tempo médio para concluir um curso para alunos de graduação da Duke?Um novo medicamento reduz o número de mortes em pacientes com doença cardíaca grave?Um novo medicamento reduz o número de mortes em pacientes com doença cardíaca grave?Cada questão de pesquisa refere-se uma população alvo. Na primeira questão, população alvo é todo o peixe-espada oceano Atlântico, e cada peixe representa um caso. Muitas vezes, é muito caro coletar dados para todos os casos em uma população. Em vez disso, uma amostra é obtida. amostra representa um subconjunto dos casos e geralmente é uma pequena fração da população. Por exemplo, 60 peixes-espada (ou algum outro número) na população podem ser selecionados, e esses dados de amostra podem ser usados para fornecer uma estimativa da média populacional e responder à pergunta da pesquisa.","code":""},{"path":"ch1-intro.html","id":"anecdotalEvidenceSubsection","chapter":"1 Introdução aos Bancos de Dados","heading":"1.3.2 Evidência anedótica","text":"Considere seguintes respostas possíveis para três questões de pesquisa:Um homem noticiário tem envenenamento por mercúrio por comer espadarte, então concentração média de mercúrio em espadarte deve ser perigosamente alta.Um homem noticiário tem envenenamento por mercúrio por comer espadarte, então concentração média de mercúrio em espadarte deve ser perigosamente alta.Eu conheci dois alunos que levaram mais de sete anos para se formar na Duke, então deve levar mais tempo para se formar na Duke que em muitas outras faculdades.Eu conheci dois alunos que levaram mais de sete anos para se formar na Duke, então deve levar mais tempo para se formar na Duke que em muitas outras faculdades.O pai da minha amiga teve um ataque cardíaco e morreu depois que eles lhe deram uma nova droga para doença cardíaca, então droga não deve funcionar.O pai da minha amiga teve um ataque cardíaco e morreu depois que eles lhe deram uma nova droga para doença cardíaca, então droga não deve funcionar.Cada conclusão é baseada em dados. entanto, existem dois problemas. Primeiro, os dados representam apenas um ou dois casos. Em segundo lugar, e mais importante, não está claro se esses casos são realmente representativos da população. Dados coletados dessa maneira casual são chamados evidência anedótica.\r\nFigura 1.4: Em fevereiro de 2010, alguns especialistas da mídia citaram uma grande tempestade de neve como evidência válida contra o aquecimento global. Como o comediante Jon Stewart apontou: É uma tempestade, em uma região, de um país.\r\nEvidência anedótica: Tenha cuidado com os dados coletados de maneira aleatória. Tal evidência pode ser verdadeira e verificável, mas pode apenas representar casos extraordinários.evidência anedótica é tipicamente composta de casos incomuns que lembramos com base em suas características marcantes. Por exemplo, é mais provável que nos lembremos das duas pessoas que conhecemos que levaram sete anos para se formar que outras seis que se formaram em quatro anos. Em vez de olhar para os casos mais incomuns, devemos examinar uma amostra de muitos casos que representam população.","code":"\nknitr::include_graphics(\"images/c1/mnWinter.jpg\")"},{"path":"ch1-intro.html","id":"popSampling","chapter":"1 Introdução aos Bancos de Dados","heading":"1.3.3 Amostragem de uma população","text":"Podemos tentar estimar o tempo para graduação de alunos de graduação da Duke nos últimos 5 anos, coletando uma amostra de alunos. Todos os graduados nos últimos 5 anos representam população, e graduados que são amostra. Em geral, procuramos sempre aleatoriamente selecionar uma amostra de uma população. O tipo mais básico de seleção aleatória é equivalente como os sorteios são conduzidos. Por exemplo, na seleção de graduados, poderíamos escrever o nome de cada graduado em um bilhete de rifa e comprar 100 ingressos. Os nomes selecionados representariam uma amostra aleatória de 100 graduados.\r\nFigura 1.5: Neste gráfico, cinco graduados são selecionados aleatoriamente da população para serem incluídos na amostra.\r\nPor que escolher uma amostra aleatoriamente? Por que não escolher apenas uma amostra à mão? Considere o seguinte cenário.Talvez ela escolheria um número desproporcional de graduados em campos relacionados à saúde. Ou talvez seleção dela fosse bem representativa da população. Ao selecionar amostras manualmente, corremos o risco de escolher uma amostra tendenciosa, mesmo que esse preconceito não seja intencional ou difícil de discernir.\r\nFigura 1.6: Em vez de amostragem de todos os graduados igualmente, um nutricionista pode, inadvertidamente, escolher graduados com cursos relacionados à saúde de forma desproporcional.\r\nSe alguém tiver permissão para escolher exatamente quais graduados foram incluídos na amostra, é totalmente possível que amostra possa ser distorcida aos interesses dessa pessoa, o que pode ser totalmente não intencional. Isso introduz um viés na amostra. Uma amostragem aleatória ajuda resolver esse problema. amostra aleatória mais básica é chamada de amostra aleatória simples, e é equivalente usar um sorteio para selecionar casos. Isso significa que cada caso na população tem uma chance igual de ser incluído e não há conexão implícita entre os casos na amostra.Às vezes, uma amostra aleatória simples é difícil de implementar e um método alternativo é útil. Um método substituto é uma amostra sistemática, onde um caso é amostrado depois de deixar um número fixo de outros, digamos 10 outros casos, passar. Como essa abordagem usa um mecanismo que não é facilmente sujeito vieses pessoais, geralmente produz uma amostra razoavelmente representativa. Este livro se concentrará em amostras aleatórias, já que o uso de amostras sistemáticas é incomum e requer considerações adicionais contexto.O ato de pegar uma amostra aleatória simples ajuda minimizar o viés. entanto, o preconceito pode surgir de outras formas. Mesmo quando pessoas são escolhidas aleatoriamente, por exemplo, deve-se ter cautela se não resposta está alta. Por exemplo, se apenas 30% das pessoas amostradas aleatoriamente para uma pesquisa realmente responderem, então não está claro se os resultados são representativos de toda população. Esse termo viés de não resposta pode distorcer resultados.\r\nFigura 1.7: Devido à possibilidade de não resposta, os estudos de pesquisa só podem atingir um determinado grupo dentro da população. É difícil, e muitas vezes impossível, corrigir completamente esse problema.\r\nOutro método comum é uma amostra de conveniência, onde os indivíduos que são facilmente acessíveis têm maior probabilidade de serem incluídos na amostra. Por exemplo, se uma pesquisa política feita em pessoas que andam Bronx, isso não representará toda cidade de Nova York. Muitas vezes é difícil discernir qual subpopulação uma amostra de conveniência representa.","code":"\ntemp <- seq(0, 2 * pi, 2 * pi / 100)\nx <- 0.5 + 0.5 * cos(temp)\ny <- 0.5 + 0.5 * sin(temp)\n\ns <- matrix(runif(700), ncol = 2)\nS <- matrix(NA, 350, 2)\nj <- 0\nsub <- rep(FALSE, 1000)\nfor (i in 1:nrow(s)) {\n  if(sum((s[i,] - 0.5)^2) < 0.23){\n    j <- j+1\n    S[j,] <- s[i,]\n  }\n  if(sum((s[i, ] - c(0.05, 0.18) - 0.5)^2) < 0.07){\n    sub[j] <- TRUE\n  }\n}\n\nset.seed(7)\nN <- sample((1:j)[sub], 25)\n\nSS <- (S[N, ] - 0.5) / 2 + 0.5\nthese <- c(2, 5, 7, 12, 15)\n\nx0 <- y0 <- x1 <- y1 <- vector()\n\nfor (i in these){\n  x0[i] <- S[N[i], 1]\n  y0[i] <- S[N[i], 2]\n  x1[i] <- SS[i, 1] + 1 - 0.03\n  y1[i] <- SS[i, 2]\n}\n\npopgrad <- data.frame(x0 = na.omit(x0), \n                      y0 = na.omit(y0), \n                      x1 = na.omit(x1), \n                      y1 = na.omit(y1))\n\nggplot() + geom_path(aes(x,y)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  xlim(0, 2) + ylim(0, 1.1) + \n  geom_point(aes(na.omit(S[,1]), na.omit(S[,2])), color = 'skyblue3') + \n  annotate(geom = 'text', 0.5, 1.07, label  = 'todos os graduados') + \n  geom_path(aes((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 + 0.5)) + \n  geom_point(aes(SS[these, 1] + 1, SS[these, 2]), color = 'tomato') + \n  annotate(geom = 'text', 1.5, 0.82, label = 'amostra') + \n  geom_segment(data = popgrad, aes(x = x0, xend = x1, y = y0, yend = y1), \n               arrow = arrow(length = unit(0.2, \"cm\")))\ntemp <- seq(0, 2 * pi, 2 * pi / 100)\nx <- 0.5 + 0.5 * cos(temp)\ny <- 0.5 + 0.5 * sin(temp)\n\ns <- matrix(runif(700), ncol = 2)\nS <- matrix(NA, 350, 2)\nj <- 0\nsub <- rep(FALSE, 1000)\nfor (i in 1:nrow(s)) {\n  if(sum((s[i,] - 0.5)^2) < 0.23){\n    j <- j+1\n    S[j,] <- s[i,]\n  }\n  if(sum((s[i, ] - c(0.05, 0.18) - 0.5)^2) < 0.07){\n    sub[j] <- TRUE\n  }\n}\n\ncol_blue <- c(\"#569BBD\", \"#569BBDC0\", \"#569BBD80\", \"#569BBD40\")\n\nset.seed(7)\nN <- sample((1:j)[sub], 25)\n\nSS <- (S[N, ] - 0.5) / 2 + 0.5\nthese <- c(2, 5, 7, 12, 15)\n\nx0 <- y0 <- x1 <- y1 <- vector()\n\nfor (i in these){\n  x0[i] <- S[N[i], 1]\n  y0[i] <- S[N[i], 2]\n  x1[i] <- SS[i, 1] + 1 - 0.03\n  y1[i] <- SS[i, 2]\n}\n\npopgrad <- data.frame(x0 = na.omit(x0), \n                      y0 = na.omit(y0), \n                      x1 = na.omit(x1), \n                      y1 = na.omit(y1))\n\nggplot() + geom_path(aes(x,y)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  xlim(0, 2) + ylim(0, 1.1) + \n  geom_point(aes(na.omit(S[,1]), na.omit(S[,2])), \n             color = col_blue[4 - 2 * sub][1:length(na.omit(S[,2]))]) + \n  annotate(geom = 'text', 0.5, 1.07, label  = 'todos os graduados') + \n  geom_path(aes((x - 0.5) * 2 * sqrt(0.07) + 0.55, (y - 0.5) * 2 * sqrt(0.07) + 0.68)) + \n  geom_path(aes((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 + 0.5)) + \n  geom_point(aes(SS[these, 1] + 1, SS[these, 2]), color = 'tomato') + \n  annotate(geom = 'text', 1.5, 0.82, label = 'amostra') + \n  geom_segment(data = popgrad, aes(x = x0, xend = x1, y = y0, yend = y1), \n               arrow = arrow(length = unit(0.2, \"cm\"))) + \n  annotate(geom = 'text', 0.55, 0.5 + 0.08 - sqrt(0.07), label = 'graduados na\\nárea da saúde')\ntemp <- seq(0, 2 * pi, 2 * pi / 100)\nx <- 0.5 + 0.5 * cos(temp)\ny <- 0.5 + 0.5 * sin(temp)\n\ns <- matrix(runif(700), ncol = 2)\nS <- matrix(NA, 350, 2)\nj <- 0\nsub <- rep(FALSE, 1000)\nfor (i in 1:nrow(s)) {\n  if (sum((s[i,] - 0.5)^2) < 0.23) {\n    j <- j + 1\n    S[j, ] <- s[i, ]\n  }\n  if (sum((s[i, ] - c(-0.15, 0.05) - 0.5)^2) < 0.115) {\n    sub[j] <- TRUE\n  }\n}\n\ncol_blue <- c(\"#569BBD\", \"#569BBDC0\", \"#569BBD80\", \"#569BBD40\")\n\nset.seed(7)\nN <- sample((1:j)[sub], 25)\n\nSS <- (S[N, ] - 0.5) / 2 + 0.5\nthese <- c(2, 5, 6, 7, 15)\n\nx0 <- y0 <- x1 <- y1 <- vector()\n\nfor (i in these){\n  x0[i] <- S[N[i], 1]\n  y0[i] <- S[N[i], 2]\n  x1[i] <- SS[i, 1] + 1 - 0.03\n  y1[i] <- SS[i, 2]\n}\n\npopgrad <- data.frame(x0 = na.omit(x0), \n                      y0 = na.omit(y0), \n                      x1 = na.omit(x1), \n                      y1 = na.omit(y1))\n\nggplot() + geom_path(aes(x,y)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  xlim(0, 2) + ylim(0, 1.1) + \n  geom_point(aes(na.omit(S[,1]), na.omit(S[,2])), \n             color = col_blue[4 - 2 * sub][1:length(na.omit(S[,2]))]) + \n  annotate(geom = 'text', 0.5, 1.07, label  = 'população de interesse') + \n  geom_path(aes((x - 0.5) * 2 * sqrt(0.115) + 0.35, (y - 0.5) * 2 * sqrt(0.115) + 0.55)) + \n  geom_path(aes((x - 0.5) / 2 + 1.5, (y - 0.5) / 2 + 0.5)) + \n  geom_point(aes(SS[these, 1] + 1, SS[these, 2]), color = 'tomato') + \n  annotate(geom = 'text', 1.5, 0.82, label = 'amostra') + \n  geom_segment(data = popgrad, aes(x = x0, xend = x1, y = y0, yend = y1), \n               arrow = arrow(length = unit(0.2, \"cm\"))) + \n  annotate(geom = 'text', 0.55, 0.5 + 0.08 - sqrt(0.07), label = 'população realmente\\n amostrada')"},{"path":"ch1-intro.html","id":"explanatoryAndResponse","chapter":"1 Introdução aos Bancos de Dados","heading":"1.3.4 Variáveis explicativas e de resposta","text":"Considere pergunta que foi feita para o conjunto de dados condado na seção 1.2.3:Os gastos federais, em média, são maiores ou menores nos condados com altas taxas de pobreza?Se suspeitarmos que pobreza possa afetar os gastos em um país, então pobreza é variável explanatória e o gasto federal é variável resposta relacionamento.11Dica: Variáveis explicativas e resposta: Para identificar variável explicativa em um par de variáveis, identifique qual das duas é suspeita de afetar outra e planeje uma análise apropriada.Cuidado: associação não implica causalidade: Rotular variáveis como explicativa e resposta não garante que relação entre os dois seja realmente causal, mesmo se houver uma associação identificada entre duas variáveis. Usamos esses rótulos apenas para rastrear qual variável suspeitamos que afeta outra.Em alguns casos, não há variável explicativa ou resposta.Considere seguinte pergunta da seção 1.2.3:Se casa própria menor que média nacional em um município, percentagem de estruturas de várias unidades naquele município provavelmente estará acima ou abaixo da média nacional?É difícil decidir qual dessas variáveis deve ser considerada variável explicativa e resposta, ou seja, direção é ambígua, portanto, nenhum rótulo explicativo ou de resposta é sugerido aqui.","code":""},{"path":"ch1-intro.html","id":"introObservationalExperimentStudies","chapter":"1 Introdução aos Bancos de Dados","heading":"1.3.5 Introduzindo estudos observacionais e experimentos","text":"Existem dois tipos principais de coleta de dados: estudos observacionais e experimentos.Pesquisadores realizam um estudo observacional quando coletam dados de uma maneira que não interfere diretamente na forma como os dados surgem. Por exemplo, os pesquisadores podem coletar informações por meio de pesquisas, revisar registros médicos ou da empresa ou seguir uma coorte de muitos indivíduos semelhantes para estudar por que certas doenças podem se desenvolver. Em cada uma dessas situações, os pesquisadores simplesmente observam os dados que surgem. Em geral, estudos observacionais podem fornecer evidências de uma associação natural entre variáveis, mas não podem, por si só, mostrar uma conexão causal.Quando os pesquisadores querem investigar possibilidade de uma conexão causal, eles conduzem um experimento. Geralmente, haverá uma variável explicativa e uma variável de resposta. Por exemplo, podemos suspeitar que administrar uma droga reduzirá mortalidade em pacientes com ataque cardíaco ano seguinte. Para verificar se existe realmente uma conexão causal entre variável explicativa e resposta, os pesquisadores coletarão uma amostra de indivíduos e os dividirão em grupos. Os indivíduos em cada grupo são atribuídos um tratamento. Quando os indivíduos são aleatoriamente designados para um grupo, o experimento é chamado de experimento aleatório. Por exemplo, cada paciente com ataque cardíaco estudo pode ser aleatoriamente designado, talvez jogando uma moeda, em um dos dois grupos: o primeiro grupo recebe um placebo e o segundo recebe o medicamento. Veja o estudo de caso na Seção 1.1 para outro exemplo de um experimento, embora esse estudo não empregou um placebo.Associação \\(\\neq\\) causa: Em geral, associação não implica causalidade, e causalidade só pode ser inferida partir de um experimento randomizado.","code":""},{"path":"ch1-intro.html","id":"observationalStudiesSamplingStrategies","chapter":"1 Introdução aos Bancos de Dados","heading":"1.4 Estudos observacionais e estratégias de amostragem","text":"","code":""},{"path":"ch1-intro.html","id":"observationalStudies","chapter":"1 Introdução aos Bancos de Dados","heading":"1.4.1 Estudos observacionais","text":"Geralmente, os dados em estudos observacionais são coletados apenas pelo monitoramento que ocorre, enquanto os experimentos exigem que variável explicativa primária em um estudo seja atribuída para cada sujeito pelos pesquisadores.Fazer conclusões causais baseadas em experimentos é geralmente razoável. entanto, fazer mesmas conclusões causais com base em dados observacionais pode ser traiçoeiro e não é recomendado. Assim, estudos observacionais são geralmente suficientes apenas para mostrar associações.Algumas pesquisas anteriores nos dizem que usar protetor solar realmente reduz o risco de câncer de pele, então talvez haja outra variável que pode explicar essa associação hipotética entre uso de filtro solar e câncer de pele. Uma informação importante que está ausente é exposição ao sol. Se alguém está sol o dia todo, ela é mais propensa usar protetor solar e mais chances de ter câncer de pele. exposição ao sol não é contabilizada na simples investigação.exposição ao sol é o que é chamado de variável de confusão13. Que é uma variável correlacionada com variáveis explicativas e respostas. Enquanto um método para justificar tomada de conclusões causais partir de estudos observacionais é exaurir busca por variáveis de confusão, não há garantia de que todas variáveis confusas possam ser examinadas ou medidas.Da mesma forma, o conjunto de dados condado é um estudo observacional com variáveis confundidoras, e seus dados não podem ser facilmente usados para fazer conclusões causais.Prática Orientada 1.8  Figura 1.3 mostra uma associação negativa entre taxa de propriedade e porcentagem de estruturas de múltiplas unidades em um município. entanto, não é razoável concluir que existe uma relação causal entre duas variáveis. Sugira uma ou mais outras variáveis que possam explicar relação visível na Figura 1.3.14Estudos observacionais vêm em duas formas: estudos prospectivos e retrospectivos. Um estudo prospectivo identifica os indivíduos e coleta informações à medida que os eventos se desdobram. Por exemplo, pesquisadores médicos podem identificar e acompanhar um grupo de indivíduos semelhantes durante muitos anos para avaliar possíveis influências comportamento risco de câncer. Um exemplo de tal estudo é Nurses ’Health Study, iniciado em 1976 e expandido em 198915. Este estudo prospectivo recruta enfermeiros registrados e, em seguida, coleta dados deles usando questionários. Estudos retrospectivos coletam dados após os eventos terem ocorrido, por exemplo os pesquisadores podem revisar os eventos passados nos registros médicos. Alguns conjuntos de dados, como condado, podem conter variáveis coletadas prospectiva e retrospectivamente. Os governos locais coletam prospectivamente algumas variáveis à medida que os eventos se desenrolam (por exemplo, vendas de varejo) enquanto o governo federal coletou retrospectivamente outras durante o censo de 2010 (por exemplo, contagem da população condado).","code":"\nvars <- data.frame(xmin = c(5, -2, 11.5),\n                   xmax = c(12, 7, 18.5),\n                   ymin = c(4.3, 2.3, 2.3), \n                   ymax = c(4.7, 2.7, 2.7), \n                   x = c(8.5, 2.5, 15), \n                   y = c(4.5, 2.5, 2.5),\n                   labs = c('exposição ao sol', 'uso do protetor solar', 'câncer de pele'), \n                   size = c(4, 4, 4))\n\narrows <- data.frame(x = c(8, 9, 7.5),\n                     y = c(4.2, 4.2, 2.5),\n                     xend = c(5, 12.5, 10.8),\n                     yend = c(2.8, 2.8, 2.5))\n\n\nggplot(data = vars) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  geom_rect(mapping = aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), \n            alpha = 0.5, color = 'black', fill = 'skyblue3') + \n  annotate(geom = 'text', x = vars$x, y = vars$y, \n           label = paste0(vars$labs), size = vars$size) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), \n        axis.title = element_blank()) +\n  geom_segment(data = arrows, aes(x = x, xend = xend, y = y, yend = yend), \n               arrow = arrow(length = unit(0.1, \"cm\"))) + \n  annotate(geom = 'text', x = 9, y = 2.8, color = 'red', label = '?')"},{"path":"ch1-intro.html","id":"fourSamplingMethods","chapter":"1 Introdução aos Bancos de Dados","heading":"1.4.2 Quatro métodos de amostragem (tópico especial)","text":"Quase todos os métodos estatísticos são baseados na noção de aleatoriedade implícita. Se os dados observacionais não forem coletados em uma estrutura aleatória de uma população, esses métodos estatísticos – estimativas e os erros associados às estimativas – não são confiáveis. Aqui, consideramos quatro técnicas de amostragem aleatória: amostragem simples, estratificada, por conglomerados e de múltiplos estágios. Figuras 1.8 e @ref(fig:clustermultistage} fornecem representações gráficas dessas técnicas.\r\nFigura 1.8: Exemplos de amostragem simples e amostragem estratificada. painel superior, amostragem aleatória simples foi usada para selecionar aleatoriamente os 18 casos. painel inferior, utilizou-se amostragem estratificada: os casos foram agrupados em estratos e, em seguida, amostragem aleatória simples foi feita para cada estrato.\r\namostragem aleatória simples é provavelmente forma mais intuitiva de amostragem aleatória. Considere os salários dos jogadores da Major League Baseball (MLB), onde cada jogador é membro de uma das 30 equipes da liga. Para pegar uma simples amostra aleatória de 120 jogadores de beisebol e seus salários da temporada de 2010, poderíamos escrever os nomes dos 828 jogadores daquela temporada em pedaços de papel, colocar os pedaços de papel num balde, sacudir o balde até termos certeza de que os nomes estão todos misturados, depois escreva os nomes tirados até que tenhamos amostra de 120 jogadores. Em geral, uma amostra é chamada de aleatória simples se cada caso na população tiver uma chance igual de ser incluído na amostra final e saber que um caso é incluído em uma amostra não fornece informações úteis sobre quais outros casos estão incluídos.amostragem Estratificada é uma estratégia de amostragem de ‘divisão e conquista.’ população é dividida em grupos chamados estratos. Os estratos são escolhidos de modo que os casos semelhantes sejam agrupados e, em seguida, um segundo método de amostragem, geralmente amostragem aleatória simples, é empregado dentro de cada estrato. exemplo salário beisebol, equipes poderiam representar os estratos, já que algumas equipes têm muito mais dinheiro (até 4 vezes mais!). Então, podemos aleatoriamente amostrar 4 jogadores de cada equipe para um total de 120 jogadores.amostragem estratificada é especialmente útil quando os casos em cada estrato são muito semelhantes em relação ao resultado de interesse. desvantagem é que analisar dados de uma amostra estratificada é uma tarefa mais complexa que analisar dados de uma amostra aleatória simples. Os métodos de análise introduzidos neste livro precisariam ser estendidos para analisar os dados coletados usando amostragem estratificada.Podemos obter uma estimativa mais estável para subpopulação em um estrato, se os casos forem muito semelhantes. Essas estimativas aprimoradas para cada subpopulação nos ajudarão construir uma estimativa confiável para toda população.Em uma amostragem por conglomerados, nós dividimos população em muitos grupos, chamados clusters. Em seguida, amostramos um número fixo de clusters e incluímos todas observações de cada um desses clusters na amostra. Uma amostra de vários estágios é como uma amostra de cluster, mas em vez de manter todas observações em cada cluster, coletamos uma amostra aleatória em cada cluster selecionado.\r\nFigura 1.9: Exemplos de comglomerados e amostragem de múltiplos estágios. painel superior, foi usada amostragem por conglomerados. Aqui, os dados foram colocados em nove clusters, três desses clusters foram amostrados e todas observações dentro desses três clusters foram incluídas na amostra. painel inferior, foi utilizada amostragem multiestágios. Diferencia-se da amostragem por conglomerados na dos clusters selecionados, selecionamos aleatoriamente um subconjunto de cada cluster ser incluído na amostra.\r\nÀs vezes, amostragem por conglomerados ou em múltiplos estágios pode ser mais econômica que técnicas alternativas de amostragem. Além disso, ao contrário da amostragem estratificada, essas abordagens são mais úteis quando há muita variabilidade caso caso dentro de um cluster, mas os próprios clusters não parecem muito diferentes um outro. Por exemplo, se os bairros representarem clusters, então o cluster ou amostragem multi-estágio funcionará melhor quando os bairros forem muito diversos. Uma desvantagem desses métodos é que técnicas de análise mais avançadas são normalmente necessárias, embora os métodos neste livro possam ser estendidos para lidar com esses dados.Uma simples amostra aleatória provavelmente atrairia indivíduos de todas 30 aldeias, o que poderia tornar coleta de dados extremamente cara. amostragem estratificada seria um desafio, pois não está claro como construiríamos estratos de indivíduos semelhantes. entanto, amostragem por conglomerados ou amostragem em múltiplos estágios parece ser uma boa ideia. Se decidirmos usar amostragem de múltiplos estágios, podemos selecionar aleatoriamente metade das aldeias e, em seguida, selecionar aleatoriamente 10 pessoas de cada uma. Isso provavelmente reduziria nossos custos de coleta de dados substancialmente em comparação uma amostra aleatória simples, e essa abordagem ainda nos forneceria informações confiáveis.","code":"\nset.seed(4)\nN <- 108\nn <- 18\nx   <- runif(N, 0, 2)\ny   <- runif(N)\nthese <- sample(N, n)\n\n# AAS\naas <- ggplot() + \n  geom_point(aes(x, y), color = 'skyblue3') + \n  geom_point(aes(x[these], y[these]), color = 'red') + \n  geom_point(aes(x[these], y[these]), color = 'red', shape = 21, size = 3) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\n#---------------------------------------------------------- Estratificada\n\nX    <- c(0.18, 0.3, 0.68, 1.18, 1.4, 1.74)\nY    <- c(0.2, 0.78, 0.44, 0.7, 0.25, 0.65)\n\nN    <- 1.1*c(15, 12, 35, 22, 13, 28)\nR    <- sqrt(N/500)\n\n\n# poligono, ou os circulos\nauxx <- auxy <- list()\n# pontos \nptx <- pty <- list()\n# pontos vermelhos\nthese <- matrix(NA, ncol = 6, nrow = 3)\n\n\nfor(i in 1:6){\n  hold <- seq(0, 2 * pi, len = 99)\n  \n  auxx[[i]] <- X[i] + (R[i]+0.01)*cos(hold)\n  auxy[[i]] <- Y[i] + (R[i]+0.01)*sin(hold)\n  \n  x <- rep(NA, N[i])\n  y <- rep(NA, N[i])\n  \n  for(j in 1:N[i]){\n    inside <- FALSE\n    while(!inside){\n      xx <- runif(1, -R[i], R[i])\n      yy <- runif(1, -R[i], R[i])\n      if(sqrt(xx^2 + yy^2) < R[i]){\n        inside <- TRUE\n        x[j]   <- xx\n        y[j]   <- yy\n      }\n    }\n  }\n  these[,i]  <- sample(N[i], 3)\n  \n  ptx[[i]]    <- X[i]+x\n  pty[[i]]    <- Y[i]+y\n}\n\nabove <- c(-1, 1, 1, 1, 1, -1)\nlabs <- c('Estrato 1', 'Estrato 2', 'Estrato 3', 'Estrato 4', 'Estrato 5', 'Estrato 6')\n\nstrat <- ggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) + \n  geom_path(aes(auxx[[1]], auxy[[1]])) + \n  geom_path(aes(auxx[[2]], auxy[[2]])) + \n  geom_path(aes(auxx[[3]], auxy[[3]])) + \n  geom_path(aes(auxx[[4]], auxy[[4]])) + \n  geom_path(aes(auxx[[5]], auxy[[5]])) + \n  geom_path(aes(auxx[[6]], auxy[[6]])) + \n  geom_point(aes(ptx[[1]], pty[[1]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[2]], pty[[2]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[3]], pty[[3]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[4]], pty[[4]]), color = 'skyblue3') +\n  geom_point(aes(ptx[[5]], pty[[5]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[6]], pty[[6]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[1]][these[,1]], pty[[1]][these[,1]]), color = 'red') + \n  geom_point(aes(ptx[[2]][these[,2]], pty[[2]][these[,2]]), color = 'red') + \n  geom_point(aes(ptx[[3]][these[,3]], pty[[3]][these[,3]]), color = 'red') + \n  geom_point(aes(ptx[[4]][these[,4]], pty[[4]][these[,4]]), color = 'red') +\n  geom_point(aes(ptx[[5]][these[,5]], pty[[5]][these[,5]]), color = 'red') + \n  geom_point(aes(ptx[[6]][these[,6]], pty[[6]][these[,6]]), color = 'red') +\n  geom_point(aes(ptx[[1]][these[,1]], pty[[1]][these[,1]]), color = 'red', shape = 21, size = 3) + \n  geom_point(aes(ptx[[2]][these[,2]], pty[[2]][these[,2]]), color = 'red', shape = 21, size = 3) + \n  geom_point(aes(ptx[[3]][these[,3]], pty[[3]][these[,3]]), color = 'red', shape = 21, size = 3) + \n  geom_point(aes(ptx[[4]][these[,4]], pty[[4]][these[,4]]), color = 'red', shape = 21, size = 3) +\n  geom_point(aes(ptx[[5]][these[,5]], pty[[5]][these[,5]]), color = 'red', shape = 21, size = 3) + \n  geom_point(aes(ptx[[6]][these[,6]], pty[[6]][these[,6]]), color = 'red', shape = 21, size = 3) + \n  annotate(geom = 'text', x = X, y = Y + above*(R) , label = labs)\n\nrequire(gridExtra)\ngrid.arrange(aas, strat, ncol = 1)\nX    <- c(0.18, 0.3, 0.68, 1.18, 1.4, 1.74, 2.18, 2.41, 2.78)\nY    <- c(0.2, 0.78, 0.44, 0.7, 0.25, 0.65, 0.33, 0.78, 0.4)\n\nN    <- 1.1*c(15, 12, 35, 22, 13, 28, 17, 25, 12)\nR    <- sqrt(N/500)\n\n\n# poligono, ou os circulos\nauxx <- auxy <- list()\n# pontos \nptx <- pty <- list()\n# pontos vermelhos\nthese <- matrix(NA, ncol = length(X), nrow = 3)\n\n\nfor(i in 1:length(X)){\n  hold <- seq(0, 2 * pi, len = 99)\n  \n  auxx[[i]] <- X[i] + (R[i]+0.01)*cos(hold)\n  auxy[[i]] <- Y[i] + (R[i]+0.01)*sin(hold)\n  \n  x <- rep(NA, N[i])\n  y <- rep(NA, N[i])\n  \n  for(j in 1:N[i]){\n    inside <- FALSE\n    while(!inside){\n      xx <- runif(1, -R[i], R[i])\n      yy <- runif(1, -R[i], R[i])\n      if(sqrt(xx^2 + yy^2) < R[i]){\n        inside <- TRUE\n        x[j]   <- xx\n        y[j]   <- yy\n      }\n    }\n  }\n  these[,i]  <- sample(N[i], 3)\n  \n  ptx[[i]]    <- X[i]+x\n  pty[[i]]    <- Y[i]+y\n}\n\nabove <- c(-1, 1, -1, 1, -1, -1, -1, 1, -1)\n\nlabs <- vector()\nfor (i in 1:length(X)){\n  labs[i] <- paste0('Cluster ', i)\n}\n\nclust <- ggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) + \n  geom_path(aes(auxx[[1]], auxy[[1]])) + \n  geom_path(aes(auxx[[2]], auxy[[2]])) + \n  geom_path(aes(auxx[[3]], auxy[[3]]), linetype = 'dashed', color = 'red') + \n  geom_path(aes(auxx[[4]], auxy[[4]]), linetype = 'dashed', color = 'red') + \n  geom_path(aes(auxx[[5]], auxy[[5]])) + \n  geom_path(aes(auxx[[6]], auxy[[6]])) + \n  geom_path(aes(auxx[[7]], auxy[[7]])) + \n  geom_path(aes(auxx[[8]], auxy[[8]]), linetype = 'dashed', color = 'red') + \n  geom_path(aes(auxx[[9]], auxy[[9]])) + \n  geom_point(aes(ptx[[1]], pty[[1]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[2]], pty[[2]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[3]], pty[[3]]), color = 'red') + \n  geom_point(aes(ptx[[3]], pty[[3]]), color = 'red', size = 3, pch = 21) + \n  geom_point(aes(ptx[[4]], pty[[4]]), color = 'red') +\n  geom_point(aes(ptx[[4]], pty[[4]]), color = 'red', size = 3, pch = 21) +\n  geom_point(aes(ptx[[5]], pty[[5]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[6]], pty[[6]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[7]], pty[[7]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[8]], pty[[8]]), color = 'red') + \n  geom_point(aes(ptx[[8]], pty[[8]]), color = 'red', size = 3, pch = 21) + \n  geom_point(aes(ptx[[9]], pty[[9]]), color = 'skyblue3') + \n  annotate(geom = 'text', x = X, y = Y + above*(R) , label = labs)\n\nmult <- ggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) + \n  geom_path(aes(auxx[[1]], auxy[[1]])) + \n  geom_path(aes(auxx[[2]], auxy[[2]])) + \n  geom_path(aes(auxx[[3]], auxy[[3]]), linetype = 'dashed', color = 'red') + \n  geom_path(aes(auxx[[4]], auxy[[4]]), linetype = 'dashed', color = 'red') + \n  geom_path(aes(auxx[[5]], auxy[[5]])) + \n  geom_path(aes(auxx[[6]], auxy[[6]])) + \n  geom_path(aes(auxx[[7]], auxy[[7]])) + \n  geom_path(aes(auxx[[8]], auxy[[8]]), linetype = 'dashed', color = 'red') + \n  geom_path(aes(auxx[[9]], auxy[[9]])) + \n  geom_point(aes(ptx[[1]], pty[[1]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[2]], pty[[2]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[3]], pty[[3]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[3]][these[,3]], pty[[3]][these[,3]]), color = 'red') + \n  geom_point(aes(ptx[[3]][these[,3]], pty[[3]][these[,3]]), color = 'red', size = 3, pch = 21) + \n  geom_point(aes(ptx[[4]], pty[[4]]), color = 'skyblue3') +\n  geom_point(aes(ptx[[4]][these[,4]], pty[[4]][these[,4]]), color = 'red') +\n  geom_point(aes(ptx[[4]][these[,4]], pty[[4]][these[,4]]), color = 'red', size = 3, pch = 21) +\n  geom_point(aes(ptx[[5]], pty[[5]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[6]], pty[[6]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[7]], pty[[7]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[8]], pty[[8]]), color = 'skyblue3') + \n  geom_point(aes(ptx[[8]][these[,8]], pty[[8]][these[,8]]), color = 'red') + \n  geom_point(aes(ptx[[8]][these[,8]], pty[[8]][these[,8]]), color = 'red', size = 3, pch = 21) + \n  geom_point(aes(ptx[[9]], pty[[9]]), color = 'skyblue3') + \n  annotate(geom = 'text', x = X, y = Y + above*(R) , label = labs)\n\nrequire(gridExtra)\ngrid.arrange(clust, mult, ncol = 1)"},{"path":"ch1-intro.html","id":"experimentsSection","chapter":"1 Introdução aos Bancos de Dados","heading":"1.5 Experimentos","text":"Estudos em que os pesquisadores atribuem tratamentos casos são chamados de experimentos. Quando esta tarefa inclui aleatoriedade, por exemplo, usando uma moeda para decidir qual tratamento um paciente recebe, é chamado de experimento aleatório. Experimentos aleatórios são fundamentalmente importantes quando se tenta mostrar uma conexão causal entre duas variáveis.","code":""},{"path":"ch1-intro.html","id":"experimentalDesignPrinciples","chapter":"1 Introdução aos Bancos de Dados","heading":"1.6 Princípios do design experimental","text":"Experimentos randomizados são geralmente construídos em quatro princípios.Controlando: Os pesquisadores atribuem tratamentos aos casos e fazem o melhor que podem para controlar quaisquer outras diferenças nos grupos. Por exemplo, quando os pacientes tomam uma droga em forma de pílula, alguns pacientes tomam pílula com apenas um gole de água enquanto outros tomam com um copo inteiro de água. Para controlar o efeito consumo de água, o médico pode pedir todos os pacientes que bebam um copo de água com pílula.Controlando: Os pesquisadores atribuem tratamentos aos casos e fazem o melhor que podem para controlar quaisquer outras diferenças nos grupos. Por exemplo, quando os pacientes tomam uma droga em forma de pílula, alguns pacientes tomam pílula com apenas um gole de água enquanto outros tomam com um copo inteiro de água. Para controlar o efeito consumo de água, o médico pode pedir todos os pacientes que bebam um copo de água com pílula.Randomização: Pesquisadores randomizam os pacientes em grupos de tratamento para responder por variáveis que não podem ser controladas. Por exemplo, alguns pacientes podem ser mais suscetíveis uma doença que outros devido seus hábitos alimentares. randomização dos pacientes grupo de tratamento ou controle ajuda nivelar essas diferenças e também evita que vieses acidentais entrem estudo.Randomização: Pesquisadores randomizam os pacientes em grupos de tratamento para responder por variáveis que não podem ser controladas. Por exemplo, alguns pacientes podem ser mais suscetíveis uma doença que outros devido seus hábitos alimentares. randomização dos pacientes grupo de tratamento ou controle ajuda nivelar essas diferenças e também evita que vieses acidentais entrem estudo.Replicação: Quanto mais casos os pesquisadores observam, mais precisamente eles podem estimar o efeito da variável explicativa sobre resposta. Em um único estudo, nós replicamos coletando uma amostra suficientemente grande. Além disso, um grupo de cientistas pode replicar um estudo inteiro para verificar uma descoberta anterior.Replicação: Quanto mais casos os pesquisadores observam, mais precisamente eles podem estimar o efeito da variável explicativa sobre resposta. Em um único estudo, nós replicamos coletando uma amostra suficientemente grande. Além disso, um grupo de cientistas pode replicar um estudo inteiro para verificar uma descoberta anterior.Bloqueio: Os pesquisadores às vezes sabem ou suspeitam que variáveis, além tratamento, influenciam resposta. Nestas circunstâncias, eles podem primeiro agrupar os indivíduos com base nesta variável bloqueadora e depois randomiza os casos dentro de cada bloco para os grupos de tratamento. Esta estratégia é frequentemente referida como bloqueio. Por exemplo, se estivermos analisando o efeito de um medicamento nos ataques cardíacos, podemos dividir os pacientes estudo em blocos de baixo risco e alto risco, e então atribuir aleatoriamente metade dos pacientes de cada bloco ao grupo controle e outra metade para o grupo de tratamento, como mostrado na Figura 1.10. Essa estratégia garante que cada grupo de tratamento tenha um número igual de pacientes de baixo risco e alto risco.Bloqueio: Os pesquisadores às vezes sabem ou suspeitam que variáveis, além tratamento, influenciam resposta. Nestas circunstâncias, eles podem primeiro agrupar os indivíduos com base nesta variável bloqueadora e depois randomiza os casos dentro de cada bloco para os grupos de tratamento. Esta estratégia é frequentemente referida como bloqueio. Por exemplo, se estivermos analisando o efeito de um medicamento nos ataques cardíacos, podemos dividir os pacientes estudo em blocos de baixo risco e alto risco, e então atribuir aleatoriamente metade dos pacientes de cada bloco ao grupo controle e outra metade para o grupo de tratamento, como mostrado na Figura 1.10. Essa estratégia garante que cada grupo de tratamento tenha um número igual de pacientes de baixo risco e alto risco.\r\nFigura 1.10: Bloqueio usando uma variável representando risco paciente. Os pacientes são primeiro divididos em blocos de baixo risco e alto risco, em seguida, cada bloco é uniformemente separado nos grupos de tratamento usando randomização. Essa estratégia garante uma representação igual dos pacientes em cada grupo de tratamento, tanto nas categorias de baixo risco quanto de alto risco.\r\nÉ importante incorporar os três primeiros princípios de projeto experimental em qualquer estudo, e este livro descreve os métodos aplicáveis para analisar dados de tais experimentos. O bloqueio é uma técnica um pouco mais avançada, e os métodos estatísticos neste livro podem ser estendidos para analisar os dados coletados usando o bloqueio.","code":"\nslimBox3 <- 0.03\n\n\nn   <- 6 * 9\nset.seed(2)\npat.df <- data.frame(expand.grid(rev(seq(0.3, 0.8, len = 6)), seq(0.1, 0.9, len = 9)), obs = 1:n)\npat.df$pch <- c(1, 21)[sample(2, n, TRUE, c(0.8, 1.2))]\npat.df$col <- ifelse(pat.df$pch == '21', 'red', 'skyblue3')\n\nthese.ctr <- which(pat.df$pch == 21)\n\nx.aux <- y.aux <- vector()\n\nx <- x.aux[1] <- 0.078\ny <- y.aux[1] <- 1.83\n\ncont = 2\n\nfor (i in these.ctr) {\n  \n  x.aux[cont] <- x\n  y.aux[cont] <- y\n  cont = cont + 1\n  \n  if(y < 1.3){\n    x <- x + 0.06\n    y <- 1.83\n  } else {\n    y <- y - 0.11\n  }\n}\n\nthese.hr <- which(pat.df$pch == 1)\nx.aux2 <- y.aux2 <- vector()\n\nx <- x.aux2[1] <- 0.615\ny <- y.aux2[1] <- 1.82\n\ncont = 2\n\nfor (i in these.hr) {\n  x.aux2[cont] <- x\n  y.aux2[cont] <- y\n  cont = cont + 1\n  \n  if(y < 1.3){\n    x <- x + 0.08\n    y <- 1.83\n  } else {\n    y <- y - 0.095\n  }\n}\n\n# --- \n\nctr.br <- sort(sample(1:length(these.ctr), length(these.ctr)/2))\nctr.ar <- sort(sample(1:length(these.hr), length(these.hr)/2))\n\ndf.br <- data.frame(obs = these.ctr[ctr.br], \n                    y = c(rep(c(0.78, 0.68, 0.58), 5), 0.78), \n                    x = sort(rep(unique(x.aux), 3))[-c(17:18)], \n                    obs2 = these.ctr[-ctr.br])\n\ndf.ar <- data.frame(obs = these.hr[ctr.ar], \n                    y = c(rep(c(0.78, 0.68, 0.58), 4)[-12]), \n                    x = sort(rep(unique(x.aux2), 3))[-12], \n                    obs2 = these.hr[-ctr.ar])\n\n\nggplot() + \n  geom_rect(mapping = aes(xmin = 0, xmax = 1, ymin = 2.2, ymax = 2.9)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  annotate(geom = 'text', \n           x = c(0.5, 0.5, 0.2, 0.2+0.55, 0.25, 0.25+0.55), \n           y = c(2.985, 2.07, 2.02, 2.02, 1.08, 1.08), \n           label = c('Pacientes numerados', 'Cria os \\nblocos', 'Pacientes de baixo-risco',\n                     'Pacientes de alto-risco', 'aleatoriamente \\n divide na metade', \n                     'aleatoriamente \\n divide na metade'), size = c(4, 3, 3, 3, 3, 3)) + \n  geom_rect(mapping = aes(xmin = c(0, 0, 0.55, 0, 0), \n                          ymin = c(2.2, 1.2, 1.2, 0.48, 0), \n                          xmax = c(1, 0.45, 1, 1, 1), \n                          ymax = c(2.9, 1.9, 1.9, 0.9, 0.42)), \n            color = 'black', fill = 'white') + \n  geom_segment(aes(x = c(0.56, 0.44, 0.09, 0.12 + 0.55), \n                   y = c(2.17, 2.17, 1.16, 1.16), \n                   xend = c(0.75, 0.25, 0.09, 0.12 + 0.55), \n                   yend = c(2.07, 2.07, 1, 1)),\n               arrow = arrow(length = unit(0.1, \"cm\"))) + \n  geom_rect(mapping = aes(xmin = c(0.02, 0.02, 0.57+slimBox3, 0.57+slimBox3), \n                          ymin = c(0.50, 0.02, 0.5, 0.02), \n                          xmax = c(0.41, 0.41, 0.98, 0.98), ymax = c(0.88, 0.4, 0.88, 0.4)), \n            fill = 'white', color = 'gray') + \n  geom_rect(mapping = aes(xmin = c(-0.05, -0.05), ymin = c(0.39 + 0.47, 0.39), \n                          xmax = c(0.14, 0.14), ymax = c(0.45 + 0.47, 0.45)), \n            color = 'black', fill = 'white') + \n  annotate(geom = 'text', x = c(0.02, 0.04), y = c(0.424 + 0.47, 0.424), \n           label = c('Controle', 'Tratamento'), size = c(3, 3)) + \n  # pacientes\n  geom_point(data = pat.df, mapping = aes(x = Var2, y = Var1 + 2), color = paste0(pat.df$col)) + \n  annotate(geom = 'text', x = pat.df$Var2, y = pat.df$Var1 + 2.06, \n           label = pat.df$obs, size = 2, color = paste0(pat.df$col)) + \n  # low-risk separados\n  geom_point(aes(x.aux, y.aux), color = 'red') + \n  annotate(geom = 'text', x = x.aux[-1], y = y.aux[-1] + 0.05, \n           label = paste0(these.ctr), color = 'red', size = 2) + \n  # high-risk separados\n  geom_point(aes(x.aux2, y.aux2), color = 'skyblue3') + \n  annotate(geom = 'text', x = x.aux2[-1], y = y.aux2[-1] + 0.05, \n           label = paste0(these.hr), color = 'skyblue3', size = 2) + \n  # controle e tratamento para low-risk \n  geom_point(data = df.br, aes(x, y), color = 'red') + \n  annotate(geom = 'text', x = df.br$x, y = df.br$y + 0.05, \n           label = paste0(df.br$obs), color = 'red', size = 2) +\n  geom_point(data = df.br, aes(x, y - 0.48), color = 'red') + \n  annotate(geom = 'text', x = df.br$x, y = df.br$y - 0.42, \n           label = paste0(df.br$obs2), color = 'red', size = 2) + \n  # controle e tratamento para high-risk\n  geom_point(data = df.ar, aes(x + 0.05, y), color = 'skyblue3') + \n  annotate(geom = 'text', x = df.ar$x + 0.05, y = df.ar$y + 0.05, \n           label = paste0(df.ar$obs), color = 'skyblue3', size = 2) +\n  geom_point(data = df.ar, aes(x + 0.05, y - 0.48), color = 'skyblue3') + \n  annotate(geom = 'text', x = df.ar$x + 0.05, y = df.ar$y - 0.42, \n           label = paste0(df.ar$obs2), color = 'skyblue3', size = 2)"},{"path":"ch1-intro.html","id":"biasInHumanExperiments","chapter":"1 Introdução aos Bancos de Dados","heading":"1.6.1 Redução do viés em experimentos em humanos","text":"Experimentos aleatórios são o padrão ouro para coleta de dados, mas não garantem uma perspectiva imparcial sobre relações de causa e efeito em todos os casos. Estudos humanos são exemplos perfeitos onde o preconceito pode surgir involuntariamente. Aqui nós reconsideramos um estudo em que um novo medicamento foi usado para tratar pacientes com ataque cardíaco16. Em particular, os pesquisadores queriam saber se droga reduziu mortes em pacientes.Esses pesquisadores planejaram um experimento aleatório porque queriam tirar conclusões causais sobre o efeito da droga. Os voluntários estudo17 Foram aleatoriamente colocados em dois grupos de estudo. Um grupo, o grupo de tratamento, recebeu o medicamento. O outro grupo, chamado de grupo controle, não recebeu nenhum tratamento medicamentoso.Coloque-se lugar de uma pessoa estudo. Se você estiver grupo de tratamento, receberá uma nova droga que você espera que o ajude. Por outro lado, uma pessoa outro grupo não recebe droga e senta-se à toa, esperando que sua participação não aumente seu risco de morte. Essas perspectivas sugerem que existem dois efeitos: o de interesse é eficácia medicamento e o segundo é um efeito emocional difícil de quantificar.Os pesquisadores geralmente não estão interessados efeito emocional, o que pode influenciar o estudo. Para contornar esse problema, os pesquisadores não querem que os pacientes saibam em que grupo estão. Quando os pesquisadores mantêm os pacientes desinformados sobre seu tratamento, o estudo é considerado como sendo cego. Mas há um problema: se um paciente não receber um tratamento, ele saberá que está grupo de controle. solução para este problema é dar tratamentos falsos aos pacientes grupo controle. Um tratamento falso é chamado de placebo, e um placebo eficaz é chave para tornar um estudo verdadeiramente cego. Um exemplo clássico de placebo é uma pílula de açúcar que é feita para se parecer com pílula de tratamento atual. Muitas vezes, um placebo resulta em uma melhora leve, mas real, nos pacientes. Este efeito foi apelidado de efeito placebo.Os pacientes não são os únicos que devem ser cegados: médicos e pesquisadores podem acidentalmente enviesar um estudo. Quando um médico sabe que um paciente recebeu o tratamento real, ele pode, inadvertidamente, dar mais atenção ou cuidado ao paciente que um paciente que ele sabe que está tomando placebo. Para se proteger contra esse viés, que de novo foi descoberto ter um efeito mensurável em alguns casos, maioria dos estudos modernos emprega configuração duplo-cego onde médicos ou pesquisadores que interagem com pacientes são, assim como os pacientes, inconscientes de quem está ou não recebendo o tratamento18.","code":""},{"path":"ch1-intro.html","id":"numericalData","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7 Examinando dados numéricos","text":"Nesta seção, serão introduzidos técnicas para explorar e resumir variáveis numéricas. Os conjuntos de dados email50 e condado da Seção 1.2 fornecem ricas oportunidades para exemplos. Lembre-se de que os resultados de variáveis numéricas são números nos quais é razoável realizar operações aritméticas básicas. Por exemplo, variável pop2010, que representa populações dos municípios em 2010, é numérica, já que podemos discutir sensivelmente diferença ou proporção das populações em dois municípios. Por outro lado, os códigos de área e CEPs não são numéricos e sim variáveis categóricas.","code":""},{"path":"ch1-intro.html","id":"scatterPlots","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.1 Gráficos de dispersão para dados pareados","text":"Um gráfico de dispersão fornece uma visão caso caso de dados para duas variáveis numéricas. Na Figura 1.2, um gráfico de dispersão foi usado para examinar como os gastos federais e pobreza estavam relacionados conjunto de dados condado. Outro gráfico de dispersão é mostrado na Figura 1.11, comparando o número de quebras de linha e número de caracteres em e-mails para o conjunto de dados email50. Em qualquer gráfico de dispersão, cada ponto representa um único caso. Como há 50 casos em email50, há 50 pontos na Figura 1.11.\r\nFigura 1.11: Um gráfico de dispersão entre variáveis número de quebras de linhas e número de caractéres em emails para o conjunto de dados email50\r\nPara colocar o número de caracteres em perspectiva, este parágrafo possui 363 caracteres. Olhando para Figura 1.11, parece que alguns e-mails são incrivelmente detalhados! Após uma investigação mais aprofundada, descobriríamos que maioria dos e-mails longos usa o formato HTML, o que significa que maioria dos caracteres desses e-mails é usada para formatar o e-mail em vez de fornecer texto.\r\nFigura 1.12: Um gráfico de dispersão de price versus weight para 54 carros.\r\nrelação é evidentemente não-linear, conforme destacado pela linha tracejada. Isso é diferente dos gráficos de dispersão anteriores que vimos, como na Figura 1.2 e Figura 1.11, que mostram relações que são muito lineares.","code":"\nggplot(data = email50, mapping = aes(x = num_char, y = line_breaks)) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Número de Caracteres', y = 'Número de linhas') + \n  geom_point(size = 2, color = 'skyblue3') \ndata(cars)\n\ng <- lm(price ~ weight + I(weight^2),\n        cars,\n        weights = 1/weight^2)\nw <- seq(1000, 5000, 75)\n\nggplot(data = cars) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Peso (em pounds)', y = 'Preço em $1000s)') + \n  geom_point(mapping = aes(x = weight, y = price), size = 2, color = 'skyblue3') + \n  geom_line(aes(x = w, y = predict(g, data.frame(weight = w))), linetype = 'dashed')"},{"path":"ch1-intro.html","id":"dotPlot","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.2 Gráfico de pontos e a média","text":"Às vezes, duas variáveis são demais: apenas uma variável pode ser de interesse. Nesses casos, um gráfico de pontos fornece informações mais básicas. Um gráfico de pontos é um gráfico de dispersão de uma variável. Um exemplo usando o número de caracteres de 50 e-mails é mostrado na Figura 1.13. Uma versão empilhada deste gráfico de pontos é mostrada na Figura 1.14.\r\nFigura 1.13: Um gráfico de pontos da variável número de caracteres para o banco de dados email50\r\n\r\nFigura 1.14: Um gráfico de pontos empilhados número de caracteres para o banco de dados email50.\r\nmédia, é uma maneira comum de medir o centro de uma distribuição de dados. Para encontrar o número médio de caracteres nos 50 e-mails, somamos todas contagens de caracteres e dividimos pelo número de e-mails. Para conveniência computacional, o número de caracteres é listado em milhares e arredondado para o primeiro decimal.\\[\\begin{eqnarray}\r\n\\bar{x} = \\frac{21.7 + 7.0 + \\cdots + 15.8}{50} = 11.6\r\n\\tag{1.1}\r\n\\end{eqnarray}\\]média da amostra é frequentemente rotulada de \\(\\bar{x}\\). letra \\(x\\) está sendo usada como um marcador genérico para variável de interesse, var_char, e barra sobre o \\(x\\) comunica que o número médio de caracteres nos 50 e-mails foi de 11.6. É útil pensar na média como o ponto de equilíbrio da distribuição. média da amostra é mostrada como um ponto vermelho na Figura 1.13 e uma linha pontilhada vermelha na Figura 1.14.Média: média amostral de uma variável numérica é calculada como soma de todas observações divididas pelo número de observações:\\[\\begin{eqnarray}\r\n\\bar{x} = \\frac{x_1+x_2+\\cdots+x_n}{n}\r\n\\tag{1.2}\r\n\\end{eqnarray}\\]onde \\(x_1, x_2, \\dots, x_n\\) representa os \\(n\\) valores observados.Prática Orientada 1.13  O que era \\(n\\) nessa amostra de e-mails?24O conjunto de dados email representa uma amostra de uma população maior de emails recebidos em janeiro e março. Podemos calcular uma média para essa população da mesma maneira que média da amostra. entanto, média populacional tem um rótulo especial: \\(\\mu\\). O símbolo \\(\\mu\\) é letra grega mu e representa média de todas observações na população. Às vezes, um subscrito, como \\(_x\\), é utilizado para representar que variável média populacional se refere, \\(\\mu_x\\).média da amostra, 11.600, pode fornecer uma estimativa razoável de \\(\\mu_x\\). Embora este número não seja perfeito, ele fornece uma estimativa pontual da média da população. Além disso, desenvolveremos ferramentas para caracterizar precisão das estimativas pontuais, e descobriremos que estimativas pontuais baseadas em amostras maiores tendem ser mais precisas que aquelas baseadas em amostras menores.O banco de dados condado é especial, pois cada condado na verdade representa muitas pessoas individuais. Se fôssemos simplesmente fazer média através da variável renda, estaríamos tratando municípios com 5.000 e 5.000.000 residentes igualmente nos cálculos. Em vez disso, devemos calcular renda total de cada município, somar todos os totais dos municípios e dividir pelo número de pessoas em todos os municípios. Se concluíssemos essas etapas com os dados de condado, descobriríamos que renda per capita dos EUA é de $27.348,43. Se tivéssemos calculado média simples de renda per capita entre os países, o resultado teria sido de apenas $ 22.504,70!O Exemplo 1.8 usou o que é chamado de média ponderada, que não será um tópico chave neste livro. entanto, fornecemos um suplemento -line sobre meios ponderados para leitores interessados:","code":"\nggplot(data = email50, aes(x = num_char, y = rep(0, times = nrow(email50)))) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Número de Caracteres', y = NULL) + \n  geom_point(color = 'skyblue3', size = 2) + \n  xlim(0, 70) + ylim(0,1) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_point(aes(x = 11.6, y = 0), color = 'red', size = 2)\nggplot(data = email50, aes(x = num_char)) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Número de Caracteres', y = NULL) + \n  geom_dotplot(fill = 'skyblue3') + \n  xlim(0, 70) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_vline(xintercept = 11.6, linetype = 'dashed', color = 'red')"},{"path":"ch1-intro.html","id":"histogramsAndShape","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.3 Histogramas e forma","text":"Os gráficos de pontos mostram o valor exato de cada observação. Isso é útil para pequenos conjuntos de dados, mas eles podem se tornar difíceis de ler com amostras maiores. Em vez de mostrar o valor de cada observação, preferimos pensar valor como pertencente um intervalo. Por exemplo, conjunto de dados email50, criamos uma tabela de contagens para o número de casos com contagens de caracteres entre 0 e 5.000, depois o número de casos entre 5.000 e 10.000 e assim por diante. Observações que caem limite de um intervalo (por exemplo, 5.000) são alocadas intervalo inferior. Esta tabulação é mostrada na Tabela 1.7. Essas contagens binárias são plotadas como barras na Figura 1.15 que é chamado de histograma, que se assemelha ao gráfico de pontos empilhados mostrado na Figura 1.14.Tabela 1.7: contagens para os dados número de caracteres em forma de intervalos\r\nFigura 1.15: Um histograma da variavel num_char. Esta distribuição é muito fortemente inclinada para direita\r\nHistogramas fornecem uma visão da densidade de dados. Barras mais altas representam onde os dados são relativamente mais comuns. Por exemplo, existem muito mais e-mails com menos de 20.000 caracteres que e-mails com pelo menos 20.000 conjunto de dados. barras facilitam ver como densidade dos dados muda em relação ao número de caracteres.Os histogramas são especialmente convenientes para descrever forma da distribuição. Figura 1.15 mostra que maioria dos e-mails tem um número relativamente pequeno de caracteres, enquanto poucos e-mails têm um número muito grande de caracteres. Quando os dados se arrastam para direita dessa maneira e têm uma maior cauda para direita, forma é dita ser assimétrico direita25.Os conjuntos de dados com característica inversa – uma cauda longa e fina à esquerda – são considerados assimétricos esquerda. Nós também dizemos que tal distribuição tem uma cauda longa e esquerda. Conjuntos de dados que mostram aproximadamente iguais em ambas direções são chamados simétricos.Cauda longa para identificar inclinação: Quando os dados desaparecem em uma direção, distribuição tem uma causa longa.Além de verificar se uma distribuição é assimétrica ou simétrica, os histogramas podem ser usados para identificar modas. Uma moda é representada por um pico proeminente na distribuição.28 Há apenas um pico proeminente histograma de _char.Figura 1.16 mostra histogramas que têm um, dois ou três picos proeminentes. Tais distribuições são chamadas unimodal, bimodal e multimodal, respectivamente. Qualquer distribuição com mais de 2 picos proeminentes é chamada multimodal. Observe que havia um pico proeminente na distribuição unimodal com um segundo pico menos proeminente que não foi contado, uma vez que só difere de seus intervalos vizinhos por algumas observações.\r\nFigura 1.16: Contando apenas picos proeminentes, distribuições são (da esquerda para direita) unimodal, bimodal e multimodal. Note que dissemos que o gráfico da esquerda é unimodal intencionalmente. Isso ocorre porque estamos contando picos proeminentes, e não apenas um pico.\r\n*** {}Procurando por modas: Procurar por modas não é encontrar uma resposta clara e correta sobre o número de modas em uma distribuição, e é por isso que proeminente não é rigorosamente definido neste livro. parte importante deste exame é entender melhor seus dados e como eles podem ser estruturados.","code":"\ncont <- matrix(c('19', '12', '6', '2', '3', '5', '···'··'0''0'1')1'), nr=w1) 1)\nrownames(cont) <- c('contagem')\ncolnames(cont) <- c('0-5', '5-10', '10-15', '15-20', \n                    '20-25', '25-30', '···'··'55-60'60'60-65')5')\n\nknitr::kable(cont , align = 'c', \n              caption = 'As contagens para os dados número de caracteres em forma de intervalos')\nggplot(data = email50, aes(x = num_char)) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Número de Caracteres', y = NULL) + \n  geom_histogram(fill = 'skyblue3', color = 'white', bins = 12) + \n  xlim(0, 70) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())\nset.seed(51)\nx1 <- rchisq(65, 6)\nx2 <- c(rchisq(22, 5.8),\n        rnorm(40, 16.5, 2))\nx3 <- c(rchisq(20, 3),\n        rnorm(35, 12),\n        rnorm(42, 18, 1.5))\n\n\np1 <- ggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  geom_histogram(aes(x = x1), color = 'white', bins = 10, fill = 'skyblue3') + \n  labs(x = NULL, y = NULL)\n\np2 <- ggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  geom_histogram(aes(x = x2), color = 'white', bins = 10, fill = 'skyblue3') + \n  labs(x = NULL, y = NULL)\n\np3 <- ggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  geom_histogram(aes(x = x3), color = 'white', bins = 10, fill = 'skyblue3') + \n  labs(x = NULL, y = NULL)\n\ngrid.arrange(p1, p2, p3, ncol = 3)"},{"path":"ch1-intro.html","id":"variability","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.4 Variância e desvio padrão","text":"média foi introduzida como um método para descrever o centro de um conjunto de dados, variância nos dados também é importante. Aqui, introduzimos duas medidas de variabilidade: variância e o desvio padrão. Ambos são muito úteis na análise de dados, apesar de suas fórmulas serem um pouco tediosas para serem calculadas manualmente. O desvio padrão é o mais fácil dos dois para entender, e descreve aproximadamente o quão longe observação típica é da média.Nós chamamos distância de uma observação de seu desvio médio. Abaixo estão os desvios para o \\(1º\\), \\(2º\\), \\(3º\\), e \\(50º\\) observações na variável num_car. Para conveniência computacional, o número de caracteres é listado em milhares e arredondado para o primeiro decimal.\\[\\begin{align*}\r\nx_1^{}-\\bar{x} &= 21.7 - 11.6 = 10.1 \\hspace{5mm}\\text{ } \\\\\r\nx_2^{}-\\bar{x} &= 7.0 - 11.6 = -4.6 \\\\\r\nx_3^{}-\\bar{x} &= 0.6 - 11.6 = -11.0 \\\\\r\n            &\\ \\vdots \\\\\r\nx_{50}^{}-\\bar{x} &= 15.8 - 11.6 = 4.2\r\n\\end{align*}\\]Se nós levarmos ao quadrado esses desvios e então tomarmos uma média, o resultado é aproximadamente igual ao da amostra, denotado por \\(s_{}^2\\).\\[\\begin{align*}\r\ns_{}^2 &= \\frac{10.1_{}^2 + (-4.6)_{}^2 + (-11.0)_{}^2 + \\cdots + 4.2_{}^2}{50-1} \\\\\r\n    &= \\frac{102.01 + 21.16 + 121.00 + \\cdots + 17.64}{49} \\\\\r\n    &= 172.44\r\n\\end{align*}\\]Nós dividimos por \\(n-1\\), em vez de dividir por \\(n\\) ao calcular variância (você não precisa se preocupar com essa nuance matemática material deste livro). Observe que quadratura dos desvios faz duas coisas. Primeiro, torna grandes valores muito maiores, vistos comparando \\(10.1^2\\), \\((-4.6)^2\\), \\((-11.0)^2\\), e \\(4.2^2\\). Em segundo lugar, elimina quaisquer sinais negativos.O desvio padrão é definido como raiz quadrada da variância:\\[s=\\sqrt{172.44} = 13.13\\]O desvio padrão número de caracteres em um e-mail é de cerca de 13.13 mil. Um subscrito de \\(_x\\) pode ser adicionado à variância e ao desvio padrão, ou seja,\\(s_x^2\\) e \\(s_x^{}\\), como um lembrete de que estas são variância e desvio padrão das observações representadas por \\(x_1^{}, x_2^{}, \\dots, x_n^{}\\). O \\(_{x}\\) subscrito é normalmente omitido quando está claro quais dados variância ou desvio padrão estão referenciando.Variância e o desvio padrão: variância é aproximadamente distância quadrada média da média. O desvio padrão é raiz quadrada da variância. O desvio padrão é útil quando se considera quão próximos os dados estão da média.Fórmulas e métodos usados para calcular variância e o desvio padrão para uma população são semelhantes aos usados para uma amostra31. entanto, como média, os valores da população têm símbolos especiais: \\(\\sigma_{}^2\\) variância populacional e \\(\\sigma\\) para o desvio padrão populacional. O simbolo \\(\\sigma\\) é letra Grega sigma.\r\nFigura 1.17: banco de dados num_char, 41 dos 50 (82%) emails estão dentro de 1 desvio padrão da média, e 47 dos 50 e-mails (94%) estão dentro de 2 desvios padrão. Normalmente, cerca de 70% dos dados estão dentro de 1 desvio padrão da média e 95% estão dentro de 2 desvios padrão, embora essa regra regal seja menos precisa para dados distorcidos, conforme mostrado neste exemplo.\r\nDesvio padrão descreve variabilidade: Concentre-se significado conceitual desvio padrão como um descritor de variabilidade em vez das fórmulas. Normalmente, 70% dos dados estarão dentro de um desvio padrão da média e cerca de 95% estarão dentro de dois desvios padrão. entanto, como visto na Figura 1.17 e na Figura1.18, estas percentagens não são regras restritas.\r\nFigura 1.18: Três distribuições populacionais muito diferentes com mesma média (0) e desvio padrão (1)\r\ndistribuição de contagens de caracteres de e-mails é unimodal e muito inclinada. Muitas das contagens se aproximam da média em 11.600, e maioria cai dentro de um desvio padrão (13.130) da média. Há um e-mail excepcionalmente longo com cerca de 65.000 caracteres.Na prática, variância e o desvio padrão às vezes são usados como um meio para um fim, onde o “fim” é capaz de estimar com precisão incerteza associada uma estatística de amostra. Por exemplo, mais frente usaremos variância e o desvio padrão para avaliar quão próxima média da amostra é da média populacional.","code":"\ns = round(sd(email50$num_char), 1)\nm = round(mean(email50$num_char), 1)\n\nggplot(data = email50, aes(x = num_char, y = rep(0, times = nrow(email50)))) +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Número de Caracteres', y = NULL) + \n  ylim(0,1) + \n  xlim(m-(3*s), 65) + \n  geom_rect(mapping = aes(xmin=m-(3*s), xmax=m+(3*s), ymin=0, ymax=1), \n            fill = \"gray48\", alpha = 0.5) +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_rect(mapping = aes(xmin = m - (2*s), xmax = m + (2*s), ymin = 0, ymax = 1),\n            fill = \"gray28\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m-s, xmax = m + s, ymin=0, ymax=1), \n            fill = \"gray60\") +\n  geom_point(color = 'skyblue3', size = 3) + \n  geom_vline(xintercept = 11.6, color = 'red', linetype = 'dashed') \nx1 <- rep(0:1, c(10,10)); x1 <- (x1-mean(x1))/sd(x1)\nx2 <- qnorm(seq(0.0025,0.9975, 0.00049)); x2 <- (x2-mean(x2))/sd(x2)\nx3 <- qchisq(seq(0.01,0.98, 0.0005), 4); x3 <- (x3-mean(x3))/sd(x3)\n\nm = 0 \ns = 1\n\ng1 <- ggplot() +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = NULL, y = NULL) + \n  xlim(-4, 4) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_rect(mapping = aes(xmin = m - (3*s), xmax = m + (3*s), ymin = 0, ymax = 10), \n            fill = \"gray48\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - (2*s), xmax = m + (2*s), ymin = 0, ymax = 10), \n            fill = \"gray28\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - s, xmax = m + s, ymin = 0, ymax = 10), \n            fill = \"gray60\") +\n  geom_histogram(aes(x = x1), color = 'white', fill = 'skyblue3') +\n  geom_vline(xintercept = m, color = 'red', linetype = 'dashed') \n\n\ng2 <- ggplot() +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = NULL, y = NULL) + \n  xlim(-4, 4) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_rect(mapping = aes(xmin = m - (3*s), xmax = m + (3*s), ymin = 0, ymax = 250), \n            fill = \"gray48\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - (2*s), xmax = m + (2*s), ymin = 0, ymax = 250), \n            fill = \"gray28\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - s, xmax = m + s, ymin = 0, ymax = 250), \n            fill = \"gray60\") +\n  geom_histogram(aes(x = x2), color = 'white', fill = 'skyblue3') +\n  geom_vline(xintercept = m, color = 'red', linetype = 'dashed') \n\ng3 <- ggplot() +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = NULL, y = NULL) + \n  xlim(-4, 4) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_rect(mapping = aes(xmin = m - (3*s), xmax = m + (3*s), ymin = 0, ymax = 250), \n            fill = \"gray48\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - (2*s), xmax = m + (2*s), ymin = 0, ymax = 250), \n            fill = \"gray28\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - s, xmax = m + s, ymin = 0, ymax = 250), \n            fill = \"gray60\") +\n  geom_histogram(aes(x = x3), color = 'white', fill = 'skyblue3') +\n  geom_vline(xintercept = m, color = 'red', linetype = 'dashed') \n\ngrid.arrange(g1, g2, g3, ncol = 1)"},{"path":"ch1-intro.html","id":"boxplotQuantileMedian","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.5 Box-plot, quartis e a mediana","text":"O box-plot resume um conjunto de dados usando cinco estatísticas ao mesmo tempo em que grava observações incomuns. Figura 1.19 fornece um gráfico de pontos vertical ao lado de um box-plot da variável var_char banco de dados email50.\r\nFigura 1.19: Um gráfico de pontos vertical ao lado de uma caixa rotulada para o número de caracteres em 50 emails. mediana (6.890) divide os dados em 50% inferiores e os 50% superiores, marcados gráfico de pontos por traços horizontais e círculos abertos, respectivamente.\r\nO primeiro passo na construção de um box-plot é desenhar uma linha escura indicando mediana, que divide os dados ao meio. Figura 1.19 mostra 50% dos dados caindo abaixo da mediana pontos vermelhos) e outros 50% caindo acima da mediana (pontos azuis). Existem 50 contagens de caracteres conjunto de dados (um número par) para que os dados sejam perfeitamente divididos em dois grupos de 25. Nós tomamos mediana, neste caso, como: \\((\\text{6.768} + \\text{7.012}) / 2 = \\text{6.890}\\). Quando há um número ímpar de observações, haverá exatamente uma observação que divide os dados em duas metades e, nesse caso, observação é mediana (sem necessidade de média).Mediana: o número meio: Se os dados forem ordenados menor para o maior, mediana é observação meio. Se houver um número par de observações, haverá dois valores meio e mediana será considerada como média desses dois valores.O segundo passo na construção de um box-plot é desenhar um retângulo para representar os 50% meio dos dados. O comprimento total da caixa, mostrado verticalmente na Figura 1.19, é chamado de intervalo interquartílico (IQR). Isso, como o desvio padrão, é uma medida de variabilidade dos dados. Quanto mais variáveis os dados, maior o desvio padrão e o IQR. Os dois limites da caixa são chamados de primeiro quartil (Q1) (o 25 percentil, ou seja, 25% dos dados ficam abaixo desse valor) e o terceiro quartil (Q3) (O 75 percentil, 75% dos dados ficam abaixo desse valor), e estes são frequentemente rotulados \\(Q_1\\) e \\(Q_3\\), respectivamente.Intervalo Interquartílico (IQR): O IQR é o comprimento da caixa em um box-plot. É calculado como\\[\\begin{eqnarray*}\r\nIQR = Q_3 - Q_1\r\n\\end{eqnarray*}\\]\r\nonde \\(Q_1\\) e \\(Q_3\\) são os 25 e 75 percentis.}Estendendo-se para fora da caixa, linhas verticais tentam capturar os dados fora da caixa, entanto, nunca é permitido que seu alcance seja superior \\(1.5\\times IQR\\)34. Eles capturam tudo dentro desse alcance. Na Figura 1.19, linha vertical superior não se estende até os últimos três pontos, o que está além de \\(Q_3 + 1.5\\times IQR\\), e assim se estende apenas até o último ponto abaixo desse limite. linha vertical inferior para valor mais baixo, uma vez que não há dados adicionais para alcançar. O limite inferior não é mostrado na figura porque o gráfico não se estende até \\(Q_1 - 1,5\\times IQR\\). Em certo sentido, caixa é como o corpo da caixa e linhas verticais são como seus braços tentando alcançar o resto dos dados.Qualquer observação que esteja além dessas linhas verticais é rotulada com um ponto. O objetivo de rotular esses pontos - em vez de apenas estender linhas aos valores mínimo e máximo observados - é ajudar identificar quaisquer observações que pareçam estar distantes resto dos dados. Observações anormalmente distantes são chamadas de outliers. Nesse caso, seria razoável classificar os e-mails com contagens de caracteres de 41.623, 42.793 e 64.401 como outliers, uma vez que estão numericamente distantes da maioria dos dados.Outliers são extremos: Um outlier é uma observação que parece extrema em relação ao resto dos dados.Por que é importante procurar outliers: O exame de dados para possíveis outliers serve muitos propósitos úteis, incluindo:Identificando forte inclinação na distribuição.Identificando forte inclinação na distribuição.Identificar na coleta de dados erros de entrada. Por exemplo, reexaminamos o email supostamente com 64.401 caracteres para garantir que esse valor é preciso.Identificar na coleta de dados erros de entrada. Por exemplo, reexaminamos o email supostamente com 64.401 caracteres para garantir que esse valor é preciso.Fornecendo informações sobre propriedades interessantes dos dados.Fornecendo informações sobre propriedades interessantes dos dados.","code":"\nquants <- as.numeric(quantile(email50$num_char, probs = c(0.25, 0.50, 0.75)))\nquants <- c(quants, sort(email50$num_char)[48:50])\n\n\nggplot(data = email50, aes(y = num_char)) +\n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + \n  labs(x = NULL, y = 'Número de caracteres') + \n  xlim(-0.6,0.6) +\n  geom_boxplot() + \n  geom_point(aes(x = rep(-0.4, times = nrow(email50)), y = num_char), \n             color = ifelse(email50$num_char > median(email50$num_char), \n                            'skyblue3', 'red')) + \n  annotate(geom = \"text\", x = rep(0.55, 6), y = c(quants[1:3], 50, 0, 30), \n           label = c('Q1', \"mediana\", 'Q3', 'Possíveis \\nOutliers', \n                     'Q1 - 1.5 x IQR', 'Q3 + 1.5 x IQR'), size = 3) +\n  geom_segment(aes(x = 0.48, xend = 0.4, y = quants[1], yend = quants[1]),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") +\n  geom_segment(aes(x = 0.48, xend = 0.4, y = quants[2], yend = quants[2]),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") +\n  geom_segment(aes(x = 0.48, xend = 0.4, y = quants[3], yend = quants[3]),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") + \n  geom_segment(aes(x = 0.48, xend = 0.03, y = 50, yend = quants[4]),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") + \n  geom_segment(aes(x = 0.48, xend = 0.03, y = 50, yend = quants[5]),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") +\n  geom_segment(aes(x = 0.48, xend = 0.03, y = 50, yend = quants[6]),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") +\n  geom_segment(aes(x = 0.45, xend = 0.03, y = 0, yend = 0),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\") +\n  geom_segment(aes(x = 0.45, xend = 0.03, y = 30, yend = 30),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"skyblue3\")"},{"path":"ch1-intro.html","id":"statisticsRobust","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.6 Estatísticas robustas","text":"Como estatísticas da amostra conjunto de dados num_char são afetados pela observação 64.401? O que teria acontecido se este email não fosse observado? O que aconteceria com estas estatísticas se observação 64.401 fosse ainda maior, digamos 150.000? Esses cenários são plotados ao lado dos dados originais na Figura 1.20, e estatísticas de amostra são computadas em cada cenário na Tabela 1.8.\r\nFigura 1.20: Gráficos de pontos dos dados de contagem de caracteres originais e dois conjuntos de dados modificados.\r\nTabela 1.8: Uma comparação de como mediana, IQR, média, e desvio padrão muda quando observações extremas estiverem presentes.Prática Orientada 1.22  () Qual é mais afetado por observações extremas, média ou mediana? Tabela 1.8 pode ser útil.O desvio padrão ou IQR é mais afetado por observações extremas?37\r\nmediana e o IQR são chamados de estimativas robustas porque observações extremas têm pouco efeito sobre seus valores. média e o desvio padrão são muito mais afetados pelas mudanças nas observações extremas.mediana e o IQR são sensíveis apenas números próximos de \\(Q_1\\), mediana e \\(Q_3\\). Como os valores nessas regiões são relativamente estáveis - não há grandes saltos entre observações - mediana e estimativas de IQR também são bastante estáveis.","code":"\nn1<- email50$num_char\nn2 <- email50$num_char; n2[11] <- -1\nn3 <- email50$num_char; n3[11] <- 150\n\nggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_point(aes(x = n1, y = rep(0.1, length(n1))), color = 'skyblue3') + \n  geom_point(aes(x = n2, y = rep(0.05, length(n2))), color = 'tomato') + \n  geom_point(aes(x = n3, y = rep(0, length(n3))), color = 'green') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  labs(x = NULL, y = NULL) + \n  xlim(0, 150)\ntable7 <- rbind(c(quantile(n1, probs = 0.5), \n                  quantile(n1, probs = 0.75) -  quantile(n1, probs = 0.25), \n                  mean(n1), sd(n1)),\n                c(quantile(n2[-11], probs = 0.5), \n                  quantile(n2[-11], probs = 0.75) -  quantile(n2[-11], probs = 0.25), \n                  mean(n2[-11]), sd(n2[-11])),\n                c(quantile(n3, probs = 0.5), \n                  quantile(n3, probs = 0.75) -  quantile(n3, probs = 0.25), \n                  mean(n3), sd(n3)))\n\ncolnames(table7) <- c('Mediana', 'IQR', 'Média', 'Desvio Padrão')\nrownames(table7) <- c('Original (Azul)', \n                      'Sem o dado 64.401 (Vermelho)', \n                      '150.000 no lugar de 64.401 (Verde)')\n\nknitr::kable(table7, align = 'c', \n             caption = 'Uma comparação de como a mediana, IQR, média, e desvio padrão muda quando observações extremas estiverem presentes.')"},{"path":"ch1-intro.html","id":"transformingDataSubsection","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.7 Transformando dados (tópico especial)","text":"Quando os dados são muito distorcidos, vezes os transformamos para que sejam mais fáceis de modelar. Considere o histograma dos salários dos jogadores de beisebol da Major League de 2010, que é mostrado na Figura 1.21.\r\nFigura 1.21: Histograma dos salários dos jogadores da MLB em 2010, em milhões de dólares\r\n\r\nFigura 1.22: Histograma dos salários dos jogadores da MLB transformados em log para 2010.\r\nmaioria dos dados é coletada em um compartimento histograma e os dados são tão distorcidos que muitos detalhes nos dados são obscurecidos.Existem algumas transformações padrão que são geralmente aplicadas quando grande parte cluster de dados está próximo de zero (em relação aos valores maiores conjunto de dados) e todas observações são positivas. transformação é um reescalonamento dos dados usando uma função. Por exemplo, uma plotagem logaritmo natural39 dos salários dos jogadores resulta em um novo histograma na Figura 1.22. Às vezes, é mais fácil trabalhar com dados transformados ao aplicar modelos estatísticos, pois os dados transformados são muito menos distorcidos e os outliers são geralmente menos extremos.Transformações também podem ser aplicadas uma ou ambas variáveis em um gráfico de dispersão. Um gráfico de dispersão das variáveis quebra_linha e num_char é mostrado na Figura 1.23, que foi mostrado anteriormente na Figura 1.11. Podemos ver uma associação positiva entre variáveis e que muitas observações são agrupadas perto de zero. Mais frente podemos querer usar uma linha reta para modelar os dados. entanto, descobriremos que os dados em seu estado atual não podem ser modelados muito bem.\r\nFigura 1.23: Gráfico de dispersão de quebra de linha contra número de caracteres para 50 emails\r\nFigura 1.24 mostra um gráfico de dispersão onde ambas variáveis foram transformadas usando uma transformação log (base \\(e\\)). Embora haja uma associação positiva em cada parcela, os dados transformados mostram uma tendência mais estável, que é mais fácil de modelar que os dados não transformados.\r\nFigura 1.24: Um gráfico de dispersão dos mesmos dados, mas em que cada variável foi transformada em log.\r\nTransformações além logaritmo podem ser úteis também. Por exemplo, raiz quadrada (\\(\\sqrt{\\text{observação original}}\\)) e inversa (\\(\\frac{1}{\\text{observação original}}\\)) são usados por estatísticos. Os objetivos comuns na transformação de dados são ver estrutura de dados de maneira diferente, reduzir distorção, auxiliar na modelagem ou endireitar um relacionamento não linear em um gráfico de dispersão.","code":"\ndata(MLB)\n\nggplot(data = MLB) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_histogram(aes(salary/1000), fill = 'skyblue3', color = 'white') + \n  labs(x = 'Salário (em milhões de dólares)', y = NULL)\nggplot(data = MLB) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_histogram(aes(log(salary/1000)), fill = 'skyblue3', color = 'white') + \n  labs(x = 'log(Salário) (em milhões de dólares)', y = NULL)\nggplot(data = email50) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  labs(x = 'Número de Caracteres', y = 'Quebra de Linhas') + \n  geom_point(aes(x = num_char, y = line_breaks), color = 'skyblue3')\nggplot(data = email50) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  labs(x = 'log(Número de Caracteres)', y = 'log(Quebra de Linhas)') + \n  geom_point(aes(x = log(num_char), y = log(line_breaks)), color = 'skyblue3')"},{"path":"ch1-intro.html","id":"mapingDataSubsection","chapter":"1 Introdução aos Bancos de Dados","heading":"1.7.8 Mapeamento de dados (tópico especial)}","text":"O banco de dados condado oferece muitas variáveis numéricas que poderíamos plotar usando gráficos de pontos, gráficos de dispersão ou box-plots, mas eles perdem verdadeira natureza dos dados. Em vez disso, quando nos deparamos com dados\r\ngeográficos, devemos mapeá-lo usando um mapa de intensidade, onde cores são usadas para mostrar valores mais altos e maisbaixos de uma variável. Figuras 1.25, 1.26, 1.27 e 1.28 mostram mapas de intensidade para gastos federais per capita (var_fed), taxa de pobreza em porcentagem (poverty), taxa de casa própria em porcentagem (homeownership), e renda familiar mediana (med_income). paleta colorida indica quais cores correspondem \r\nquais valores. Observe que os mapas de intensidade geralmente não são muito úteis para obter valores precisos em nenhum estado, mas são muito úteis para ver tendências geográficas e gerar interessantes perguntas de pesquisa.\r\nFigura 1.25: Mapa dos gastos federais (dólares per capita)\r\n\r\nFigura 1.26: Mapa de intensidade da taxa de pobreza (por cento).\r\n\r\nFigura 1.27: Mapa de intensidade da taxa de propriedade (por cento).\r\n\r\nFigura 1.28: Mapa de intensidade da renda familiar média ($1000s).\r\nO mapa de intensidade de gasto federal mostra gastos substanciais nas Dakotas e ao longo da parte central oeste da fronteira canadense, o que pode estar relacionado ao boom petróleo nesta região. Há várias outras parcelas de gastos federais, como uma faixa vertical leste de Utah e Arizona e área onde o Colorado, Nebraska e Kansas se encontram. Há também condados aparentemente aleatórios com gastos federais muito altos em relação aos seus vizinhos. Se não limitássemos o gasto federal em $18 per capita, descobriríamos que alguns municípios têm gastos federais extremamente altos, enquanto quase não há gastos federais nos municípios vizinhos. Esses municípios de alto gasto podem conter bases militares, empresas com grandes contratos governamentais ou outras instalações governamentais com muitos funcionários.taxas de pobreza são evidentemente mais altas em alguns locais. Notavelmente, o sul mostra taxas de pobreza mais altas, assim como fronteira sudoeste Texas. faixa vertical leste de Utah e Arizona, mencionada acima por seus gastos federais mais altos, também parece ter taxas mais altas de pobreza (embora geralmente seja observada pouca relação entre duas variáveis). Altos índices de pobreza são evidentes nas planícies aluviais Mississipi, um pouco ao norte de Nova Orleans e também em uma grande parte de Kentucky e West Virginia.","code":"\nknitr::include_graphics('images/c1/countyFedSpendMap.png')\nknitr::include_graphics('images/c1/countyPovertyMap.png')\nknitr::include_graphics('images/c1/countyMedIncomeMap.png')\nknitr::include_graphics('images/c1/countyHomeownershipMap.png')"},{"path":"ch1-intro.html","id":"categoricalData","chapter":"1 Introdução aos Bancos de Dados","heading":"1.8 Considerando dados categóricos","text":"Como os dados numéricos, os dados categóricos também podem ser organizados e analisados. Nesta seção, apresentaremos tabelas e outras ferramentas básicas para dados categóricos que são usadas neste livro. O conjunto de dados email50 representa uma amostra de um conjunto de dados de e-mail maior chamado email. Este conjunto de dados maior contém informações sobre 3.921 e-mails. Nesta seção, examinaremos se presença de números, pequenos ou grandes, em um e-mail fornece qualquer valor útil na classificação de e-mail como spam ou não spam.","code":""},{"path":"ch1-intro.html","id":"tablesBarGraphics","chapter":"1 Introdução aos Bancos de Dados","heading":"1.8.1 Tabelas de Contingência e Gráficos de Barras","text":"Tabela 1.9 resume duas variáveis: spam e número. Lembre-se de que número é uma variável categórica que descreve se um email não contém números, apenas números pequenos (valores abaixo de 1 milhão) ou pelo menos um número grande (um valor de 1 milhão ou mais). Uma tabela que resume dados para duas variáveis categóricas dessa maneira é chamada de tabela de contingência. Cada valor na tabela representa o número de vezes que uma combinação específica de resultados de variáveis ocorreu. Por exemplo, o valor 149 corresponde ao número de e-mails conjunto de dados que são spam e não tinham nenhum número listado e-mail. Os totais de linha e coluna também estão incluídos. O termo totais da linha fornece contagens totais em cada linha (por ex.\\(149 + 168 + 50 = 367\\)), e os totais da coluna são totais contagens abaixo de cada coluna.Uma tabela para uma única variável é chamada de tabela de frequência. Tabela 1.10 é uma tabela de frequência para variável número. Se substituíssemos contagens por porcentagens ou proporções, tabela seria chamada de tabela de frequência relativa.Tabela 1.9: Uma tabela de contingência para spam e número.Tabela 1.10: Uma tabela de frequências para variável númeroUm gráfico de barras é uma maneira comum de exibir uma única variável categórica. O painel esquerdo da Figura 1.29 mostra um gráfico de barras para variável número. gráfico da direita, contagens são convertidas em proporções (por ex. \\(549/3921=0.140\\) para nenhum), mostrando proporção de observações que estão em cada nível (ou seja, em cada categoria).\r\nFigura 1.29: Dois gráficos de barras para variável número. O gráfico da esquerda mostra contagens e o gráfico da direita mostra proporções em cada grupo.\r\n","code":"\ndata(email)\n\ntable7 <- addmargins(table(email$spam, email$number))\ncolnames(table7) <- c('Nenhum', 'Pequeno', 'Grande', 'Total')\nrownames(table7) <- c('Não Spam', 'Spam', 'Total')\n\nknitr::kable(table7, align = 'c',\n             caption = 'Uma tabela de contingência para spam e número.')\ntable8 <- addmargins(t(table(email$number)))[1,]\nnames(table8) <- c('Nenhum', 'Pequeno', 'Grande', 'Total')\n\nknitr::kable(t(table8), align = 'c', \n             caption = 'Uma tabela de frequências para a variável número')\nbar1 <- ggplot(email) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_bar(aes(x = number), fill = 'skyblue3') + labs(x = 'Number', y = 'Contagem')\n\nbar2 <- ggplot(data.frame(table(email$number)/nrow(email))) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_bar(aes(x = Var1, y = Freq), stat = 'identity', fill = 'skyblue3') + \n  labs(x = 'Number', y = 'Proporção')\n\ngrid.arrange(bar1, bar2, ncol = 2)"},{"path":"ch1-intro.html","id":"rowColumnProportion","chapter":"1 Introdução aos Bancos de Dados","heading":"1.8.2 Proporções de linha e coluna","text":"Tabela 1.11 mostra proporções de linha para Tabela 1.9. proporções de linha são computadas como contagens divididas por seus totais de linha. O valor 149 na interseção de spam e nenhum é substituído por \\(149/367=0.406\\), isto é, 149 dividido por seu total de linhas, 367. Então, o que 0.406 representa? Corresponde à proporção de e-mails de spam na amostra que não inclui números na mensagem.Tabela 1.11: Uma tabela de contingência com proporções de linha para variáveis spam e númeroUma tabela de contingência das proporções da coluna é calculada de forma semelhante, onde cada proporção da coluna é calculada como contagem dividida pelo total da coluna correspondente. Tabela 1.12 mostra tal tabela, e aqui o valor 0.271 indica que 27,1% de emails sem números eram spam. Essa taxa de spam é muito maior em comparação e-mails com apenas números pequenos (5,9%) ou grandes números (9,2%). Porque essas taxas de spam variam entre os três níveis de número (nenhum, pequeno, grande), isso fornece evidências de que variáveis spam e número estão associadas.Tabela 1.12: Uma tabela de contingência com proporções de coluna para variáveis spam e númeroTambém poderíamos ter verificado uma associação entre spam e número na Tabela 1.11 usando proporção de colunas. Ao comparar essas proporções de linha, analisamos colunas para ver se fração de emails sem números, números pequenos e números grandes variava de spam à não~spam.Essa pessoa estaria interessada em saber como proporção de spam é alterada em cada formato de email. Isso corresponde proporções de coluna: proporção de spam em emails de texto sem formatação e proporção de spam em emails HTML.Se gerarmos proporções da coluna, poderemos ver que uma fração maior de e-mails de texto sem formatação é spam (\\(209/1195 = 17.5\\%\\)) que em comparação com e-mails em HTML (\\(158/2726 = 5.8\\%\\)). Esta informação por si só é insuficiente para classificar um email como spam ou não spam, pois mais de 80% dos emails com texto simples não são spam. entanto, quando combinamos cuidadosamente essas informações com muitas outras características, como número e outras variáveis, temos uma chance razoável de sermos capazes de classificar alguns e-mails como spam ou não spam.Tabela 1.13: Uma tabela de contingência para spam e format.O Exemplo 1.13 aponta que proporções de linha e coluna não são equivalentes. Antes de escolher um formulário para uma tabela, é importante considerar cada um para garantir que tabela mais útil seja construída.","code":"\ntable9 <- table7\n\nfor(i in 1:3) table9[i,] <- table9[i,]/table9[i,4]\n\nknitr::kable(table9, align = 'c', digits = 3,  \n             caption = 'Uma tabela de contingência com proporções de linha para as variáveis spam e número')\ntable10 <- table7\nfor (i in 1:4) table10[,i] <- table10[,i]/table10[3,i]\n\nknitr::kable(table10, align = 'c', digits = 3,  \n             caption = 'Uma tabela de contingência com proporções de coluna para as variáveis spam e número')\ntable11 <- addmargins(table(email$spam, email$format))\ncolnames(table11) <- c('texto', 'HTML', 'Total')\nrownames(table11) <- c('Não Spam', 'Spam', 'Total')\n\nknitr::kable(table11, align = 'c', \n             caption = 'Uma tabela de contingência para spam e format.')"},{"path":"ch1-intro.html","id":"segmentedBarPlotsAndIndependence","chapter":"1 Introdução aos Bancos de Dados","heading":"1.8.3 Barras segmentadas e mosaicos","text":"Tabelas de contingência que usam proporções de linha ou coluna são especialmente úteis para examinar como duas variáveis categóricas estão relacionadas. Barras segmentadas e gráficos de mosaico fornecem uma maneira de visualizar informações nessas tabelas.Um gráfico de barras segmentadas é uma exibição gráfica das informações da tabela de contingência. Por exemplo, um gráfico de barras segmentado representado na Tabela 1.12 é mostrado na Figura 1.30, onde criamos primeiro um gráfico de barras usando variável número e depois dividimos cada grupo pelos níveis de spam. proporções da coluna da Tabela 1.12 foram traduzidos em um gráfico de barras segmentadas padronizadas na Figura 1.30, que é uma visualização útil da fração de e-mails de spam em cada nível de número.\r\nFigura 1.30: () Gráficos de barras segmentadas para números encontrados em emails, onde contagens foram divididas pela variável spam e (b) Versão normalizada\r\nPela Figura 1.30, o primeiro gráfico contém mais informações, mas o segundo apresenta informação mais claramente. Este segundo gráfico deixa claro que e-mails sem número têm uma taxa relativamente alta de e-mail de spam – cerca de 27%! Por outro lado, menos de 10% de e-mail com números pequenos ou grandes são spam.Como proporção de spam é alterada entre os grupos na segundo gráfico, Podemos concluir que variáveis são dependentes, o que é algo que também conseguimos discernir usando proporções de tabela. Porque tanto o grupo nenhum quanto o grupo grande têm relativamente poucas observações em comparação com o grupo pequeno, associação é mais difícil de ver na Figura 1.30.Em alguns outros casos, um gráfico de barras segmentado que não seja padronizado será mais útil na comunicação de informações importantes. Antes de estabelecer um gráfico de barras segmentado específico, crie formulários padronizados e não padronizados e decida qual deles é mais eficaz na comunicação de características dos dados.\r\nFigura 1.31: () O mosaico de uma variável para número e (b) o mosaico de duas variáveis para ambos número e spam.\r\nUm gráfico de mosaico é uma exibição gráfica de informações da tabela de contingência que é semelhante um gráfico de barras para uma variável ou um gráfico de barras segmentadas ao usar duas variáveis. O primeiro plot da Figura 1.31 mostra um gráfico de mosaico para variável número. Cada coluna representa um nível de número, e larguras das colunas correspondem à proporção de e-mails para cada tipo de número. Por exemplo, há menos e-mails sem números que e-mails com apenas números pequenos, portanto coluna de e-mails não numerados é menor. Em geral, os gráficos de mosaico usam áreas para representar o número de observações que caixa representa.Esta plotagem em mosaico de uma variável é dividida em partes na segunda figura usando variável spam. Cada coluna é dividida proporcionalmente de acordo com fração de e-mails que eram spam em cada categoria de número. Por exemplo, segunda coluna, representando e-mails com apenas números pequenos, foi dividida em e-mails que eram spam e não spam.Como outro exemplo, terceira coluna representa e-mails de spam que tinham números grandes, e parte superior da terceira coluna representa e-mails regulares que tinham números grandes. Podemos novamente usar este gráfico para ver que variáveis spam e número estão associadas, pois algumas colunas são divididas em diferentes localizações verticais que outras, que é mesma técnica usada para verificar uma associação na versão padronizada gráfico de barras segmentadas.\r\nFigura 1.32: Gráfico em que os e-mails são agrupados pela variável número depois de terem sido divididos em spam e não spam.\r\nDe forma semelhante, um mosaico representando proporções da Tabela 1.9 poderia ser construído, como mostrado na Figura 1.32. entanto, como é mais perspicaz para esse aplicativo considerar fração de spam em cada categoria da variável número, preferimos Figura 1.31.","code":"\nbar1 <- ggplot(email) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_bar(aes(x = number, fill = as.factor(spam))) + \n  labs(x = '(a)', y = NULL, fill = 'Spam') \n\n\ntemp = table(email$spam, email$number)\nfor (i in 1:3){\n  temp[,i] <- temp[,i]/apply(temp, 2, sum)[i]\n}\n\nbar2 <- ggplot(data.frame(data.frame(temp))) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_bar(aes(x = Var2, y = Freq, fill = as.factor(Var1)), stat = 'identity') + \n  labs(x = '(b)', y = NULL, fill = 'Spam')\n\ngrid.arrange(bar1, bar2, ncol = 2)\nrequire(ggmosaic)\n\nbar1 <- ggplot(email) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_mosaic(aes(x = product(number), fill = number)) +\n  theme(legend.position = 'none') + \n  labs(x = '(a)', y = NULL) + \n  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank())\n\n\ntemp = table(email$spam, email$number)\nfor (i in 1:3){\n  temp[,i] <- temp[,i]/apply(temp, 2, sum)[i]\n}\n\nlibrary(ggmosaic)\ntemp = data.frame(data.frame(temp))\ntemp$Var1 <- ifelse(temp$Var1 == '0', 'Não é Spam', 'Spam')\n\nbar2 <- ggplot(data = temp) +\n  geom_mosaic(aes(weight = Freq, x = product(Var2), fill = factor(Var1))) +\n  theme(legend.position = 'none') + \n  labs(x = '(b)', y = NULL) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(bar1, bar2, ncol = 2)\nggplot(data = temp) +\n  geom_mosaic(aes(weight = Freq, x = product(Var1), fill = factor(Var2))) +\n  theme(legend.position = 'none') + \n  labs(x = NULL, y = NULL) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1))"},{"path":"ch1-intro.html","id":"onlyPizzaGraph","chapter":"1 Introdução aos Bancos de Dados","heading":"1.8.4 O único gráfico de pizza que você verá nesta apostila","text":"Embora os gráficos de pizza sejam bem conhecidos, eles normalmente não são tão úteis quanto outros gráficos em uma análise de dados. Um gráfico de pizza é mostrado na Figura 1.33 ao lado de um gráfico de barra. Geralmente, é mais difícil comparar tamanhos de grupos em um gráfico de pizza que em um gráfico de barras, especialmente quando categorias têm contagens ou proporções quase idênticas. caso das categorias nenhum e grande, diferença é tão pequena que você pode ser incapaz de distinguir qualquer diferença nos tamanhos dos grupos para ambos os gráficos!\r\nFigura 1.33: Um gráfico de pizza e um gráfico de barras de número para o conjunto de dados email.\r\n","code":"\nbar2 <- ggplot(email) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(legend.position = 'none') + \n  labs(x = NULL, y = NULL) + \n  geom_bar(aes(x = number, fill = number)) \n\n\nbar1 <-  ggplot(data.frame(table(email$number)/nrow(email)), \n                aes(x = \"\", y = Freq, fill = Var1)) + \n  geom_bar(width = 1, stat = \"identity\", color = \"white\") +\n  coord_polar(\"y\", start = 0) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(legend.position = 'bottom') + \n  labs(x = NULL, y = NULL, fill = 'número') + \n  theme(axis.text = element_blank())\n\ngrid.arrange(bar1, bar2, ncol = 2)"},{"path":"ch1-intro.html","id":"comparingAcrossGroups","chapter":"1 Introdução aos Bancos de Dados","heading":"1.8.5 Comparando dados numéricos entre grupos","text":"Algumas das investigações mais interessantes podem ser consideradas examinando dados numéricos entre grupos. Os métodos necessários aqui não são realmente novos. Tudo o que é necessário é fazer um gráfico numérico para cada grupo. Aqui dois métodos convenientes são introduzidos: box-plot lado lado e histogramas.Vamos dar uma olhada novamente conjunto de dados condado e comparar renda familiar média para os municípios, em comparação com os municípios que não tiveram ganho. Embora possamos gostar de estabelecer uma conexão causal aqui, lembre-se de que esses dados são observacionais e, portanto, tal interpretação seria injustificada.Havia 2.041 municípios, onde população aumentou de 2000 2010, e havia 1.099 municípios sem ganho (todos, exceto um, foram uma perda). Uma amostra aleatória de 100 municípios primeiro grupo e 50 segundo grupo são mostrados na Tabela 1.14 para dar uma melhor noção de alguns dos dados brutos.Tabela 1.14: Nesta tabela, renda familiar média (em $1000s) de uma amostra aleatória de 100 municípios que ganharam população entre 2000-2010. Rendimentos médios de uma amostra aleatória de 50 municípios que não tiveram ganho de população são mostrados tambémO box-plot lado lado é uma ferramenta tradicional para comparação entre grupos. Um exemplo é mostrado gráfico esquerdo da Figura 1.34, onde há dois gráficos, um para cada grupo, colocados em uma janela de plotagem e desenhados na mesma escala.\r\nFigura 1.34: Box-plot lado lado e histogramas para variável renda_med, onde os municípios são divididos por se houce um ganho ou perda populacional de 2000 2010. Os dados de renda foram coletados entre 2006 e 2010.\r\nOutro método de plotagem útil são histogramas juntos para comparar dados numéricos entre grupos. Estes são os histogramas de cada grupo colocados mesmo enredo, como mostrado gráfico lado direito da Figura 1.34.","code":"\nganho <- c(\n  '41.2, 22.9, 47.9, 50.1, 57.4, 43.8, 41.3, 68.3, 42.6, 66.4',\n  '51.9, 44.5, 39.4, 43.8, 71.3, 50.2, 35.8, 33.1, 39.9, 36.4',\n  '27.3, 42.6, 26, 40.5, 48.3, 53.6, 41.4, 83.3, 34, 38.6',\n  '71.7, 36.3, 45.8, 40.4, 30.4, 31.4, 42.2, 37.5, 40.6, 33.8',\n  '68.3, 38.7, 50.7, 34.3, 46.3, 48.7, 40, 45.1, 36.4, 45.7',\n  '51.5, 37.3, 45.1, 43.2, 53.5, 48.8, 35.7, 31, 62, 35.1',\n  '38.9, 48.4, 45.2, 57.3, 32.2, 41,60.2, 66.4, 79.1, 50.6',\n  '31.8, 26.1, 28.1, 38.5, 46.7, 37.6, 30.6, 37.3, 40.8, 34.7',\n  '45.2, 63.3, 37, 53.1, 36.1, 34.5, 59.4, 36.9, 57.2, 29.4',\n  '42.3, 30.5, 32.2, 56.8, 41.7, 42.6, 32.2, 33.1, 54.7, 66.7')\n\nnganho <- c('40.3, 29.5, 28, 38.1, 43.3',\n            '43.7, 35.8, 46, 38.6, 37.6',\n            '57.5, 46.2, 38.4, 36.4, 39.7',\n            '21.4, 43.6, 33.5, 31.8, 39.1',\n            '39.5, 37.5, 36.7, 38.7, 42.3',\n            '31.9, 29.3, 32.6, 26.5, 46.7',\n            '41.5, 37, 29.3, 39.8, 34.8',\n            '41.3, 42.8, 22.3, 47.1, 36',\n            '39.8, 48.2, 31.1, 30.1, 31.1',\n            '40.1, 25.9, 45.7, 37.7, 50.1')\n\ntable13 <- cbind(ganho, nganho)\ncolnames(table13) <- c('ganho populacional', 'nenhum ganho')\n\nlibrary(dplyr)\n\n\nknitr::kable(table13, caption = 'Nesta tabela, a renda familiar média (em $1000s) de uma amostra aleatória de 100 municípios que ganharam população entre 2000-2010. Rendimentos médios de uma amostra aleatória de 50 municípios que não tiveram ganho de população são mostrados também')\nlibrary(openintro)\ndata(countyComplete)\ndata(COL)\n\ncc  <- countyComplete\npop <- sign(cc$pop2010 - cc$pop2000 - 0.5)\npov <- cc$median_household_income / 1000\n\nset.seed(1)\nthese <- sample(sum(pop == -1, na.rm = TRUE), 50)\nsampL <- round(pov[pop == -1][these], 1)\nthese <- sample(sum(pop == 1, na.rm = TRUE), 100)\nsampG <- round(pov[pop == 1][these], 1)\nM  <- matrix(c(sampG, rep(\"\", 2), sampL, rep(\"\", 1)), 17)\nDB <- 6\n\npop[pop == 1] <- \"gain\"\npop[pop == -1] <- \"no gain\"\n\nside_side <- na.omit(data.frame(pop, pov))\n\ng1 <- ggplot(side_side) + \n  geom_boxplot(aes(y = pov, color = pop)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  labs(x = 'Mudança na População', y = 'Renda Média ($1000)', color = NULL)\n\ng2 <- ggplot(side_side) + \n  geom_histogram(aes(x = pov, fill = pop), alpha = 0.7, color = 'white') +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  labs(x = 'Mudança na População', y = 'Renda Média ($1000)', fill = NULL)\n\ngrid.arrange(g1, g2, ncol = 2)"},{"path":"ch1-intro.html","id":"caseStudyGenderDiscrimination","chapter":"1 Introdução aos Bancos de Dados","heading":"1.9 Estudo de caso: discriminação de gênero (tópico especial)","text":"Embora proporções provavelmente estivessem próximas umas das outras, seria incomum que elas fossem exatamente mesmas. Nós provavelmente observaríamos uma pequena diferença devido ao acaso.","code":""},{"path":"ch1-intro.html","id":"variabilityWithinData","chapter":"1 Introdução aos Bancos de Dados","heading":"1.9.1 Variabilidade nos dados","text":"Consideramos um estudo investigando discriminação de gênero na década de 1970, que é definida contexto das decisões de pessoal dentro de um banco47. pergunta de pesquisa que esperamos responder é“mulheres são discriminadas injustamente em decisões de promoção feitas por gerentes sexo masculino?”Os participantes deste estudo são 48 supervisores bancários sexo masculino que frequentam um instituto de gestão da Universidade da Carolina Norte em 1972. Eles foram solicitados assumir o papel de diretor de pessoal de um banco e receberam um arquivo pessoal para julgar se pessoa deveria ser promovido um cargo de gerente de filial. Os arquivos dados aos participantes eram idênticos, exceto que metade deles indicava que o candidato era sexo masculino e outra metade indicava que o candidato era sexo feminino. Esses arquivos foram aleatoriamente atribuídos.Para cada supervisor, registramos o gênero associado ao arquivo atribuído e à decisão da promoção. Usando os resultados estudo resumidos na Tabela 1.15, gostaríamos de avaliar se mulheres são injustamente discriminadas nas decisões de promoção. Neste estudo, uma proporção menor de mulheres é promovida que os homens (0.583 versus 0.875), mas não está claro se diferença fornece evidências convincentes de que mulheres são discriminadas injustamente.Tabela 1.15: Resultados resumidos para o estudo de discriminação de gênero.taxas de promoção observadas (58,3% para mulheres versus 87,5% para homens) sugerem que pode haver discriminação contra mulheres nas decisões de promoção. entanto, não podemos ter certeza se diferença observada representa discriminação ou se é apenas por acaso. Geralmente, há um pouco de flutuação nos dados da amostra, e não esperamos que proporções da amostra sejam exatamente iguais, mesmo que verdade seja que decisões de promoção eram independentes gênero.O Exemplo 1.16 é um lembrete de que os resultados observados na amostra podem não refletir perfeitamente relações verdadeiras entre variáveis na população subjacente. Tabela 1.15 mostra que houve 7 menos promoções grupo feminino que masculino, uma diferença nas taxas de promoção de 29.2% \\(\\left( \\frac{21}{24} - \\frac{14}{24} = 0.292 \\right)\\). Essa diferença é grande, mas o tamanho da amostra para o estudo é pequeno, não ficando claro se essa diferença observada representa discriminação ou se é simplesmente por acaso. Nós rotulamos essas duas afirmações concorrentes, \\(H_0\\) e \\(H_1\\):\\(H_0\\): Hipótese nula: variáveis gênero e decisão são independentes. Eles não têm nenhum relacionamento, e diferença observada entre proporção de homens e mulheres que foram promovidos, 29,2%, deu-se pelo acaso.\\(H_0\\): Hipótese nula: variáveis gênero e decisão são independentes. Eles não têm nenhum relacionamento, e diferença observada entre proporção de homens e mulheres que foram promovidos, 29,2%, deu-se pelo acaso.\\(H_A\\): Hipótese alternativa: variáveis gênero e decisão não são independentes. diferença nas taxas de promoção de 29,2% não se deve ao acaso, e mulheres igualmente qualificadas são menos propensas serem promovidas que os homens.\\(H_A\\): Hipótese alternativa: variáveis gênero e decisão não são independentes. diferença nas taxas de promoção de 29,2% não se deve ao acaso, e mulheres igualmente qualificadas são menos propensas serem promovidas que os homens.O que significaria se o modelo de independência, que diz que variáveis gênero e decisão não estão relacionadas, é verdade? Isso significaria que cada banqueiro iria decidir se promoveria o candidato sem considerar o gênero indicado arquivo. diferença nas porcentagens de promoção se deu à maneira como os arquivos foram aleatoriamente divididos entre os banqueiros, e aleatorização acabou dando origem uma diferença relativamente grande de 29,2%.Considere o modelo alternativo: os banqueiros foram influenciados por qual gênero foi listado arquivo pessoal. Se isso fosse verdade, e especialmente se essa influência fosse substancial, esperaríamos ver alguma diferença nas taxas de promoção de candidatos sexo masculino e feminino. Se esse viés de gênero fosse contra mulheres, esperaríamos uma fração menor das decisões de promoção para os arquivos de pessoal feminino em relação aos arquivos masculinos.Escolhemos entre essas duas afirmações concorrentes, avaliando se os dados conflitam tanto com \\(H_0\\) que o modelo de independência não pode ser considerado razoável. Se este o caso, e os dados suportarem \\(H_1\\), então rejeitaremos noção de independência e concluiremos que houve discriminação.","code":"\ntable14 <- data.frame(promovido = c(21,14,35), \n                      npromovido = c(3,10,13), \n                      total = c(24,24,48))\n\ncolnames(table14) <- c('Promovido', 'Não Promovido', 'Total')\nrownames(table14) <- c('Homem', 'Mulher', 'Total')\n\nknitr::kable(table14, align = 'c', caption = 'Resultados resumidos para o estudo de discriminação de gênero.')"},{"path":"ch1-intro.html","id":"simulatingTheStudy","chapter":"1 Introdução aos Bancos de Dados","heading":"1.9.2 Simulando o estudo","text":"Tabela 1.15 mostra que 35 supervisores bancários recomendaram promoção e 13 não o fizeram. Agora, suponha que decisões dos banqueiros fossem independentes gênero. Então, se conduzirmos o experimento novamente com um arranjo aleatório diferente de arquivos, diferenças nas taxas de promoção seriam baseadas apenas na flutuação aleatória. Na verdade, podemos realizar essa randomização, que simula o que teria acontecido se decisões dos banqueiros tivessem sido independentes gênero, mas tivéssemos distribuído os arquivos de maneira diferente.Nesta simulação, nós misturamos 48 arquivos pessoais, 24 rotulados masculino e 24 rotulados femininos e processe esses arquivos em duas pilhas. Vamos distribuir 35 arquivos na primeira pilha, o que representará os 35 supervisores que recomendaram promoção. segunda pilha terá 13 arquivos e representará os 13 supervisores que recomendaram contra promoção. Então, como fizemos com os dados originais, tabulamos os resultados e determinamos fração de homens e mulheres que foram promovidos. randomização de arquivos nesta simulação é independente das decisões de promoção, o que significa que qualquer diferença nas duas frações é inteiramente devido ao acaso. Tabela 1.16 mostra os resultados de tal simulação.Tabela 1.16: Resultados da simulação, em que qualquer diferença nas taxas de promoção entre homens e mulheres é puramente devido ao acaso.","code":"\ntable15 <- data.frame(promovido = c(18,17,35), \n                      npromovido = c(6,7,13), \n                      total = c(24,24,48))\n\ncolnames(table15) <- c('Promovido', 'Não Promovido', 'Total')\nrownames(table15) <- c('Homem', 'Mulher', 'Total')\n\nknitr::kable(table15, align = 'c', caption = 'Resultados da simulação, em que qualquer diferença nas taxas de promoção entre homens e mulheres é puramente devido ao acaso.')"},{"path":"ch1-intro.html","id":"checkingIndependence","chapter":"1 Introdução aos Bancos de Dados","heading":"1.9.3 Checando independência","text":"Calculamos uma diferença possível sob o modelo de independência na Prática Orientada 1.32, que representa uma diferença devido ao acaso. Enquanto nesta primeira simulação, nós distribuímos arquivos fisicamente, é mais eficiente executar esta simulação usando um computador. Repetindo simulação em um computador, temos outra diferença devido ao acaso: -0,042. E outro: 0,208. E assim por diante, até repetirmos simulação suficientemente para termos uma boa idéia que representa distribuição das diferenças acaso. Figura 1.35 mostra um gráfico das diferenças encontradas em 100 simulações, onde cada ponto representa uma diferença simulada entre proporções de arquivos masculinos e femininos que foram recomendadas para promoção.\r\nFigura 1.35: Um gráfico de pontos empilhados de diferenças de 100 simulações produzidas sob o modelo independente, H0, onde gênero e decisão são independentes. Duas das 100 simulações apresentaram diferença de pelo menos 29.2%, diferença observada estudo.\r\nObserve que distribuição dessas diferenças simuladas é centralizada em torno de 0. Simulamos essas diferenças assumindo que o modelo de independência era verdadeiro e, sob essa condição, esperamos que diferença seja zero com alguma flutuação aleatória. Nós geralmente ficariamos surpresos ao ver uma diferença de exatamente 0: às vezes, apenas por acaso, diferença é maior que 0, e outras vezes é menor que zero.Parece que uma diferença de pelo menos 29,2% devido ao acaso só aconteceria em torno de 2% tempo, de acordo com Figura 1.35. Uma probabilidade tão baixa indica um evento raro.diferença de 29,2% sendo um evento raro sugere duas possíveis interpretações dos resultados estudo:\\(H_0\\) Modelo independente. O gênero não tem efeito sobre decisão de promoção, e observamos uma diferença que só aconteceria raramente.\\(H_0\\) Modelo independente. O gênero não tem efeito sobre decisão de promoção, e observamos uma diferença que só aconteceria raramente.\\(H_1\\) Modelo alternativo. O gênero tem um efeito sobre decisão de promoção, e o que observamos foi, na verdade, devido mulheres igualmente qualificadas serem discriminadas nas decisões de promoção, o que explica grande diferença de 29,2%.\\(H_1\\) Modelo alternativo. O gênero tem um efeito sobre decisão de promoção, e o que observamos foi, na verdade, devido mulheres igualmente qualificadas serem discriminadas nas decisões de promoção, o que explica grande diferença de 29,2%.Com base nas simulações, temos duas opções:Concluímos que os resultados estudo não fornecem fortes evidências contra o modelo de independência. Ou seja, não temos evidências suficientemente fortes para concluir que houve discriminação de gênero.\r\nConcluímos que os resultados estudo não fornecem fortes evidências contra o modelo de independência. Ou seja, não temos evidências suficientemente fortes para concluir que houve discriminação de gênero.Concluímos que evidência é suficientemente forte para rejeitar \\(H_0\\) e afirmar que houve discriminação de gênero. Quando conduzimos estudos formais, geralmente rejeitamos noção de que acabamos de observar um evento raro.49 Assim, neste caso, rejeitamos o modelo de independência em favor da alternativa. Ou seja, estamos concluindo que os dados fornecem fortes evidências de discriminação de gênero contra mulheres pelos supervisores.\r\nConcluímos que evidência é suficientemente forte para rejeitar \\(H_0\\) e afirmar que houve discriminação de gênero. Quando conduzimos estudos formais, geralmente rejeitamos noção de que acabamos de observar um evento raro.49 Assim, neste caso, rejeitamos o modelo de independência em favor da alternativa. Ou seja, estamos concluindo que os dados fornecem fortes evidências de discriminação de gênero contra mulheres pelos supervisores.Um campo de estatística, inferência estatística, é construído sobre avaliação se tais diferenças são devidas ao acaso. Na inferência estatística, os estatísticos avaliam qual modelo é mais razoável, dados os dados. Ocorrem erros, assim como eventos raros, e podemos escolher o modelo errado. Embora nem sempre escolhamos corretamente, inferência estatística nos fornece ferramentas para controlar e avaliar com que frequência esses erros ocorrem. Mais frente, damos uma introdução formal ao problema da seleção de modelos. seguir construiremos uma base de probabilidade e teoria necessária para tornar essa discussão rigorosa.","code":"\nlibrary(openintro)\ndata(COL)\n\nset.seed(8535)\n\ngender  <- c(rep('male', 24), rep('female', 24))\noutcome <- c(rep(c('promoted', 'not promoted'), c(21, 3)),\n             rep(c('promoted', 'not promoted'), c(14, 10)))\n\nnsim    <- 100\nn       <- length(gender)\ngroup   <- gender\nvar1    <- outcome\nsuccess <- \"promoted\"\nsim     <- matrix(NA, nrow = n, ncol = nsim)\nn1      <- 24\nn2      <- 24\n\nstatistic <- function(var1, group) {\n  t1 <- var1 == success & group == levels(as.factor(group))[1]\n  t2 <- var1 == success & group == levels(as.factor(group))[2]\n  return(sum(t1) / n1 - sum(t2) / n2)\n}\n\nfor (i in 1:nsim) {\n  sim[,i] <- sample(group, replace = FALSE)\n}\n\n\nsim_dist <- apply(sim, 2, statistic, var1 = outcome)\ndiffs    <- sim_dist\npval     <- sum(diffs >= 0.29) / nsim\nvalues   <- table(sim_dist)\n\n\nX <- c()\nY <- c()\nfor (i in 1:length(diffs)) {\n  x   <- diffs[i]\n  rec <- sum(sim_dist == x)\n  X   <- append(X, rep(x, rec))\n  Y   <- append(Y, 1:rec)\n}\n\nggplot() + \n  geom_point(aes(x = X, y = Y), color = 'skyblue3') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  labs(x = 'Diferença', y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())"},{"path":"ch2-prob.html","id":"ch2-prob","chapter":"2 Probabilidade (tópico especial)","heading":"2 Probabilidade (tópico especial)","text":"Probabilidade forma uma base para estatística, e você pode já estar familiarizado com muitos aspectos da probabilidade. entanto, formalização dos conceitos é nova para maioria. Este capítulo tem como objetivo introduzir probabilidade em termos familiares usando processos que maioria das pessoas já viu antes.","code":""},{"path":"ch2-prob.html","id":"basicsOfProbability","chapter":"2 Probabilidade (tópico especial)","heading":"2.1 Definindo probabilidade (tópico especial)","text":"Se o dado é honesto, então chance de um 1 é tão provável quanto chance de qualquer outro número. Como há seis resultados, chance deve ser de 1 em 6 ou, equivalentemente, \\(1/6\\).1 e 2 constituem dois dos seis resultados igualmente prováveis, então chance de obter um desses dois resultados deve ser \\(2/6 = 1/3\\).100%. O resultado deve ser um desses números.Já que chance de cair um 2 é \\(1/6\\) ou \\(16.66\\%\\), chance de não cair um 2 deve ser \\(100\\% - 16.66\\% = 83.33\\%\\) ou \\(5/6\\).Alternativamente, poderíamos ter notado que não caindo 2 é o mesmo que conseguir um 1, 3, 4, 5, ou 6, que compõe cinco dos seis resultados igualmente prováveis e tem probabilidade \\(5/6\\).Se em \\(1/6\\) das vezes o primeiro dado é um 1 e \\(1/6\\) dessas vezes o segundo dado também é um 1, então chance de que ambos os dados são 1 é \\((1/6)\\times (1/6)\\) ou \\(1/36\\).","code":""},{"path":"ch2-prob.html","id":"probability","chapter":"2 Probabilidade (tópico especial)","heading":"2.1.1 Probabilidade","text":"Usamos probabilidade para construir ferramentas para descrever e entender aparente aleatoriedade. Nós geralmente enquadramos probabilidade em termos de um processo aleatório dando origem um resultado.\\[\\text{Jogue um dado} \\longrightarrow 1, 2, 3, 4, 5 \\text{ ou } 6 \\\\ \r\n\\text{Jogue uma moeda} \\longrightarrow \\text{cara, coroa}\\]Jogar um dado ou jogar uma moeda é um processo aparentemente aleatório e cada um dá origem um resultado.Probabilidade:  probabilidade de um resultado é proporção de vezes que o resultado ocorreria se observássemos o processo aleatório um número infinito de vezes.probabilidade é definida como uma proporção e sempre recebe valores intervalo fechado de 0 1. Também pode ser exibido como uma porcentagem entre 0% e 100%.probabilidade pode ser ilustrada jogando um dado muitas vezes. \\(\\hat{p}_n\\) é proporção de resultados que são 1 após primeiras \\(n\\) jogadas. À medida que o número de jogadas aumenta, \\(\\hat{p}_n\\) irá convergir para probabilidade de jogar um 1, \\(p = 1/6\\). Figura 2.1 mostra essa convergência para 100.000 jogadas de dados. tendência de \\(\\hat{p}_n\\) estabilizar em torno de \\(p\\) é descrito pela Lei dos Grandes Números.\r\nFigura 2.1: fração de jogadas de dados que deram 1 em cada estágio de uma simulação. proporção tende se aproximar da probabilidade 1/6 à medida que o número de jogadas aumenta.\r\nLei dos Grandes Números À medida que mais observações são coletadas, proporção \\(\\hat{p}_n\\) de ocorrências com um determinado resultado converge para probabilidade \\(p\\) desse resultado.Ocasionalmente, proporção se desviará da probabilidade e parecerá desafiar Lei dos Grandes Números, como acontece com \\(\\hat{p}_n\\) muitas vezes, pela Figura 2.1. entanto, esses desvios diminuem à medida que o número de jogadas aumenta.Acima, escrevemos \\(p\\) como probabilidade de lançar um 1. Também podemos escrever essa probabilidade como\\[\\begin{eqnarray*}\r\nP(\\text{lançar um 1})\r\n\\end{eqnarray*}\\]À medida que nos tornarmos mais confortáveis com essa notação, vamos abreviá-la ainda mais. Por exemplo, se está claro que o processo é “jogar um dado,” nós poderíamos abreviar \\(P(\\)lançando um 1\\()\\) como \\(P(1)\\).Prática Orientada 2.1  \r\nProcessos aleatórios incluem jogar um dado e lançar uma moeda. () Pense em outro processo aleatório. (b) Descreva todos os resultados possíveis desse processo. Por exemplo, jogar um dado é um processo aleatório com possíveis resultados \\(1, 2, \\dots, 6\\).50O que pensamos como processos aleatórios não são necessariamente aleatórios, mas podem ser muito difíceis de entender exatamente. O quarto exemplo na solução de nota de rodapé para Prática Orientada 2.1 sugere que o comportamento de um colega de quarto é um processo aleatório. entanto, mesmo que o comportamento de um colega de quarto não seja verdadeiramente aleatório, modelar seu comportamento como um processo aleatório ainda pode ser útil.Modelando um processo como aleatório Pode ser útil modelar um processo como aleatório, mesmo que não seja verdadeiramente aleatório.","code":"\nlibrary(openintro)\ndata(COL)\n\n# _____ Simulate _____ #\nset.seed(51)\nn <- 10^5\nx <- sample(0:1, n, TRUE, p = c(5 / 6, 1 / 6))\ny <- cumsum(x) / 1:n\nX <- c(1:100, seq(102, 500, 2),\n    seq(510, 1500, 10), seq(1550, 10000, 50),\n    seq(10100, 25000, 100), seq(25250, 100000, 250))\nY <- y[X]\n\nplot(X, Y,\n     log = 'x',\n     type = 'l',\n     xlab = '',\n     ylab = '',\n     axes = FALSE,\n     col = COL[1],\n     lwd = 2)\nmtext('n (number of rolls)', side = 1, line = 2.5)\nabline(h = 1 / 6, lty = 2)\nat <- 10^(0:5)\nlabels <- c('1', '10', '100', '1,000', '10,000', '100,000')\naxis(1, at, labels)\naxis(2, at = seq(0, 0.3, 0.1))\naxis(2, at = seq(0.05, 0.3, 0.1), labels = rep(NA, 3), tcl = -0.15)\nat <- 1 / 6\nlabels <- expression(paste(hat(p)[n]))\naxis(2, at, labels,\n     line = 2.3,\n     tick = FALSE,\n     cex.axis = 1.1)"},{"path":"ch2-prob.html","id":"disjointMutuallyExclusiveResults","chapter":"2 Probabilidade (tópico especial)","heading":"2.1.2 Resultados disjuntos ou mutuamente exclusivos","text":"Dois resultados são chamados de disjuntos ou mutuamente exclusivos se ambos não puderem acontecer. Por exemplo, se jogarmos um dado, os resultados 1 e 2 são disjuntos, pois não podem ocorrer. Por outro lado, os resultados 1 e jogar um número ímpar não são disjuntos, pois ambos ocorrem se o resultado teste um 1. Os termos disjunto e mutuamente exclusivos são equivalentes e intercambiáveis.Calcular probabilidade de desfechos desarticulados é fácil. Ao jogar um dado, os resultados 1 e 2 são disjuntos e calculamos probabilidade de que um desses resultados ocorra, adicionando suas probabilidades separadas:\\[\\begin{eqnarray*}\r\nP(\\text{1 ou 2}) = P(\\text{1}) + P(\\text{2}) = 1/6 + 1/6 = 1/3\r\n\\end{eqnarray*}\\]Quanto à probabilidade de lançar um 1, 2, 3, 4, 5, ou 6? Aqui, novamente, todos os resultados são disjuntos, então adicionamos probabilidades:\\[\\begin{eqnarray*}\r\n&&P(\\text{1 ou 2 ou 3 ou 4 ou 5 ou 6}) \\\\\r\n    &&\\quad= P(\\text{1})+P(\\text{2})+P(\\text{3})+P(\\text{4})+P(\\text{5})+P(\\text{6}) \\\\\r\n    &&\\quad= 1/6 + 1/6 + 1/6 + 1/6 + 1/6 + 1/6 = 1.\r\n\\end{eqnarray*}\\]Regra da Adição garante precisão desta abordagem quando os resultados são disjuntos.Regra da adição de resultados disjuntos Se \\(A_1\\) e \\(A_2\\) representam dois desfechos disjuntos, então probabilidade de que um deles ocorra é dada por\\[\\begin{eqnarray*}\r\nP(A_1\\text{ ou } A_2) = P(A_1) + P(A_2)\r\n\\end{eqnarray*}\\]Se houver muitos resultados disjuntos \\(A_1,\\dots, A_k\\), então probabilidade de que um desses resultados ocorra é\\[\\begin{eqnarray}\r\nP(A_1) + P(A_2) + \\cdots + P(A_k)\r\n\\end{eqnarray}\\]Prática Orientada 2.2  Estamos interessados na probabilidade de rolar um 1, 4, ou 5.Explicar porque os resultados 1, 4, e 5 são disjuntos.Explicar porque os resultados 1, 4, e 5 são disjuntos.Aplicar Regra da Adição para resultados disjuntos para determinar \\(P(1 ou 4 ou 5)\\).51\r\nAplicar Regra da Adição para resultados disjuntos para determinar \\(P(1 ou 4 ou 5)\\).51Prática Orientada 2.3  banco de dados email da introdução, variável número descreveu se nenhum número, apenas um ou mais números pequenos, ou se pelo menos um grande número apareceu em um email. Dos 3.921 e-mails, 549 não tinham números, 2.827 tinham apenas um ou mais números pequenos e 545 tinham pelo menos um número grande.Os resultados nenhum, pequeno, e grande são disjuntos?Os resultados nenhum, pequeno, e grande são disjuntos?Determinar proporção de emails com valor pequeno e grande, separadamente.Determinar proporção de emails com valor pequeno e grande, separadamente.Use Regra da Adição para resultados disjuntos para calcular probabilidade de um e-mail selecionado aleatoriamente conjunto de dados ter um número, pequeno ou grande.52\r\nUse Regra da Adição para resultados disjuntos para calcular probabilidade de um e-mail selecionado aleatoriamente conjunto de dados ter um número, pequeno ou grande.52Suponha que \\(\\) representa o evento qual um lançamento de dados resulta 1 ou 2 e \\(B\\) representa o evento que o dado é um 4 ou 6. Escrevemos \\(\\) como o conjunto de resultados \\(\\{1,2\\}\\) e \\(B = \\{4, 6\\}\\). Esses conjuntos são comumente chamados de eventos. Como \\(\\) e \\(B\\) não possuem elementos em comum, eles são eventos disjuntos. \\(\\) e \\(B\\) estão representados na Figura 2.2.\r\nFigura 2.2: Três eventos, , B e D, consistem em resultados lançamento de um dado. e B são disjuntos, pois não tem nenhum resultado em comum.\r\nRegra da Adição aplica-se tanto resultados disjuntos quanto eventos disjuntos. probabilidade de que um dos eventos disjuntos \\(\\) ou \\(B\\) ocorra é soma das probabilidades separadas:\\[\\begin{align*}\r\nP(\\text{ ou }B) = P() + P(B) = 1/3 + 1/3 = 2/3\r\n\\end{align*}\\]Prática Orientada 2.4  () Verifique probabilidade evento \\(\\), \\(P() = 1/3\\) usando Regra da Adição.Faça o mesmo para o evento \\(B\\).53\r\nPrática Orientada 2.5  () Usando Figura 2.2 como referência, que resultados são representados pelo evento \\(D\\)?Os eventos \\(B\\) e \\(D\\) são disjuntos?Os eventos \\(B\\) e \\(D\\) são disjuntos?Os eventos \\(\\) e \\(D\\) são disjuntos?54\r\nOs eventos \\(\\) e \\(D\\) são disjuntos?54","code":"\nlibrary(openintro)\ndata(COL)\n\npar(mar = rep(0, 4))\nplot(c(0.05, 0.95),\n     c(0.13, 0.82),\n     type = 'n',\n     axes = FALSE)\n\nfor(i in 1:6){\n  text(i / 7, 0.5, i)\n}\ntheta <- seq(0, 2 * pi, length.out = 100)\n\n# _____ A _____ #\nlines(1 / 7 * cos(theta) + 1.5 / 7,\n      1 / 6 * sin(theta) + 0.5,\n      col = COL[1])\ntext(1.5 / 7, 0.75, 'A', col = COL[1])\n\n# _____ B _____ #\nx <- 1 / 15 * cos(seq(3 * pi / 2, 3 * pi-0.3, length.out = 40)) + 6 / 7\ny <- 1 / 6 * sin(seq(3 * pi / 2, 3 * pi, length.out = 40)) + 0.5\nx <- c(x, seq(11 / 14, 9 / 14, length.out = 10))\ny <- c(y, seq(-0.3, 0.3, length.out = 10)^2 + 0.4)\nx <- c(x, 1 / 15 * cos(seq(0.3, 3 * pi / 2, length.out = 40)) + 4 / 7)\ny <- c(y, 1 / 6 * sin(seq(0, 3 * pi / 2, length.out = 40)) + 0.5)\nx <- c(x, x[1])\ny <- c(y, y[1])\nlines(x, y, lty = 2, col = COL[2])\ntext(5 / 7, 0.2, 'B', col = COL[2])\n\n# _____ D _____ #\nlines(1 / 7 * cos(theta) + 2.5 / 7,\n      1 / 6 * sin(theta) + 0.5,\n      lty = 3,\n      col = COL[4],\n      lwd = 2.425)\ntext(2.5 / 7, 0.75, 'D', col = COL[4])"},{"path":"ch2-prob.html","id":"probabilityEventsNotDisjoint","chapter":"2 Probabilidade (tópico especial)","heading":"2.1.3 Probabilidades quando os eventos não são disjuntos","text":"Vamos considerar cálculos para dois eventos que não são disjuntos contexto de um baralho padrão de 52 cartas. Se você não estiver familiarizado com cartas em um baralho regular, consulte nota de rodapé.^[52 cartas são divididas em quatro naipes: \\(\\clubsuit\\) (paus), \\(\\diamondsuit\\) (ouros), \\(\\heartsuit\\) (copas) e \\(\\spadesuit\\) (espadas). Cada naipe tem suas 13 cartas rotulados: \\(2, 3, \\dots, 10, J (valete), Q (rainha), K (rei), e (ás)\\). Assim, cada carta é uma combinação única de um naipe e um rótulo, por exemplo 4\\(\\heartsuit\\) e J\\(\\clubsuit\\). 12 cartas representadas pelos valetes, rainhas e reis são chamadas figuras. cartas que são \\(\\diamondsuit\\) ou \\(\\heartsuit\\) são tipicamente vermelhas enquanto os outros dois naipes são tipicamente de cor preta.Prática Orientada 2.7  () Qual é probabilidade de uma carta selecionada aleatoriamente ser um ouro?Os Diagramas de Venn são úteis quando os resultados podem ser categorizados como dentro ou fora para duas ou três variáveis, atributos ou processos aleatórios. O diagrama de Venn na Figura 2.3 usa um círculo para representar ouros e outro para representar cartas de figura. Se uma carta é um ouro e uma carta de figura, ela cai na interseção dos círculos. Se um ouro, mas não uma carta de figura, ele será parte círculo esquerdo que não está círculo direito (e assim por diante). O número total de cartas que são ouro é dado pelo número total de cartas círculo de ouros: \\(10+3=13\\). probabilidades também são mostradas (por ex. \\(10/52 = 0.1923\\)).\r\nFigura 2.3: Um diagrama de Venn para ouros e cartas de figura.\r\n\\(\\) representa o evento em que uma carta selecionada aleatoriamente é um ouro e \\(B\\) representa o evento que é uma carta de figura. Como calculamos \\(P(\\text{ ou } B)\\)? Eventos \\(\\) e \\(B\\) não são disjuntos – cartas \\(J\\diamondsuit, Q\\diamondsuit\\), e \\(K\\diamondsuit\\) caem em ambas categorias - por isso não podemos usar Regra da Adição para eventos disjuntos. Em vez disso, usamos o diagrama de Venn. Começamos adicionando probabilidades dos dois eventos:\\[\\begin{eqnarray}\r\nP() + P(B)\r\n  = P({\\diamondsuit}) + P(\\text{figuras})\r\n  = 13/52 + 12/52\r\n  \\tag{2.1}\r\n\\end{eqnarray}\\]entanto, três cartas que estão em ambos os eventos foram contadas duas vezes, uma vez em cada probabilidade. Devemos corrigir essa contagem dupla:\\[\\begin{eqnarray}\r\nP(\\text{ ou } B) &=&P(\\diamondsuit\\text{ ou figura}) \\\\\r\n  &=& P({\\color{redcards}\\diamondsuit}) + P(\\text{figura}) - P({\\color{redcards}\\diamondsuit}\\text{ e figura})  \\\\\r\n  &=& 13/52 + 12/52 - 3/52 \\\\\r\n  &=& 22/52 = 11/26 \r\n    \\tag{2.2}\r\n\\end{eqnarray}\\]Equação (2.2) é um exemplo da Regra Geral da Adição.Regra Geral da Adição Se \\(\\) e \\(B\\) são quaisquer dois eventos, disjuntos ou não, então probabilidade de que pelo menos um deles ocorra é\\[\\begin{eqnarray}\r\nP(\\text{ ou }B) = P() + P(B) - P(\\text{ e }B)\r\n\\tag{2.3}\r\n\\end{eqnarray}\\]onde \\(P(\\text{ e }B)\\) é probabilidade de que ambos os eventos ocorram.ou é inclusivo Quando escrevemos ou em estatística, queremos dizer e/ou, menos que declaremos explicitamente o contrário. Assim, \\(\\) ou \\(B\\) ocorrer significa que \\(\\), \\(B\\), ou ambos \\(\\) e \\(B\\) ocorrem.Prática Orientada 2.9  () Se \\(\\) e \\(B\\) forem disjuntos, descreva porque isso implica \\(P(\\) e \\(B) = 0\\).Usando parte (), verifique se Regra da Adição Geral engloba regra de adição para eventos disjuntos se \\(\\) e \\(B\\) forem disjuntos58\r\nPrática Orientada 2.11  () Use seu diagrama de Venn da Prática Orientada 2.10 para determinar probabilidade de um e-mail tirado aleatoriamente conjunto de dados ser spam e ter números pequenos (mas não números grandes).Qual é probabilidade de que o email tenha um desses atributos?60\r\n","code":"\nlibrary(openintro)\ndata(COL)\n\nplot(c(0.2, 2.5),\n     c(-0.13, 1.15),\n     type = 'n',\n     axes = FALSE)\n\nz <- seq(0,2 * pi, len = 99)\nx2 <- cos(z) / 2 + 1.3\ny2 <- sin(z) / 3 + 0.5\npolygon(c(x2, x2[1]), c(y2, y2[1]), col = COL[3,3])\n\nx1 <- cos(z) / 2 + 0.7\ny1 <- sin(z) / 3 + 0.5\npolygon(c(x1, x1[1]),c(y1, y1[1]), col = COL[1,3])\n\ntext(c(0.55, 1, 1.45),\n     rep(0.57, 3),\n     c(10, 3, 9),\n     cex = c(1.3, 1.2, 1.3))\ntext(c(0.55, 1, 1.45),\n     c(0.41, 0.43, 0.41),\n     c('0.1923', '0.0577', '0.1731'),\n     cex = c(1, 0.9, 1))\n# text(0.5, -0.25, 'Other cards: 30', cex = 0.8)\n# text(0.98, -0.26, '(0.5769)', cex = 0.8)\ntext(2.25, 0.55, cex = 0.8,\n     paste(\"There are also\", \"30 cards that are\",\n           \"neither diamonds\", \"nor face cards\", sep = \"\\n\"))\n# text(2.25, 0.28, '(0.5769)', cex = 0.8)\nBraces(0.7, 0.92, 3 * pi / 2, 0.98, 0.12)\ntext(0.7, 1.09, 'Diamonds, 0.2500')\nBraces(1.3, 0.08, pi / 2, 0.98, 0.12)\ntext(1.3, -0.08, 'Face cards, 0.2308')"},{"path":"ch2-prob.html","id":"probabilityDistribution","chapter":"2 Probabilidade (tópico especial)","heading":"2.1.4 Distribuições de probabilidade","text":"distribuição de probabilidade é uma tabela de todos os resultados separados e suas probabilidades associadas. Tabela 2.1 mostra distribuição de probabilidade para soma de dois dados.Tabela 2.1: Distribuição de probabilidade da soma de dois dados.Regras para distribuições de probabilidade Uma distribuição de probabilidade é uma lista dos resultados possíveis com probabilidades correspondentes que satisfazem três regras:Os resultados listados devem ser separados.Os resultados listados devem ser separados.Cada probabilidade deve estar entre 0 e 1.Cada probabilidade deve estar entre 0 e 1.probabilidades devem totalizar 1.probabilidades devem totalizar 1.Tabela 2.2: Propostas de distribuições de renda familiar nos EUACapítulo anterior enfatizou importância de plotar dados para fornecer resumos rápidos. distribuições de probabilidade também podem ser resumidas em um gráfico de barras. Por exemplo, distribuição dos rendimentos familiares nos EUA é mostrada na Figura 2.4 como um gráfico de barra.62A distribuição de probabilidade para soma de dois dados é mostrada na Tabela 2.1 e plotado na Figura 2.5.\r\nFigura 2.4: distribuição de probabilidade da renda familiar dos EUA.\r\n\r\nFigura 2.5: distribuição de probabilidade da soma de dois dados.\r\nNestas colunas de barras, alturas das barras representam probabilidades de resultados. Se os resultados forem numéricos e discretos, geralmente é (visualmente) conveniente fazer um gráfico de barras que se pareça com um histograma, como caso da soma de dois dados. Outro exemplo de gráfico de barras em suas respectivas localizações é mostrado na Figura 2.12.","code":"\ntab1 <- rbind(c(2:12), c('1/36', '2/36', '3/36', '4/36', '5/36', '6/36', \n                         '5/36', '4/36', '3/36', '2/36', '1/36'))\n\nrownames(tab1) <- c('Soma dos Dados', 'Probabilidade')\n\nknitr::kable(tab1, caption = 'Distribuição de probabilidade da soma de dois dados.', \n             align = 'c')\ntab2 = cbind(c(0.18, 0.38, 0.28), c(0.39, -0.27, 0.27), \n             c(0.33, 0.52, 0.29), c(0.16, 0.37, 0.16))\n\nrownames(tab2) <- c('(a)', '(b)', '(c)')\ncolnames(tab2) <- c('0-25', '25-50', '50-100', '100+')\n\nknitr::kable(tab2, align = 'c', caption = 'Propostas de distribuições de renda familiar nos EUA')\ntemp <- data.frame(p = c(0.28, 0.27, 0.29, 0.16), \n                   name = c('0-25', '25-50', '50-100', '100+'))\n\ntemp$name <- factor(temp$name, levels = c('0-25', '25-50', '50-100', '100+'))\n\n\nrequire(ggplot2)\n\nggplot(data = temp) + \n  geom_col(aes(x = name, y = p), fill = 'skyblue3') + \n  labs(x = 'Renda Familiar do US ($1000s)', y = 'Probabilidade') + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1))\nlibrary(openintro)\ndata(COL)\n\nprobDist <- function(x,\n                     prob,\n                     labels1 = NA,\n                     labels2 = NA,\n                     thickness = NA,\n                     col = NA,\n                     ylim = NULL,\n                     ...) {\n  R <- range(x)\n  R <- R + c(-1,1)*(R[2]-R[1])/20\n  Ry <- c(0, range(prob)[2])\n  if (!is.null(ylim)[1]) {\n    Ry <- ylim\n  }\n  plot(x, prob, type = 'n', axes = F, xlim = R, ylim = Ry, ...)\n  if(is.na(labels1)[1]) labels1 <- x\n  if(is.na(labels2)[1]) labels2 <- TRUE\n  axis(1, at = x, labels = labels1)\n  make.bar(x, prob, thickness = thickness, col = col)\n}\n\nmake.bar <- function(at,\n                     height,\n                     thickness = NA,\n                     col = NA) {\n  if (is.na(thickness)) {\n    R <- range(at)\n    minDiff <- min(diff(at))\n    thickness <- min(c(minDiff), (R[2]-R[1])/12)\n  }\n  x1 <- at - thickness/2\n  x2 <- at + thickness/2\n  if (is.na(col)) {\n    col <- 'grey'\n  }\n  for (i in 1:length(at)) {\n    rect(x1[i], 0, x2[i], height[i], col = col)\n  }\n}\n\nat = 2:12\nprob = c(1:6, 5:1)/36\n\n\nprobDist(at, prob,\n         xlab = 'Dice sum',\n         ylab = '',\n         thickness = 0.5,\n         col = COL[1])\nabline(h = 0)\naxis(2)\nmtext('Probability', side = 2, 3.3, las = 0)"},{"path":"ch2-prob.html","id":"complementEvent","chapter":"2 Probabilidade (tópico especial)","heading":"2.1.5 Complemento de um evento","text":"Jogar um dado produz um valor conjunto \\(\\{1, 2, 3, 4, 5, 6\\}\\). Esse conjunto de todos os resultados possíveis é chamado de espaço amostral (\\(S\\))Vamos considerar que \\(D=\\{2, 3\\}\\) representa o evento que o resultado de um rolamento de dados é 2 ou 3. Então o complemento \\(D\\) representa todos os resultados em nosso espaço amostral que não estão em \\(D\\), que é denotado por \\(D^c = \\{1, 4, 5, 6\\}\\). Ou seja, \\(D^c\\) é o conjunto de todos os resultados ainda possíveis e não incluídos \\(D\\). Figura 2.6 mostra relação entre \\(D\\), \\(D^c\\), e o espaço amostral \\(S\\).\r\nFigura 2.6: Evento D = {2, 3} e seu complemento {1, 4, 5, 6}. S representa o espaço amostral, que é o conjunto de todos os resultados possíveis.\r\nPrática Orientada 2.13  () Calcule \\(P(D^c) = P(\\text{lançar um} 1, 4, 5,\\text{ ou }6)\\).Qual é \\(P(D) + P(D^c)\\)?63\r\nPrática Orientada 2.14  Eventos \\(=\\{1, 2, 4, 6\\}\\) são mostrados na Figura 2.2.Escreva o que \\(^c\\) e \\(B^c\\) representam.(b)Calcule \\(P(^c)\\) e \\(P(B^c)\\).Um complemento de um evento \\(\\) é construído para ter duas propriedades muito importantes: () todo resultado possível não em \\(\\) é em \\(^c\\), e (ii) \\(\\) e \\(^c\\) são disjunto. Propriedade () implica\\[\\begin{eqnarray}\r\nP(\\text{ ou }^c) = 1\r\n\\tag{2.4}\r\n\\end{eqnarray}\\]Isto é, se o resultado não estiver em \\(\\), deve ser representado em \\(^c\\). Usamos regra da adição para eventos separados para aplicar propriedade (ii):\\[\\begin{eqnarray}\r\nP(\\text{ ou }^c) = P() + P(^c)\r\n\\tag{2.5}\r\n\\end{eqnarray}\\]Combinando Equações @ref(eq:complementSumTo1} e (2.5) rende uma relação muito útil entre probabilidade de um evento e seu complemento.Complemento O complemento evento \\(\\) é denotado por \\(^c\\) e representa todos os resultados que não estão em~ \\(\\). \\(\\) e \\(^c\\) estão matematicamente relacionados:\\[\\begin{eqnarray}\r\nP() + P(^c) = 1, \\text{ .e. } P() = 1-P(^c)\r\n\\tag{2.6}\r\n\\end{eqnarray}\\]Em exemplos simples, computação de \\(\\) ou \\(^c\\) é viável em poucos passos. entanto, usar o complemento pode economizar muito tempo à medida que os problemas aumentam em complexidade.Prática Orientada 2.15  Vamos representar \\(\\) o evento onde jogamos dois dados e o total deles é menor que 12.O que o evento \\(^c\\) representa?O que o evento \\(^c\\) representa?Determine \\(P(^c)\\) da Tabela 2.1.Determine \\(P(^c)\\) da Tabela 2.1.Determine \\(P()\\).65\r\nDetermine \\(P()\\).65Prática Orientada 2.16  Considere novamente probabilidades da Tabela 2.1 e o jogar dois dados. Encontre seguintes probabilidades:soma dos dados não é 6.soma dos dados não é 6.soma é pelo menos 4. Ou seja, determine probabilidade evento \\(B=\\{4, 5, \\dots, 12\\}\\).soma é pelo menos 4. Ou seja, determine probabilidade evento \\(B=\\{4, 5, \\dots, 12\\}\\).soma não é mais que 10. Ou seja, determine probabilidade evento \\(D=\\{2, 3, \\dots, 10\\}\\).66\r\nsoma não é mais que 10. Ou seja, determine probabilidade evento \\(D=\\{2, 3, \\dots, 10\\}\\).66","code":"\nlibrary(openintro)\ndata(COL)\n\npar(mar = rep(0, 4))\nplot(c(-0.05, 1), c(0.18, 0.92), type = 'n', axes = FALSE)\n\nfor(i in c(1,4,5,6)){\n  text(i / 7, 0.5, i)\n}\nfor(i in 2:3){\n  text(i / 7, 0.55, i)\n}\ntheta <- seq(0,2 * pi,length.out = 100)\n\n# _____ D _____ #\nlines(1 / 7 * cos(theta) + 2.5 / 7,\n      1 / 9 * sin(theta) + 0.55,\n      lty = 3,\n      col = COL[4],\n      lwd = 2.425)\ntext(2.5 / 7, 0.75, 'D', col = COL[4])\n\n# _____ D^c _____ #\nx <- 1 / 20 * cos(seq(0.5, 3 * pi / 2, length.out = 20)) + 1 / 7\ny <- 1 / 5 * sin(seq(0.2, 3 * pi / 2, length.out = 20)) + 0.5\nx <- c(x, 1 / 20 * cos(seq(-pi / 2, pi / 2, length.out = 20)) + 6 / 7)\ny <- c(y, 0.175 * sin(seq(-pi / 2, pi / 2, length.out = 20)) + 0.47)\nx <- c(x, 1 / 20 * cos(seq(pi / 2, pi, length.out = 10)) + 4 / 7)\ny <- c(y, 1 / 5 * sin(seq(pi / 2, pi-0.5, length.out = 10)) + .45)\nx <- c(x, seq(1 / 2, 3 / 14, length.out = 10))\ny <- c(y, seq(-0.35, 0.35, length.out = 10)^2 + 0.33)\nx <- c(x, x[1])\ny <- c(y, y[1])\nlines(x, y, lty = 2, col = COL[2])\ntext(5 / 7, 0.75, expression(D^C), col = COL[2])\n\n# _____ S _____ #\nx <- 1 / 10 * cos(seq(pi / 2, 3 * pi / 2, length.out = 20)) + 1 / 9\ny <- 1 / 3 * sin(seq(pi / 2, 3 * pi / 2, length.out = 20)) + 0.55\nx <- c(x, 1 / 10 * cos(seq(-pi / 2, pi / 2, length.out = 20)) + 8 / 9)\ny <- c(y, 1 / 3 * sin(seq(-pi / 2, pi / 2, length.out = 20)) + 0.55)\n#x <- c(x, 1 / 20 * cos(seq(pi / 2, pi, length.out = 10)) + 4 / 7)\n#y <- c(y, 1 / 5 * sin(seq(pi / 2, pi-0.5, length.out = 10)) + .45)\n#x <- c(x, seq(1 / 2, 3 / 14, length.out = 10))\n#y <- c(y, seq(-0.35, 0.35, length.out = 10)^2 + 0.33)\nx <- c(x, x[1])\ny <- c(y, y[1])\nlines(x, y, lty = 1, col = COL[1])\ntext(0, 0.55, expression(S), col = COL[1], pos = 2, cex = 1.3)"},{"path":"ch2-prob.html","id":"probabilityIndependence","chapter":"2 Probabilidade (tópico especial)","heading":"2.1.6 Independência","text":"Assim como variáveis e observações podem ser independentes, processos aleatórios podem ser independentes também. Dois processos são independentes, se conhecer o resultado de um não fornece informações úteis sobre o resultado outro. Por exemplo, jogar uma moeda e jogar um dado são dois processos independentes – saber que moeda é cara não ajuda determinar o resultado de um lançamento de dados. Por outro lado, os preços das ações geralmente sobem ou descem juntos, então eles não são independentes.O Exemplo 2.5 fornece um exemplo básico de dois processos independentes: jogar dois dados. Queremos determinar probabilidade de ambos serem 1. Suponha que um dos dados seja vermelho e o outro branco. Se o resultado dado vermelho 1, ele não fornece informações sobre o resultado dado branco. Nós encontramos mesma pergunta pela primeira vez Exemplo 2.5, onde calculamos probabilidade usando o seguinte raciocínio: \\(1/6\\) das vezes o dado vermelho é um 1, e \\(1/6\\) dessas vezes o dado branco também será 1. Isso é ilustrado na Figura 2.7. Como os testes são independentes, probabilidades dos resultados correspondentes podem ser multiplicadas para obter resposta final: \\((1/6)\\times(1/6)=1/36\\). Isso pode ser generalizado para muitos processos independentes.\r\nFigura 2.7: 1/6 das vezes, primeira jogada é um 1. Então 1/6 dessas vezes, segunda jogada também será um 1.\r\nmesma lógica se aplica partir Exemplo 2.5. Se \\(1/36\\) das vezes os dados brancos e vermelhos são ambos 1, então \\(1/6\\) dessas vezes o dado azul também será 1, então multiplique:\\[\\begin{align*}\r\nP(\\text{branco} = 1 \\text{ e vermelho } = 1 \\text{ e azul } = 1) \\\\\r\n= P(\\text{branco} = 1) \\times P(\\text{vermelho } = 1) \\times P(\\text{azul } = 1) \\\\\r\n= 1/6 \\times 1/6 \\times 1/6 = 1/216.\r\n\\end{align*}\\]O Exemplo 2.6 ilustra o que é chamado de Regra da Multiplicação para processos independentes,Regra da Multiplicação para processos independentes Se \\(\\) e \\(B\\) representam eventos de dois processos diferentes e independentes, então probabilidade de ocorrer tanto \\(\\) como \\(B\\) pode ser calculada como o produto de suas probabilidades separadas:\\[\\begin{eqnarray}\r\nP(\\text{ e }B) = P() \\times  P(B)\r\n\\tag{2.7}\r\n\\end{eqnarray}\\]Da mesma forma, se houver \\(k\\) eventos \\(A_1,\\dots, A_k\\) de \\(k\\) processos independentes, então probabilidade de que todos ocorram é\\[\\begin{eqnarray*}\r\nP(A_1) \\times  P(A_2)\\times  \\cdots \\times  P(A_k)\r\n\\end{eqnarray*}\\]Prática Orientada 2.18  \r\nSuponha que 5 pessoas sejam selecionadas aleatoriamente.68$]Qual é probabilidade de que todos sejam destros?Qual é probabilidade de que todos sejam destros?Qual é probabilidade de que todos sejam canhotos?Qual é probabilidade de que todos sejam canhotos?Qual é probabilidade de que nem todas pessoas sejam destras?\r\nQual é probabilidade de que nem todas pessoas sejam destras?Suponha que variáveis servidão e gênero sejam independentes, ou seja, saber que o gênero de alguém não fornece informações úteis sobre servidão e vice-versa. Então podemos calcular se uma pessoa selecionada aleatoriamente é destra e mulher69. Usando regra de multiplicação:\\[\\begin{eqnarray*}\r\nP(\\text{destro e mulher }) &=& P(\\text{destro }) \\times  P(\\text{feminino}) \\\\\r\n&=& 0,91 \\times  0,50 = 0,455\r\n\\end{eqnarray*}\\]Prática Orientada 2.19  \r\nTrês pessoas são selecionadas aleatoriamente.70Qual é probabilidade de que primeira pessoa seja sexo masculino e destro?Qual é probabilidade de que primeira pessoa seja sexo masculino e destro?Qual é probabilidade de que duas primeiras pessoas sejam sexo masculino e destras ?.Qual é probabilidade de que duas primeiras pessoas sejam sexo masculino e destras ?.Qual é probabilidade de que terceira pessoa seja sexo feminino e canhoto?Qual é probabilidade de que terceira pessoa seja sexo feminino e canhoto?Qual é probabilidade de que duas primeiras pessoas sejam sexo masculino e destras e terceira pessoa seja sexo feminino e canhoto?Qual é probabilidade de que duas primeiras pessoas sejam sexo masculino e destras e terceira pessoa seja sexo feminino e canhoto?Às vezes nos perguntamos se um resultado fornece informações úteis sobre outro resultado. pergunta que estamos fazendo é: ocorrências dos dois eventos são independentes? Dizemos que dois eventos \\(\\) e \\(B\\) são independentes se satisfizerem Equação (2.7).\\[\\begin{align*}\r\nP({\\heartsuit})\\times P(\\text{ás}) = \\frac{1}{4}\\times \\frac{1}{13} = \\frac{1}{52} \r\n                    = P({\\color{redcards}\\heartsuit}\\text{ e ás})\r\n\\end{align*}\\]Porque equação é válida, o evento em que carta é de copas e o evento em que carta é um ás são eventos independentes.","code":"\nlibrary(openintro)\ndata(COL)\n\npar(mar = rep(0, 4))\nplot(0:1, c(0, 1.1), type = 'n', axes = FALSE)\nx <- cos(seq(0, 2 * pi, length.out = 99))\ny <- sin(seq(0, 2 * pi, length.out = 99))\n#lines(x / 2 + 0.5, y / 2 + 0.5)\ntext(0, 1.05, pos = 4, 'All rolls')\nrect(0, 0, 1, 1)\nrect(1/6, 0, 2/6, 1,\n     lty = 2,\n     border = COL[1],\n     col = COL[1,3])\ntext(2/6, 0.7,\n     '1/6th of the first\\nrolls are a 1.',\n     pos = 4,\n     col = COL[1])\nrect(1/6, 1/6, 2/6, 2/6,\n     lty = 3,\n     border = \"#00000000\",\n     col = COL[2])\nthe.text <- paste(\"1/6th of those times where\",\n                  \"the first roll is a 1 the\",\n                  \"second roll is also a 1.\",\n                  sep  =  \"\\n\")\ntext(2 / 6, 3 / 12 - 0.02,\n    the.text,\n    pos = 4,\n    col = COL[2])"},{"path":"ch2-prob.html","id":"conditionalProbabilitySection","chapter":"2 Probabilidade (tópico especial)","heading":"2.2 Probabilidade condicional (tópico especial)","text":"O conjunto de dados família_ensino contém uma amostra de 792 casos com duas variáveis, adolescentes e pais, e está resumido na Tabela 2.3.71 variável adolescentes é: faculdade ou não, onde o rótulo faculdade significa que o adolescente foi para faculdade imediatamente após o ensino médio. variável pais recebe o valor graduado se pelo menos um dos pais adolescente tiver completado o ensino superior.Tabela 2.3: Tabela de contingência resumindo o conjunto de dados familia_ensino\r\nFigura 2.8: Um diagrama de Venn usando caixas para o conjunto de dados familia_ensino\r\nPodemos estimar essa probabilidade usando os dados. Dos 280 casos neste conjunto de dados onde pais leva valor graduado, 231 representam casos em que variável adolescente leva valor faculdade:\\[\\begin{eqnarray*}\r\nP(\\text{adolescente faculdade | pais graduado}) = \\frac{231}{280} = 0.825\r\n\\end{eqnarray*}\\]Se adolescente não frequentou faculdade logo após o ensino médio, ela é uma das 347 adolescentes da segunda fila. Dos 347 adolescentes, 49 tiveram pelo menos um dos pais que obteve um diploma universitário:\\[\\begin{eqnarray*}\r\nP(\\text{pais graduado | adolescente não}) = \\frac{49}{347} = 0.141\r\n\\end{eqnarray*}\\]","code":"\ntab3 <- cbind(c(231, 49, 280), c(214, 298, 512), c(445, 347, 792))\nrownames(tab3) <- c('faculdade', 'não', 'total')\ncolnames(tab3) <- c('graduado', 'não', 'total')\n\nknitr::kable(tab3, align = 'c', \n             caption = 'Tabela de contingência resumindo o conjunto de dados familia_ensino')\nlibrary(openintro)\ndata(COL)\n\n# Proportions not exactly right. Adjusted slightly for aesthetics.\n\npar(mar = rep(0, 4))\nplot(0:1, 0:1, type = 'n', axes = FALSE)\nrect(0, 0, 1, 1, lwd=2)\nrect(0.07, 0.15,\n     0.59, 0.82,\n     border = COL[4,2],\n     col = paste0(COL[4], \"25\"),\n     lty = 3,\n     lwd = 2.512)\ntext(0.33, 0.07, 'parent completed a college degree', col=COL[4,2])\nrect(0.18, 0.14,\n     0.96, 0.86,\n     border=COL[1],\n     col = paste0(COL[1], \"40\"),\n     lty = 2,\n     lwd = 2)\ntext(0.74, 0.84, 'Teenager went to college', col = COL[1], pos = 3)\ntext(0.39, 0.48, 0.29, col = COL[5]) # intersection\ntext(0.13, 0.47, 0.06, col = COL[4])\ntext(0.8, 0.5, 0.27, col = COL[1])\ntext(0.83, 0.05, 'Neither: 0.38', col = COL[6]) # outersection"},{"path":"ch2-prob.html","id":"marginalAndJointProbabilities","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.1 Probabilidades marginais e conjuntas","text":"Tabela 2.3 inclui totais de linha e coluna para cada variável separadamente conjunto de dados faculdade_família. Esses totais representam probabilidades marginais para amostra, que são probabilidades baseadas em uma única variável sem considerar quaisquer outras variáveis. Por exemplo, uma probabilidade baseada apenas na variável adolescente é uma probabilidade marginal:\\[\\begin{align*}\r\nP(\\text{adolescente faculdade}) = \\frac{445}{792} = 0.56\r\n\\end{align*}\\]Uma probabilidade de resultados para duas ou mais variáveis ou processos é chamada de probabilidade conjunta:\\[\\begin{align*}\r\nP(\\text{adolescente faculdade e pais não}) = \\frac{214}{792} = 0.27\r\n\\end{align*}\\]É comum substituir uma vírgula por ``e’’ em uma probabilidade conjunta, embora seja aceitável. Isso é,\\[\r\nP(\\text{adolescente faculdade, pais não}) = P(\\text{adolescente faculdade e pais não})\r\n\\]Probabilidades marginais e conjuntas:  Se uma probabilidade é baseada em uma única variável, é uma probabilidade marginal. probabilidade de resultados para duas ou mais variáveis ou processos é chamada de probabilidade conjunta.Nós usamos tabelas de proporções para resumir probabilidades conjuntas para amostra faculdade\\_família. Essas proporções são calculadas dividindo cada contagem na Tabela 2.3 pelo total da tabela, 792, para obter proporções na Tabela 2.4. distribuição de probabilidade conjunta das variáveis pais e adolescentes é mostrada na Tabela 2.5.Tabela 2.4: Tabela de probabilidade resumindo se pelo menos um dos pais tinha um diploma universitário e se o adolescente frequentou faculdade.Tabela 2.5: Distribuição de probabilidade conjunta para o conjunto de dados faculdade_familiaPodemos calcular probabilidades marginais usando probabilidades conjuntas em casos simples. Por exemplo, probabilidade de um adolescente aleatório estudo ir para faculdade é encontrada somando os resultados onde adolescente leva o valor faculdade:\\[\\begin{align*}\r\nP(\\text{adolescente faculdade})\r\n&=  P(\\text{pais graduado e adolescente faculdade}) + P(\\text{pais não e adolescente faculdade}) \\\\\r\n&= 0.29 + 0.27 \\\\\r\n&= 0.56\r\n\\end{align*}\\]","code":"\ntab4 <- cbind(c(0.29, 0.06, 0.35), c(0.27, 0.38, 0.65), c(0.56, 0.44, 1.00))\nrownames(tab4) <- c('adolescente:faculdade', 'adolescente:não', 'Total')\ncolnames(tab4) <- c('pais:graduado', 'pais:não', 'Total')\n\nknitr::kable(tab4, allign = 'c', \n             caption = 'Tabela de probabilidade resumindo se pelo menos um dos pais tinha um diploma universitário e se o adolescente frequentou a faculdade.')\ntab5 = cbind(c('pais:graduado e adolescente:faculdade', 'pais:graduado e adolescente:não', \n               'pais:não e adolescente:faculdade', 'pais:não e adolescente:não', 'Total'), \n             c(0.29, 0.06, 0.27, 0.38, 1.00))\n\ncolnames(tab5) <- c('Resultado Conjunto', 'Probabilidade')\n\nknitr::kable(tab5, align = 'c', \n             caption = 'Distribuição de probabilidade conjunta para o conjunto de dados faculdade_familia')"},{"path":"ch2-prob.html","id":"definingConditionalProbability","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.2 Definindo probabilidade condicional","text":"Há alguma conexão entre o nível de escolaridade dos pais e adolescente: um diploma universitário de um dos pais está associado com decisão de ir para uma faculdade adolescente. Nesta seção, discutiremos como usar informações sobre associações entre duas variáveis para melhorar estimativa de probabilidade.probabilidade de um adolescente aleatório estudo freqüentar faculdade é de 0,56. Poderíamos atualizar essa probabilidade se soubéssemos que um dos pais adolescente tem um diploma universitário? Absolutamente. Para fazer isso, limitamos nossa visão apenas aos 280 casos em que um pai tem um diploma universitário e olha fração em que o adolescente frequentou faculdade:\\[\\begin{eqnarray*}\r\nP(\\text{adolescente faculdade | pais graduado}) = \\frac{231}{280} = 0.825\r\n\\end{eqnarray*}\\]Chamamos isso de probabilidade condicional porque calculamos probabilidade sob uma condição: um pai tem um diploma universitário. Existem duas partes para uma probabilidade condicional, o termo de interesse e condição. É útil pensar na condição como informação que sabemos ser verdadeira, e essa informação geralmente pode ser descrita como um resultado ou evento conhecido.Nós separamos o texto dentro de nossa notação de probabilidade resultado de interesse e condição73:\\[\\begin{eqnarray}\r\n&& P(\\text{adolescente faculdade | pais graduado})  \\\\\r\n&& = P(\\text{adolescente faculdade}\\ |\\ \\text{pais graduado}) = \\frac{231}{280} = 0.825\r\n\\tag{2.8}\r\n\\end{eqnarray}\\]Na Equação (2.8), calculamos probabilidade de um adolescente frequentar faculdade com base na condição de que pelo menos um dos pais tenha um diploma universitário como uma fração:\\[\\begin{eqnarray}\r\n&& P(\\text{adolescente faculdade} | \\text{pais graduado}) \\\\\r\n&&\\quad = \\frac{\\text{\\# casos onde adolescente faculdade e pais graduado}}{\\text{\\# casos onde pais graduado}} \\\\\r\n&&\\quad = \\frac{231}{280} = 0.825 \\notag\r\n\\tag{2.9}\r\n\\end{eqnarray}\\]Consideramos apenas os casos que preenchiam condição, pais graduado e, em seguida, calculamos proporção dos casos que satisfizeram nosso resultado de interesse, o adolescente cursou faculdade.Frequentemente, probabilidades marginais e conjuntas são fornecidas em vez de dados de contagem. Por exemplo, taxas de doenças são comumente listadas em porcentagens, e não em um formato de contagem. Gostaríamos de poder computar probabilidades condicionais mesmo quando não há contagens disponíveis, e usamos Equação(2.9) como um modelo para entender essa técnica.Consideramos apenas os casos que satisfizeram condição, pais graduado. Destes casos, probabilidade condicional foi fração que representou o desfecho de interesse, adolescente faculdade. Suponha que nos foram fornecidas apenas informações na Tabela 2.4, isto é, apenas dados de probabilidade. Então, se pegássemos uma amostra de 1000 pessoas, anteciparíamos cerca de 35% ou \\(0.35\\times 1000 = 350\\) satisfariam o critério de informação (pais graduado). Da mesma forma, seria de esperar cerca de 29% ou \\(0.29\\times 1000 = 290\\) para atender aos critérios de informação e representar nosso resultado de interesse. Então probabilidade condicional pode ser computada como:\\[\\begin{align}\r\n&P(\\text{adolescente faculdade} | \\text{pais graduado})  \\\\\r\n    &= \\frac{\\text{\\# (adolescente faculdade e pais graduado)}}{\\text{\\# (pais graduado)}}  \\\\\r\n    &= \\frac{290}{350}\r\n        = \\frac{0.29}{0.35}\r\n        = 0.829\\quad\\text{( diferente de 0.825 devido erro de arredondamento)}\r\n\\tag{2.10}\r\n\\end{align}\\]Na Equação (2.10), nós examinamos exatamente fração de duas probabilidades, 0.29 e 0.35, que podemos escrever como\\[\\begin{align*}\r\nP(\\text{adolescente faculdade e pais graduado})\r\n    \\quad\\text{e}\\quad\r\n    P(\\text{pais graduado}).\r\n\\end{align*}\\]fração dessas probabilidades é um exemplo da fórmula geral para probabilidade condicional.Probabilidade condicional:  probabilidade condicional resultado evento \\(\\) dada condição \\(B\\) é calculada como o seguinte:\\[\\begin{align}\r\nP(| B) = \\frac{P(\\text{ e }B)}{P(B)}\r\n\\tag{2.11}\r\n\\end{align}\\]Prática Orientada 2.21  () Escreva seguinte declaração em notação de probabilidade condicional: probabilidade de um caso aleatório em que nenhum dos pais tem um diploma universitário, se é sabido que o adolescente não frequentou faculdade logo após o ensino médio. Observe que condição agora é baseada adolescente, não nos pais.Determinar probabilidade de parte (). Tabela 2.4 pode ser útil.74\r\nPrática Orientada 2.22  () Determinar probabilidade de um dos pais ter um diploma universitário, se se sabe que o adolescente não frequentou faculdade.Usando respostas da parte () e Prática Orientada 2.21 (b), calcule \\(P(\\text{pais graduado | adolescente não}) + P(\\text{pais não | adolescente não})\\)Usando respostas da parte () e Prática Orientada 2.21 (b), calcule \\(P(\\text{pais graduado | adolescente não}) + P(\\text{pais não | adolescente não})\\)Forneça um argumento intuitivo para explicar por que soma de (b) é 1.75\r\nForneça um argumento intuitivo para explicar por que soma de (b) é 1.75","code":""},{"path":"ch2-prob.html","id":"boston1721","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.3 Varíola em Boston, 1721","text":"O conjunto de dados varíola fornece uma amostra de 6.224 pessoas partir ano de 1721 que foram expostas à varíola em Boston.77 Os médicos da época acreditavam que inoculação, que envolve exposição de uma pessoa à doença de forma controlada, poderia reduzir probabilidade de morte.Cada caso representa uma pessoa com duas variáveis: inoculada e resultado. variável inoculada leva dois níveis: sim ou não, indicando se pessoa foi inoculada ou não. variável resultado tem resultados viveu ou morreu. Estes dados estão resumidos nas Tabelas 2.6 e 2.7.Tabela 2.6: Tabela de contingência para o conjunto de dados varíolaTabela 2.7: Proporções da tabela para os dados de varíola, calculados dividindo cada contagem pelo total da tabela, 6224.Prática Orientada 2.26  pessoas de Boston se auto-selecionaram se deveriam ou não ser inoculadas.Este estudo é observacional ou foi uma experiência?Este estudo é observacional ou foi uma experiência?Podemos inferir qualquer conexão causal usando esses dados?Podemos inferir qualquer conexão causal usando esses dados?Quais são algumas possíveis variáveis de confusão que podem influenciar se alguém viveu ou morreu e também afeta se essa pessoa foi inoculada?80\r\nQuais são algumas possíveis variáveis de confusão que podem influenciar se alguém viveu ou morreu e também afeta se essa pessoa foi inoculada?80","code":"\ntab6 <- cbind(c(238, 6, 244), c(5136, 844, 5980), c(5374, 850, 6224))\ncolnames(tab6) <- c('inoculado: sim', 'inoculado: não', 'Total')\nrownames(tab6) <- c('resultado: viveu', 'resultado: morreu', 'Total')\n\nknitr::kable(tab6, align = 'c', caption = 'Tabela de contingência para o conjunto de dados varíola')\ntab7 <- cbind(c(238/6224, 6/6224, 244/6224), \n              c(5136/6224, 844/6224, 5980/6224), \n              c(5374/6224, 850/6224, 6224/6224))\n\ncolnames(tab7) <- c('inoculado: sim', 'inoculado: não', 'Total')\nrownames(tab7) <- c('resultado: viveu', 'resultado: morreu', 'Total')\n\nknitr::kable(round(tab7, 4), align = 'c', caption = 'Proporções da tabela para os dados de varíola, calculados dividindo cada contagem pelo total da tabela, 6224.')"},{"path":"ch2-prob.html","id":"generalRuleMultiplication","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.4 Regra geral da multiplicação","text":"Seção 2.1.6 introduziu regra da multiplicação para processos independentes. Aqui nós fornecemos Regra Geral de Multiplicação para eventos que podem não ser independentes.Regra Geral de Multiplicação:  Se \\(\\) e \\(B\\) representam dois resultados ou eventos, então\\[\\begin{eqnarray*}\r\nP(\\text{ e }B) = P(| B)\\times P(B)\r\n\\end{eqnarray*}\\]É útil pensar em \\(\\) como resultado de interesse e \\(B\\) como condição.Esta Regra Geral de Multiplicação é simplesmente um rearranjo da definição de probabilidade condicional na Equação (2.11).Exemplo 2.10  Considere o conjunto de dados varíola. Suponha que nos sejam dadas apenas duas informações: 96,08% dos residentes não foram inoculados e 85,88% dos residentes que não foram inoculados acabaram por sobreviver. Como poderíamos calcular probabilidade de um residente não ter sido inoculado e vivido?Nós calcularemos nossa resposta usando regra de multiplicação geral e, em seguida, verificá-la usando Tabela 2.7. Queremos determinar\\[\\begin{eqnarray*}\r\nP(\\text{resultado = viveu e inoculado = não})\r\n\\end{eqnarray*}\\]e nos é dado que\\[\\begin{eqnarray*}\r\nP(\\text{resultado = viveu | inoculado = não})=0,8588 \\\\\r\nP(\\text{inoculado = não})=0,9608\r\n\\end{eqnarray*}\\]Entre os 96,08% de pessoas que não foram inoculadas, 85,88% sobreviveram:\\[\\begin{eqnarray*}\r\nP(\\text{resultado = viveu e inoculado = não}) = 0,8588 \\times 0,9608 = 0,8251\r\n\\end{eqnarray*}\\]Soma das probabilidades condicionais:  Vamos representar \\(A_1, \\dots, A_k\\) todos os resultados disjuntos para uma variável ou processo. Então, se \\(B\\) é um evento, possivelmente para outra variável ou processo, temos:\\[\\begin{eqnarray*}\r\nP(A_1|B)+\\cdots+P(A_k|B) = 1\r\n\\end{eqnarray*}\\]regra para complementos também é válida quando um evento e seu complemento são condicionados à mesma informação:\\[\\begin{eqnarray*}\r\nP(| B) = 1 - P(^c | B)\r\n\\end{eqnarray*}\\]","code":""},{"path":"ch2-prob.html","id":"indConsiderationsCondProb","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.5 Considerações de independência em probabilidade condicional","text":"Se dois eventos são independentes, saber o resultado de um não deve fornecer informações sobre o outro. Nós podemos mostrar que isso é matematicamente verdadeiro usando probabilidades condicionais.Prática Orientada 2.30  Vamos representar \\(X\\) e \\(Y\\) como resultados de jogar dois dados.84Qual é probabilidade de que \\(X\\) seja 1?Qual é probabilidade de que \\(X\\) seja 1?Qual é probabilidade de que tanto \\(X\\) quanto \\(Y\\) sejam 1?Qual é probabilidade de que tanto \\(X\\) quanto \\(Y\\) sejam 1?Use fórmula para probabilidade condicional para calcular \\(P(Y = 1\\ | X = 1)\\).Use fórmula para probabilidade condicional para calcular \\(P(Y = 1\\ | X = 1)\\).O que é \\(P(Y=1)\\)? Isso é diferente da resposta da parte (c)? Explique.\r\nO que é \\(P(Y=1)\\)? Isso é diferente da resposta da parte (c)? Explique.Podemos mostrar na Prática Orientada 2.30(c) que informação de condicionamento não tem influência usando Regra de Multiplicação para processos independentes:\\[\\begin{eqnarray*}\r\nP(Y=\\text{1}\\ |\\ X=\\text{1})\r\n    &=& \\frac{P(Y=\\text{1 e }X=\\text{1})}{P(X=\\text{1})} \\\\\r\n    &=& \\frac{P(Y=\\text{1})\\times P(X=\\text{1})}{P(X=\\text{1})} \\\\\r\n    &=& P(Y=\\text{1}) \\\\\r\n\\end{eqnarray*}\\]","code":""},{"path":"ch2-prob.html","id":"treeDiagram","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.6 Diagramas de árvore","text":"Diagramas de árvore são uma ferramenta para organizar resultados e probabilidades em torno da estrutura dos dados. Eles são mais úteis quando dois ou mais processos ocorrem em uma sequência e cada processo é condicionado em seus predecessores.O varíola se encaixa nessa descrição. Nós vemos população dividida por inoculação: sim e não. Após esta divisão, taxas de sobrevivência foram observadas para cada grupo. Essa estrutura é refletida diagrama de árvore mostrado na Figura 2.9. O primeiro ramo para inoculação é dito ser o ramo primário enquanto os outros ramos são secundários.\r\nFigura 2.9: Um diagrama de árvore conjunto de dados varíola\r\nOs diagramas de árvore são anotados com probabilidades marginais e condicionais, como mostrado na Figura 2.9. Este diagrama de árvore divide os dados de varíola por inoculação nos grupos sim e não com respectivas probabilidades marginais de 0.0392 e 0.9608. ramificações secundárias são condicionadas na primeira, portanto, atribuímos probabilidades condicionais essas ramificações. Por exemplo, o ramo superior na Figura 2.9 é probabilidade de que resultado = viveu condicionado à informação de que inoculado = sim. Podemos (e geralmente) construir probabilidades conjuntas final de cada ramo em nossa árvore, multiplicando os números que encontramos enquanto nos movemos da esquerda para direita. Estas probabilidades conjuntas são calculadas usando Regra Geral de Multiplicação:\\[\\begin{eqnarray*}\r\n&& P(\\text{inoculado = sim e resultado = viveu}) \\\\\r\n    &&\\quad = P(\\text{inoculado = sim})\\times P(\\text{resultado = viveu}|\\text{inoculado = sim}) \\\\\r\n    &&\\quad = 0,0392\\times 0,9754=0,0382\r\n\\end{eqnarray*}\\]O objetivo final é encontrar \\(P(\\text{parcial = } | \\text{final = })\\). Para calcular essa probabilidade condicional, precisamos das seguintes probabilidades:\\[\\begin{eqnarray*}\r\nP(\\text{parcial = e final = }) \\qquad\\text{e}\\qquad\r\nP(\\text{final = })\r\n\\end{eqnarray*}\\]entanto, essas informações não são fornecidas e não é óbvio como calcular essas probabilidades. Como não temos certeza de como proceder, é útil organizar informações em um diagrama de árvore, como mostrado na Figura 2.10. Ao construir um diagrama de árvore, variáveis fornecidas com probabilidades marginais são freqüentemente usadas para criar os ramos primários da árvore; Nesse caso, probabilidades marginais são fornecidas para os graus intermediários. notas finais, que correspondem às probabilidades condicionais fornecidas, serão mostradas nos ramos secundários.\r\nFigura 2.10: Um diagrama de árvora descrevendo variáveis parcial e final.\r\nCom o diagrama de árvore construído, podemos calcular probabilidades necessárias:\\[\\begin{eqnarray*}\r\n&&P(\\text{parcial = e final = }) = 0,0611 \\\\\r\n&&P(\\text{final = })  \\\\\r\n&& \\quad= P(\\text{parcial = \\resp{outra} e final = }) + P(\\text{parcial = e final = }) \\\\\r\n&& \\quad= 0,0957 + 0,0611  = 0,1568\r\n\\end{eqnarray*}\\]probabilidade marginal, \\(P(\\text{final = })\\), foi calculado somando todas probabilidades conjuntas lado direito da árvore que correspondem final = . Podemos agora finalmente pegar razão das duas probabilidades:\\[\\begin{eqnarray*}\r\nP(\\text{parcial = } | \\text{final = }) &=& \\frac{P(\\text{parcial = e final = })}{P(\\text{final = })} \\\\\r\n&=& \\frac{0,0611}{0,1568} = 0,3897\r\n\\end{eqnarray*}\\]probabilidade de o aluno também ganhar um meio ano é de cerca de 0,39.Prática Orientada 2.32  Após um curso de estatística introdutória, 78% dos alunos podem construir com sucesso diagramas de árvore. Daqueles que podem construir diagramas de árvores, 97% foram aprovados, enquanto apenas 57% dos alunos que não puderam construir diagramas de árvores foram aprovados.86Organize esta informação em um diagrama de árvore.Organize esta informação em um diagrama de árvore.Qual é probabilidade de um aluno selecionado aleatoriamente passar?Qual é probabilidade de um aluno selecionado aleatoriamente passar?(c)Computar probabilidade de um aluno ser capaz de construir um diagrama de árvore, se é sabido que ele passou.","code":"\nlibrary(openintro)\n\ntreeDiag(c('Inoculated', 'Result'),\n         c(0.0392, 0.9608),\n         list(c(0.9754, 0.0246),\n              c(0.8589, 0.1411)),\n         textwd = 0.2,\n         solwd = 0.35,\n         cex.main = 1.4,\n         c('yes', 'no'),\n         c('lived', 'died'),\n         digits = 5,\n         col.main = COL[1],\n         showWork = TRUE)\nlibrary(openintro)\n\ntreeDiag(c('Midterm', 'Final'),\n         c(0.13, 0.87),\n         list(c(0.47, 0.53),\n              c(0.11, 0.89)),\n         textwd = 0.2,\n         solwd = 0.35,\n         cex.main = 1.4,\n         c('A', 'other'),\n         c('A', 'other'),\n         digits = 5,\n         col.main = COL[1],\n         showWork = TRUE)"},{"path":"ch2-prob.html","id":"bayesTheoremSubsection","chapter":"2 Probabilidade (tópico especial)","heading":"2.2.7 Teorema de Bayes","text":"Em muitos casos, nos é dada uma probabilidade condicional da forma\\[\\begin{align*}\r\nP(\\text{ declaração sobre variável 1} | \\text{ declaração sobre variável 2})\r\n\\end{align*}\\]mas nós realmente gostaríamos de saber probabilidade condicional invertida:\\[\\begin{align*}\r\nP(\\text{ declaração sobre variável 2} | \\text{ declaração sobre variável 1})\r\n\\end{align*}\\]Diagramas de árvore podem ser usados para encontrar segunda probabilidade condicional quando dada primeira. entanto, às vezes, não é possível desenhar o cenário em um diagrama de árvore. Nestes casos, podemos aplicar uma fórmula muito útil e geral: o Teorema de Bayes.Primeiramente, examinamos criticamente um exemplo de inversão de probabilidades condicionais em que ainda aplicamos um diagrama de árvore.\r\nFigura 2.11: Diagrama de árvore para o Exemplo acima, calculando probabilidade de um paciente aleatório que testa positivo em uma mamografia realmente ter câncer de mama.\r\nObserve que nos é dada informação suficiente para calcular rapidamente probabilidade de testes positivos se uma mulher tiver câncer de mama ($ 1.00-0.11 = 0.89 $). entanto, buscamos probabilidade invertida: de câncer, dado um resultado positivo. (Cuidado com linguagem médica não intuitiva: um resultado positivo}teste sugere possível presença de câncer em um rastreamento mamográfico.) Esta probabilidade invertida pode ser dividida em dois pedaços:\\[\\begin{align*}\r\nP(\\text{tem CM  |  mamografia}^+) = \\frac{P(\\text{ tem CM e mamografia}^+)}{P(\\text{ mamografia}^+)}\r\n\\end{align*}\\]onde tem CM é uma abreviação para o paciente realmente ter câncer de mama e mamografia\\(^+\\) significa que o rastreio da mamografia foi positivo. Um diagrama em árvore é útil para identificar cada probabilidade e é mostrado na Figura 2.11. probabilidade de o paciente ter câncer de mama e mamografia ser positiva é\\[\\begin{align*}\r\nP(\\text{ tem CM e mamografia}^+) &= P(\\text{ mamografia}^+ | \\text{ tem CM})P(\\text{tem CM}) \\\\\r\n    &= 0,89\\times 0,0035 = 0,00312\r\n\\end{align*}\\]probabilidade de um resultado de teste positivo é soma dos dois cenários correspondentes:\\[\\begin{align*}\r\nP(\\text{mamografia}^+) &= P(\\text{mamografia}^+ \\text{e tem CM}) + P(\\text{mamografia}^+ \\text{e sem CM}) \\\\\r\n    &= P(\\text{tem CM})P(\\text{mamografia}^+ | \\text{ tem CM}) \\\\\r\n    &\\qquad\\qquad   + P(\\text{sem CM})P(\\text{mamografia}^+ | \\text{ sem CM}) \\\\\r\n    &= 0,0035\\times 0,89 + 0,9965\\times 0,07 = 0,07288\r\n\\end{align*}\\]Então, se triagem mamográfica positiva para um paciente, probabilidade de o paciente ter câncer de mama é\\[\\begin{align*}\r\nP(\\text{tem CM } | \\text{ mamografia}^+)\r\n    &= \\frac{P(\\text{tem CM e mamografia} ^+)}{P(\\text{mamografia}^+)}\\\\\r\n    &= \\frac{0.00312}{0.07288} \\approx 0.0428\r\n\\end{align*}\\]Ou seja, mesmo que um paciente tenha uma triagem mamográfica positiva, ainda há apenas uma chance de 4% que ela tenha câncer de mama.O Exemplo 2.12 destaca por que os médicos geralmente realizam mais testes, independentemente primeiro resultado positivo teste. Quando uma condição médica é rara, um único teste positivo geralmente não é definitivo.Considere novamente última equação Exemplo 2.12.\r\nUsando o diagrama de árvore, podemos ver que o numerador (o topo da fração) é igual ao seguinte produto:\\[\\begin{align*}\r\nP(\\text{tem CM e mamografia}^+) = P(\\text{mamografia}^+ | \\text{ tem CM})P(\\text{tem CM})\r\n\\end{align*}\\]O denominador – probabilidade de o rastreamento ser positivo – é igual à soma das probabilidades para cada cenário de rastreamento positivo:\\[\\begin{align*}\r\nP(\\text{mamografia}^+)\r\n    &= P(\\text{mamografia}^+\\text{ e sem CM})\r\n        + P(\\text{mamografia}^+\\text{ e tem CM})\r\n\\end{align*}\\]exemplo, cada uma das probabilidades lado direito foi dividida em um produto de uma probabilidade condicional e probabilidade marginal usando o diagrama de árvore.\\[\\begin{align*}\r\nP(\\text{mamografia}^+)\r\n&= P(\\text{mamografia}^+\\text{ e sem CM}) + P(\\text{mamografia}^+\\text{ e tem CM}) \\\\\r\n&= P(\\text{mamografia}^+ | \\text{ sem CM})P(\\text{sem CM}) + P(\\text{mamografia}^+ | \\text{ tem CM})P(\\text{tem CM})\r\n\\end{align*}\\]Podemos ver uma aplicação Teorema de Bayes substituindo expressões de probabilidade resultantes numerador e denominador da probabilidade condicional original.\\[\\begin{align*}\r\n& P(\\text{tem CM } | \\text{ mamografia}^+)\r\n= \\frac{P(\\text{mamografia}^+ | \\text{ tem CM})P(\\text{tem CM})}\r\n    {P(\\text{mamografia}^+ | \\text{ sem CM})P(\\text{sem CM}) + P(\\text{mamografia}^+ | \\text{ tem CM})P(\\text{tem CM})}\r\n\\end{align*}\\]Teorema de Bayes: invertendo probabilidades:  Considere seguinte probabilidade condicional para variável 1 e variável 2:\\[\\begin{align*}\r\nP(\\text{ resultado }A_1\\text{ da variável 1} | \\text{ resultado B da variável 2})\r\n\\end{align*}\\]O Teorema de Bayes afirma que essa probabilidade condicional pode ser identificada como seguinte fração:\\[\\begin{align}\r\n\\frac{P(B | A_1) P(A_1)}\r\n    {P(B | A_1) P(A_1) + P(B | A_2) P(A_2) + \\cdots + P(B | A_k) P(A_k)}\r\n    \\tag{2.12}\r\n\\end{align}\\]onde \\(A_2, A_3, \\dots, A_k\\) representam todos os outros resultados possíveis da primeira variável.O Teorema de Bayes é apenas uma generalização que fizemos usando diagramas de árvores. O numerador identifica probabilidade de obter \\(A_1\\) e \\(B\\). O denominador é probabilidade marginal de obter \\(B\\). Este componente inferior da fração parece longo e complicado, uma vez que temos que somar probabilidades de todas maneiras diferentes para obter \\(B\\). Nós sempre completamos este passo quando usamos diagramas de árvores. entanto, nós geralmente fizemos isso em uma etapa separada para que não parecesse tão complexo.Para aplicar o Teorema de Bayes corretamente, existem duas etapas preparatórias:Primeiro, identifique probabilidades marginais de cada resultado possível da primeira variável: \\(P(A_1), P(A_2), \\dots, P(A_k)\\).Primeiro, identifique probabilidades marginais de cada resultado possível da primeira variável: \\(P(A_1), P(A_2), \\dots, P(A_k)\\).Em seguida, identifique probabilidade resultado \\(B\\), condicionada em cada cenário possível para primeira variável: \\(P(B | A_1), P(B | A_2), \\dots, P(B | A_k)\\).Em seguida, identifique probabilidade resultado \\(B\\), condicionada em cada cenário possível para primeira variável: \\(P(B | A_1), P(B | A_2), \\dots, P(B | A_k)\\).Uma vez que cada uma dessas probabilidades sejam identificadas, elas podem ser aplicadas diretamente dentro da fórmula.Dica: Use somente o Teorema de Bayes quando os diagramas de árvore são difíceis:  Desenhar um diagrama de árvore facilita compreensão de como duas variáveis estão conectadas. Use o Teorema de Bayes somente quando houver muitos cenários que desenhar um diagrama de árvore seria complexo.O resultado interesse é saber se há um evento esportivo (ligue para esse valor de \\(A_1\\)) e condição é que o lote esteja cheio (\\(B\\)). Deixe \\(A_2\\) representar um evento acadêmico e \\(A_3\\) representam não haver evento campus. Então probabilidades dadas podem ser escritas como\\[\\begin{align*}\r\n&P(A_1) = 0,2 &&P(A_2) = 0,35 &&P(A_3) = 0,45 \\\\\r\n&P(B | A_1) = 0,7 &&P(B | A_2) = 0,25 &&P(B | A_3) = 0,05\r\n\\end{align*}\\]Teorema de Bayes pode ser usado para calcular probabilidade de um evento esportivo (\\(A_1\\)) sob condição de que o estacionamento esteja cheio (\\(B\\)):\\[\\begin{align*}\r\nP(A_1 | B) &= \\frac{P(B | A_1) P(A_1)}{P(B | A_1) P(A_1) + P(B | A_2) P(A_2) + P(B | A_3) P(A_3)} \\\\\r\n        &= \\frac{(0,7)(0,2)}{(0,7)(0,2) + (0,25)(0,35) + (0,05)(0,45)} \\\\\r\n        &= 0.56 \r\n\\end{align*}\\]Com base nas informações de que garagem está cheia, há uma probabilidade de 56% de que um evento esportivo seja realizado campus naquela noite.Os últimos exercícios ofereceram uma maneira de atualizar nossa crença sobre se há um evento esportivo, um evento acadêmico ou nenhum evento acontecendo na escola com base nas informações de que o estacionamento estava lotado. Essa estratégia de atualizar crenças usando o Teorema de Bayes é, na verdade, base de toda uma seção de estatísticas chamada de Estatística Bayesiana. Embora estatísticas bayesianas sejam muito importantes e úteis, não teremos tempo para abordar muito mais delas neste livro.","code":"\nlibrary(openintro)\n\ntreeDiag(c('Truth', 'Mammogram'),\n         c(0.0035, 0.9965),\n         list(c(0.89, 0.11),\n              c(0.07, 0.93)),\n         textwd = 0.2,\n         solwd = 0.35,\n         cex.main = 1.4,\n         c('cancer', 'no cancer'),\n         c('positive','negative'),\n         digits = 5,\n         col.main = COL[1],\n         showWork = TRUE)"},{"path":"ch2-prob.html","id":"smallPop","chapter":"2 Probabilidade (tópico especial)","heading":"2.3 Amostragem de uma população pequena (tópico especial)","text":"Se há 15 pessoas para perguntar, então probabilidade é \\(1/15\\), ou \\(0.067\\).Para primeira pergunta, ele escolherá outra pessoa com probabilidade de \\(14/15\\). Quando ele faz segunda pergunta, ela só tem 14 pessoas que ainda não foram perguntadas. Assim, se você não foi escolhido na primeira pergunta, probabilidade de você não ser novamente escolhido é \\(13/14\\). Da mesma forma, probabilidade de você não ser novamente escolhido na terceira pergunta é de \\(12/13\\), e probabilidade de não ser escolhido para qualquer uma das três perguntas é\\[\\begin{eqnarray*}\r\n&&P(\\text{não chamoar em 3 perguntas}) = P(\\text{Q1} = \\text{não escolhido}, \\text{Q2} = \\text{não escolhido}, \\text{Q3} = \\text{não escolhido}) \\\\\r\n&&\\quad = \\frac{14}{15}\\times\\frac{13}{14}\\times\\frac{12}{13} = \\frac{12}{15} = 0.80\r\n\\end{eqnarray*}\\]Cada escolha é independente e probabilidade de não ser escolhido para qualquer questão individual é de \\(14/15\\). Assim, podemos usar regra de multiplicação para processos independentes.\\[\\begin{eqnarray*}\r\n&&P(\\text{ não pegou em 3 perguntas}) \\\\\r\n&&\\quad = P(\\text{Q1} = \\text{não escolhido}, \\text{Q2} = \\text{não escolhido}, \\text{Q3} = \\text{não escolhido}.) \\\\\r\n&&\\quad = \\frac{14}{15}\\times\\frac{14}{15}\\times\\frac{14}{15} = 0,813\r\n\\end{eqnarray*}\\]Você tem uma chance um pouco maior de não ser escolhida em comparação quando ela escolheu uma nova pessoa para cada pergunta. entanto, você agora pode ser escolhido mais de uma vez.Se nós provamos de uma pequena população sem reposição, nós não temos mais independência entre nossas observações. Exemplo 2.15, probabilidade de não ser escolhido para segunda questão estava condicionada ao fato de você não ter sido escolhido para primeira questão. Exemplo 2.16, professora escolheu seus alunos com substituição: ela repetidamente escolheu entre turma inteira sem considerar quem ela já havia escolhido.Prática Orientada 2.38  Seu departamento está sorteando uma rifa. Eles vendem 30 ingressos e oferecem sete prêmios.Colocam os ingressos em um chapéu e pegam um para cada prêmio. Os bilhetes são amostrados sem substituição, ou seja, os bilhetes selecionados não são colocados de volta chapéu. Qual é probabilidade de ganhar um prêmio se você comprar um ingresso?Colocam os ingressos em um chapéu e pegam um para cada prêmio. Os bilhetes são amostrados sem substituição, ou seja, os bilhetes selecionados não são colocados de volta chapéu. Qual é probabilidade de ganhar um prêmio se você comprar um ingresso?E se os bilhetes forem amostrados com substituição?93\r\nE se os bilhetes forem amostrados com substituição?93Se tivéssemos repetido Prática Orientada 2.38 com 300 tíquetes em vez de 30, teríamos encontrado algo interessante: os resultados seriam quase idênticos. probabilidade seria 0,0233 sem reposição e 0,0231 com reposição. Quando o tamanho da amostra é apenas uma pequena fração da população (abaixo de 10%), observações são quase independentes, mesmo quando amostragem é feita sem reposição.","code":""},{"path":"ch2-prob.html","id":"randomVariablesSection","chapter":"2 Probabilidade (tópico especial)","heading":"2.4 Variáveis aleatórias (tópico especial)","text":"Cerca de 20 alunos não compram nenhum livro (0 livros total), cerca de 55 compram um livro (55 livros total) e cerca de 25 compram dois livros (totalizando 50 livros para estes 25 alunos). livraria deve vender cerca de 105 livros para esta classe.Cerca de 55 alunos irão apenas comprar um livro didático, fornecendo receita de\\[\\begin{eqnarray*}\r\n\\$137 \\times  55 = \\$7.535\r\n\\end{eqnarray*}\\]Cerca de 25 alunos que compram o livro didático e o guia de estudo pagariam um total de\\[\\begin{eqnarray*}\r\n(\\$137 + \\$33) \\times  25 = \\$170 \\times  25 = \\$4,250\r\n\\end{eqnarray*}\\]Assim, livraria deve gerar cerca de \\(\\$7.535 + \\$4.250 = \\$11.785\\) desses 100 alunos para essa classe. entanto, pode haver alguma variabilidade de amostragem para que quantidade real possa diferir um pouco.\r\nFigura 2.12: Distribuição de probabilidade para receita da livraria de um único aluno. distribuição se equilibra em um triângulo representando receita média por estudante.\r\nreceita total esperada é de $11.785 e há 100 alunos. Portanto, receita esperada por aluno é \\(\\$11,785/100 = \\$117.85\\).","code":"\nlibrary(openintro)\ndata(COL)\n\nmake.bar <- function(at,\n                     height,\n                     thickness = NA,\n                     col = NA) {\n  if(is.na(thickness)){\n    R <- range(at)\n    minDiff <- min(diff(at))\n    thickness <- min(minDiff, diff(R) / 12)\n  }\n  x1 <- at - thickness / 2\n  x2 <- at + thickness / 2\n  if(is.na(col)) {\n    col <- 'grey'\n  }\n  for (i in 1:length(at)) {\n    rect(x1[i], 0,\n         x2[i], height[i],\n         col = col)\n  }\n}\n\nprobDist <- function(x,\n                     prob,\n                     labels1 = NA,\n                     labels2 = NA,\n                     thickness = NA,\n                     col = NA,\n                     ylim = NULL,\n                     ...) {\n  R <- range(x)\n  R <- R + c(-1, 1) * diff(R)/20\n  Ry <- c(0, range(prob)[2])\n  if(!is.null(ylim)[1]){\n    Ry <- ylim\n  }\n  plot(x, prob,\n       type = 'n',\n       axes = FALSE,\n       xlim = R,\n       ylim = Ry,\n       ...)\n  if (is.na(labels1)[1]) {\n    labels1 <- x\n  }\n  if (is.na(labels2)[1]) {\n    labels2 <- TRUE\n  }\n  axis(1, at = x, labels = labels1)\n  make.bar(x, prob, thickness = thickness, col = col)\n}\n\nat <- c(0, 137, 170)\nprob <- c(0.2, .55, .25)\n\npar(mar = c(2.9, 4, 0.1, 0.5),\n    mgp = c(1.7, 0.7, 0))\nprobDist(at, prob,\n         xlab = 'Cost (US Dollars)',\n         ylab = '',\n         ylim = c(-0.02, 0.55),\n         col = COL[1])\naxis(2, at = seq(0,0.5, 0.1))\nlines(c(-10, 180), c(0,0))\npolygon(117.85 + c(-17, 17, 0),\n        c(-0.08, -0.08, 0),\n        col = COL[4])\npar(las = 0)\nmtext('Probability', side = 2, line = 2.8)"},{"path":"ch2-prob.html","id":"expectation","chapter":"2 Probabilidade (tópico especial)","heading":"2.4.1 Experança","text":"Chamamos uma variável ou processo com um resultado numérico de variável aleatória, e geralmente representamos essa variável aleatória com uma letra maiúscula, como \\(X\\), \\(Y\\) ou \\(Z\\). quantidade de dinheiro que um único aluno gastará em seus livros de estatística é uma variável aleatória, e nós representamos por \\(X\\).Variável aleatória:  Um processo aleatório ou variável com um resultado numérico.Os possíveis resultados de \\(X\\) são rotulados com uma letra minúscula correspondente \\(x\\) e subscritos. Por exemplo, nós escrevemos \\(x_1=\\$0\\), \\(x_2=\\$137\\), e \\(x_3=\\$170\\), que ocorrem com probabilidades de \\(0,20\\), \\(0,55\\) e \\(0,25\\). distribuição de \\(X\\) é resumida na Figura 2.12 e Tabela 2.8.Tabela 2.8: distribuição de probabilidade para variável aleatória X, representando receita da livraria de um único aluno.Calculamos o resultado médio de \\(X\\) como $117,85 Exemplo 2.19. Chamamos essa média de valor esperado de \\(X\\), denotado por \\(E(X)\\). O valor esperado de uma variável aleatória é calculado adicionando cada resultado ponderado por sua probabilidade:\\[\\begin{align*}\r\nE(X) &= 0 \\times  P(X=0) + 137 \\times  P(X=137) + 170 \\times  P(X=170) \\\\\r\n    &= 0 \\times  0.20 + 137 \\times  0.55 + 170 \\times  0.25 = 117.85\r\n\\end{align*}\\] Valor esperado de uma variável aleatória discreta:  Se \\(X\\) tiver resultados \\(x_1, \\dots, x_k\\) com probabilidades \\(P(X=x_1),\\dots, P(X=x_k)\\), o valor esperado de \\(X\\) é soma de cada resultado multiplicado por sua probabilidade correspondente:\\[\\begin{align}\r\nE(X)    &= x_1\\times P(X=x_1) + \\cdots + x_k\\times P(X=x_k) \\notag \\\\\r\n    &= \\sum_{=1}^{k}x_iP(X=x_i)\r\n\\end{align}\\]letra grega \\(\\mu\\) pode ser usado lugar da notação \\(E(X)\\).O valor esperado de uma variável aleatória representa o resultado médio. Por exemplo, \\(E(X) = 117,85\\) representa o valor médio que livraria espera fazer de um único aluno, que também poderíamos escrever como \\(\\mu=117.85\\).Também é possível calcular o valor esperado de uma variável aleatória contínua (veja Seção 2.5. entanto, requer um pouco de cálculo e nós o salvamos para uma aula posterior.96Na física, esperança tem o mesmo significado que o centro de gravidade. distribuição pode ser representada por uma série de pesos em cada resultado e média representa o ponto de equilíbrio. Isso é representado nas Figuras 2.12 e 2.13. ideia de um centro de gravidade também se expande para distribuições de probabilidade contínuas. Figura 2.14 mostra uma distribuição de probabilidade contínua equilibrada sobre uma cunha colocada na média.\r\nFigura 2.13: Um sistema de pesos representando distribuição de probabilidade para \\(X\\). corda mantém distribuição na média para manter o sistema balanceado.\r\n\r\nFigura 2.14: Uma distribuição contínua também pode ser balanceada em sua média.\r\n","code":"\ntab8 <- rbind(c('$0', '$137', '$170', '-'), \n              c(0.20, 0.55, 0.25, 1.00))\n\ncolnames(tab8) <- c(1:3, 'Total')\nrownames(tab8) <- c('i', 'P(X = xi)')\n\nknitr::kable(tab8, align = 'c', caption = 'A distribuição de probabilidade para a variável aleatória X, representando a receita da livraria de um único aluno.')\nlibrary(openintro)\ndata(COL)\n\nat <- c(0, 137, 170)\nwt <- c(0.2, 0.55, 0.25)\n\ncreateWtSystem <- function(at, wt, size = 1, label = TRUE){\n  R <- range(at)\n  r <- diff(R)\n  W <- range(wt)\n  M <- weighted.mean(at, wt)\n  par(mar = rep(0, 4))\n  plot(R + c(-1, 1) * r / 12,\n       0:1,\n       type = 'n')\n\n  # make hanger\n  x <- c(M, M)\n  y <- c(0.7, 1.0)\n  lines(x, y)\n\n  # make the board\n  rect(R[1],0.685,R[2],0.7)\n\n  # add weights\n  for(i in 1:length(at)) {\n    createWt(at[i],wt[i], size)\n  }\n\n  # label\n  if(label){\n    text(at, rep(0.74, length(at)), at)\n    text(M, 0.64, M)\n  }\n}\n\ncreateWt <- function(at, wt, size = 1){\n  # hook\n  x <- rep(at, 2)\n  y <- c(0.64, 0.6925)\n  lines(x, y)\n\n  # the weight\n  x <- x + c(-1, 1) * size\n  y <- c(0.64, 0.64 - wt)\n  rect(x[1], y[1],\n       x[2], y[2],\n       col = COL[1])\n}\n\ncreateWtSystem(at, wt, 5, TRUE)\nlibrary(openintro)\ndata(COL)\n\nx <- seq(0, 22, 0.01)\ny <- dchisq(x, 5)\nM <- weighted.mean(x, y)\n\npar(mar = c(1.65, 0, 0, 0), mgp = c(5, 0.5, 0))\nplot(x, y + 0.035,\n     type = 'l',\n     ylim = range(c(0.025, y + 0.035)),\n     axes = FALSE)\naxis(1, at = c(-100, M, 100), labels = c('', expression(mu), ''))\nlines(c(0, 22), rep(0.035, 2))\npolygon(x, y + 0.035, col = COL[1])\npolygon(c(M - 20, M + 20, M),\n        c(-0.2, -0.2, 0.035),\n        col = COL[4])"},{"path":"ch2-prob.html","id":"variabilityRandomVariables","chapter":"2 Probabilidade (tópico especial)","heading":"2.4.2 Variabilidade em variáveis aleatórias","text":"Suponha que você administrasse livraria da universidade. Além de quanto receita você espera gerar, você também pode querer saber volatilidade (variabilidade) de sua receita.variância e desvio padrão pode ser usado para descrever variabilidade de uma variável aleatória. Seção 1.7.4 introduziu um método para encontrar variância e desvio padrão para um conjunto de dados. Nós primeiro calculamos desvios da média (\\(x_i - \\mu\\)), eleva ao quadrado esses desvios, e faz uma média para obter variância. caso de uma variável aleatória, novamente calculamos os desvios quadrados. entanto, consideramos soma ponderada pelas probabilidades correspondentes, exatamente como fizemos para esperança. Essa soma ponderada de desvios quadrados é igual à variância e calculamos o desvio padrão tomando raiz quadrada da variância, como fizemos na Seção 1.7.4. Fórmula geral da variância:  Se \\(X\\) leva os resultados \\(x_1, \\dots, x_k\\) com probabilidades \\(P(X=x_1), \\dots, P(X=x_k)\\) e valor esperado \\(\\mu=E(X)\\), então variância de \\(X\\), denotada por \\(Var(X)\\) ou o símbolo \\(\\sigma^2\\), é\\[\\begin{align}\r\n\\sigma^2 &= (x_1-\\mu)^2\\times P(X=x_1) + \\cdots \\notag \\\\\r\n    & \\qquad\\quad\\cdots+ (x_k-\\mu)^2\\times P(X=x_k) \\notag \\\\\r\n    &= \\sum_{j=1}^{k} (x_j - \\mu)^2 P(X=x_j)\r\n\\end{align}\\]O desvio padrão de \\(X\\), rotulado \\(\\sigma\\), é raiz quadrada da variância.É útil construir uma tabela que armazene os cálculos para cada resultado separadamente e depois os resultados.Assim, o valor esperado é \\(\\mu = 117,85\\), que calculamos anteriormente. variância pode ser construída estendendo essa tabela:variação de \\(X\\) é \\(\\sigma^2 = 3659,3\\), o que significa que o desvio padrão é \\(\\sigma = \\sqrt{3659,3} = \\$60,49\\).Prática Orientada 2.41  livraria também oferece um livro de química por $159 e um complemento para o livro por $41. partir da experiência passada, eles sabem que cerca de 25% de estudantes de química apenas compram o livro enquanto 60% compram o livro e o suplemento.97$. esperança para parte (c) é dada como o total de \\(y_i\\times P(Y=y_i) = 159,75\\). O resultado da parte (d) é raiz quadrada da variância: \\(\\sigma = \\sqrt{Var(Y)} = \\$69,28\\).]Que proporção de estudantes não compra um dos livros? Suponha que nenhum aluno compre o suplemento sem o livro didático.\r\nQue proporção de estudantes não compra um dos livros? Suponha que nenhum aluno compre o suplemento sem o livro didático.Se \\(Y\\) representar receita de um único aluno. Escreva distribuição de probabilidade de \\(Y\\), ou seja, uma tabela para cada resultado e sua probabilidade associada.\r\nSe \\(Y\\) representar receita de um único aluno. Escreva distribuição de probabilidade de \\(Y\\), ou seja, uma tabela para cada resultado e sua probabilidade associada.Calcule receita esperada de um único estudante de química.\r\nCalcule receita esperada de um único estudante de química.Encontre o desvio padrão para descrever variabilidade associada à receita de um único aluno.\r\nEncontre o desvio padrão para descrever variabilidade associada à receita de um único aluno.\r\n","code":"\ntab9 <- rbind(tab8, c(0, 75.35, 42.50, 117.85))\nrownames(tab9)[3] <- 'xi * P(X = xi)'\n\n\nknitr::kable(tab9, align = 'c')\ntab10 <- rbind(tab9, \n               c(-117.85, 19.15, 52.15, ''),\n               c(13888.62, 366.72, 2719.62, ''),\n               c(2777.7, 201.7, 679.9, 3659.3))\nrownames(tab10)[4:6] <- c('xi - mu', '(xi - mu)²'','(xi - mu)² * P(X = xi)')')\n\n\nknitr::kable(tab10, align = 'c')"},{"path":"ch2-prob.html","id":"linearCombinationRandomVariables","chapter":"2 Probabilidade (tópico especial)","heading":"2.4.3 Combinações lineares de variáveis aleatórias","text":"Até agora, pensamos que cada variável é uma história completa em si mesma. Às vezes é mais apropriado usar uma combinação de variáveis. Por exemplo, quantidade de tempo que uma pessoa gasta diariamente para ir ao trabalho pode ser dividida em vários deslocamentos diários. Da mesma forma, o ganho ou perda total em uma carteira de ações é soma dos ganhos e perdas em seus componentes.Seu tempo total de viagem semanal é soma dos cinco valores diários:\r\n\\[W = X_1 + X_2 + X_3 + X_4 + X_5\\]\r\nQuebrar o tempo de viagem semanal \\(W\\) em pedaços fornece uma estrutura para entender cada fonte de aleatoriedade e é útil para modelar \\(W\\).Fomos informados de que média (ou seja, o valor esperado) tempo de viagem é de 18 minutos por dia: \\(E(X_i) = 18\\). Para obter o tempo esperado para soma dos cinco dias, podemos adicionar o tempo esperado para cada dia individual:\\[\\begin{align*}\r\nE(W) &= E(X_1 + X_2 + X_3 + X_4 + X_5) \\\\\r\n    &= E(X_1) + E(X_2) + E(X_3) + E(X_4) + E(X_5) \\\\\r\n    &= 18 + 18 + 18 + 18 + 18 = 90\\text{ minutos}\r\n\\end{align*}\\]esperança tempo total é igual à soma dos tempos individuais esperados. Mais geralmente, esperança de uma soma de variáveis aleatórias é sempre soma da esperança para cada variável aleatória.Dois conceitos importantes sobre combinações de variáveis aleatórias foram introduzidos até agora. Primeiro, um valor final pode às vezes ser descrito como soma de suas partes em uma equação. Segundo, intuição sugere que colocar os valores médios individuais nessa equação fornece o valor médio que esperamos total. Este segundo ponto precisa de esclarecimento – é garantido que é verdade naquilo que é chamado de combinações lineares de variáveis aleatórias.Uma combinação linear de duas variáveis aleatórias \\(X\\) e \\(Y\\) é uma frase chique para descrever uma combinação\\[ aX + \\]onde \\(\\) e \\(b\\) são números fixos e conhecidos. Para o tempo de deslocamento de John, havia cinco variáveis aleatórias – uma para cada dia de trabalho – e cada variável aleatória poderia ser escrita como tendo um coeficiente fixo em 1:\\[1X_1 + 1 X_2 + 1 X_3 + 1 X_4 + 1 X_5\\]Para o ganho ou perda líquida de Elena, variável aleatória \\(X\\) tinha um coeficiente de +1 e variável aleatória \\(Y\\) tinha um coeficiente -1.Ao considerar média de uma combinação linear de variáveis aleatórias, é seguro inserir média de cada variável aleatória e depois calcular o resultado final. Para alguns exemplos de combinações não-lineares de variáveis aleatórias – casos em que não podemos simplesmente conectar os meios – veja nota de rodapé.100Combinações lineares de variáveis aleatórias e o resultado médio:  Se \\(X\\) e \\(Y\\) são variáveis aleatórias, então uma combinação linear das variáveis aleatórias é dada por\\[\\begin{align}\r\naX + \r\n\\tag{2.13}\r\n\\end{align}\\]onde \\(\\) e \\(b\\) são alguns números fixos. Para calcular o valor médio de uma combinação linear de variáveis aleatórias, conecte média de cada variável aleatória individual e calcule o resultado:\\[\\begin{align*}\r\n\\times E(X) + b\\times E(Y)\r\n\\end{align*}\\]Lembre-se de que o valor esperado é o mesmo que média, por exemplo. \\(E(X) = \\mu_X\\).Por simplicidade, vamos supor que \\(X\\) e \\(Y\\) não estão em porcentagem, mas estão na forma decimal (por exemplo, se o estoque Google aumenta 1%, então \\(X = 0,01\\); ou se ele perder 1%, então \\(X = -0,01\\)). Então podemos escrever uma equação para o ganho Leonard como\\[\\begin{align*}\r\n\\$6000\\times X + \\$2000\\times Y\r\n\\end{align*}\\]Se inserirmos mudança valor estoque para \\(X\\) e \\(Y\\), essa equação fornece mudança valor da carteira de ações da Leonard para o mês. Um valor positivo representa um ganho e um valor negativo representa uma perda.","code":""},{"path":"ch2-prob.html","id":"variabilityLinearCombinationRandomVariables","chapter":"2 Probabilidade (tópico especial)","heading":"2.4.4 Variabilidade em combinações lineares de variáveis aleatórias","text":"quantificação resultado médio de uma combinação linear de variáveis aleatórias é útil, mas também é importante ter alguma noção da incerteza associada ao resultado total dessa combinação de variáveis aleatórias. O ganho ou perda líquida esperada da carteira de ações da Leonard foi considerado na Prática Orientada 2.45. entanto, não houve discussão quantitativa da volatilidade desta carteira. Por exemplo, enquanto o ganho médio mensal pode ser de aproximadamente $134 de acordo com os dados, esse ganho não é garantido. Figura 2.15 mostra mudanças mensais em uma carteira como da Leonard durante os 36 meses de 2009 2011. Os ganhos e perdas variam muito, e quantificar essas flutuações é importante quando se investe em ações.\r\nFigura 2.15: mudança em um portfólio como o de Leonard para os 36 meses de 2009 2011, em que $6000 está estoque Google e $2000 está da Exxon Mobil.\r\nAssim como fizemos em muitos casos anteriores, usamos variância e o desvio padrão para descrever incerteza associada aos retornos mensais de Leonard. Para fazer isso, variações retorno mensal de cada ação serão úteis, e elas são mostradas na Tabela 2.9. Os retornos das ações são quase independentes.Tabela 2.9: média, desvio padrão e variância dos estoques GOOG e XOM. Essas estatísticas foram estimadas partir de dados históricos de estoque.Aqui usamos uma equação da teoria da probabilidade para descrever incerteza dos retornos mensais de Leonard; deixamos prova deste método para um curso de probabilidade avançado. variância de uma combinação linear de variáveis aleatórias pode ser computada por meio das variâncias das variáveis aleatórias individuais e quadratura dos coeficientes das variáveis aleatórias:\\[\\begin{align*}\r\nVar(aX + ) = ^2\\times Var(X) + b^2\\times Var(Y)\r\n\\end{align*}\\]É importante notar que essa igualdade assume que variáveis aleatórias são independentes; se independência não se sustenta, então são necessários métodos mais avançados. Essa equação pode ser usada para calcular variância retorno mensal de Leonard:\\[\\begin{align*}\r\nVar(6000\\times X + 2000\\times Y)\r\n    &= 6000^2\\times Var(X) + 2000^2\\times Var(Y) \\\\\r\n    &= 36.000.000\\times 0,0072 + 4,000,000\\times 0,0027 \\\\\r\n    &= 270.000\r\n\\end{align*}\\]O desvio padrão é calculado como raiz quadrada da variância: \\(\\sqrt{270.000} = \\$520\\). Enquanto um retorno mensal médio de $134 em um investimento de $8000 não é baixo, os retornos mensais são tão voláteis que Leonard não deve esperar que essa renda seja muito estável.Variabilidade de combinações lineares de variáveis aleatórias:  variância de uma combinação linear de variáveis aleatórias pode ser calculada por meio da quadratura das constantes, substituindo nas variâncias variáveis aleatórias e calculando o resultado:\\[\\begin{align*}\r\nVar(aX + ) = ^2\\times Var(X) + b^2\\times Var(Y)\r\n\\end{align*}\\]Essa equação é válida desde que variáveis aleatórias sejam independentes umas das outras. O desvio padrão da combinação linear pode ser encontrado tomando raiz quadrada da variância.expressão para o tempo de viagem de John era\\[\\begin{align*}\r\nX_1 + X_2 + X_3 + X_4 + X_5\r\n\\end{align*}\\]Cada coeficiente é 1 e variância tempo de cada dia é \\(4^2=16\\). Assim, variância tempo total semanal de deslocamento é\\[\\begin{align*}\r\n&\\text{variância }= 1^2 \\times  16 + 1^2 \\times  16 + 1^2 \\times  16 + 1^2 \\times  16 + 1^2 \\times  16 = 5\\times 16 = 80 \\\\\r\n&\\text{desvio padrão} = \\sqrt{\\text{variância}} = \\sqrt{80} = 8.94\r\n\\end{align*}\\]O desvio padrão para o horário de trabalho semanal de John é de cerca de 9 minutos.Considere novamente Prática Orienada 2.48. O coeficiente negativo para \\(Y\\) na combinação linear foi eliminado quando nós ajustamos os coeficientes. Isso geralmente é verdade: os negativos em uma combinação linear não terão impacto sobre variabilidade calculada para uma combinação linear, mas afetam os cálculos valor esperado.","code":"\nknitr::include_graphics('images/c2/changeInLeonardsStockPortfolioFor36Months.png')\ntab11 <- rbind(c(0.0210, 0.0846,    0.0072), c(0.0038, 0.0519, 0.0027))\ncolnames(tab11) <- c('Média', 'Desvio Padrão', 'Variância')\nrownames(tab11) <- c('GOOG', 'XOM')\n\nknitr::kable(tab11, align = 'c', \n             caption = 'A média, desvio padrão e variância dos estoques GOOG e XOM. Essas estatísticas foram estimadas a partir de dados históricos de estoque.')"},{"path":"ch2-prob.html","id":"contDist","chapter":"2 Probabilidade (tópico especial)","heading":"2.5 Distribuições contínuas (tópico especial)]","text":"Adicionando mais “caixas”\" fornece maiores detalhes. Essa amostra é extremamente grande, e é por isso que intervalos muito pequenos ainda funcionam bem. Normalmente, não usamos muitos intervalos com tamanhos de amostra menores, pois contagens pequenas por intervalos significam que alturas intervalo são muito voláteis.\r\nFigura 2.16:  Quatro histogramas de alturas de adultos dos EUA com diferentes larguras de intervalo.\r\nPodemos adicionar alturas dos intervalos 180cm e 185cm e dividir pelo tamanho da amostra. Por exemplo, isso pode ser feito com os dois intervalos sombreados mostrados na Figura 2.17. Os dois intervalos nesta região têm contagens de 195.307 e 156.239 pessoas, resultando na seguinte estimativa da probabilidade:\\[\\begin{eqnarray*}\r\n\\frac{195307+156239}{\\text{3.000.000}} = 0,1172\r\n\\end{eqnarray*}\\]Essa fração é igual à proporção da área histograma que cai intervalo 180cm até 185cm.\r\nFigura 2.17: Um histograma com tamanhos de intervalo de 2,5 cm. região sombreada representa indivíduos com alturas entre 180cm e 185cm.\r\n","code":"\nlibrary(openintro)\ndata(COL)\nload(\"data/fdicHistograms.rda\")\n\npar(mfrow = c(2,2))\n\nMIDS <- br[-1] - diff(br[1:2]) / 2\nBR <- list()\nBR[[1]] <- seq(110, 210, 10)\nBR[[2]] <- seq(115, 210, 5)\nBR[[3]] <- seq(110, 210, 2)\nBR[[4]] <- seq(110, 210, 1)\nCOUNTS <- list()\nfor (i in 1:4) {\n  COUNTS[[i]] <- rep(0, length(BR[[i]])-1)\n  for (j in 1:(length(BR[[i]])-1)) {\n    these <- apply(cbind(MIDS < BR[[i]][j+1],\n                         MIDS >= BR[[i]][j]),\n                   1,\n                   all)\n    if (any(these)) {\n      COUNTS[[i]][j] <- sum(counts[these])\n    }\n  }\n}\n\nhistTemp <- function(\n    BR, COUNTS, col = fadeColor(COL[1], \"10\"),\n    border = COL[1,4], probability = FALSE,\n    xlab = '', ylab = NULL,\n    xlim = NULL, ylim = NULL,\n    ...) {\n  br <- BR\n  h  <- COUNTS\n  if (probability) {\n    h <- h / sum(h) / diff(br)\n  }\n  if (is.null(ylab)) {\n    ylab <- 'frequency'\n    if (probability) {\n      ylab <- 'probability'\n    }\n  }\n  if (is.null(xlim)[1]) {\n    xR <- range(br)\n    xlim <- xR + c(-0.05, 0.05) * diff(xR)\n  }\n  if (is.null(ylim)[1]) {\n    ylim <- range(c(0, h))\n  }\n  plot(-1, -1,\n       xlab = xlab,\n       ylab = ylab,\n       xlim = xlim,\n       ylim = ylim,\n       type = 'n',\n       ...)\n  abline(h = 0)\n  lines(c(br[1], br[1]), c(0, h[1]), col = border)\n  for (i in 1:length(h)) {\n    if (i > 1) {\n      if (h[i] > h[i-1]) {\n        lines(rep(br[i], 2), h[c(i - 1, i)], col = border)\n      }\n    }\n    lines(br[i + 0:1], rep(h[i], 2), col = border)\n    lines(rep(br[i + 1], 2), c(0, h[i]), col = border)\n    rect(br[i], 0,\n         br[i + 1], h[i],\n         col = col,\n         border = '#00000000')\n  }\n}\n\n\n\nfor (i in 1:4) {\n  histTemp(BR[[i]],\n           COUNTS[[i]],\n           xlim = c(125, 210),\n           axes = FALSE,\n           xlab = 'height (cm)')\n  lines(BR[[i]],\n        c(COUNTS[[i]], 0),\n        type = 's',\n        col = COL[1],\n        lwd = 2)\n  axis(1, cex.axis = 0.9)\n}\nlibrary(openintro)\ndata(COL)\n\n# _____ Load Data Set From fdicHistograms _____ #\nload(\"data/fdicHistograms.rda\")\n\nBR      <- list()\nMIDS    <- br[-1] - 0.25\nBR[[1]] <- seq(110, 210, 10)\nBR[[2]] <- seq(115, 210, 2.5)\nCOUNTS  <- list()\nfor (i in 1:2) {\n  COUNTS[[i]] <- rep(0, length(BR[[i]])-1)\n  for (j in 1:(length(BR[[i]])-1)) {\n    these <- apply(cbind(MIDS < BR[[i]][j + 1],\n                         MIDS >= BR[[i]][j]),\n                   1,\n                   all)\n    if (any(these)) {\n      COUNTS[[i]][j] <- sum(counts[these])\n    }\n  }\n}\n\nhistTemp <- function(\n    BR, COUNTS, col = fadeColor(COL[1], \"10\"),\n    border = COL[1,4], probability = FALSE,\n    xlab = '', ylab = NULL,\n    xlim = NULL, ylim = NULL,\n    ...) {\n  br <- BR\n  h  <- COUNTS\n  if (probability) {\n    h <- h / sum(h) / diff(br)\n  }\n  if (is.null(ylab)) {\n    ylab <- 'frequency'\n    if (probability) {\n      ylab <- 'probability'\n    }\n  }\n  if (is.null(xlim)[1]) {\n    xR <- range(br)\n    xlim <- xR + c(-0.05, 0.05) * diff(xR)\n  }\n  if (is.null(ylim)[1]) {\n    ylim <- range(c(0,h))\n  }\n  plot(-1, -1,\n       xlab = xlab,\n       ylab = ylab,\n       xlim = xlim,\n       ylim = ylim,\n       type = 'n',\n       ...)\n  abline(h = 0)\n  lines(c(br[1], br[1]), c(0, h[1]), col = border)\n  for (i in 1:length(h)) {\n    if (i > 1) {\n      if (h[i] > h[i - 1]) {\n        lines(rep(br[i], 2), h[c(i - 1, i)], col = border)\n      }\n    }\n    lines(br[i + 0:1], rep(h[i], 2), col = border)\n    lines(rep(br[i + 1], 2), c(0, h[i]), col = border)\n    rect(br[i], 0, br[i + 1], h[i],\n         col = col,\n         border = '#00000000')\n  }\n}\n\nhistTemp(BR[[2]],\n         COUNTS[[2]],\n         xlim = c(125, 210),\n         axes = FALSE,\n         xlab = 'height (cm)',\n         probability = FALSE)\nlines(BR[[i]],\n      c(COUNTS[[i]], 0),\n      type = 's',\n      col = COL[1],\n      lwd = 2)\naxis(1)\nrect(BR[[2]][27], 0,\n     BR[[2]][28], COUNTS[[2]][27],\n     col = COL[1],\n     border = COL[1])\nrect(BR[[2]][28], 0,\n     BR[[2]][29], COUNTS[[2]][28],\n     col = COL[1],\n     border = COL[1])"},{"path":"ch2-prob.html","id":"histContinuousDistribution","chapter":"2 Probabilidade (tópico especial)","heading":"2.5.1 De histogramas a distribuições contínuas","text":"Examine transição de um histograma canto superior esquerdo da Figura 2.16 para um muito mais suave canto inferior direito. Nesse último os intervalos são tão finos que o histograma começa assemelhar-se uma curva suave. Isto sugere altura da população como um variável numérica contínua que pode ser melhor explicada por uma curva que representa o esboço de intervalos extremamente finos.Esta curva suave representa uma função de densidade de probabilidade (também chamado uma densidade ou distribuição) e uma curva, isso é mostrado na Figura 2.18 sobrepostos em um histograma da amostra. Uma densidade tem uma propriedade especial: área total sob curva da densidade é 1.\r\nFigura 2.18: distribuição de probabilidade contínua de altura para adultos dos EUA.\r\n","code":"\nlibrary(openintro)\ndata(COL)\n\n# _____ Load Data Set From fdicHistograms _____ #\nload(\"data/fdicHistograms.rda\")\n\nBR <- list()\nMIDS <- br[-1]-0.25\nBR[[1]] <- seq(110, 210, 10)\nBR[[2]] <- seq(115, 210, 2.5)\nCOUNTS <- list()\nfor (i in 1:2) {\n  COUNTS[[i]] <- rep(0, length(BR[[i]])-1)\n  for (j in 1:(length(BR[[i]]) - 1)) {\n    these <- apply(cbind(MIDS < BR[[i]][j + 1],\n                         MIDS >= BR[[i]][j]),\n                   1,\n                   all)\n    if (any(these)) {\n      COUNTS[[i]][j] <- sum(counts[these])\n    }\n  }\n}\n\nhistTemp <- function(\n    BR, COUNTS, col = fadeColor(COL[1], \"10\"),\n    border = COL[1, 4], probability = TRUE,\n    xlab = '', ylab = NULL, xlim = NULL, ylim = NULL,\n    ...) {\n  br <- BR\n  h  <- COUNTS\n  if (probability) {\n    h <- h/sum(h)/diff(br)\n  }\n  if (is.null(ylab)) {\n    ylab <- 'frequency'\n    if (probability) {\n      ylab <- 'probability'\n    }\n  }\n  if (is.null(xlim)[1]) {\n    xR <- range(br)\n    xlim <- xR + c(-0.05, 0.05)*diff(xR)\n  }\n  if (is.null(ylim)[1]) {\n    ylim <- range(c(0,h))\n  }\n  plot(-1, -1,\n       xlab = xlab,\n       ylab = ylab,\n       xlim = xlim,\n       ylim = ylim,\n       type = 'n',\n       ...)\n  abline(h = 0)\n  lines(c(br[1], br[1]), c(0, h[1]), col = border)\n  for (i in 1:length(h)) {\n    if (i > 1) {\n      if (h[i] > h[i - 1]) {\n        lines(rep(br[i], 2), h[c(i - 1, i)], col = border)\n      }\n    }\n    lines(br[i + 0:1], rep(h[i], 2), col = border)\n    lines(rep(br[i + 1], 2), c(0, h[i]), col = border)\n    rect(br[i], 0, br[i + 1], h[i], col = col, border = border)\n  }\n}\n\npar(mfrow = c(1, 1),\n    mar = c(3, 1, 0.1, 1),\n    mgp = c(1.8, 0.7, 0))\nhistTemp(BR[[2]],\n         COUNTS[[2]],\n         xlab = 'height (cm)',\n         axes = FALSE,\n         xlim = c(125, 210),\n         col = fadeColor(COL[1], \"10\"),\n         border = COL[1,4])\naxis(1)\nlines(dens$x, dens$y,\n      col = COL[1],\n      lwd = 2)"},{"path":"ch2-prob.html","id":"probContinuousDistribution","chapter":"2 Probabilidade (tópico especial)","heading":"2.5.2 Probabilidades de distribuições contínuas","text":"Calculamos proporção de indivíduos com altura 180cm até 185cm Exemplo 2.26 como uma fração:\\[\\begin{eqnarray*}\r\n\\frac{\\text{ número de pessoas entre 180cm e 185cm}}{\\text{ tamanho total da amostra}}\r\n\\end{eqnarray*}\\]Encontramos o número de pessoas com altura entre 180cm e 185cm determinando fração da área histograma nessa região. Da mesma forma, podemos usar área na região sombreada sob curva para encontrar uma probabilidade (com ajuda de um computador):\\[\\begin{eqnarray*}\r\nP(\\text{altura entre 180cm e 185cm})\r\n    = \\text{área entre 180cm e 185cm}\r\n    = 0,1157\r\n\\end{eqnarray*}\\]probabilidade de que uma pessoa selecionada aleatoriamente esteja entre 180cm e 185cm seja 0,1157. Isso é muito próximo da estimativa Exemplo 2.26: 0,1172.\r\nFigura 2.19: Densidade para alturas na população adulta dos EUA com área entre 180 e 185 cm sombreada.\r\nPrática Orientada 2.49  Três adultos dos EUA são selecionados aleatoriamente. probabilidade de um adulto solteiro estar entre 180cm e 185cm é 0,1157.106Qual é probabilidade de que todos os três estejam entre 180cm e 185cm cm de altura?\r\nQual é probabilidade de que todos os três estejam entre 180cm e 185cm cm de altura?Qual é probabilidade de que nenhum deles esteja entre 180cm e 185cm?\r\nQual é probabilidade de que nenhum deles esteja entre 180cm e 185cm?\r\nEssa probabilidade é zero. Uma pessoa pode estar perto de 180cm, mas não exatamente 180cm de altura. Isso também faz sentido com definição de probabilidade como área: não há área capturada entre 180cm e 180cm.","code":"\nlibrary(openintro)\ndata(COL)\n\n# _____ Load Data Set From fdicHistograms _____ #\nload(\"data/fdicHistograms.rda\")\n\nBR <- list()\nMIDS <- br[-1] - 0.25\nBR[[1]] <- seq(110, 210, 10)\nBR[[2]] <- seq(115, 210, 2.5)\nCOUNTS <- list()\nfor (i in 1:2) {\n  COUNTS[[i]] <- rep(0, length(BR[[i]]) - 1)\n  for (j in 1:(length(BR[[i]]) - 1)) {\n    these <- apply(cbind(MIDS < BR[[i]][j + 1],\n                         MIDS >= BR[[i]][j]),\n                   1,\n                   all)\n    if (any(these)) {\n      COUNTS[[i]][j] <- sum(counts[these])\n    }\n  }\n}\n\nBR <- list()\nMIDS <- br[-1] - 0.25\nBR[[1]] <- seq(110, 210, 10)\nBR[[2]] <- seq(115, 210, 2.5)\nCOUNTS <- list()\nfor (i in 1:2) {\n  COUNTS[[i]] <- rep(0, length(BR[[i]]) - 1)\n  for (j in 1:(length(BR[[i]]) - 1)) {\n    these <- apply(cbind(MIDS < BR[[i]][j + 1],\n                         MIDS >= BR[[i]][j]),\n                   1,\n                   all)\n    if (any(these)) {\n      COUNTS[[i]][j] <- sum(counts[these])\n    }\n  }\n}\n\n\nhistTemp <- function(\n    BR, COUNTS, col = fadeColor(COL[1], \"10\"),\n    border = COL[1, 4], probability = TRUE,\n    xlab = '', ylab = NULL,\n    xlim = NULL, ylim = NULL,\n    ...) {\n  br <- BR\n  h  <- COUNTS\n  if (probability) {\n    h <- h/sum(h)/diff(br)\n  }\n  if (is.null(ylab)) {\n    ylab <- 'frequency'\n    if (probability) {\n      ylab <- 'probability'\n    }\n  }\n  if (is.null(xlim)[1]) {\n    xR <- range(br)\n    xlim <- xR + c(-0.05, 0.05)*diff(xR)\n  }\n  if (is.null(ylim)[1]) {\n    ylim <- range(c(0,h))\n  }\n  plot(-1, -1,\n       xlab = xlab,\n       ylab = ylab,\n       xlim = xlim,\n       ylim = ylim,\n       type = 'n',\n       ...)\n  abline(h = 0)\n  lines(c(br[1],br[1]), c(0,h[1]), col = border)\n  for (i in 1:length(h)) {\n    if (i > 1) {\n      if (h[i] > h[i-1]) {\n        lines(rep(br[i],2), h[c(i-1,i)], col = border)\n      }\n    }\n    lines(br[i + 0:1],\n          rep(h[i], 2),\n          col = border)\n    lines(rep(br[i + 1], 2),\n          c(0, h[i]),\n          col = border)\n    rect(br[i], 0,\n         br[i + 1], h[i],\n         col = col,\n         border = border)\n  }\n}\n\nhistTemp(BR[[2]],\n         COUNTS[[2]],\n         col = fadeColor(COL[1], \"10\"),\n         border = COL[1,4],\n         xlim = c(125, 210),\n         axes = FALSE,\n         xlab = 'height (cm)',\n         ylab = '',\n         probability = TRUE)\naxis(1)\nlines(dens$x, dens$y, col = COL[1], lwd = 2)\nthese <- dens$x > 180 & dens$x < 185\npolygon(c(dens$x[these][1], dens$x[these], rev(dens$x[these])[1]),\n        c(0, dens$y[these], 0),\n        col = COL[1],\n        border = COL[1])"},{"path":"ch3-distribuicoes.html","id":"ch3-distribuicoes","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3 Distribuições de Variáveis Aleatórias","text":"","code":""},{"path":"ch3-distribuicoes.html","id":"normalDist","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.1 Distribuição Normal","text":"Entre todas distribuições que vemos na prática, uma é mais comum. curva de sino simétrica, unimodal, é onipresente em toda estatística. Na verdade, é tão comum que pessoas muitas vezes conhecem como curva normal ou distribuição normal108 mostrada na Figura 3.1. Variáveis como os pontos SAT e alturas dos homens adultos norte-americanos seguem de perto distribuição normal.\r\nFigura 3.1: Uma curva normal\r\nFatos da distribuição normal: Muitas variáveis são quase normais, mas nenhuma é exatamente normal. Assim, distribuição normal, embora não seja perfeita para qualquer problema individual, é muito útil para uma variedade de problemas. Vamos usá-lo na exploração de dados e resolver problemas importantes em estatísticas.","code":"\nggplot(data = data.frame(x = c(-4, 4)), aes(x)) +\n  stat_function(fun = dnorm, n = 1001, args = list(mean = 0, sd = 1), size = 1)  +\n  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), \n        axis.ticks.x = element_blank()) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  geom_hline(yintercept = -0.008, size = 1) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch3-distribuicoes.html","id":"normalDistributionModel","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.1.1 Modelo de distribuição normal","text":"O modelo de distribuição normal sempre descreve uma curva simétrica, unimodal e em forma de sino. entanto, essas curvas podem parecer diferentes dependendo dos detalhes modelo. Especificamente, o modelo de distribuição normal pode ser ajustado usando dois parâmetros: média e desvio padrão. Como você provavelmente pode adivinhar, alterar média desloca curva sino para esquerda ou para direita, enquanto alterar o desvio padrão estende ou restringe curva. Figura 3.2 mostra distribuição normal com média \\(0\\) e desvio padrão \\(1\\) painel esquerdo e distribuições normais com média \\(19\\) e desvio padrão \\(4\\) painel direito. Figura 3.3 mostra essas distribuições mesmo eixo.\r\nFigura 3.2: Ambas curvas representam distribuição normal, entanto, diferem em seu centro e propagação. distribuição normal com média 0 e desvio padrão 1 é chamada de distribuição normal padrão.\r\n\r\nFigura 3.3: Os modelos normais mostrados acima, mas plotados simultaneamente e na mesma escala.\r\nSe uma distribuição normal tem média \\(\\mu\\) e desvio padrão \\(\\sigma\\), podemos escrever distribuição como \\(N(\\mu, \\sigma)\\)109. duas distribuições na Figura 3.3 podem ser escritas como\\[\\begin{align*}\r\nN(\\mu=0,\\sigma=1)\\quad\\text{e}\\quad N(\\mu=19,\\sigma=4)\r\n\\end{align*}\\]Como média e o desvio padrão descrevem exatamente uma distribuição normal, eles são chamados parâmetros da distribuição.Prática Orientada 3.1  Anote representação de uma distribuição normal com110:média 5 e desvio padrão 3,\r\nmédia 5 e desvio padrão 3,média -100 e desvio padrão 10, e\r\nmédia -100 e desvio padrão 10, emédia 2 e desvio padrão 9.\r\nmédia 2 e desvio padrão 9.\r\n","code":"\nset.seed(1)\nx1 <- rnorm(100000, 0, 1)\nnorm1 <- ggplot(mapping = aes(x = x1)) + \n  geom_histogram(aes(y = ..density..), color = \"white\", bins = 30, alpha = 0.5, fill = \"#EAB217\") + \n  stat_function(data = data.frame(), fun = dnorm, n = 1001, args = list(mean = 0, sd = 1), size = 1, color = \"#EAB217\") +\n  scale_x_continuous(breaks = seq(-3, 3, 1)) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  labs(x = NULL, y = NULL) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nx2 <- rnorm(100000, 19, 4)\nnorm2 <- ggplot(mapping = aes(x = x2)) + \n  geom_histogram(aes(y = ..density..), color = \"white\", bins = 30, alpha = 0.5, fill = \"#E6205F\") + \n  stat_function(data = data.frame(),fun = dnorm, n = 1001, args = list(mean = 19, sd = 4), size = 1, color = \"#E6205F\")+\n  scale_x_continuous(breaks = seq(7, 31, 4)) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),\n        axis.line.y = element_blank()) + \n  labs(x = NULL, y = NULL) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nrequire(gridExtra)\ngrid.arrange(norm1, norm2, ncol = 2)\nggplot(data = data.frame(x = c(-3, 33)), aes(x)) + \n  stat_function(fun = dnorm, n = 10001, args = list(mean = 0, sd = 1), \n                size = 1, color = \"#EAB217\") +\n  stat_function(fun = dnorm, n = 10001, args = list(mean = 19, sd = 4), \n                size = 1, color = \"#E6205F\") + \n  scale_x_continuous(breaks = seq(-3, 33, 4)) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  labs(x = NULL, y = NULL) + \n  geom_hline(yintercept=0, colour=\"white\", size = 1) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch3-distribuicoes.html","id":"patterningZPoints","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.1.2 Padronizando com pontos Z","text":"Tabela 3.1: Média e desvio padrão para o SAT e ACT.Nós usamos o desvio padrão como um guia. Ana é 1 desvio padrão acima da média na SAT: \\(1500 + 300=1800\\). Thiago é 0,6 desvios padrão acima da média ACT: \\(21+0.6\\times 5=24\\). Na Figura 3.4, podemos ver que Ana tende se sair melhor em relação Thiago, então sua pontuação foi melhor.\r\nFigura 3.4: Pontuação de Ana e Thiago mostrados com distribuições dos pontos SAT e ACT.\r\nExemplo 3.1 usaram uma técnica de padronização chamada ponto Z, um método mais comumente empregado para observações quase normais, mas que pode ser usado com qualquer distribuição. O ponto Z111 de uma observação é definida como o número de desvios padrão que cai acima ou abaixo da média. Se observação é um desvio padrão acima da média, sua pontuação Z é 1. Se 1,5 desvios-padrão abaixo da média, então seu Z-escore é -1,5. E se \\(x\\) é uma observação de uma distribuição \\(N(\\mu, \\sigma)\\), nós definimos o Z-escore matematicamente como\\[\\begin{eqnarray*}\r\nZ = \\frac{x-\\mu}{\\sigma}\r\n\\end{eqnarray*}\\]Usando \\(\\mu_{SAT}=1500\\), \\(\\sigma_{SAT}=300\\), e \\(x_{Ana}=1800\\), nós achamos o Z-escore da Ana:\\[\\begin{eqnarray*}\r\nZ_{Ana} = \\frac{x_{Ana} - \\mu_{SAT}}{\\sigma_{SAT}} = \\frac{1800-1500}{300} = 1\r\n\\end{eqnarray*}\\]O Z-escore: O escore Z de uma observação é o número de desvios padrão que cai acima ou abaixo da média. Calculamos o escore Z para uma observação \\(x\\) que segue uma distribuição com média \\(\\mu\\) e desvio padrão \\(\\sigma\\) usando\r\n\\[\\begin{eqnarray*}\r\nZ = \\frac{x-\\mu}{\\sigma}\r\n\\end{eqnarray*}\\]Observações acima da média sempre têm escores Z positivos, enquanto aquelas abaixo da média têm escores Z negativos. Se uma observação é igual à média (por exemplo, pontuação SAT de 1500), então pontuação Z é \\(0\\).Prática Orientada 3.3  \\(X\\) representa uma variável aleatória de \\(N(\\mu=3, \\sigma=2)\\), e suponha que observemos \\(x=5.19\\).113Descubra o escore Z de \\(x\\).\r\nDescubra o escore Z de \\(x\\).Use o Z-escore para determinar quantos desvios padrões acima ou abaixo da média \\(x\\) cai.\r\nUse o Z-escore para determinar quantos desvios padrões acima ou abaixo da média \\(x\\) cai.\r\nPodemos usar escores Z para identificar aproximadamente quais observações são mais incomuns que outras. Uma observação \\(x_1\\) é mais incomum que outra observação \\(x_2\\) se o valor absoluto de seu Z-escore maior que o valor absoluto Z-escore da outra observação:\\(|Z_1| > |Z_2|\\). Essa técnica é especialmente perspicaz quando uma distribuição é simétrica.","code":"\nrequire(knitr)\nex3_1 <- cbind(c(1500, 300), c(20, 5))\nrownames(ex3_1) <- c(\"Média\", \"DP\")\ncolnames(ex3_1) <- c(\"SAT\", \"ACT\")\nkable(ex3_1, caption = \"Média e desvio padrão para o SAT e ACT.\", align = \"c\")\nset.seed(1)\nm <- 1500\ns <- 300\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\nann <- ggplot(mapping = aes(x = X, y = Y)) + geom_line() + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  geom_vline(xintercept = m, linetype = \"dotted\") + \n  geom_vline(xintercept = m + s, linetype = \"dashed\", color = \"coral4\") + \n  annotate(\"text\", x = m + s + s/2, y = Y[which(grepl(m + s, X))], \n           label = \"Ana\", color = \"coral4\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n\nmt <- 21\nst <- 5\nXt <- mt + st * seq(-4, 4, 0.01)\nYt <- dnorm(Xt, mt, st)\n\ntom <- ggplot(mapping = aes(x = Xt, y = Yt)) + geom_line() + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  scale_x_continuous(breaks = seq(mt - 3*st, mt + 3*st, st)) + \n  geom_vline(xintercept = mt, linetype = \"dotted\") + \n  geom_vline(xintercept = mt + 0.6*st, linetype = \"dashed\", color = \"cyan4\") + \n  annotate(\"text\", x = mt + st, y = Yt[which(grepl(mt + st, Xt))[20]]-0.006, \n           label = \"Thiago\", color = \"cyan4\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n\ngrid.arrange(ann, tom, ncol = 1)"},{"path":"ch3-distribuicoes.html","id":"normalProbabilityTabel","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.1.3 Tabela de probabilidade normal","text":"\r\nFigura 3.5: O modelo normal para pontuação SAT, sombreando área daqueles indivíduos que pontuaram abaixo de Ana.\r\nO resultado percentil de Ana é porcentagem de pessoas que obtiveram uma pontuação menor SAT que Ana. Nós sombreamos área que representa aqueles indivíduos na Figura 3.5. área total abaixo da curva normal é sempre igual 1, e proporção de pessoas que pontuaram abaixo de Ana SAT é igual à área sombreada na Figura 3.5: 0.8413. Em outras palavras, Ana está 84 percentil de participantes SAT.Podemos usar o modelo normal para encontrar percentis. Uma tabela de probabilidade normal, que lista os escores Z e os percentis correspondentes, pode ser usado para identificar um percentil baseado escore Z (e vice-versa). O software estatístico também pode ser usado.caso software R, função pnorm calcula essa área e é dada por:pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)Uma tabela de probabilidade normal é abreviado na Tabela 3.2. Usamos essa tabela para identificar o percentil correspondente qualquer pontuação Z específica. Por exemplo, o percentil de \\(Z=0,43\\) é mostrado na linha \\(0,4\\) e coluna \\(0,03\\) na Tabela 3.2: 0.6664, ou o 66.64 percentual. Geralmente, arredondamos \\(Z\\) para duas casas decimais, identificamos linha apropriada na tabela de probabilidade normal até o primeiro decimal e depois determinamos coluna que representa o segundo valor decimal. intersecção desta linha e coluna é o percentil da observação.Tabela 3.2: Uma seção da tabela de probabilidade normal. O percentil de uma variável aleatória normal com Z = 0.43 foi destacado e o percentilmais próoximo de 0.8000 também foi destacado.Também podemos encontrar o escore Z associado um percentil. Por exemplo, para identificar Z para o 84 percentil, procuramos o valor mais próximo de 0,8000 na parte central da tabela: 0,7995. Determinamos o ponto Z para o 80 percentil combinando os valores de linha e coluna Z: 0.84.","code":"\nset.seed(1)\nm <- 1500\ns <- 300\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nlibrary(ggplot2)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 1800,], aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") +\n  geom_path(size = 1) +\n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = m + s, linetype = \"dashed\", color = \"coral4\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n# Estabelecendo aos argumentos 'q', 'mean' e 'sd' como a pontuação de Ana, \n# a média e o desvio padrão para as pontuações totais no SAT, respectivamente:\n# lower.tail se TRUE então P[X = x] se não, P[X > x].\n# log.p se as probabilidades p são dadas como log(p)\n  \npnorm(q = 1800, mean = 1500, sd = 300, lower.tail = TRUE, log.p = FALSE)\nset.seed(1)\nm <- 1500\ns <- 300\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nesq <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 1300,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = m, linetype = \"dashed\", color = \"lightyellow4\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ndir <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 1700,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = m, linetype = \"dashed\", color = \"lightyellow4\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nrequire(grid)\ngrid.arrange(esq, dir, ncol = 2, \n             top = textGrob(\"Z negativo vs. Z positivo\", gp = gpar(fontsize = 27,font = 8)))\ntab8 <- cbind(c(0.5000,0.5040,0.5080,0.5120,0.5160,0.5199,0.5239,0.5279,0.5319,0.5359),c(0.5398,0.5438,0.5478,0.5517,0.5557,0.5596,0.5636,0.5675,0.5714,0.5753),c(0.5793,0.5832,0.5871,0.5910,0.5948,0.5987,0.6026,0.6064,0.6103,0.6141),c(0.6179,0.6217,0.6255,0.6293,0.6331,0.6368,0.6406,0.6443,0.6480,0.6517),c(0.6554,0.6591,0.6628,0.6664,0.6700,0.6736,0.6772,0.6808,0.6844,0.6879),c(0.6915,0.6950,0.6985,0.7019,0.7054,0.7088,0.7123,0.7157,0.7190,0.7224),c(0.7257,0.7291,0.7324,0.7357,0.7389,0.7422,0.7454,0.7486,0.7517,0.7549),c(0.7580,0.7611,0.7642,0.7673,0.7704,0.7734,0.7764,0.7794,0.7823,0.7852),c(0.7881,0.7910,0.7939,0.7967,0.7995,0.8023,0.8051,0.8078,0.8106,0.8133),c(0.8159,0.8186,0.8212,0.8238,0.8264,0.8289,0.8315,0.8340,0.8365,0.8389))\n\ntab8 <- t(tab8)\n\ncolnames(tab8) <- seq(0.00, 0.09, by = 0.01)\nrownames(tab8) <- seq(0.0, 0.9, by = 0.1)\n\n\nkable(tab8, caption = \"Uma seção da tabela de probabilidade normal. O percentil de uma  variável  aleatória  normal com Z =  0.43  foi destacado e o percentilmais próoximo de 0.8000 também foi destacado.\", align = \"c\")"},{"path":"ch3-distribuicoes.html","id":"normalProbabiliyExamples","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.1.4 Exemplos de probabilidade normal","text":"pontuação cumulativa SAT são bem aproximadas por um modelo normal, \\(N(\\mu=1500, \\sigma=300)\\).Exemplo 3.3  Sabrina é uma candidata de SAT aleatoriamente selecionada, e nada se sabe sobre aptidão SAT de Sabrina. Qual é probabilidade de Sabrina marcar pelo menos 1630 em seus SATs?figura mostra média e os valores em 3 desvios padrão acima e abaixo da média. maneira mais simples de encontrar área sombreada sob curva faz uso ponto Z valor de corte. Com \\(\\mu=1500\\), \\(\\sigma=300\\), e o valor de corte \\(x=1630\\), o ponto Z é computado como\\[\\begin{eqnarray*}\r\nZ = \\frac{x - \\mu}{\\sigma} = \\frac{1630 - 1500}{300} = \\frac{130}{300} = 0.43\r\n\\end{eqnarray*}\\]Procuramos o percentil de \\(Z=0.43\\) na tabela de probabilidade normal mostrada na Tabela 3.2, que é 0.6664. entanto, o percentil descreve aqueles que tiveram um ponto Z menor de 0,43. Para encontrar área acima de \\(Z=0.43\\), calculamos um menos área da cauda inferior:probabilidade de Sabrina ter pelo menos 1630 SAT é de 0.3336. Essa probabilidade pode ser calculada direto pelo software R.pnorm(q = 1630, mean = 1500, sd = 300, lower.tail = FALSE)117Dica: primeiro desenhe figura, em seguida encontre o score Z: Para qualquer situação de probabilidade normal, sempre sempre sempre desenhar e rotular curva normal e sombrear área de interesse em primeiro lugar. imagem fornecerá uma estimativa da probabilidade.Depois de desenhar uma figura para representar situação, identifique pontuação Z para observação de interesse.Primeiro, uma foto é necessária. O percentil de Edward é proporção de pessoas que não chegam tão alto quanto 1400. Essas são pontuações à esquerda de 1400.Identificando média \\(\\mu=1500\\), o desvio padrão \\(\\sigma=300\\), e o limite para área de cauda \\(x=1400\\) facilita o cálculo ponto Z:\\[\\begin{eqnarray*}\r\nZ = \\frac{x - \\mu}{\\sigma} = \\frac{1400 - 1500}{300} = -0.33\r\n\\end{eqnarray*}\\]Usando tabela de probabilidade normal, identifique linha de \\(-0.3\\) e coluna de \\(0.03\\), o que corresponde à probabilidade de \\(0.3707\\). Edward está 37 percentil.Prática Orientada 3.9  Stuart obteve uma pontuação SAT de 2100. Faça uma figura para cada parte.120Qual é o seu percentil?\r\nQual é o seu percentil?Qual percentual de participantes SAT se saiu melhor que Stuart?\r\nQual percentual de participantes SAT se saiu melhor que Stuart?\r\nPrática Orientada 3.10  \r\nBaseado em uma amostra de 100 homens121, altura de adultos sexo masculino entre idades de 20 e 62 anos nos EUA é quase normal, com média de 178cm e desvio padrão de 8.38cm.Mike tem 170cm e Jim tem 193cm.122Qual é o percentil de altura de Mike?\r\nQual é o percentil de altura de Mike?Qual é o percentil de altura de Jim? Também desenhe uma imagem para cada parte.\r\nQual é o percentil de altura de Jim? Também desenhe uma imagem para cada parte.\r\nOs últimos vários problemas se concentraram em encontrar probabilidade ou o percentil de uma observação em particular. E se você quiser saber observação correspondente um percentil específico?Como sempre, primeiro desenhe distribuição.Neste caso, probabilidade de cauda inferior é conhecida (0.40), que pode ser sombreada figura. Queremos encontrar observação que corresponde esse valor. Como primeiro passo nessa direção, determinamos o ponto Z associado ao percentil 40.Porque o percentil está abaixo 50%, Sabemos que \\(Z\\) será negativo. Olhando na parte negativa da tabela de probabilidade normal, procuramos probabilidade dentro da tabela mais próxima de 0.4000. Descobrimos que 0.4000 cai na linha \\(-0.2\\) e entre colunas \\(0.05\\) e \\(0.06\\). Uma vez que se aproxima de \\(0.05\\), tomamos este: \\(Z = -0.25\\). Sabendo \\(Z_{Erik}=-0.25\\) e os parâmetros da população \\(\\mu= 178\\) e \\(\\sigma= 8.38\\)cm, fórmula ponto Z pode ser configurada para determinar altura desconhecida de Erik, \\(x_{Erik}\\):\\[\\begin{eqnarray*}\r\n-0.25 = Z_{Erik} = \\frac{x_{Erik} - \\mu}{\\sigma} = \\frac{x_{Erik} - 178}{8.38}\r\n\\end{eqnarray*}\\]Resolvendo para \\(x_{Erik}\\) produz altura 175.88cm. Ou seja, Erik possui certa de 1,76m.Mais uma vez, desenhamos figura primeiro.Em seguida, queremos encontrar o ponto Z percentil 82, qual será um valor positivo. Olhando na tabela Z, encontramos \\(Z\\) na linha \\(0.9\\) e coluna mais próxima é \\(0.02\\), .e. \\(Z=0.92\\). Finalmente, altura \\(x\\) é encontrada usando fórmula escore Z com média conhecida \\(\\mu\\), desvio padrão \\(\\sigma\\), e ponto Z, \\(Z=0.92\\):\\[\\begin{eqnarray*}\r\n0.92 = Z = \\frac{x-\\mu}{\\sigma} = \\frac{x - 178}{8.38}\r\n\\end{eqnarray*}\\]Isto rende 185.67 cm. Ou seja, uma altura de aproximadamente 1.86m como altura 82 percentil.Prática Orientada 3.11  \r\nQual é o:12395 percentil para pontos da SAT?\r\n95 percentil para pontos da SAT?97.5 percentil das alturas masculinas? Como sempre com problemas de probabilidade normais, primeiro desenhe uma figura.\r\n97.5 percentil das alturas masculinas? Como sempre com problemas de probabilidade normais, primeiro desenhe uma figura.\r\nPrática Orientada 3.12  \r\nQual é probabilidade de um adulto:124homem selecionado aleatoriamente ter pelo menos 188cm?\r\nhomem selecionado aleatoriamente ter pelo menos 188cm?sexo masculino ser menor que 175cm?\r\nsexo masculino ser menor que 175cm?\r\nEssas alturas correspondem 1.75m e 1.88m. Primeiro, desenhe figura. área de interesse não é mais uma cauda superior ou inferior.área total sob curva é 1. Se encontrarmos área das duas caudas que não estão sombreadas (da Prática Orientada 3.7, estas áreas são \\(0.3602\\) e \\(0.1164\\)), então podemos encontrar área meio:Ou seja, probabilidade de estar entre 1.75m e 1.88m é 0.5234.","code":"\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 1630,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n  geom_path(size = 1) +\n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = m + 130, linetype = \"dashed\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nall <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 2700,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  # geom_vline(xintercept = m + 130, linetype = \"dashed\", color = \"gold4\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nesquerda <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 1630,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") +\n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = m + 130, linetype = \"dashed\", color = \"gold4\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ndireita <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 1630,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") +\n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = m + 130, linetype = \"dashed\", color = \"gold4\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nrequire(grid)\ngrid.arrange(all, esquerda, direita, ncol = 3, \n             top = textGrob(\"1.0000 - 0.6664 = 0.3336\", gp = gpar(fontsize = 27,font = 8)))\npnorm(q = 1630, mean = 1500, sd = 300, lower.tail = FALSE)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 1400,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = m - 100, linetype = \"dashed\") + \n  geom_hline(yintercept = 0) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\npnorm(q = 1400, mean = 1500, sd = 300, lower.tail = TRUE)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 1400,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n    geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = m - 100, linetype = \"dashed\") + \n  geom_hline(yintercept = 0) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\npnorm(q = 2100, mean = 1500, sd = 300, lower.tail = FALSE)\nset.seed(1)\nm <- 178\ns <- 8.38\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < qnorm(p = 0.40, mean = m, sd = s),], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n    geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = qnorm(p = 0.40, mean = m, sd = s), \n             linetype = \"dashed\") + \n  geom_hline(yintercept = 0) + \n  annotate(\"text\", x = m - 2*s, \n           y = Y[which(grepl(m - s, X))], label = \"0.40 (40%)\") + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s*1.5)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nqnorm(p = 0.40, mean = 178, sd = 8.38)\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < qnorm(p = 0.82, mean = m, sd = s),], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = qnorm(p = 0.82, mean = m, sd = s), \n             linetype = \"dashed\") + \n  geom_hline(yintercept = 0) + \n  annotate(\"text\", x = m - 2*s, \n           y = Y[which(grepl(m - s, X))], label = \"0.82 (82%)\") + \n    annotate(\"text\", x = m + 2*s, \n           y = Y[which(grepl(m - s, X))], label = \"0.18 (18%)\") + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s*1.5)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nqnorm(p = 0.82, mean = 178, sd = 8.38)\npnorm(q = 188, mean = 178, sd = 8.38, lower.tail = FALSE)\n\npnorm(q = 175, mean = 178, sd = 8.38, lower.tail = TRUE)\n# entre 175 e 188\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 175 & gg$X < 188, ], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + \n  geom_vline(xintercept = c(175, 188), \n             linetype = \"dashed\") + \n  geom_hline(yintercept = 0) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s*1.5)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\ninicio <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 144, ], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\np175 <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 175, ], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = 175, \n             linetype = \"dashed\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\np188 <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 188, ], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = 188, \n             linetype = \"dashed\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n\nfinal <- ggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 175 & gg$X < 188, ], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(), axis.text.x = element_blank()) + \n  geom_vline(xintercept = c(175, 188), \n             linetype = \"dashed\") + \n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(inicio, p175, p188, final, ncol = 4, \n             top = textGrob(\"1.000 - 0.3602 - 0.1164 = 0.5234\", gp = gpar(fontsize = 27,font = 8)))"},{"path":"ch3-distribuicoes.html","id":"rule689599","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.1.5 Lei 68-95-99.7","text":"Aqui, apresentamos uma regra útil para probabilidade de cair dentro de 1, 2 e 3 desvios padrão da média na distribuição normal. Isso será útil em uma ampla gama de configurações práticas, especialmente ao tentar fazer uma estimativa rápida sem uma calculadora ou tabela Z.\r\nFigura 3.6: Probabilidades de cair dentro de 1, 2 e 3 desvios padrão da média em uma distribuição normal.\r\nÉ possível que uma variável aleatória normal caia 4, 5 ou ainda mais desvios padrão da média. entanto, essas ocorrências são muito raras se os dados forem quase normais. probabilidade de estar mais que 4 desvios padrão da média é de cerca de 1 em 15.000. Para 5 e 6 desvios padrão, é cerca de 1 em 2 milhões e 1 em 500 milhões, respectivamente.Prática Orientada 3.16  pontuação SAT seguem de perto o modelo normal com média \\(\\mu = 1500\\) e desvio padrão \\(\\sigma = 300\\).128Sobre qual percentual de usuários de teste obtém entre 900 e 2100?\r\nSobre qual percentual de usuários de teste obtém entre 900 e 2100?Qual pontuação percentual entre 1500 e 2100?\r\nQual pontuação percentual entre 1500 e 2100?\r\n","code":"\nset.seed(1)\nm <- 0\ns <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nlibrary(ggplot2)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 2.97 & gg$X > -2.97,], # 99.7% \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") +\n  geom_linerange(data = gg[gg$X < 1.96 & gg$X > -1.96,], # 95%\n                 aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n  geom_linerange(data = gg[gg$X < .99 & gg$X > -.99,], # 68% \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank(),\n        axis.text.x = element_blank(), axis.ticks.x = element_blank(), \n        axis.line.x = element_blank()) + \n  geom_hline(yintercept = 0) + \n  annotate(geom = \"text\", x = 0, y = 0.09, label = \"95%\", size = 4) + \n  annotate(geom = \"text\", x = 0, y = 0.03, label = \"99.7%\", size = 4) + \n  annotate(geom = \"text\", x = 0, y = 0.26, label = \"68%\", size = 4) + \n  geom_segment(aes(x = -1.96, y = 0.07, xend = 1.96, yend = 0.07)) + \n  geom_segment(aes(x = -1.96, y = 0, xend = -1.96, yend = 0.07), linetype = \"dashed\") +\n  geom_segment(aes(x = 1.96, y = 0, xend = 1.96, yend = 0.07), linetype = \"dashed\") + # 95%\n  geom_segment(aes(x = -2.97, y = 0.02, xend = 2.97, yend = 0.02)) + \n  geom_segment(aes(x = -2.97, y = 0, xend = -2.97, yend = 0.02), linetype = \"dashed\") +\n  geom_segment(aes(x = 2.97, y = 0, xend = 2.97, yend = 0.02), linetype = \"dashed\") + #99.7%\n  geom_segment(aes(x = -.99, y = 0.25, xend = .99, yend = 0.25)) + \n  geom_segment(aes(x = -.99, y = 0, xend = -.99, yend = 0.25), linetype = \"dashed\") +\n  geom_segment(aes(x = .99, y = 0, xend = .99, yend = 0.25), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 0, y = -0.02, label = expression(mu*''), size = 4) +\n  annotate(geom = \"text\", x = 1, y = -0.02, label = expression(mu*'+'*sigma), size = 4) +\n  annotate(geom = \"text\", x = -1, y = -0.02, label = expression(mu*'-'*sigma), size = 4) +\n  annotate(geom = \"text\", x = 2, y = -0.02, label = expression(mu*'+ 2'*sigma), size = 4) +\n  annotate(geom = \"text\", x = -2, y = -0.02, label = expression(mu*'- 2'*sigma), size = 4) +\n  annotate(geom = \"text\", x = 3, y = -0.02, label = expression(mu*'+ 3'*sigma), size = 4) +\n  annotate(geom = \"text\", x = -3, y = -0.02, label = expression(mu*'- 3'*sigma), size = 4) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch3-distribuicoes.html","id":"assessingNormalApproach","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.2 Avaliando a aproximação normal","text":"Muitos processos podem ser bem aproximados pela distribuição normal. Já vimos dois bons exemplos: os resultados SAT e alturas dos homens adultos dos EUA. Embora o uso de um modelo normal possa ser extremamente conveniente e útil, é importante lembrar que normalidade é sempre uma aproximação. Avaliar adequação da suposição normal é um passo fundamental em muitas análises de dados.Exemplo da altura sugere que distribuição das alturas dos homens norte-americanos é bem aproximada pelo modelo normal. Estamos interessados em prosseguir com suposição de que os dados são normalmente distribuídos, mas primeiro devemos verificar se isso é razoável.Existem dois métodos visuais para verificar suposição de normalidade, que podem ser implementados e interpretados rapidamente. O primeiro é um histograma simples com curva normal de melhor ajuste sobreposta à plotagem, como mostrado painel Figura 3.7. média da amostra \\(\\bar{x}\\) e desvio padrão \\(s\\) são usados como os parâmetros da curva normal de melhor ajuste. Quanto mais esta curva se encaixa histograma, mais razoável é suposição modelo normal. Outro método mais comum é examinar um gráfico de probabilidade normal129, mostrado painel direito da Figura 3.7. Quanto mais próximos os pontos estiverem de uma linha reta perfeita, mais confiantes estaremos de que os dados seguem o modelo normal.\r\nFigura 3.7: Uma amostra de 100 alturas masculinas. observações são arredondadas para o centímetro inteiro mais próximo, explicando por que os pontos parecem saltar em incrementos gráfico de probabilidade normal.\r\n\r\nFigura 3.8: Histogramas e gráficos de probabilidade normal para três conjuntos de dados normais simulados; \\(n=40\\) (esquerda), \\(n=100\\) (meio), \\(n=400\\) (direita).\r\nOs painéis da esquerda mostram o histograma (superior) e o gráfico de probabilidade normal (inferior) para o conjunto de dados simulado com 40 observações. O conjunto de dados é muito pequeno para realmente ver uma estrutura clara histograma. O gráfico de probabilidade normal também reflete isso, onde existem alguns desvios da linha. Devemos esperar desvios desse valor para um conjunto de dados tão pequeno.\r\nOs painéis meio mostram gráficos de diagnóstico para o conjunto de dados com 100 observações simuladas. O histograma mostra mais normalidade e o gráfico de probabilidade normal mostra um melhor ajuste. Embora existam algumas observações que se desviam notavelmente da linha, elas não são particularmente extremas.O conjunto de dados com 400 observações tem um histograma que se assemelha muito à distribuição normal, enquanto o gráfico de probabilidade normal é quase uma linha reta perfeita. Novamente, gráfico de probabilidade normal, há uma observação (maior) que se desvia ligeiramente da linha. Se essa observação tivesse se desviado três vezes mais da linha, seria mais importante em um conjunto de dados real. Os outliers aparentes podem ocorrer em dados normalmente distribuídos, mas são raros.Observe que os histogramas parecem mais normais à medida que o tamanho da amostra aumenta, e o gráfico de probabilidade normal se torna mais reto e mais estável. Pela Figura 3.9 é possível notar o comportamento histograma conforme aumentamos o tamanho da amostra e como seu comportamento vai ficando mais parecido com o de uma distribuição normal.\r\nFigura 3.9: Histogramas simulados para dados normalmente distribuídos conforme o tamanho da amostra aumenta\r\nPrimeiro criamos um histograma e um gráfico de probabilidade normal das alturas dos jogadores da NBA. O histograma painel esquerdo está ligeiramente inclinado para esquerda, o que não contrasta com distribuição normal simétrica. Os pontos gráfico de probabilidade normal não parecem seguir de perto uma linha reta, mas mostram o que parece ser uma “onda.” Podemos comparar essas características com amostra de 400 observações normalmente distribuídas exemplo anterior e ver que eles representam desvios muito mais fortes modelo normal. alturas dos jogadores da NBA não parecem vir de uma distribuição normal.\r\nFigura 3.10: Histograma e gráfico de probabilidade normal para alturas da NBA da temporada de 2008-9.\r\nOs dados são muito fortemente distorcidos histograma, que corresponde aos desvios muito fortes componente superior direito gráfico de probabilidade normal. Se compararmos esses resultados com amostra de 40 observações normais Exemplo 3.8 dos três conjuntos de dados normais simulados, é evidente que esses dados mostram desvios muito fortes modelo normal.\r\nFigura 3.11: Um histograma de dados de pôquer com distribuição normal mais adequada e um gráfico de probabilidade normal.\r\n\r\nFigura 3.12:  Quatro parcelas de probabilidades normais.\r\nDica: : Quando observações aparecem para baixo lado esquerdo de um gráfico de probabilidade normal, isso significa que os dados têm mais outliers na cauda esquerda que esperávamos em uma distribuição normal. Quando observações surgem lado direito, isso significa que os dados têm mais outliers na cauda direita que o esperado na distribuição normal.\r\nFigura 3.13: Gráficos de probabilidade normal para Prática orientada.\r\n","code":"\nobs <- c(180.34, 170.18, 175.26, 177.8, 172.72, 160.02, 172.72, 182.88, 177.8, 177.8, 167.64, 180.34, 180.34, 172.72, 165.1, 154.94, 180.34, 172.72, 165.1, 167.64, 182.88, 175.26, 182.88, 177.8, 175.26, 185.42, 175.26, 167.64, 187.96, 175.26, 180.34, 175.26, 198.12, 177.8, 185.42, 175.26, 180.34, 187.96, 182.88, 187.96, 177.8, 182.88, 187.96, 170.18, 182.88, 182.88, 175.26, 170.18, 182.88, 180.34, 180.34, 170.18, 180.34, 187.96, 193.04, 175.26, 193.04, 182.88, 177.8, 167.64, 170.18, 160.02, 172.72, 193.04, 187.96, 190.5, 172.72, 175.26, 193.04, 180.34, 162.56, 187.96, 182.88, 180.34, 177.8, 172.72, 185.42, 180.34, 180.34, 182.88, 185.42, 180.34, 195.58, 185.42, 170.18, 170.18, 172.72, 180.34, 190.5, 172.72, 182.88, 170.18, 177.8, 175.26, 162.56, 162.56, 175.26, 167.64, 170.18, 177.8) #dados\n\nrequire(qqplotr) # para o qqplot \n\nhist <- ggplot() + \n  geom_histogram(aes(x = obs, y = ..density..), bins = 9, color = \"white\", fill = \"#EAB217\") + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  labs(x = \"Altura masculina (em cm)\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n  \ndados <- data.frame(obs)\nqq <- ggplot(data = dados, mapping = aes(sample = obs)) +\n  stat_qq_line(color = 'white') +\n  stat_qq_point(color = \"#EAB217\") +\n  labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n\ngrid.arrange(hist, qq, ncol = 2)\nset.seed(35)\ndados = data.frame(c(rnorm(40), rnorm(100), rnorm(400)),\n                   c(rep(\"40\", 40), rep(\"100\", 100), rep(\"400\", 400))) #simulando os dados\ncolnames(dados) <- c(\"obs\", \"n\") #nomear as colunas\n\ndados$n <- factor(dados$n, levels = unique(dados$n)) #deixar a ordem de acordo com o banco\n\n\nhis_3 <- ggplot(data = dados) + \n  geom_histogram(aes(x = obs, y = ..density.., fill = n), bins = 13, \n                 color = \"white\") + \n  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) +\n  labs(x = \"\", y = \"\") + facet_wrap(~n) + \n  theme(legend.position = \"none\") + \n  scale_fill_manual(values = c('#E6205F', '#E97C31', \"#EAB217\")) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nqq_3 <- ggplot(data = dados, aes(sample = obs, color = n)) + \n  stat_qq() +\n  stat_qq_line() + \n  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) +\n  labs(x = \"\",y = \"\") + facet_wrap(~n) + \n  theme(legend.position = \"none\") + \n  scale_color_manual(values = c('#E6205F', '#E97C31', \"#EAB217\")) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(his_3, qq_3, ncol = 1) \nlibrary(gganimate)\nlibrary(magick)\n\nset.seed(1)\ntres <- data.frame(obs <- c(rnorm(40), rnorm(100), rnorm(400), rnorm(1000)), \n           n <- c(rep(40, 40), rep(100, 100), rep(400, 400), rep(1000, 1000)))\n\ncolnames(tres) <- c(\"obs\", \"n\")\n\nanim <- ggplot(tres, aes(x = obs, fill = n)) +\n  geom_histogram(aes(y = ..density..), bins = 10, color = \"white\") + \n  scale_x_continuous(breaks = seq(-4, 4, 1)) + \n  scale_fill_gradient(low = \"#E6205F\", high = \"#EAB217\") + \n  theme(axis.ticks.y = element_blank(), \n        axis.text.y = element_blank(), legend.position = 'none') + \n  # Especifico do gganimate\n  labs(title = 'Tamanho da amostra: {frame_time}', x = ' ', y = ' ') +\n  transition_time(as.integer(n)) +\n  ease_aes('linear') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nanimate(anim, renderer = magick_renderer())\nanim_save(\"images/c3/anim.gif\")\nknitr::include_graphics(\"images/c3/anim.gif\")\nlibrary(openintro)\ndata(nba.heights)\n\nobs <- nba.heights[, 4]\n\nobs <- obs*2.54 #está em inches, transformar para cm \n\nhist2 <- ggplot() + \n  geom_histogram(aes(x = obs, y = ..density..), bins = 11, color = \"white\", fill = \"#E97C31\") + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  labs(x = \"Altura (em cm)\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ndados <- data.frame(obs)\nqq2 <- ggplot(data = dados, mapping = aes(sample = obs)) +\n  stat_qq_line(color = 'white') +\n  stat_qq_point(color = \"#E97C31\") +\n  labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(hist2, qq2, ncol = 2)\nobs <- c(-110, -9, -60, 316, -200, -196,\n         320, -160, 31, 331, 1731, 21,\n         -926, -475, 914, -300, -15, 1,\n         -29, 829, 761, 227, -141, -672,\n         352, 385, 24, 103, -826, 95,\n         115, 39, -9, -1000, -35, -200,\n         -200, 235, 70, 307, 135, 60,\n         -100, -295, -1000, 361, -95,\n         337, 3712, -255)\n\nhist2 <- ggplot() + \n  geom_histogram(aes(x = obs, y = ..density..), bins = 11, color = \"white\", fill = \"#E97C31\") + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  labs(x = \"Altura (em cm)\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ndados <- data.frame(obs)\nqq2 <- ggplot(data = dados, mapping = aes(sample = obs)) +\n  stat_qq_line(color = 'white') +\n  stat_qq_point(color = \"#E97C31\") +\n  labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(hist2, qq2, ncol = 2)\nobs1 <- c(94.26, 79.54, 68.06, 63.96, 68.19, 89.73, 85.41, 76.29, 87.96, 87.32, 77.23, 58.01, 82.76, 80.17, 111.07, 88.07, 68.12, 87.58, 78.14, 39.64, 54.84, 84.88, 77.49, 91.56, 112.59, 97.78, 92.86, 100.78, 88.17, 71.69, 86.64, 80.79, 64.77, 103.2, 84.88, 69.51, 60.65, 68.41, 80.48, 71.39, 84.21, 87.66, 78.76, 74.04, 101.89, 89.83, 74.83, 84.47, 77.82, 88.07, 79.19, 58.31, 96.49, 4.27, 81.02, 80.36, 69.74, 77.78, 78.58, 62.12, 116.55, 83.32, 103.85, 90.29, 86.96, 71.35, 119.21, 82.68, 63.13, 109.77, 30.63, 93.48, 97.25, 56.43, 94.07, 74.97, 105.69, 76.5, 89.74, 47.85, 92.37, 128.92, 70.12, 74.07, 92.88, 81.49, 69.54, 70.66, 88.6, 92.74, 103.38, 109.85, 83.35, 94.64, 74.3, 93.15, 62.33, 72.77, 75.63, 91.18)\n\nobs2 <- c(10.41, 8.256, 9.035, 8.487, 7.985, 12.801, 8.367, 8.619, 10.431, 9.883, 12.596, 9.962, 12.641, 11.221, 12.362, 8.111, 5.772, 11.269, 9.259, 12.357, 8.928, 8.173, 6.02, 6.59, 10.582, 9.163, 5.017, 7.32, 8.195, 8.181, 12.547, 9.042, 13.811, 7.195, 9.215, 9.873, 11.662, 10.123, 7.784, 9.383, 8.754, 10.248, 8.332, 9.878, 11.794, 8.868, 11.171, 4.703, 9.362, 10.648)\n\nobs3 <- c(-2.271, -2.205, -2.516, -1.583, -2.641, -1.948, -2.109, -1.847, -2.484, -2.523, -1.458, -1.544, -0.976, -1.652, -1.894, -1.781, -1.788, -2.733, -2.422, -1.015, -1.939, -1.381, -1.754, -1.358, -1.77, -1.46, -2.018, -2.659, -2.137, -2.064, -2.503, -1.969, -1.309, -2.121, -2.247, -1.361, -2.423, -1.846, -1.851, -2.164, -2.579, -2.094, -1.758, -2.553, -2.175, -2.037, -2.134, -1.728, -2.008, -2.269, -1.962, -2.729, -2.063, -1.657, -2.076, -1.678, -1.766, -2.022, -1.716, -1.33, -3.047, -1.198, -3.141, -2.026, -3.251, -2.766, -2.127, -1.191, -1.879, -2.203, -1.871, -1.762, -2.114, -2.617, -2.041, -1.446, -1.844, -2.224, -3.023, -1.231, -1.001, -1.324, -2.18, -0.937, -1.862, -2.136, -1.821, -1.245, -2.025, -2.27, -1.746, -2.103, -2.224, -1.676, -1.369, -1.865, -1.841, -2.098, -1.728, -2.152, -1.959, -1.781, -1.635, -1.856, -2.037, -0.793, -2.663, -1.976, -1.851, -1.548, -1.594, -1.375, -2.372, -1.983, -1.761, -1.937, -2.559, -1.753, -0.6, -1.688, -1.605, -1.215, -2.31, -1.846, -1.919, -2.582, -2.923, -1.74, -3.141, -1.33, -2.46, -2.361, -2.727, -1.74, -2.372, -2.187, -2.339, -1.777, -2.358, -1.973, -2.094, -2.028, -1.905, -2.289, -1.001, -1.948, -2.55, -1.304, -2.81, -1.943, -2.19, -1.809, -2.509, -1.948, -1.455, -1.6, -2.81, -1.021, -1.264, -1.853, -2.357, -2.012, -2.379, -1.681, -1.795, -2.39, -2.217, -2.812, -2.625, -1.219, -1.21, -1.303, -2.825, -1.94, -1.388, -2.627, -1.85, -1.661, -1.369, -1.853, -1.177, -2.011, -2.505, -2.017, -1.262, -2.238, -2.513, -1.847, -2.333, -2.874, -1.802, -1.914, -2.002, -1.963, -3.067, -2.139, -1.611, -2.574, -2.037, -1.368, -1.574, -2.48, -2.62, -2.77, -1.608, -2.062, -1.773, -0.881, -2.073, -2.505, -2.122, -1.438, -2.187, -2.27, -1.692, -1.647, -3.085, -1.436, -2.867, -1.702, -1.708, -1.837, -1.327, -2.478, -1.971, -2.941, -1.395, -1.975, -2.145, -1.919, -1.81, -2.276, -2.183, -1.37, -2.328, -1.408, -2.925, -2.092, -2.462, -1.629, -2.461, -1.795, -2.299, -1.725, -1.69, -2.434, -1.472, -1.849, -1.793, -1.906, -2.643, -2.016, -2.032, -2.696, -2.169, -2.285, -2.301, -2.154, -3.027, -2.141, -2.835, -1.704, -2.788, -1.029, -2.727, -1.444, -1.508, -2.153, -2.57, -2.339, -1.515, -1.356, -2.242, -2.204, -2.093, -2.41, -2.009, -2.357, -1.214, -2.751, -1.587, -2.438, -2.194, -2.271, -2.278, -1.829, -2.14, -1.503, -2.075, -1.235, -1.965, -2.183, -1.596, -2.551, -2.462, -3.723, -2.059, -2.113, -2.174, -3.183, -1.831, -0.748, -2.482, -1.605, -1.25, -1.358, -2.845, -2.539, -1.431, -2.654, -2.003, -1.891, -2.593, -1.782, -1.756, -2.477, -1.882, -1.637, -2.467, -1.089, -2.739, -1.822, -2.153, -2.073, -1.828, -2.325, -1.213, -1.869, -1.708, -1.508, -2.31, -1.262, -2.788, -2.32, -1.697, -1.681, -1.935, -2.677, -1.792, -1.802, -2.876, -1.652, -1.861, -2.209, -3.094, -1.013, -2.992, -3.04, -1.948, -1.572, -1.95, -1.742, -1.958, -2.513, -1.599, -2.027, -1.605, -1.52, -1.955, -1.95, -1.474, -2.284, -0.96, -2.222, -2.618, -2.14, -1.752, -1.108, -1.687, -2.145, -1.921, -2.184, -1.818, -1.84, -2.474, -2.005, -1.76, -1.991, -2.461, -2.383, -2.652, -2.385, -1.529, -2.079, -2.112, -2.192, -1.696, -2.206, -1.737, -1.858, -2.573, -2.474, -1.539, -1.689, -1.854, -1.737, -2.021, -1.606, -2.009, -1.419, -2.55, -1.558, -1.887, -2.149, -2.666, -2.271, -1.587, -2.419, -1.902, -2.953, -1.811, -2.449, -2.2, -1.736, -1.537, -1.26, -2.184, -2.096, -1.73, -1.958, -2.4, -3.378, -1.808, -2.565, -1.508, -1.577, -2.504, -2.399, -2.333, -1.634, -1.11, -1.98, -2.014, -1.509, -2.143, -1.432, -1.899, -1.325, -1.32, -1.617, -1.834, -1.849, -1.636, -1.916, -1.166, -1.768, -1.388, -2.293, -2.254, -2.814, -1.44, -1.846, -1.699, -1.499, -2.043, -2.077, -2.02, -1.765, -2.472, -1.547, -2.317, -2.318, -1.686, -1.46, -2.514, -1.343, -2.233, -2.277, -2.298, -2.191, -2.014, -2.219, -1.853, -0.72, -1.607, -1.699, -2.443, -0.588, -1.78, -2.298, -2.168, -2.23, -2.497, -2.585, -3.055, -1.472, -1.456, -2.195, -0.845, -2.057, -2.952, -1.802, -1.841, -1.58, -3.105, -1.996, -1.799, -1.844, -1.373)\n          \nobs4 <- c(-2.428, -9.492, 22.085, 0.348, -11.842, -7.309, -8.679, 62.64, 44.868, -11.637, -3.771, 29.815, -15.36, 15.987, 0.455)\n          \ndados <- data.frame(obs1)\nq1 <- ggplot(data = dados, mapping = aes(sample = obs1)) +\n            stat_qq_point(color = \"#E6205F\") +\n            labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n          \ndados <- data.frame(obs2)\nq2 <- ggplot(data = dados, mapping = aes(sample = obs2)) +\n            stat_qq_point(color = \"#E6205F\") +\n            labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n          \ndados <- data.frame(obs3)\nq3 <- ggplot(data = dados, mapping = aes(sample = obs3)) +\n            stat_qq_point(color = \"#E6205F\") +\n            labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n          \ndados <- data.frame(obs4)\nq4 <- ggplot(data = dados, mapping = aes(sample = obs4)) +\n            stat_qq_point(color = \"#E6205F\") +\n            labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n          \ngrid.arrange(q1, q2, q3, q4, ncol = 2)\nset.seed(1)\nobs1 <- 0.3 * rchisq(25, 1.4)\n\nset.seed(5)\nobs2 <- 16 - 2 * rlnorm(50, sdlog = 0.8)\n\ndados <- data.frame(obs1)\nq1 <- ggplot(data = dados, mapping = aes(sample = obs1)) +\n            stat_qq_point(color = \"#EAB217\") +\n            labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n          \ndados <- data.frame(obs2)\nq2 <- ggplot(data = dados, mapping = aes(sample = obs2)) +\n            stat_qq_point(color = \"#EAB217\") +\n            labs(x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n          \ngrid.arrange(q1, q2, ncol = 2)"},{"path":"ch3-distribuicoes.html","id":"geometricDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.3 Distribuição geométrica (tópico especial)","text":"Quanto tempo devemos esperar para lançar uma moeda até que ela apareça cara? Ou quantas vezes devemos esperar rolar um dado até obtermos um 1? Essas perguntas podem ser respondidas usando distribuição geométrica. Inicialmente, formalizamos cada tentativa - como um lançamento de uma única moeda ou lançamento de dados - usando distribuição de Bernoulli, e então combinamos esses dados com nossas ferramentas de probabilidade para construir distribuição geométrica.","code":""},{"path":"ch3-distribuicoes.html","id":"bernoulliDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.3.1 Distribuição de Bernoulli","text":"Stanley Milgram começou uma série de experimentos em 1963 para estimar que proporção de pessoas obedeceria voluntariamente uma autoridade e daria choques severos um estranho. Milgram descobriu que cerca de 65% das pessoas obedeceriam autoridade e dariam tais choques. Ao longo dos anos, pesquisas adicionais sugeriram que esse número é aproximadamente consistente entre comunidades e o tempo.133Cada pessoa na experiência de Milgram pode ser pensada como prova. Nós rotulamos uma pessoa sucesso se ela se recusar administrar o pior choque. Uma pessoa é rotulada como falha se ela administrar o pior choque. Porque apenas 35% dos indivíduos se recusaram administrar o choque mais grave, nós denotamos o probabilidade de sucesso com \\(p=0.35\\). probabilidade de uma falha é algumas vezes denotada \\(q=1-p\\).Portanto, sucesso ou falha é registrado para cada pessoa estudo. Quando um teste individual tem apenas dois resultados possíveis, ele é chamado de Variável aleatória de Bernoulli.Variável aleatória de Bernoulli, descritiva: Uma variável aleatória de Bernoulli tem exatamente dois resultados possíveis. Normalmente rotulamos um desses resultados como “sucesso” e o outro como “falha.” Podemos também denotar um sucesso por 1 e um fracasso por 0.Dica: “sucesso” não precisa ser algo positivo.: Nós escolhemos rotular uma pessoa que se recusa administrar o pior choque de um “sucesso” e todos os outros como “fracassos.” entanto, poderíamos facilmente reverter esses rótulos. O arcabouço matemático que vamos construir não depende de qual resultado é rotulado como sucesso e qual falha, desde que seja consistente.Variáveis aleatórias de Bernoulli são frequentemente indicadas como 1 para um sucesso e 0 para uma falha. Além de ser conveniente ao inserir dados, também é matematicamente útil. Suponha que observemos dez tentativas:Então proporção amostral, \\(\\hat{p}\\), é média amostral dessas observações:\\[\\begin{eqnarray*}\r\n\\hat{p} = \\frac{\\text{# de sucessos}}{\\text{# de tentativas}} = \\frac{0+1+1+1+1+0+1+1+0+0}{10} = 0.6\r\n\\end{eqnarray*}\\]Esta investigação matemática das variáveis aleatórias de Bernoulli pode ser ampliada ainda mais. Como 0 e 1 são resultados numéricos, podemos definir média e desvio padrão de uma variável aleatória de Bernoulli.Se \\({p}\\) é verdadeira probabilidade de um sucesso, então média de uma variável aleatória de Bernoulli \\(X\\) é dado por\\[\\begin{align*}\r\n\\mu = E[X] &= P(X=0)\\times0 + P(X=1)\\times1 \\\\\r\n    &= (1-p)\\times0 + p\\times 1 = 0+p \\\\\r\n    &= p\r\n\\end{align*}\\]Da mesma forma, variância \\(X\\) pode ser calculado:\\[\\begin{align*}\r\n\\sigma^2 &= {P(X=0)(0-p)^2 + P(X=1)(1-p)^2} \\\\\r\n    &= {(1-p)p^2 + p(1-p)^2} \\\\\r\n    &= p(1-p)\r\n\\end{align*}\\]O desvio padrão é \\(\\sigma=\\sqrt{p(1-p)}\\).Variável aleatória de Bernoulli, matemática: Se \\(X\\) é uma variável aleatória que leva valor 1 com probabilidade de sucesso \\(p\\) e 0 com probabilidade \\(1-p\\), então \\(X\\) é uma variável aleatória de Bernoulli com média e desvio padrão\\[\\begin{align*}\r\n\\mu &= p\r\n    &\\sigma&= \\sqrt{p(1-p)}\r\n\\end{align*}\\]Em geral, é útil pensar em uma variável aleatória de Bernoulli como um processo aleatório com apenas dois resultados: um sucesso ou fracasso. Em seguida, construímos nossa estrutura matemética usando os rótulos numéricos 1 e 0 para sucessos e falhas, respectivamente.","code":""},{"path":"ch3-distribuicoes.html","id":"geometricDistribution2","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.3.2 Distribuição Geométrica","text":"probabilidade de parar após primeira pessoa é apenas chance de primeira pessoa não administrar o pior choque: \\(1-0.65=0.35\\). probabilidade de ser segunda pessoa é\\[\\begin{eqnarray*}\r\n&&P(\\text{segunda pessoa é o primeiro não administrar o pior choque}) \\\\\r\n&&\\quad = P(\\text{o primeiro vai, o segundo não}) = (0.65)\\times(0.35) = 0.228\r\n\\end{eqnarray*}\\]Da mesma forma, probabilidade de ser terceira pessoa ? \\((0.65)\\times(0.65)\\times(0.35) = 0.148\\).Se o primeiro sucesso está \\(n^{th}\\) pessoa, então eles são \\(n-1\\) falhas e, finalmente, 1 sucesso, o que corresponde ? probabilidade \\((0.65)^{n-1}(0.35)\\). Isso é o mesmo que \\((1-0.35)^{n-1}(0.35)\\).Esse exemplo ilustra o que é chamado de distribuição geométrica, que descreve o tempo de espera até um sucesso para distribuição independente e identicamente distribuída (iid). Neste caso, o aspecto independência apenas significa que os indivíduos exemplo não afetam uns aos outros, e idêntico significa que cada um deles tem mesma probabilidade de sucesso.Dica: : distribuição geométrica pode ser simulada através da função rgeom disponível na base software R.rgeom(n, prob)distribuição geométrica exemplo é mostrado na Figura 3.14. Em geral, probabilidades de uma redução na distribuição geométrica exponencialmente rápida.\r\nFigura 3.14: distribuição geométrica quando probabilidade de sucesso é \\(p=0.35\\).\r\nEnquanto este texto não deriva fórmulas para o número médio (esperado) de tentativas necessárias para encontrar o primeiro sucesso ou o desvio padrão ou variância desta distribuição, apresentamos fórmulas gerais para cada um.Distribuição geométrica: Se probabilidade de sucesso em um teste é \\(p\\) e probabilidade de uma falha é \\(1-p\\), então probabilidade de encontrar o primeiro sucesso na n-ésima observação é dada por\\[\\begin{eqnarray}\r\n(1-p)^{n-1}p\r\n\\end{eqnarray}\\]média (ou seja, o valor esperado), variância e o desvio padrão desse tempo de espera são fornecidos por\\[\\begin{align*}\r\n  \\mu &= \\frac{1}{p}\r\n    &\\sigma^2&=\\frac{1-p}{p^2}\r\n    &\\sigma &= \\sqrt{\\frac{1-p}{p^2}}\r\n  \\tag{3.1}\r\n\\end{align*}\\]Não é por acaso que usamos o símbolo \\(\\mu\\) para o valor médio e esperado. média e o valor esperado são o mesmo. O lado esquerdo da Equação (3.1) diz que, em média, são necessários \\(1/p\\) para obter sucesso. Este resultado matemático é consistente com o que esperamos intuitivamente. Se probabilidade de um sucesso é alta (por exemplo, 0.8), então, normalmente, não esperamos muito tempo por um sucesso: \\(1/0.8 = 1.25\\) ensaios em média. Se probabilidade de sucesso baixa (por exemplo, 0.1), esperaríamos ver muitos testes antes de vermos um sucesso: \\(1/0.1 = 10\\) ensaios.Esta é chance da primeira (\\(n=1\\)), segunda (\\(n=2\\)), terceira (\\(n=3\\)), ou quarta (\\(n=4\\)) pessoa ser o primeiro sucesso, que são quatro desfechos disjuntos. Como os indivíduos da amostra são amostrados aleatoriamente em uma grande população, eles são independentes. Calculamos probabilidade de cada caso e adicionamos os resultados separados:\\[\\begin{eqnarray*}\r\n&&P(n=1, 2, 3,\\text{ }4) \\\\\r\n    && \\quad = P(n=1)+P(n=2)+P(n=3)+P(n=4) \\\\\r\n    && \\quad = (0.65)^{1-1}(0.35) + (0.65)^{2-1}(0.35) + (0.65)^{3-1}(0.35) + (0.65)^{4-1}(0.35) \\\\\r\n    && \\quad = 0.82\r\n\\end{eqnarray*}\\]Há 82% de chance que ela irá acabar os estudos com 4 pessoas.Um sucesso é quando alguém não vai infligir o pior choque, que tem probabilidade \\(p=1-0.55=0.45\\) para esta região. O número esperado de pessoas serem verificadas é \\(1/p = 1/0.45 = 2.22\\) e o desvio padrão é \\(\\sqrt{(1-p)/p^2} = 1.65\\).suposição de independência é crucial para descrição precisa da distribuição geométrica de um cenário. Matematicamente, podemos ver que para construir probabilidade sucesso n julgamento, tivemos que usar regra de multiplicação para processos independentes. Não é tarefa simples generalizar o modelo geométrico para tentativas dependentes.","code":"\nset.seed(242)\nggplot() + \n  geom_histogram(aes(x = rgeom(n = 1000, prob = 0.35), y = ..density..), bins = 12, \n                 color = \"white\", fill = \"#E6205F\") + \n  labs(x = \"Número de tentativas\", y = \"Probabilidade\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch3-distribuicoes.html","id":"binomialDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.4 Distribuição binomial (tópico especial)","text":"Vamos considerar um cenário em que uma pessoa se recusa:\\[\\begin{eqnarray*}\r\n&&P(=\\text{recusa},\\text{ }B=\\text{choque},\\text{ }C=\\text{choque},\\text{ }D=\\text{choque}) \\\\\r\n &&\\quad =  P(=\\text{recusa})\\ P(B=\\text{choque})\\ P(C=\\text{choque})\\ P(D=\\text{choque}) \\\\\r\n &&\\quad =  (0.35)  (0.65)  (0.65)  (0.65) = (0.35)^1 (0.65)^3 = 0.096\r\n\\end{eqnarray*}\\]Mas há três outros cenários: Brittany, Caroline ou Damian poderiam ter recusado. Em cada um desses casos, probabilidade é novamente \\((0.35)^1(0.65)^3\\). Esses quatro cenários esgotam todas maneiras possíveis que exatamente uma dessas quatro pessoas pode se recusar administrar o choque mais severo, então probabilidade total é de \\(4\\times(0.35)^1(0.65)^3 = 0.38\\).","code":""},{"path":"ch3-distribuicoes.html","id":"theBinomialDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.4.1 A distribuição binomial","text":"O cenário descrito exemplo acima é um caso especial que é chamado de distribuição binomial. distribuição binomial descreve probabilidade de ter exatamente \\(k\\) sucessos em \\(n\\) ensaios independentes de Bernoulli com probabilidade de sucesso \\(p\\) (Exemplo, \\(n=4\\), \\(k=1\\), \\(p=0.35\\)). Gostaríamos de determinar probabilidades associadas à distribuição binomial de forma mais geral, ou seja, queremos uma fórmula onde possamos usar \\(n\\), \\(k\\), e \\(p\\) para obter probabilidade. Para fazer isso, reexaminamos cada parte exemplo.Havia quatro indivíduos que poderiam ter recusado, e cada um desses quatro cenários tinha mesma probabilidade. Assim, poderíamos identificar probabilidade final como\\[\\begin{eqnarray}\r\n[\\text{# de cenários}] \\times P(\\text{cenário único})\r\n\\tag{3.2}\r\n\\end{eqnarray}\\]O primeiro componente da Equação (3.2) é o número de maneiras de organizar os \\(k=1\\) sucessos entre tentativas \\(n=4\\). O segundo componente é probabilidade de qualquer um dos quatro (igualmente prováveis) cenários. Considere \\(P(\\)cenário único\\()\\) caso geral de \\(k\\) sucessos e \\(n-k\\) falhas nos \\(n\\) ensaios. Em qualquer cenário, aplicamos regra de multiplicação para eventos independentes:\\[\\begin{eqnarray*}\r\np^k(1-p)^{n-k}\r\n\\end{eqnarray*}\\]Esta é nossa fórmula geral para \\(P(\\)cenário único\\()\\).Em segundo lugar, introduzimos uma fórmula geral para o número de maneiras de escolher \\(k\\) sucessos em \\(n\\) tentativas, ou seja, organizar \\(k\\) sucessos e o restante de falhas (\\(n-k\\)):\\[\\begin{eqnarray*}\r\n{n\\choose k} = \\frac{n!}{k!(n-k)!}\r\n\\end{eqnarray*}\\]quantidade \\({n\\choose k}\\) é lida como n escolhe k.139 notação ponto de exclamação (por exemplo \\(k!\\)) denota uma expressão fatorial.\\[\\begin{eqnarray*}\r\n&& 0! = 1 \\label{zeroFactorial} \\\\\r\n&& 1! = 1 \\\\\r\n&& 2! = 2\\times1 = 2 \\\\\r\n&& 3! = 3\\times2\\times1 = 6 \\\\\r\n&& 4! = 4\\times3\\times2\\times1 = 24 \\\\\r\n&& \\vdots \\\\\r\n&& n! = n\\times(n-1)\\times...\\times3\\times2\\times1\r\n\\end{eqnarray*}\\]Usando fórmula, podemos calcular o número de maneiras de escolher \\(k=1\\) sucessos em \\(n=4\\) ensaios:\\[\\begin{eqnarray*}\r\n{4 \\choose 1} = \\frac{4!}{1!(4-1)!} =  \\frac{4!}{1!3!} \r\n    = \\frac{4\\times3\\times2\\times1}{(1)(3\\times2\\times1)} = 4\r\n\\end{eqnarray*}\\]Este resultado é exatamente o que encontramos pensando cuidadosamente em cada cenário possível Exemplo 3.14.Substituindo combinação \\(n\\) e \\(k\\) pelo número de cenários e \\(p^k(1-p)^{n-k}\\) para probabilidade cenário único, fórmula \\([\\text{# de cenários}] \\times P(\\text{cenário único})\\) produz fórmula binomial geral.Distribuição binomial: Suponha que probabilidade de um único teste ser um sucesso seja \\(p\\). Então probabilidade de observar exatamente \\(k\\) sucessos em \\(n\\) tentativas independentes é dada por\\[\\begin{eqnarray}\r\n{n\\choose k}p^k(1-p)^{n-k} = \\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\r\n\\tag{3.3}\r\n\\end{eqnarray}\\]Além disso, média, variância e desvio padrâo número de sucessos observados são\\[\\begin{align}\r\n\\mu &= np\r\n    &\\sigma^2 &= np(1-p)\r\n    &\\sigma &= \\sqrt{np(1-p)}\r\n    \\tag{3.4}\r\n\\end{align}\\]Dica: é binomial? Quatro condições para verificar:Os ensaios são independentes.Os ensaios são independentes.O número de tentativas, \\(n\\), é fixo.O número de tentativas, \\(n\\), é fixo.Cada resultado ensaio pode ser classificado como sucesso ou falha.Cada resultado ensaio pode ser classificado como sucesso ou falha.probabilidade de sucesso, \\(p\\), é mesma para cada tentativa.probabilidade de sucesso, \\(p\\), é mesma para cada tentativa.Nós gostaríamos de aplicar o modelo binomial, então checamos nossas condições. O número de tentativas é fixo (\\(n=8\\)) (condição 2) e cada resultado da avaliação pode ser classificado como um sucesso ou falha (condição 3). Como amostra é aleatória, os testes são independentes (condição 1) e probabilidade de sucesso é mesma para cada tentativa (condição 4).resultado de interesse, há \\(k=3\\) sucessos em \\(n=8\\) tentativas e probabilidade de um sucesso é \\(p= 0.35\\). Assim, probabilidade de que 3 de 8 se recusem é dada por\\[\\begin{eqnarray*}\r\n{ 8 \\choose 3}(0.35)^3(1-0.35)^{8-3}\r\n    &=& \\frac{8!}{3!(8-3)!}(0.35)^3(1-0.35)^{8-3} \\\\\r\n    &=& \\frac{8!}{3!5!}(0.35)^3(0.65)^5\r\n\\end{eqnarray*}\\]Trabalhando com parte fatorial:\\[\\begin{eqnarray*}\r\n\\frac{8!}{3!5!} = \\frac{8\\times7\\times6\\times5\\times4\\times3\\times2\\times1}{(3\\times2\\times1)(5\\times4\\times3\\times2\\times1)} = \\frac{8\\times7\\times6}{3\\times2\\times1} = 56\r\n\\end{eqnarray*}\\]Usando \\((0.35)^3(0.65)^5 \\approx 0.005\\), probabilidade final é sobre \\(56*0.005 = 0.28\\).dbinom(x, size, prob, log = FALSE)140Dica: calculando probabilidades binomiais: O primeiro passo para usar o modelo binomial é verificar se o modelo é apropriado. O segundo passo é identificar \\(n\\), \\(p\\) e \\(k\\). O passo final é aplicar fórmulas e interpretar os resultados.Dica: computando combinação entre \\(n\\) e \\(k\\): Em geral, é útil fazer algum cancelamento nos fatoriais imediatamente. Alternativamente, muitos programas de computador e calculadoras incorporaram funções para calcular combinação entre \\(n\\) e \\(k\\), fatoriais e até probabilidades binomiais inteiras.Prática Orientada 3.25  Suponha que esses quatro amigos não se conheçam e possamos tratá-los como se fossem uma amostra aleatória da população. O modelo binomial é apropriado? Qual é probabilidade de que143nenhum deles desenvolva uma condição pulmonar grave?\r\nnenhum deles desenvolva uma condição pulmonar grave?Um irá desenvolver uma condição pulmonar grave?\r\nUm irá desenvolver uma condição pulmonar grave?Que não mais que um irá desenvolver uma condição pulmonar grave?\r\nQue não mais que um irá desenvolver uma condição pulmonar grave?\r\nPrática Orientada 3.27  Suponha que você tenha 7 amigos que sejam fumantes e eles possam ser tratados como uma amostra aleatória de fumantes.Quantos você esperaria desenvolver uma condição pulmonar grave, ou seja, qual é média?\r\nQuantos você esperaria desenvolver uma condição pulmonar grave, ou seja, qual é média?Qual é probabilidade de que máximo 2 dos seus 7 amigos desenvolvam uma condição pulmonar grave?145\r\nQual é probabilidade de que máximo 2 dos seus 7 amigos desenvolvam uma condição pulmonar grave?145\r\nEm seguida, consideramos o primeiro termo na probabilidade binomial, combinação de \\(n\\) e \\(k\\), em alguns cenários especiais.","code":"\ndbinom(x = 3, size = 8, prob = 0.35, log = FALSE)"},{"path":"ch3-distribuicoes.html","id":"normalApproximationBinomialDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.4.2 Aproximação normal à distribuição binomial","text":"fórmula binomial é incômoda quando o tamanho da amostra (\\(n\\)) é grande, principalmente quando consideramos uma série de observações. Em alguns casos, podemos usar distribuição normal como uma maneira mais fácil e rápida de estimar probabilidades binomiais.Deixamos verificação usual de que quatro condições para o modelo binomial são válidas como um exercício. questão colocada é equivalente perguntar, qual é probabilidade de observar \\(k=0\\), \\(1,\\dots,58\\), ou 59 fumantes em uma amostra de \\(n=400\\) quando \\(p=0.20\\)? Podemos calcular essas 60 probabilidades diferentes e juntá-las para encontrar resposta:\\[\\begin{align*}\r\n&P(k=0\\text{ }k=1\\text{ }\\cdots\\text{ } k=59) \\\\\r\n    &\\qquad= P(k=0) + P(k=1) + \\cdots + P(k=59) \\\\\r\n    &\\qquad=0.0041\r\n\\end{align*}\\]Se proporção real de fumantes na comunidade \\(p=0,20\\), então probabilidade de observar 59 ou menos fumantes em uma amostra de \\(n=400\\) é menor que 0,0041.Os cálculos exemplo acima são tediosos e longos. Em geral, devemos evitar esse trabalho se existir um método alternativo que seja mais rápido, mais fácil e ainda preciso. Lembre-se de que calcular probabilidades de um intervalo de valores é muito mais fácil modelo normal. Podemos nos perguntar, é razoável usar o modelo normal lugar da distribuição binomial? Surpreendentemente, sim, se certas condições forem cumpridas.\r\nFigura 3.15: Histogramas ocos de amostras modelo binomial quando \\(p=0.10\\). Os tamanhos das amostras para quatro parcelas são \\(n=10\\), 30, 100, e 300, respectivamente.\r\nAproximação normal da distribuição binomial: distribuição binomial com probabilidade de sucesso \\(p\\) é quase normal quando o tamanho da amostra \\(n\\) é suficientemente grande que \\(np\\) e \\(n(1-p)\\) são ambos pelo menos 10. distribuição normal aproximada tem parâmetros correspondentes à média e desvio padrão da distribuição binomial:\\[\\begin{align*}\r\n\\mu &= np\r\n&&\\sigma= \\sqrt{np(1-p)}\r\n\\end{align*}\\]aproximação normal pode ser usada ao calcular o alcance de muitos sucessos possíveis.Mostrar que o modelo binomial é razoável foi um exercício sugerido anteriormente. Também verificamos que tanto \\(np\\) como \\(n(1-p)\\) são pelo menos 10:\\[\\begin{align*}\r\nnp&=400\\times 0.20=80\r\n&n(1-p)&=400\\times 0.8=320\r\n\\end{align*}\\]Com estas condições verificadas, podemos usar aproximação normal lugar da distribuição binomial usando média e o desvio padrão modelo binomial:\\[\\begin{align*}\r\n\\mu &= np = 80\r\n&\\sigma &= \\sqrt{np(1-p)} = 8\r\n\\end{align*}\\]Queremos encontrar probabilidade de observar menos de 59 fumantes usando esse modelo.","code":"\nk  <- -50:500\np  <- 0.1\nn  <- c(10, 30, 100, 300)\nxl <- c(0, 0, 0, 10) - 1\nxu <- c(7, 11, 24, 50) - 1\n\nste1 = ggplot() + \n  geom_step(aes(k - 0.05, dbinom(k, n[1], p)), color = \"#EAB217\") + \n  xlim(c(xl[1], xu[1])) + \n  labs(x = paste0(\"n = \", n[1])) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n\nste2 = ggplot() + \n  geom_step(aes(k - 0.05, dbinom(k, n[2], p)), color = \"#EAB217\") + \n  xlim(c(xl[2], xu[2])) + \n  labs(x = paste0(\"n = \", n[2])) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nste3 = ggplot() + \n  geom_step(aes(k - 0.05, dbinom(k, n[3], p)), color = \"#EAB217\") + \n  xlim(c(xl[3], xu[3])) + \n  labs(x = paste0(\"n = \", n[3])) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nste4 = ggplot() + \n  geom_step(aes(k - 0.05, dbinom(k, n[4], p)), color = \"#EAB217\") + \n  xlim(c(xl[4], xu[4])) + \n  labs(x = paste0(\"n = \", n[4])) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(ste1, ste2, ste3, ste4, ncol = 2)"},{"path":"ch3-distribuicoes.html","id":"normalApproximationSmallIntervals","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.4.3 A aproximação normal se divide em pequenos intervalos","text":"Cuidado: aproximação normal pode falhar em pequenos intervalos: aproximação normal da distribuição binomial tende ter um desempenho ruim ao estimar probabilidade de um pequeno intervalo de contagens, mesmo quando condições são atendidas.Suponha que nós quiséssemos calcular probabilidade de observar 69, 70 ou 71 fumantes em 400 quando \\(p=0,20\\). Com uma amostra tão grande, poderíamos ser tentados aplicar aproximação normal e usar o intervalo de 69 71. entanto, descobriríamos que solução binomial e aproximação normal diferem notavelmente:\\[\\begin{align*}\r\n\\text{Binomial:}&\\ 0.0703\r\n&\\text{Normal:}&\\ 0.0476\r\n\\end{align*}\\]Melhorando precisão da aproximação normal à distribuição binomial: aproximação normal da distribuição binomial para intervalos de valores é geralmente melhorada se os valores de corte forem modificados ligeiramente. Os valores de corte para extremidade inferior de uma região sombreada devem ser reduzidos em 0,5 e o valor de corte para extremidade superior deve ser aumentado em 0,5.ponta para adicionar área extra ao aplicar aproximação normal é mais útil quando se examina uma série de observações. Embora seja possível aplicá-lo ao calcular uma área de cauda, o benefício da modificação geralmente desaparece, já que o intervalo total é tipicamente bastante amplo.","code":""},{"path":"ch3-distribuicoes.html","id":"discreteDistribuiton","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.5 Distribuições mais discretas (tópico especial)","text":"","code":""},{"path":"ch3-distribuicoes.html","id":"negativeBinomialDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.5.1 Distribuição binomial negativa","text":"distribuição geométrica descreve probabilidade de observar o primeiro sucesso na n tentativa. O distribuição binomial negativa é mais geral: descreve probabilidade de observar o k sucesso na n tentativa.Estamos aguardando o quarto sucesso (\\(k=4\\)). Se probabilidade de um sucesso (\\(p\\)) pequena, o número de tentativas (\\(n\\)) provavelmente será grande. Isso significa que Brian é mais provável que precise de muitas tentativas antes de receber \\(k=4\\) sucessos. Para colocar isso de outra maneira, probabilidade de \\(n\\) ser pequeno é baixa.Para identificar um caso binomial negativo, verificamos 4 condições. Os três primeiros são comuns à distribuição binomial.É uma binomial negativa? Quatro condições para verificar.:Os ensaios são independentes.\r\nOs ensaios são independentes.Cada resultado estudo pode ser classificado como um sucesso ou fracasso.\r\nCada resultado estudo pode ser classificado como um sucesso ou fracasso.probabilidade de sucesso (\\(p\\)) é mesma para cada tentativa.\r\nprobabilidade de sucesso (\\(p\\)) é mesma para cada tentativa.última tentativa deve ser um sucesso.\r\núltima tentativa deve ser um sucesso.Como Brian levou seis tentativas para obter o quarto sucesso, sabemos que o último chute deve ter sido um sucesso. Isso deixa três chutes de sucesso e dois chutes sem sucesso (os rotulamos como falhas) que compõem primeiras cinco tentativas. Existem dez sequências possíveis desses cinco primeiros chutes, mostradas na Tabela. Se Brian conseguiu seu quarto sucesso (\\(k=4\\)) em sua sexta tentativa (\\(n=6\\)), então sua ordem de sucessos e fracassos deve ser uma dessas dez sequências possíveis.dez sequências possíveis quando o quarto chute de sucesso está na sexta tentativa.Se probabilidade de Brian chutar um field goal de 35 jardas \\(p=0.8\\), qual é probabilidade de Brian levar exatamente seis tentativas para obter seu quarto chute de sucesso? Podemos escrever isso como\\[\\begin{align*}\r\n&P(\\text{Brian leva seis tentativas para fazer quatro gols de campo}) \\\\\r\n& \\quad = P(\\text{ Brian faz três dos seus primeiros cinco gols de campo, e ele faz o sexto}) \\\\\r\n& \\quad = P(\\text{1 sequência ou 2 sequência ou ... ou 10 sequência})\r\n\\end{align*}\\]onde sequências estão na tablea. Podemos dividir essa última probabilidade na soma de dez possibilidades diferentes:\\[\\begin{align*}\r\n&P(\\text{$1^{st}$1 sequência ou 2 sequência ou ... ou 10 sequência}) \\\\\r\n&\\quad = P(\\text{1 sequência}) + P(\\text{$2^{nd}$ sequência}) + \\cdots + P(\\text{$10^{th}$ sequência })\r\n\\end{align*}\\]probabilidade da primeira sequência foi identificada na prática guiada como 0,0164, e cada uma das outras sequências tem mesma probabilidade. Como cada uma das dez sequências tem mesma probabilidade, probabilidade total é dez vezes de qualquer sequência individual. maneira de computar essa probabilidade binomial negativa é semelhante como os problemas binários foram resolvidos. probabilidade é dividida em duas partes:\\[\\begin{align*}\r\n&P(\\text{Brian leva seis tentativas para fazer quatro gols de campo}) \\\\\r\n&= [\\text{Número de sequências possíveis}] \\times P(\\text{Sequência única})\r\n\\end{align*}\\]Cada parte é examinada separadamente, depois multiplicamos para obter o resultado final.Primeiro identificamos probabilidade de uma única sequência. Um caso particular é primeiro observar todas falhas (\\(n-k\\) delas) seguidas dos \\(k\\) sucessos:\\[\\begin{align*}\r\n&P(\\text{Sequência única}) \\\\\r\n&= P(\\text{$n-k$ falhas e, em seguida, $k$ sucessos}) \\\\\r\n&= (1-p)^{n-k} p^{k}\r\n\\end{align*}\\]Também devemos identificar o número de sequências para o caso geral. Acima, dez sequências foram identificadas onde o quarto sucesso veio na sexta tentativa. Essas sequências foram identificadas fixando última observação como um sucesso e procurando todas maneiras de organizar outras observações. Em outras palavras, quantas maneiras podemos conseguir \\(k-1\\) sucessos em \\(n-1\\) tentativas? Isso pode ser encontrado usando o coeficiente \\(n\\) escolha \\(k\\), mas para \\(n-1\\) e \\(k-1\\) em vez disso:\\[\\begin{eqnarray*}\r\n{n-1 \\choose k-1} = \\frac{(n-1)!}{(k-1)! \\left((n-1) - (k-1)\\right)!} = \\frac{(n-1)!}{(k-1)! \\left(n - k\\right)!}\r\n\\end{eqnarray*}\\]Este é o número de diferentes maneiras pelas quais podemos solicitar \\(k-1\\) sucessos e \\(n-k\\) falhas em \\(n-1\\) tentativas.Distribuição binomial negativa: distribuição binomial negativa descreve probabilidade de observar o k sucesso na n tentativa:\\[\\begin{eqnarray}\r\nP(\\text{o k sucesso na tentativa n}) = {n-1 \\choose k-1} p^{k}(1-p)^{n-k}\r\n\\tag{3.5}\r\n\\end{eqnarray}\\]onde \\(p\\) é probabilidade de um teste individual ser um sucesso. Todas tentativas são consideradas independentes.Mostre usando Equação (3.5) que probabilidade de Brian chutar seu quarto gol de sucesso na sexta tentativa é 0.164.probabilidade de um único sucesso é \\(p=0,8\\), o número de sucessos é \\(k=4\\) e o número de tentativas necessárias sob este cenário é \\(n=6\\).\\[\\begin{align*}\r\n{n-1 \\choose k-1}p^k(1-p)^{n-k}\\ \r\n    =\\ \\frac{5!}{3!2!} (0.8)^4 (0.2)^2\\ \r\n    =\\ 10\\times 0.0164\\ \r\n    =\\ 0.164\r\n\\end{align*}\\]Binomial versus binomial negativo: o caso binomial, normalmente temos um número fixo de tentativas e, em vez disso, consideramos o número de sucessos. caso binômio negativo, examinamos quantas tentativas são necessárias para observar um número fixo de sucessos e exigir que última observação seja um sucesso.Prática Orientada 3.36  Em \\(70\\%\\) dos dias, um hospital admite pelo menos um paciente com ataque cardíaco. Em \\(30\\%\\) dos dias, nenhum paciente com ataque cardíaco é admitido. Identifique cada caso abaixo como um caso binomial ou negativo e calcule probabilidade.155Qual é probabilidade de o hospital admitir um paciente com ataque cardíaco em exatamente três dias esta semana?\r\nQual é probabilidade de o hospital admitir um paciente com ataque cardíaco em exatamente três dias esta semana?Qual é probabilidade segundo dia com um paciente de ataque cardíaco ser o quarto dia da semana?\r\nQual é probabilidade segundo dia com um paciente de ataque cardíaco ser o quarto dia da semana?Qual é probabilidade de o quinto dia próximo mês ser o primeiro dia com um paciente com ataque cardíaco?\r\nQual é probabilidade de o quinto dia próximo mês ser o primeiro dia com um paciente com ataque cardíaco?\r\n","code":""},{"path":"ch3-distribuicoes.html","id":"poissonDistribution","chapter":"3 Distribuições de Variáveis Aleatórias","heading":"3.5.2 Distribuição de Poisson","text":"Um histograma número de ocorrências de AMI em 365 dias para NYC é mostrado na Figura 3.16.156 média da amostra (4,38) é semelhante à média histórica de 4,4. O desvio padrão da amostra é de cerca de 2, e o histograma indica que cerca de 70% dos dados estão entre 2,4 e 6,4. forma da distribuição é unimodal e inclinada para direita.\r\nFigura 3.16: Um histograma número de ocorrências de IAM em 365 dias separados em NYC.\r\nDistribuição de Poisson geralmente é útil para estimar o número de eventos em uma grande população em uma unidade de tempo. Por exemplo, considere cada um dos seguintes eventos:tendo um ataque cardíaco,tendo um ataque cardíaco,se casar ese casar esendo atingido por um raio.sendo atingido por um raio.distribuição de Poisson nos ajuda descrever o número de tais eventos que ocorrerão em um dia para uma população fixa se os indivíduos dentro da população forem independentes. distribuição de Poisson também pode ser usada em outra unidade de tempo, como uma hora ou uma semana.O histograma na Figura 3.16 aproxima uma distribuição de Poisson com taxa igual 4,4. taxa para uma distribuição de Poisson é o número médio de ocorrências em uma população predominantemente fixa por unidade de tempo. Exemplo apresentado, unidade de tempo é um dia, população é toda cidade de Nova Iorque, e taxa histórica é de 4,4. O parâmetro na distribuição de Poisson é taxa - ou quantos eventos esperamos observar - e é tipicamente denotada por \\(\\lambda\\) (letra grega lambda) ou \\(\\mu\\). Usando taxa, podemos descrever probabilidade de observar exatamente \\(k\\) eventos em uma única unidade de tempo.Distribuição de Poisson: Suponha que estamos observando eventos e o número de eventos observados segue uma distribuição de Poisson com taxa \\(\\lambda\\). Então\\[\\begin{align*}\r\nP(\\text{observe $k$ eventos}) = \\frac{\\lambda^{k} e^{-\\lambda}}{k!}\r\n\\end{align*}\\]onde \\(k\\) pode ter um valor 0, 1, 2 e assim por diante, e \\(k!\\) representa \\(k\\)-fatorial. letra \\(e\\approx2.718\\) é base logaritmo natural. média e o desvio padrão desta distribuição são \\(\\lambda\\) e \\(\\sqrt{\\lambda}\\), respectivamente.Deixaremos um conjunto rigoroso de condições para distribuição de Poisson para um curso posterior. entanto, oferecemos algumas diretrizes simples que podem ser usadas para uma avaliação inicial de se o modelo de Poisson seria apropriado.É Poisson?: Uma variável aleatória pode seguir uma distribuição de Poisson se estivermos procurando pelo número de eventos, população que gera tais eventos grande e os eventos ocorrerem independentemente uns dos outros.Mesmo quando os eventos não são realmente independentes - por exemplo, sábados e domingos são especialmente populares para casamentos - um modelo de Poisson pode às vezes ainda ser razoável se permitirmos que ele tenha uma taxa diferente para momentos diferentes. exemplo casamento, taxa seria modelada como maior nos fins de semana que nos dias da semana. ideia de modelar taxas para uma distribuição de Poisson contra uma segunda variável como dia da semana forma base de alguns métodos mais avançados que se enquadram reino dos modelos lineares generalizados.","code":"\nset.seed(1)\nr <- 200 / 10^6\nN <- 8 * 10^6\nn <- 365\nx <- rpois(n, r * N / 365)\n\nggplot() + \n  geom_histogram(aes(x = x), bins = 11, color = \"white\", fill = \"#EAB217\") + \n  scale_x_continuous(breaks = seq(0, 10, 1)) + \n  labs(x = NULL, y = NULL) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"ch4-fund-inf","chapter":"4 Fundamentos para Inferência","heading":"4 Fundamentos para Inferência","text":"inferência estatística está relacionada principalmente com compreensão da qualidade das estimativas de parâmetros. Por exemplo, uma pergunta inferencial clássica é: \"Como estamos certos de que média estimada, \\(\\overline{x}\\), está perto da verdadeira média populacional, \\(\\mu\\)?’’ Enquanto equações e detalhes mudam dependendo da configuração, bases para inferência são mesmas em todas estatísticas. Introduzimos esses temas comuns nas primeiras quatro seções discutindo inferência sobre média da população, \\(\\mu\\), e definir o cenário para outros parâmetros e cenários na Seção 5. Entender este capítulo fará com que o restante deste livro, e de fato o resto das estatísticas, pareça muito mais familiar.Ao longo das próximas seções, consideramos um conjunto de dados chamado yrbss, que representa todos os 13.583 estudantes ensino médio Sistema de Vigilância Comportamento de Risco Juvenil (YRBSS) de 2013.157 Parte deste conjunto de dados é mostrada na Tabela 4.1.Tabela 4.1: Cinco casos conjunto de dados yrbss. Algumas observações estão em branco, pois há dados ausentes. Por exemplo, altura e o peso dos alunos 1 e 2 estão ausentes.variáveis são descritas como:idade: Idade estudante,idade: Idade estudante,gênero: Gênero estudante,gênero: Gênero estudante,grau: Grau ensino méedio,grau: Grau ensino méedio,altura: Altura (em metros),altura: Altura (em metros),peso: Peso (em quilogramas),peso: Peso (em quilogramas),capacete: Frequência em que o estudante usou um capacete ao andar de bicicleta nos últimos 12 mesescapacete: Frequência em que o estudante usou um capacete ao andar de bicicleta nos últimos 12 mesesativo: Número de dias fisicamente ativos por 60+ minutos nosúultimos 7 dias eativo: Número de dias fisicamente ativos por 60+ minutos nosúultimos 7 dias elevantamento: Número de dias de treinamento de força (.é, levantamento de peso) nos últimos 7 dias.levantamento: Número de dias de treinamento de força (.é, levantamento de peso) nos últimos 7 dias.Vamos considerar população de alunos ensino médio que participaram YRBSS de 2013. Nós pegamos uma amostra aleatória simples dessa população, que é representada na Tabela 4.2.158Tabela 4.2: Cinco observações para o conjunto de dados da amostra, que representa uma amostra aleatória simples de 100 alunos ensino médio de 2013.Usaremos essa amostra, à qual nos referimos como o conjunto de dados amostra_yrbss, para tirar conclusões sobre população de participantes YRBSS. Essa é prática da inferência estatística sentido mais amplo. Quatro histogramas resumindo variáveis altura, peso, ativo, e levantamento conjunto de dados amostra_yrbss são mostrados na Figura 4.1.\r\nFigura 4.1: Histogramas de altura, peso, ativo, e levantamento para os dados de amostra YRBSS. distribuição altura é aproximadamente simétrica, peso está moderadamente inclinada para direita, ativo é bimodal ou multimodal (com inclinação indefinida) e levantamento está fortemente enviesada para direita.\r\n","code":"\nlibrary(openintro)\ndata(yrbss)\n\nrequire(dplyr)\ndados = select(yrbss, age, gender, grade, height, weight, helmet_12m,\n               physically_active_7d, strength_training_7d)\ncolnames(dados) = c('idade', 'genero', 'grau', 'altura', 'peso', \n                    'capacete', 'ativo', 'levantamento')\n\nknitr::kable(head(dados, 5), \n      caption = \"Cinco casos do conjunto de dados yrbss. Algumas observações estão em branco, pois há dados ausentes. Por exemplo, a altura e o peso dos alunos 1 e 2 estão ausentes.\")\nlibrary(openintro)\ndata(yrbss.samp)\n\nrequire(dplyr)\ndados_samp = select(yrbss.samp, age, gender, grade, height, weight, helmet_12m, \n                    physically_active_7d, strength_training_7d)\ncolnames(dados_samp) = c('idade', 'genero', 'grau', 'altura', 'peso', \n                         'capacete', 'ativo', 'levantamento')\n\nknitr::kable(head(dados_samp, 5), \n      caption = \"Cinco observações para o conjunto de dados da amostra, que representa uma amostra aleatória simples de 100 alunos do ensino médio de 2013.\")\nrequire(ggplot2)\n\nalt <- ggplot(data = dados_samp, mapping = aes(x = altura)) + \n  labs(x = \"Altura (em metros)\", y = NULL) + \n  geom_histogram(bins = 12, color = \"white\", fill = \"#EAB217\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\npes <- ggplot(data = dados_samp, mapping = aes(x = peso)) + \n  labs(x = \"Peso (em quilogramas)\", y = NULL) + \n  geom_histogram(bins = 12, color = \"white\", fill = \"#EAB217\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nati <- ggplot(data = dados_samp, mapping = aes(x = ativo)) + \n  labs(x = \"Núm. de dias fisicamente ativos por 60+ minutos \\n nos últimos 7 dias\", y = NULL) + \n  geom_histogram(bins = 8, color = \"white\", fill = \"#EAB217\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nlev <- ggplot(data = dados_samp, mapping = aes(x = levantamento)) + \n  labs(x = \"Núm.  de  dias  de  treinamento  de  força  \\n (levantamento  de  peso)  nos últimos 7 dias\", y = NULL) + \n  geom_histogram(bins = 8, color = \"white\", fill = \"#EAB217\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nrequire(gridExtra)\ngrid.arrange(alt, pes, ati, lev, ncol = 2)"},{"path":"ch4-fund-inf.html","id":"variabilityEstimates","chapter":"4 Fundamentos para Inferência","heading":"4.1 Variabilidade nas estimativas","text":"Gostaríamos de estimar quatro características dos alunos ensino médio em YRBSS usando amostra.[(1)] Qual é altura média dos alunos ensino médio YRBSS?[(1)] Qual é altura média dos alunos ensino médio YRBSS?[(2)] Qual é o peso médio dos alunos ensino médio YRBSS? {}[(2)] Qual é o peso médio dos alunos ensino médio YRBSS? {}[(3)] Em média, quantos dias por semana os estudantes YRBSS são fisicamente ativos?[(3)] Em média, quantos dias por semana os estudantes YRBSS são fisicamente ativos?[(4)] Em média, quantos dias por semana os alunos ensino médio da YRBSS fazem treinamento com pesos?[(4)] Em média, quantos dias por semana os alunos ensino médio da YRBSS fazem treinamento com pesos?Enquanto nos concentramos na média neste capítulo, questões relativas à variação são frequentemente tão importantes na prática. Por exemplo, se os alunos são muito ativos ou quase totalmente inativos (distribuição é bimodal), podemos tentar diferentes estratégias para promover um estilo de vida saudável entre os alunos que se todos os alunos ensino médio já estivessem ativos.","code":""},{"path":"ch4-fund-inf.html","id":"pointEstimates","chapter":"4 Fundamentos para Inferência","heading":"4.1.1 Estimativas pontuais","text":"Queremos estimar média da população com base na amostra. maneira mais intuitiva de fazer isso é simplesmente pegar média amostral. Ou seja, para estimar altura média de todos os alunos YRBSS, calcule altura média da amostra:\\[\\begin{eqnarray*}\r\n\\bar{x}_{altura} = \\frac{1,50 + 1,78 + \\dots + 1,70}{100} = 1,697\r\n\\end{eqnarray*}\\]media amostral \\(\\bar{x} = 1,697\\) metros é chamada de estimativa pontual da média populacional: se pudermos escolher apenas um valor para estimar média populacional, este é o nosso melhor palpite. Suponha que tomemos uma nova amostra de 100 pessoas e recompomos média; provavelmente não obteremos mesma resposta que recebemos usando o conjunto de dados amostra_yrbss. estimativas geralmente variam de uma amostra para outra, e essa variação de amostragem sugere que nossa estimativa pode estar perto, mas não vai ser exatamente igual ao parâmetro.Podemos também estimar o peso médio dos respondentes YRBSS, examinando média da amostra de peso (em kg), e número médio de dias fisicamente ativos em uma semana:\\[\\begin{align*}\r\n\\bar{x}_{peso} &= \\frac{52,6 + 74,8 + \\dots + 55,8}{100} = 68,89\r\n&\\bar{x}_{ativo} &= \\frac{0 + 7 + \\dots + 1}{100} = 3,75\r\n\\end{align*}\\]O peso médio é de 68,89 kg, o que equivale 151.6 libras (medidas americanas).Que tal gerar estimativas pontuais de outros parâmetros de população, tais como mediana da população ou o desvio padrão da população? Mais uma vez podemos estimar parâmetros com base em estatísticas de amostra, como mostrado na Tabela 4.3. Por exemplo, o desvio padrão da população ativa é 2.56 dias.Tabela 4.3: Estimativas pontuais e valores de parâmetros para variável ‘ativo.’ Os parâmetros foram obtidos pelo cálculo da média, mediana e desvio padrão para todos os respondentes YRBSS.","code":"\naux = matrix(c(c(mean(dados$ativo, na.rm = TRUE), \n                 mean(dados_samp$ativo, na.rm = TRUE)), \n               c(median(dados$ativo, na.rm = TRUE), \n                 median(dados_samp$ativo, na.rm = TRUE)),\n               c(sd(dados$ativo, na.rm = TRUE), \n                 sd(dados_samp$ativo, na.rm = TRUE))), \n             ncol = 2, nrow = 3, byrow = TRUE)\n\nrownames(aux) <- c(\"Média\", \"Mediana\", \"Desvio Padrão\")\ncolnames(aux) <- c(\"Parâmetro\", \"Estimativa\")\n\nknitr::kable(aux,\n      caption = \"Estimativas pontuais e valores de parâmetros para a variável 'ativo'. Os parâmetros foram obtidos pelo cálculo da média, mediana e desvio padrão para todos os respondentes do YRBSS.\",\n      align = \"c\", digits = 4)"},{"path":"ch4-fund-inf.html","id":"pointEstimatesNotExact","chapter":"4 Fundamentos para Inferência","heading":"4.1.2 Estimativas pontuais não são exatas","text":"estimativas geralmente não são exatamente iguais à verdade, mas melhoram à medida que mais dados são disponibilizados. Podemos ver isso traçando uma média de execução de amostra_yrbss. média móvel é uma sequência de médias, em que cada média usa mais uma observação em seu cálculo que média diretamente antes dela na sequência. Por exemplo, segunda média na sequência é média das duas primeiras observações e terceira na sequência é média das três primeiras. média para variável ativo na amostra_yrbss é mostrado na Figura 4.2, e se aproxima da real, 3.90 dias, à medida que o tamanho de amostra aumenta.\r\nFigura 4.2: média computada após adicionar cada indivíduo à amostra. média tende se aproximar da média real da população à medida que mais dados se tornam disponíveis.\r\nEstimativas pontuais da amostra apenas se aproximam parâmetro populacional e variam de uma amostra para outra. Se pegássemos outra amostra aleatória simples dos alunos YRBSS, descobriríamos que média da amostra para o número de dias ativos seria um pouco diferente. Será útil quantificar quão variável é uma estimativa de uma amostra para outra. Se esta variabilidade é pequena (ou seja, média da amostra não muda muito de uma amostra para outra), então essa estimativa é provavelmente muito precisa. Se variar muito de uma amostra para outra, então não devemos esperar que nossa estimativa seja muito boa.","code":"\nd <- dados_samp$ativo\nxBars <- cumsum(d) / (1:100)\nm <- mean(dados$ativo, na.rm = TRUE)\n\nrequire(plotly)\n\n\np <- ggplot(data = data.frame(n = 1:100, xBars), aes(x = n, y = xBars)) + \n  geom_line(color = \"#E6205F\") + \n  geom_hline(yintercept = m, linetype = \"dashed\", color = \"#E6205F\") + \n  labs(y = \"Média de dias fisicamente ativo \\n /por semana\", \n      x = \"Tamanho da amostra\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nggplotly(p)"},{"path":"ch4-fund-inf.html","id":"standardErrorMean","chapter":"4 Fundamentos para Inferência","heading":"4.1.3 Erro padrão da média","text":"Da amostra aleatória representada em amostra_yrbss, adivinhamos que o número médio de dias que um aluno YRBSS está fisicamente ativo é de 3.75 dias. Suponha que tomemos outra amostra aleatória de 100 indivíduos e tomemos sua média: 3.22 dias. Suponha que tenhamos outro (3.67 dias) e outro (4.10 dias) e assim por diante. Se fizermos isso muitas e muitas vezes – o que podemos fazer apenas porque temos todos os alunos YRBSS – podemos construir uma distribuição amostral para média da amostra quando o tamanho da amostra 100, mostrado na Figura 4.3.\r\nFigura 4.3: Um histograma de 1000 amostras significa para o número de dias fisicamente ativos por semana, onde amostras são de tamanho \\(n=100\\).\r\nDistribuição Amostral: distribuição amostral representa distribuição das estimativas pontuais com base em amostras de um tamanho fixo de uma determinada população. É útil pensar em uma determinada estimativa pontual como sendo extraída de tal distribuição. Entender o conceito de uma distribuição amostral é fundamental para entender inferência estatística.distribuição amostral mostrada na Figura 4.3 é unimodal e aproximadamente simétrica. Também é centrada exatamente na verdadeira média da população: \\(\\mu=3.90\\). Intuitivamente, isso faz sentido. médias amostrais devem tender “cair ao redor” da média populacional.Podemos ver que média amostral possui alguma variabilidade em torno da média populacional, que pode ser quantificada usando o desvio padrão desta distribuição de médias amostrais: \\(\\sigma_{\\bar{x}} = 0.26\\). O desvio padrão da média da amostra nos diz até que ponto estimativa típica está distante da média real da população, 3.90 dias. Ele também descreve o típico erro da estimativa pontual e, por esse motivo, geralmente chamamos esse desvio padrão de erro padrão (EP) da estimativa.Erro padrão de uma estimativa: O desvio padrão associado uma estimativa é chamado de erro padrão. Descreve o erro típico ou incerteza associada à estimativa.Ao considerar o caso da estimativa pontual \\(\\bar{x}\\), há um problema: não há uma maneira óbvia de estimar seu erro padrão partir de uma única amostra. entanto, teoria estatística fornece uma ferramenta útil para resolver esse problema.Prática Orientada 4.3  161Você prefere usar uma amostra pequena ou uma amostra grande ao estimar um parâmetro? Por quê?\r\nVocê prefere usar uma amostra pequena ou uma amostra grande ao estimar um parâmetro? Por quê?Usando seu raciocínio de (), você esperaria que uma estimativa pontual baseada em uma amostra pequena tivesse um erro padrão menor ou maior que uma estimativa pontual baseada em uma amostra maior?\r\nUsando seu raciocínio de (), você esperaria que uma estimativa pontual baseada em uma amostra pequena tivesse um erro padrão menor ou maior que uma estimativa pontual baseada em uma amostra maior?\r\nNa amostra de 100 alunos, o erro padrão da média da amostra é igual ao desvio padrão da população dividido pela raiz quadrada tamanho da amostra:\\[\\begin{eqnarray*}\r\nEP_{\\bar{x}} = \\sigma_{\\bar{x}} = \\frac{\\sigma_{x}}{\\sqrt{n}} = \\frac{2,6}{\\sqrt{100}} = 0,26\r\n\\end{eqnarray*}\\]onde \\(\\sigma_{x}\\) é o desvio padrão das observações individuais. Isso não é coincidência. Podemos mostrar matematicamente que esta equação está correta quando observações são independentes usando ferramentas de probabilidade.Calculando EP para amostra média: considerando observações independentes de \\(n\\) de uma população com desvio padrão \\(\\sigma\\), o erro padrão da média amostral é igual \\[\\begin{eqnarray}\r\nEP = \\frac{\\sigma}{\\sqrt{n}}\r\n  \\tag{4.1}\r\n\\end{eqnarray}\\]Um método confiável para garantir que observações da amostra sejam independentes é conduzir uma amostra aleatória simples que consiste em pelo menos 10% da população.Há uma questão sutil na Equação (4.1): o desvio padrão da população é tipicamente desconhecido. Você já deve ter adivinhado como resolver esse problema: podemos usar estimativa pontual desvio padrão da amostra. Esta estimativa tende ser suficientemente boa quando o tamanho da amostra é de pelo menos 30 e distribuição da população não é fortemente distorcida. Assim, muitas vezes usamos apenas o desvio padrão da amostra \\(s\\) \\(\\sigma\\). Quando o tamanho da amostra menor que 30, precisaremos usar um método para considerar incerteza extra erro padrão. Se condição de inclinação não atendida, uma amostra maior será necessária para compensar o desvio extra.Prática Orientada 4.4  Na amostra de 100 alunos, o desvio padrão das alturas dos alunos é \\(s_{altura} = 0,088\\) metros. Neste caso, podemos confirmar que observações são independentes, verificando se os dados provêm de uma amostra aleatória simples que consiste em pelo menos de 10% da população.162Qual é o erro padrão da média da amostra?, \\(\\bar{x}_{altura} = 1,70\\) metros?\r\nQual é o erro padrão da média da amostra?, \\(\\bar{x}_{altura} = 1,70\\) metros?Você ficaria surpreso se alguém lhe dissesse que altura média de todos os entrevistados da YRBSS era de 1,69 metros?\r\nVocê ficaria surpreso se alguém lhe dissesse que altura média de todos os entrevistados da YRBSS era de 1,69 metros?\r\nPrática Orientada 4.5  163Você confiaria mais em uma amostra que tivesse 100 observações ou 400 observações?\r\nVocê confiaria mais em uma amostra que tivesse 100 observações ou 400 observações?Queremos mostrar matematicamente que nossa estimativa tende ser melhor quando o tamanho da amostra é maior. Se o desvio padrão das observações individuais 10, qual é nossa estimativa erro padrão quando o tamanho da amostra é 100? E quando é 400?\r\nQueremos mostrar matematicamente que nossa estimativa tende ser melhor quando o tamanho da amostra é maior. Se o desvio padrão das observações individuais 10, qual é nossa estimativa erro padrão quando o tamanho da amostra é 100? E quando é 400?Explique como sua resposta à parte (b) matematicamente justifica sua intuição em parte ().\r\nExplique como sua resposta à parte (b) matematicamente justifica sua intuição em parte ().\r\n","code":"\nset.seed(5)\nmeans <- c()\nfor (i in 1:1000) {\n  these <- sample(nrow(dados), 100)\n  means[i] <- mean(dados$ativo[these], na.rm = TRUE)\n}\n\nm <- mean(dados$ativo, na.rm = TRUE)\ns <- sd(dados$ativo, na.rm = TRUE) / 10\n\nggplot() + \n  labs(x = \"Média Amostral\", y = \"Frequência\") + \n  geom_rect(mapping = aes(xmin = m - s, xmax = m + s, ymin = 0, ymax = 93),\n            fill = \"gray60\") +\n  geom_rect(mapping = aes(xmin = m - (2*s), xmax = m + (2*s), ymin = 0, ymax = 93),\n            fill = \"gray28\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - (3*s), xmax = m + (3*s), ymin = 0, ymax = 93),\n            fill = \"gray48\", alpha = 0.5) +\n  geom_histogram(aes(x = means), color = \"black\", fill = \"#E97C31\") + \n  geom_vline(xintercept = m, linetype = \"dashed\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"basicPropertiesPointEstimates","chapter":"4 Fundamentos para Inferência","heading":"4.1.4 Propriedades básicas de estimativas pontuais","text":"Conseguimos três objetivos nesta seção. Primeiro, determinamos que estimativas pontuais de uma amostra podem ser usadas para estimar parâmetros populacionais. Também determinamos que essas estimativas pontuais não são exatas: elas variam de uma amostra para outra. Por fim, quantificamos incerteza da média amostral usando o que chamamos de erro padrão, representado matematicamente na Equação (4.1). Embora possamos quantificar o erro padrão para outras estimativas – como mediana, o desvio padrão ou qualquer outro número de estatísticas – adiaremos essas extensões para capítulos ou cursos posteriores.","code":""},{"path":"ch4-fund-inf.html","id":"confidenceIntervals","chapter":"4 Fundamentos para Inferência","heading":"4.2 Intervalos de confiança","text":"Uma estimativa pontual fornece um único valor plausível para um parâmetro. entanto, uma estimativa pontual raramente é perfeita; geralmente há algum erro na estimativa. Em vez de fornecer apenas uma estimativa pontual de um parâmetro, um próximo passo lógico seria fornecer um plausível intervalo de valores para o parâmetro.","code":""},{"path":"ch4-fund-inf.html","id":"capturingPopParameter","chapter":"4 Fundamentos para Inferência","heading":"4.2.1 Capturando o parâmetro populacional","text":"Um intervalo plausível de valores para o parâmetro populacional é chamado de intervalo de confiança.Usar apenas uma estimativa pontual é como pescar em um lago escuro com uma lança, e usar um intervalo de confiança é como pescar com uma rede. Podemos lançar uma lança onde vimos um peixe, mas provavelmente vamos errar. Por outro lado, se atirarmos uma rede nessa área, temos uma boa chance de pegar o peixe.Se reportarmos uma estimativa pontual, provavelmente não atingiremos o parâmetro populacional exato. Por outro lado, se reportarmos um intervalo de valores plausíveis – um intervalo de confiança – temos uma boa chance de capturar o parâmetro.","code":""},{"path":"ch4-fund-inf.html","id":"confidenceIntervalApproximate95","chapter":"4 Fundamentos para Inferência","heading":"4.2.2 Um intervalo de confiança aproximado de 95 %","text":"estimativa pontual é o valor mais plausível parâmetro, portanto, faz sentido construir o intervalo de confiança em torno da estimativa pontual. O erro padrão, que é uma medida da incerteza associada à estimativa pontual, fornece um guia de quão grande devemos fazer o intervalo de confiança.O erro padrão representa o desvio padrão associado à estimativa e em aproximadamente 95% tempo estará dentro de 2 erros padrão parâmetro. Se o intervalo cobrir 2 erros padrão da estimativa pontual, podemos ter aproximadamente 95% de confiança que capturamos o verdadeiro parâmetro:\\[\\begin{eqnarray}\r\n\\text{estimativa pontual}\\ \\pm\\ 2\\times EP\r\n\\tag{4.2}\r\n\\end{eqnarray}\\]Mas o que significa “95% confiante?” Suponha que tirássemos muitas amostras e construíssemos um intervalo de confiança de cada amostra usando Equação (4.2). Então, cerca de 95% desses intervalos conteriam média real, \\(\\mu\\). Figura 4.4 mostra este processo com 25 amostras, em que 24 dos intervalos de confiança resultantes contêm o número médio de dias por semana em que os alunos YRBSS estão fisicamente ativos, \\(\\mu=3.90\\) dias, e um intervalo não.\r\nFigura 4.4: Vinte e cinco amostras de tamanho n=100 foram tiradas banco yrbss. Para cada amostra, um intervalo de confiança foi criado para tentar capturar o número médio de dias por semana em que os alunos estão fisicamente ativos. Apenas 1 desses 25 intervalos não capturou verdadeira média de 3.90.\r\nregra em que cerca de 95% das observações estão dentro de dois desvios padrão da média é apenas aproximadamente verdadeira. entanto, vale muito bem para distribuição normal. Como veremos em breve, média tende ser normalmente distribuída quando o tamanho da amostra é suficientemente grande.Nós aplicamos Equação (4.2):\\[\\begin{eqnarray*}\r\n3.75\\ \\pm\\ 2 \\times  0.26 \\quad \\rightarrow \\quad (3.23, 4.27)\r\n\\end{eqnarray*}\\]Com base nesses dados, temos cerca de 95% de certeza de que média de dias ativos por semana para todos os alunos da YRBSS foi maior que 3.23, mas menor que 4.27 dias. Nosso intervalo estende-se 2 erros padrão da estimativa pontual, \\(\\bar{x}_{ativo}\\).","code":"\nset.seed(1)\namostras <- matrix(NA, ncol = 25, nrow = 100)\n\nfor (i in 1:25){\n  amostras[,i] <- sample(x = dados$ativo, size = 100, replace = FALSE)\n}\n\nvetor_medias <- apply(amostras, 2, mean, na.rm=TRUE) #vetor de medias\nvetor_sd <- apply(amostras, 2, sd, na.rm=TRUE) #vetor de desvio padrao\n\nvetor_ic_inf <- vetor_medias - (qnorm(0.975))*(vetor_sd/sqrt(100)) #vetor de IC inferior\nvetor_ic_sup <- vetor_medias + (qnorm(0.975))*(vetor_sd/sqrt(100)) #vetor de IC superior\n\nggplot() + \n  geom_vline(xintercept = m, linetype = \"dashed\") +\n  geom_segment(aes(x = vetor_ic_inf, y = 1:25, \n                   xend = vetor_ic_sup, yend = 1:25), \n               color = ifelse(vetor_ic_inf < m, '#E6205F', '#EAB217')) + \n  geom_point(aes(x = vetor_medias, y = 1:25), \n             color = ifelse(vetor_ic_inf < m, '#E6205F', '#EAB217')) + \n  labs(y = NULL, x = NULL) + \n  theme(axis.ticks = element_blank(), axis.text = element_blank()) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"meanSampleDistribution","chapter":"4 Fundamentos para Inferência","heading":"4.2.3 A distribuição amostral para a média","text":"Foi introduzido uma distribuição amostral para \\(\\bar{x}\\), média de dias fisicamente ativos por semana para amostras de tamanho 100. Examinamos essa distribuição na Figura 4.3. Agora vamos pegar 100.000 amos\r\ntras, calcular média de cada uma e plotar em um histograma para obter uma representação especialmente precisa da distribuição amostral. Este histograma é mostrado painel esquerdo da Figura 4.5.\r\nFigura 4.5: O painel esquerdo mostra um histograma das médias amostrais para 100.000 amostras aleatórias diferentes. O painel da direita mostra um gráfico de probabilidade normal dessas médias amostrais.\r\nEsta distribuição parece familiar? Esperamos que sim! distribuição das médias amostrais é muito semelhante à distribuição normal. Um gráfico de probabilidade normal dessas médias amostrais é mostrado painel direito Figura 4.5. Como todos os pontos caem em torno de uma linha reta, podemos concluir que distribuição das médias da amostra é quase normal. Este resultado pode ser explicado pelo Teorema Central Limite.Teorema Limite Central, descrição informal: Se uma amostra consistir em pelo menos 30 observações independentes e os dados não estiverem fortemente distorcidos, então distribuição da média amostral é bem aproximada por um modelo normal.Nós vamos aplicar esta versão informal Teorema Central Limite por enquanto, e discutiremos seus detalhes mais à frente.escolha de usar 2 erros padrão na Equação (4.2) foi baseado em nossa diretriz geral de que aproximadamente 95% tempo, observações estão dentro de dois desvios padrão da média. Sob o modelo normal, podemos tornar isso mais preciso usando 1.96 lugar de 2.\\[\\begin{eqnarray}\r\n\\text{estimativa pontual}\\ \\pm\\ 1.96\\times EP\r\n\\tag{4.3}\r\n\\end{eqnarray}\\]Se uma estimativa pontual, como \\(\\bar{x}\\), está associado um modelo normal e erro padrão \\(EP\\), então usamos este intervalo de confiança mais preciso de 95%.","code":"\nset.seed(5)\nmeans <- c()\nfor (i in 1:100000) {\n  these <- sample(nrow(dados), 100)\n  means[i] <- mean(dados$ativo[these], na.rm = TRUE)\n}\n\ns_mean <- ggplot() + \n  labs(x = \"Média Amostral\", y = \"Frequência\") + \n  geom_rect(mapping = aes(xmin = m - s, xmax = m + s, ymin = 0, ymax = 12500),\n            fill = \"gray60\") +\n  geom_rect(mapping = aes(xmin = m - (2*s), xmax = m + (2*s), ymin = 0, ymax = 12500),\n            fill = \"gray28\", alpha = 0.5) +\n  geom_rect(mapping = aes(xmin = m - (3*s), xmax = m + (3*s), ymin = 0, ymax = 12500),\n            fill = \"gray48\", alpha = 0.5) +\n  geom_histogram(aes(x = means), color = \"black\", fill = \"#E97C31\") + \n  geom_vline(xintercept = m, linetype = \"dashed\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\n\ns_qq <-ggplot(data.frame(means), aes(sample = means)) + \n  stat_qq(color = \"#E97C31\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\ngrid.arrange(s_mean, s_qq, ncol = 2)"},{"path":"ch4-fund-inf.html","id":"changingLevelConfidence","chapter":"4 Fundamentos para Inferência","heading":"4.2.4 Alterando o nível de confiança","text":"Suponha que nós queremos considerar intervalos de confiança onde o nível de confiança é um pouco maior que 95%; talvez nós gostaríamos de um nível de confiança de 99%. Pense na analogia sobre tentar pegar um peixe: se queremos ter mais certeza de que vamos pegar o peixe, devemos usar uma rede mais ampla. Para criar um nível de confiança de 99%, devemos também ampliar nosso intervalo de 95%. Por outro lado, se quisermos um intervalo com menor confiança, como 90%, poderíamos tornar nosso intervalo original de 95% um pouco mais magro.estrutura intervalo de confiança de 95% fornece orientação sobre como fazer intervalos com novos níveis de confiança. Abaixo está um intervalo de confiança geral de 95% para uma estimativa pontual que vem de uma distribuição quase normal:\\[\\begin{eqnarray}\r\n\\text{estimativa pontual}\\ \\pm\\ 1.96\\times EP\r\n\\end{eqnarray}\\]Existem três componentes para este intervalo: estimativa pontual, “1.96” e o erro padrão. escolha de \\(1.96\\times EP\\) foi baseada na captura de 95% dos dados, pois estimativa está dentro dos desvios padrão de 1.96 parâmetro, aproximadamente 95% tempo. escolha de 1.96 corresponde um nível de confiança de 95%.Para criar um intervalo de confiança de 99%, altere 1.96 na fórmula intervalo de confiança de 95% para \\(2.58\\). Na prática orientada 4.9, destaca-se que 99% tempo uma variável aleatória normal estará dentro de 2.58 desvios padrão da média. Esta abordagem – usando pontuações Z modelo normal para calcular os níveis de confiança – é apropriada quando \\(\\bar{x}\\) está associado uma distribuição normal com média \\(\\mu\\) e erro padrão \\(EP_{\\bar{x}}\\). Assim, fórmula para um intervalo de confiança de 99% é\\[\\begin{eqnarray}\r\n\\bar{x}\\ \\pm\\ 2,58\\times EP_{\\bar{x}}\r\n\\tag{4.4}\r\n\\end{eqnarray}\\]\r\nFigura 4.6: área entre -z e z aumenta ao passo que |z| torna-se maior. Se o nível de confiança é de 99%, nós escolhemos z tal que 99% da curva normal está entre -z e z, que corresponde 0.005% na cauda inferior e 0.005% na cauda superior: z=2.58.\r\naproximação normal é crucial para precisão desses intervalos de confiança. Seção 4.4 fornece uma discussão mais detalhada sobre quando o modelo normal pode ser aplicado com segurança. Quando o modelo normal não é um bom ajuste, usaremos distribuições alternativas que melhor caracterizem distribuição amostral.Condições para \\(\\bar{x}\\) ser quase normal e \\(EP\\) ser exato: Condições importantes para ajudar garantir que distribuição amostral de \\(\\bar{x}\\) é quase normal e estimativa de EP suficientemente precisa:observações da amostra são independentes.observações da amostra são independentes.O tamanho da amostra é grande: \\(n\\geq30\\) é uma boa regra prática.O tamanho da amostra é grande: \\(n\\geq30\\) é uma boa regra prática.distribuição da população não é fortemente distorcida. Essa condição pode ser difícil de avaliar, então apenas use seu melhor julgamento.distribuição da população não é fortemente distorcida. Essa condição pode ser difícil de avaliar, então apenas use seu melhor julgamento.Além disso, quanto maior o tamanho da amostra, mais leniente que podemos ser com o desvio da amostra.Como verificar que observações da amostra são independentes: Se observações são de uma amostra aleatória simples e consistem em pelo menos 10% da população, então elas são independentes.Os participantes de um experimento são considerados independentes se forem submetidos aleatoriamente aos grupos de tratamento.Se uma amostra é de um processo aparentemente aleatório, por exemplo, o tempo de vida de chaves usadas em um processo de fabricação específico, verificação da independência é mais difícil. Nesse caso, use seu melhor julgamento.verificação de inclinação forte geralmente significa verificar se há desvios óbvios: Quando há outliers proeminentes presentes, amostra deve conter pelo menos 100 observações e, em alguns casos, muito mais.Intervalo de confiança para qualquer nível de confiança: Se estimativa pontual segue o modelo normal com erro padrão \\(EP\\), então um intervalo de confiança para o parâmetro população é\\[\\begin{eqnarray*}\r\n\\text{estimativa pontual}\\ \\pm\\ z^{\\star} \\times EP\r\n\\end{eqnarray*}\\]onde \\(z^{\\star}\\) corresponde ao nível de confiança selecionado, ou seja, é o valor na tabela z que corresponde \\(|z_{\\alpha/2}|\\).Figura 4.6 fornece uma imagem de como identificar \\(z^{\\star}\\) com base em um nível de confiança. Nós selecionamos \\(z^{\\star}\\) de modo que área entre -\\(z^{\\star}\\) e \\(z^{\\star}\\) modelo normal corresponde ao nível de confiança.Margem de erro: Em um intervalo de confiança, \\(z^{\\star}\\times EP\\) é chamado margem de erro.","code":"\nset.seed(1)\nm <- 0\ns <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nlibrary(ggplot2)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_rect(mapping = aes(xmin = -2.58, xmax = 2.58, ymin = 0, ymax = 0.5),\n            fill = \"gray94\") + \n  geom_rect(mapping = aes(xmin = -1.96, xmax = 1.96, ymin = 0, ymax = 0.42),\n            fill = \"gray88\") + \n  geom_linerange(data = gg[gg$X < 2.58 & gg$X > -2.58,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n  geom_linerange(data = gg[gg$X < 1.96 & gg$X > -1.96,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") + \n  geom_path(size = 1) +\n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + geom_hline(yintercept = 0) + \n  annotate(geom = \"text\", x = 0, y = 0.45, \n           label = \"95%, se estende de -1.96 a 1.96\", size = 3) + \n  annotate(geom = \"text\", x = 0, y = 0.53, \n           label = \"99%, se estende de -2.58 a 2.58\", size = 3) + \n  geom_segment(aes(x = -1.96, y = 0.42, xend = 1.96, yend = 0.42)) + \n  geom_segment(aes(x = -2.58, y = 0.5, xend = 2.58, yend = 0.5)) + \n  geom_segment(aes(x = -1.96, y = 0, xend = -1.96, yend = 0.42), linetype = \"dashed\") +\n  geom_segment(aes(x = 1.96, y = 0, xend = 1.96, yend = 0.42), linetype = \"dashed\") + \n  geom_segment(aes(x = -2.58, y = 0, xend = -2.58, yend = 0.5), linetype = \"dashed\") +\n  geom_segment(aes(x = 2.58, y = 0, xend = 2.58, yend = 0.5), linetype = \"dashed\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"interpretingConfidenceIntervals","chapter":"4 Fundamentos para Inferência","heading":"4.2.5 Interpretando intervalos de confiança","text":"Um olho atento pode ter observado linguagem um pouco desajeitada usada para descrever os intervalos de confiança. Interpretação correta:Nós temos XX% de confiança de que o parâmetro populacional é entre…linguagem incorreta pode tentar descrever o intervalo de confiança como capturando o parâmetro da população com uma certa probabilidade. Este é um erro comum: embora possa ser útil pensar nisso como uma probabilidade, o nível de confiança apenas quantifica como é plausível que o parâmetro esteja intervalo.\r\nOutra consideração importante dos intervalos de confiança é que eles tentam apenas capturar o parâmetro de população. Um intervalo de confiança não diz nada sobre confiança de capturar observações individuais, uma proporção das observações ou sobre captura de estimativas pontuais. Os intervalos de confiança tentam apenas capturar os parâmetros da população.","code":""},{"path":"ch4-fund-inf.html","id":"hypothesisTest","chapter":"4 Fundamentos para Inferência","heading":"4.3 Teste de hipóteses","text":"Os alunos estão levantando pesos ou realizando outros exercícios de treinamento de força mais ou menos frequentemente que passado? Compararemos os dados dos alunos da pesquisa de 2011 da YRBSS com nossa amostra de 100 alunos da pesquisa de 2013 da YRBSS.Nós também vamos considerar o comportamento sono. Um estudo recente descobriu que os estudantes universitários têm em média 7 horas de sono por noite.170. entanto, pesquisadores de uma faculdade rural estão interessados em mostrar que seus alunos dormem mais de sete horas em média. Nós investigamos este tópico mais à frente.","code":""},{"path":"ch4-fund-inf.html","id":"hypothesisTestFramework","chapter":"4 Fundamentos para Inferência","heading":"4.3.1 Quadro de testes de hipóteses","text":"Os alunos YRBSS de 2011 levantaram pesos (ou realizaram outros exercícios de treinamento de força) em média 3.09 dias por semana. Queremos determinar se o conjunto de dados fornece fortes evidências de que os alunos YRBSS selecionados em 2013 estão levantando mais ou menos que os alunos YRBSS de 2011, em comparação com outra possibilidade de que não houve mudanças.171 Simplificamos essas três opções em duas hipóteses conflitantes:\\[\r\n\\begin{cases}\r\n  H_0: & \\mbox{média de dias por semana que os alunos da YRBSS levantaram pesos foi mesma para 2011 e 2013.} \\\\\r\n  H_1: & \\mbox{média de dias por semana que os alunos da YRBSS levantaram pesos foi diferente para 2011 e 2013.}\r\n\\end{cases}\r\n\\]Nós chamamos \\(H_0\\) de hipótese nula e \\(H_1\\) de hipótese alternativa.Hipóteses nula e alternativa: hipótese nula (\\(H_0\\)) muitas vezes representa uma perspectiva cética ou uma reivindicação ser testada. hipótese alternativa (\\(H_1\\)) representa uma alegação alternativa em consideração e é frequentemente representada por um intervalo de possíveis valores de parâmetro.hipótese nula frequentemente representa uma posição cética ou uma perspectiva de nenhuma diferença. hipótese alternativa frequentemente representa uma nova perspectiva, como possibilidade de que houve uma mudança.Quadro de testes de hipóteses: O cético não rejeitará hipótese nula (\\(H_0\\)), menos que evidência em favor da hipótese alternativa (\\(H_1\\)) seja tão forte que ela rejeite \\(H_0\\) favor da \\(H_1\\).estrutura de testes de hipóteses é uma ferramenta muito genérica e geralmente usamos sem pensar duas vezes. Se uma pessoa faz uma afirmação um pouco inacreditável, estamos inicialmente céticos. entanto, se houver evidência suficiente que suporte afirmação, deixamos de lado nosso ceticismo e rejeitamos hipótese nula em favor da alternativa. marcas teste de hipóteses também são encontradas sistema judiciário dos EUA.Os jurados examinam evidências para ver se mostram convincentemente que um réu é culpado. Mesmo que os jurados não se deixem convencer da culpa além de uma dúvida razoável, isso não significa que eles acreditem que o réu é inocente. Esse também é o caso teste de hipóteses: mesmo se falharmos em rejeitar hipótese nula, normalmente não aceitamos hipótese nula como verdadeira. Não encontrar evidências fortes para hipótese alternativa não é equivalente aceitar hipótese nula.exemplo com o YRBSS, hipótese nula não representa diferença na média de dias por semana de levantamento de peso em 2011 e 2013. hipótese alternativa representa algo novo ou mais interessante: houve uma diferença, um aumento ou uma diminuição. Estas hipóteses podem ser descritas em notação matemática usando \\(\\mu_{13}\\) como os dias médios de levantamento de peso para 2013:\\[\r\n\\begin{cases}\r\nH_0: & \\mu_{13} = 3.09 \\\\\r\nH_1: & \\mu_{13} \\neq 3.09\r\n\\end{cases}\r\n\\]onde 3.09 é o número médio de dias por semana que os alunos YRBSS de 2011 levantaram pesos. Usando notação matemática, hipóteses podem ser mais facilmente avaliadas usando ferramentas estatísticas. Chamamos de 3.09 o valor nulo, pois representa o valor parâmetro se hipótese nula verdadeira.","code":""},{"path":"ch4-fund-inf.html","id":"testHypothesisConfidenceIntervals","chapter":"4 Fundamentos para Inferência","heading":"4.3.2 Testando hipóteses usando intervalos de confiança","text":"Nós vamos usar o conjunto de dados amostra_yrbss para avaliar o teste de hipótese, e começamos comparando estimativa pontual de 2013 número de dias por semana em que os alunos levantaram pesos: \\(\\bar{x}_{13} = 2.78\\) dias. Essa estimativa sugere que os alunos YRBSS de 2013 estavam levantando pesos menores que os alunos YRBSS de 2011. entanto, para avaliar se isso fornece fortes evidências de que houve uma mudança, devemos considerar incerteza associada com \\(\\bar{x}_{13}\\).Nós aprendemos que há flutuação de uma amostra para outra, e é improvável que média da amostra seja exatamente igual ao parâmetro: não devemos esperar \\(\\bar{x}_{13}\\) exatamente igual \\(\\mu_{13}\\). Dado que \\(\\bar{x}_{13} = 2.78\\), talvez ainda seja possível que média de todos os alunos da pesquisa de 2013 YRBSS seja igual à média da pesquisa de 2011 YRBSS. diferença entre \\(\\bar{x}_{13}\\) e 3.09 poderia ser devido variação amostral, ou seja, variabilidade associada à estimativa pontual quando tomamos uma amostra aleatória. E intervalos de confiança foram introduzidos como forma de encontrar uma gama de valores plausíveis para média populacional.fórmula geral para o intervalo de confiança com base na distribuição normal é\\[\\begin{align*}\r\n\\bar{x} \\pm z^{\\star} EP_{\\bar{x}}\r\n\\end{align*}\\]Nos é dado \\(\\bar{x}_{13} = 2.78\\), nós usamos \\(z^{\\star} = 1.96\\) para um nível de confiança de 95%, e podemos calcular o erro padrão usando o desvio padrão dividido pela raiz quadrada tamanho da amostra:\\[\\begin{align*}\r\nEP_{\\bar{x}} = \\frac{s_{13}}{\\sqrt{n}} = \\frac{2,56}{\\sqrt{100}} = 0,256\r\n\\end{align*}\\]Inserindo média da amostra, \\(z^{\\star}\\), e o erro padrão na fórmula intervalo de confiança resulta em (2.27, 3.29). Temos 95% de confiança de que o número médio de dias por semana que todos os alunos YRBSS 2013 levantaram pesos ficou entre 2.27 e 3.29 dias.Como média de todos os alunos da pesquisa YRBSS de 2011 é de 3.09, que se enquadra na faixa de valores plausíveis intervalo de confiança, não podemos dizer que hipótese nula seja implausível. Ou seja, deixamos de rejeitar hipótese nula, \\(H_0\\).Dupla negação às vezes podem ser usados em estatísticas: Em muitas explicações estatísticas, usamos dupla negação. Por exemplo, podemos dizer que hipótese nula é não implausível ou nós não rejeitamos hipótese nula. Dupla negação são usados para comunicar que, embora não rejeitemos uma posição, também não estamos dizendo que ela está correta.\r\nFigura 4.7: Amostra de distribuição de despesas com moradia estudantil. Estes dados são fortemente distorcidos, que podemos ver pela cauda direita longa com alguns outliers notáveis.\r\nAvaliar condição de inclinação é desafiadora: Não se desespere se verificar condição de inclinação difícil ou confusa. Você não está sozinho – quase todos os alunos ficam frustrados ao verificar inclinação. Avaliar corretamente o desvio requer prática e você não será um profissional, mesmo final deste livro.Mas isso não significa que você deva desistir. Verificar inclinação e outras condições é extremamente importante para uma análise de dados responsável. entanto, tenha certeza de que avaliar inclinação não é algo que você precisa dominar até o final livro, embora nesse momento você deva ser capaz de avaliar corretamente casos claros.O erro padrão associado à média pode ser estimado usando o desvio padrão da amostra dividido pela raiz quadrada tamanho da amostra. Lembre-se de que \\(n = 175\\) estudantes foram amostrados.\\[\\begin{align*}\r\nEP = \\frac{s}{\\sqrt{n}} = \\frac{128,65}{\\sqrt{175}} = 9,73\r\n\\end{align*}\\]Você mostrou na Prática Orientada 4.14 que o modelo normal pode ser aplicado à média da amostra. Isso garante que um intervalo de confiança de 95% possa ser construído com precisão:\\[\\bar{x}\\ \\pm\\ z^{\\star} EP \\quad\\\\quad 616,91\\ \\pm\\ 1,96 \\times 9,73 \\quad \\\\quad (597.84, 635.98) \\]Como o valor nulo $650 não está intervalo de confiança, uma média real de $650 é implausível e rejeitamos hipótese nula. Os dados fornecem evidências estatisticamente significativas de que despesa média real de habitação é menor que $650 por mês.","code":"\nx <- student.housing$price\n\nggplot() + geom_histogram(aes(x), color = \"white\", fill = \"#E6205F\", bins = 17) + \n  labs(x = \"Despesas de Habitação (dólares)\", y = \"Frequência\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"decisionErrors","chapter":"4 Fundamentos para Inferência","heading":"4.3.3 Erros de decisão","text":"Os testes de hipóteses não são perfeitos, já que podemos tomar uma decisão errada nos testes de hipóteses estatísticas com base nos dados. Por exemplo, sistema judiciário, pessoas inocentes são às vezes erroneamente condenadas e os culpados, por vezes, andam livres. entanto, diferença é que, nos testes de hipóteses estatísticos, temos ferramentas necessárias para quantificar com que frequência cometemos esses erros.Existem duas hipóteses concorrentes: nula e alternativa. Em um teste de hipótese, fazemos uma declaração sobre qual delas pode ser verdadeira, mas podemos escolher incorretamente. Existem quatro cenários possíveis, resumidos na Tabela 4.4.Tabela 4.4: Quatro cenários diferentes para testes de hipóteses.O erro tipo está rejeitando hipótese nula quando \\(H_0\\) é realmente verdade. Um erro tipo II está falhando em rejeitar hipótese nula quando alternativa é realmente verdadeira.práticas orientadas 4.15, 4.16 e 4.17 fornecem uma lição importante: se reduzirmos frequência com que cometemos um tipo de erro, geralmente fazemos mais outro tipo.O teste de hipóteses é construído em torno de rejeitar ou não rejeitar hipótese nula. Ou seja, nós não rejeitamos \\(H_0\\) menos que tenhamos fortes evidências. Mas o que exatamente significa forte evidência? Como regra geral, para os casos em que hipótese nula é realmente verdadeira, não queremos rejeitar incorretamente \\(H_0\\) mais de 5% tempo. Isso corresponde um nível de significância de 0.05. Costumamos escrever o nível de significância usando \\(\\alpha\\) (letra grega) então \\(\\alpha = 0.05\\). Discutimos adequação de diferentes níveis de significância mais frente.Se usarmos um intervalo de confiança de 95% para avaliar um teste de hipótese em que hipótese nula é verdadeira, faremos um erro sempre que estimativa pontual estiver pelo menos 1.96 erros padrão fora parâmetro população. Isso acontece cerca de 5% tempo (2.5% em cada cauda). Da mesma forma, usar um intervalo de confiança de 99% para avaliar uma hipótese é equivalente um nível de significância de \\(\\alpha = 0.01\\).Um intervalo de confiança é, num certo sentido, simplista mundo dos testes de hipóteses. Considere os dois cenários seguir:O valor nulo (o valor parâmetro sob hipótese nula) está intervalo de confiança de 95%, mas apenas por pouco, por isso não rejeitaríamos \\(H_0\\). entanto, gostaríamos de dizer, quantitativamente, que foi uma decisão próxima.O valor nulo (o valor parâmetro sob hipótese nula) está intervalo de confiança de 95%, mas apenas por pouco, por isso não rejeitaríamos \\(H_0\\). entanto, gostaríamos de dizer, quantitativamente, que foi uma decisão próxima.O valor nulo está muito longe intervalo, por isso rejeitamos \\(H_0\\). entanto, queremos comunicar que, não só rejeitamos hipótese nula, como também não foi nem perto. Tal caso é descrito na Figura 4.8.O valor nulo está muito longe intervalo, por isso rejeitamos \\(H_0\\). entanto, queremos comunicar que, não só rejeitamos hipótese nula, como também não foi nem perto. Tal caso é descrito na Figura 4.8.\r\nFigura 4.8: Seria útil quantificar força da evidência contra hipótese nula. Neste caso, evidência é extremamente forte.\r\nNa próxima seção será introduzido uma ferramenta chamada p-valor que será útil nesses casos. O método p-valor também se estende testes de hipóteses nos quais os intervalos de confiança não podem ser facilmente construídos ou aplicados.","code":"\nteste_hip <- matrix(NA, ncol = 2, nrow = 2)\nteste_hip[1,] <- c(\"ok\", \"Erro tipo I\")\nteste_hip[2,] <- c(\"Erro tipo II\", \"ok\")\nrownames(teste_hip) <- c(\"H0 verdadeiro\", \"H1 verdadeiro\")\ncolnames(teste_hip) <- c(\"Não rejeitamos H0\", \"Rejeitamos H0 em favor de H1\")\n  \nknitr::kable(teste_hip, align = \"c\", \n      caption = \"Quatro cenários diferentes para testes de hipóteses.\")\nset.seed(1)\nm <- 0\ns <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nlibrary(ggplot2)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  xlim(-10, 4) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.line.y = element_blank(), axis.text = element_blank(), \n        axis.ticks.y = element_blank()) + \n  geom_hline(yintercept = 0) + \n  annotate(geom = \"text\", x = 0, y = 0.15, \n           label = \"Distribuição da \\n média se H0 \\n for verdade\", size = 3) + \n  annotate(geom = \"text\", x = -7, y = 0.09, \n           label = \"média observada\", size = 3, color = \"#E6205F\") + \n  geom_segment(aes(x = -7, xend = -7, y = 0.07, yend = 0.01),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#E6205F\") +\n  geom_path(size = 1) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"formalTestPValue","chapter":"4 Fundamentos para Inferência","heading":"4.3.4 Teste formal usando p-valores","text":"O p-valor é uma maneira de quantificar força da evidência contra hipótese nula e em favor da alternativa. Formalmente, o p-valor é uma probabilidade condicional.P-valor: O p-valor é probabilidade de observar dados pelo menos tão favoráveis à hipótese alternativa quanto nosso conjunto de dados atual, se hipótese nula verdadeira. Normalmente usamos uma estatística resumida dos dados, neste capítulo média da amostra, para ajudar calcular o p-valor e avaliar hipóteses.Podemos configurar hipótese nula para este teste como uma perspectiva cética: os alunos nesta escola têm em média 7 horas de sono por noite. hipótese alternativa assume uma nova forma refletindo os interesses da pesquisa: os alunos têm em média mais de 7 horas de sono. Podemos escrever essas hipóteses como\\[\r\n\\begin{cases}\r\n  H_0: & \\mu = 7 \\\\\r\n  H_1: & \\mu > 7\r\n\\end{cases}\r\n\\]Usando \\(\\mu > 7\\) como alternativa é um exemplo de um teste de hipótese unilateral. Nesta investigação, não há interesse aparente em saber se média é inferior 7 horas.179 Anteriormente encontramos uma hipótese bilateral em que procuramos qualquer diferença clara, maior ou menor que o valor nulo.Sempre use um teste bilateral, menos que tenha sido esclarecido antes da coleta de dados que o teste deve ser unilateral. Mudar um teste bilteral para um teste unilateral depois de observar os dados é perigoso porque pode inflar taxa de erro tipo .Testes unilaterais e bilaterais: Quando você estiver interessado em verificar um aumento ou uma diminuição, mas não ambos, use um teste unilateral. Quando você está interessado em alguma diferença valor nulo – um aumento ou diminuição – então o teste deve ser bilateral.Sempre escreva hipótese nula como uma igualdade: Consideraremos mais útil se listarmos sempre hipótese nula como uma igualdade (por ex.\\(\\mu = 7\\)) enquanto alternativa sempre usa uma desigualdade (por ex.\\(\\mu\\neq7\\), \\(\\mu>7\\), ou \\(\\mu<7\\)).Os pesquisadores da escola rural conduziram uma amostra aleatória simples de \\(n = 110\\) estudantes campus. Eles descobriram que esses alunos tiveram uma média de 7.42 horas de sono e o desvio padrão da quantidade de sono para os alunos foi de 1.75 horas. Um histograma da amostra é mostrado na Figura 4.9.\r\nFigura 4.9: Distribuição de uma noite de sono para 110 estudantes universitários. Estes dados são fortemente distorcidos.\r\nAntes de podermos usar um modelo normal para média da amostra ou computar o erro padrão da média da amostra, devemos verificar condições.(1) Porque esta é uma amostra aleatória simples de pelo menos de 10% corpo discente, observações são independentes.(2) O tamanho da amostra estudo sono é suficientemente grande, uma vez que é maior que 30.(3) Os dados mostram uma forte inclinação na Figura 4.9 e presença de alguns outliers. Esta inclinação e os outliers são aceitáveis para um tamanho de amostra de \\(n=110\\). Com essas condições verificadas, o modelo normal pode ser aplicado com segurança \\(\\bar{x}\\) e podemos calcular razoavelmente o erro padrão.O teste de hipóteses para o estudo sono será avaliado utilizando um nível de significância de \\(\\alpha = 0,05\\). Queremos considerar os dados sob o cenário de que hipótese nula é verdadeira. Neste caso, média da amostra é de uma distribuição que é quase normal e tem média 7 e desvio padrão de cerca de \\(EP_{\\bar{x}} = 0.17\\). Essa distribuição é mostrada na Figura 4.10.\r\nFigura 4.10: Se hipótese nula verdadeira, então média da amostra veio dessa distribuição quase normal. cauda direita descreve probabilidade de se observar uma amostra tão grande significa se hipótese nula é verdadeira.\r\ncauda sombreada na Figura 4.10 representa chance de observar uma média tão grande, condicionada à hipótese nula ser verdadeira. Ou seja, cauda sombreada representa o p-valor. Nós sombreamos todos os valores maiores que nossa média de amostra, \\(\\bar{x} = 7.42\\), porque são mais favoráveis à hipótese alternativa que média observada.Calculamos o p-valor encontrando área da cauda dessa distribuição normal, que aprendemos fazer na Seção 3. Primeiro calcule o Z-escore da média da amostra, \\(\\bar{x} = 7.42\\):\\[\\begin{eqnarray*}\r\nZ = \\frac{\\bar{x} - \\text{valor nulo}}{EP_{\\bar{x}}} = \\frac{7.42 - 7}{0.17} = 2.47\r\n\\end{eqnarray*}\\]Usando tabela de probabilidades normal, área não sombreada inferior é 0.993. Assim, área sombreada é \\(1-0.993 = 0.007\\). Se hipótese nula verdadeira, probabilidade de observar uma amostra significante de pelo menos 7.42 horas para uma amostra de 110 alunos é de apenas 0.007. Isto é, se hipótese nula verdadeira, não veríamos frequentemente uma média tão grande.Avaliamos hipóteses comparando o p-valor ao nível de significância. Porque o p-valor é menor que o nível de significância (p-valor \\(= 0.007 < 0.05 = \\alpha\\)), rejeitamos hipótese nula. O que observamos é tão incomum em relação à hipótese nula que lança sérias dúvidas sobre \\(H_0\\) e fornece fortes evidências favorecendo \\(H_1\\).P-valor como uma ferramenta teste de hipóteses: Quanto menor o p-valor, mais fortes são os dados que favorecem \\(H_1\\) acima de \\(H_0\\). Um pequeno p-valor (geralmente \\(<0.05\\)) corresponde evidência suficiente para rejeitar \\(H_0\\) em favor de \\(H_1\\).É útil primeiro desenhar uma figura para encontrar o p-valor: É útil desenhar uma imagem da distribuição de \\(\\bar{x}\\) como se \\(H_0\\) fosse verdadeiro (ou seja, \\(\\mu\\) é igual ao valor nulo), e sombrear região (ou regiões) de médias amostrais que são pelo menos tão favoráveis à hipótese alternativa. Essas regiões sombreadas representam o p-valor.ideias abaixo revisam o processo de avaliação de testes de hipóteses com p-valores:hipótese nula representa posição de um cético ou uma posição sem diferença. Rejeitamos essa posição somente se evidência favorecer fortemente \\(H_1\\).hipótese nula representa posição de um cético ou uma posição sem diferença. Rejeitamos essa posição somente se evidência favorecer fortemente \\(H_1\\).Um pequeno p-valor significa que se hipótese nula verdadeira, há uma baixa probabilidade de ver uma estimativa pontual pelo menos tão extrema quanto que vimos. Nós interpretamos isso como uma forte evidência em favor da alternativa.Um pequeno p-valor significa que se hipótese nula verdadeira, há uma baixa probabilidade de ver uma estimativa pontual pelo menos tão extrema quanto que vimos. Nós interpretamos isso como uma forte evidência em favor da alternativa.Rejeitamos hipótese nula se o p-valor menor que o nível de significância, \\(\\alpha\\), que normalmente é 0.05. Caso contrário, não poderemos rejeitar \\(H_0\\).Rejeitamos hipótese nula se o p-valor menor que o nível de significância, \\(\\alpha\\), que normalmente é 0.05. Caso contrário, não poderemos rejeitar \\(H_0\\).Devemos sempre declarar conclusão teste de hipóteses em linguagem clara, para que os não-estatísticos também possam entender os resultados.Devemos sempre declarar conclusão teste de hipóteses em linguagem clara, para que os não-estatísticos também possam entender os resultados.O p-valor é construído de tal forma que podemos compará-lo diretamente ao nível de significância (\\(\\alpha\\)) para determinar se devemos ou não rejeitar \\(H_0\\). Este método garante que taxa de erro tipo não exceda o nível de significância padrão.\r\nFigura 4.11: Para identificar o p-valor, distribuição da média da amostra é considerada como se hipótese nula fosse verdadeira. Então o p-valor é definido e calculado como probabilidade valor da média observada ou uma média ainda mais favorável H1 sob esta distribuição.\r\nPrática Orientada 4.23  Durante o início de outubro de 2009, foram registrados 52 leilões Ebay para Mario Kart.184 Os preços totais para os leilões são apresentados usando um histograma em Figura 4.12, e podemos gostar de aplicar o modelo normal à média da amostra. Verifique três condições exigidas para aplicação modelo normal:185independência,ter pelo menos 30 observações eos dados não são fortemente distorcidos.\r\n\r\nFigura 4.12: Um histograma dos preços totais de leilão para 52 leilões Ebay.\r\nhipóteses foram estabelecidas e condições foram verificadas. O próximo passo é encontrar o erro padrão da média da amostra e produzir um esboço para ajudar encontrar o p-valor.\\[\\begin{eqnarray*}\r\nEP_{\\bar{x}} = s/\\sqrt{n} = 4.15/\\sqrt{52} = 0.5755\r\n\\end{eqnarray*}\\]Como hipótese alternativa diz que estamos procurando uma média menor, nós sombreamos cauda inferior. Encontramos esta área sombreada usando o ponto Z e tabela de probabilidade normal: \\(Z = \\frac{44.17 – 46.99}{0.5755} = -4.90\\), que tem área inferior 0.0002. área é tão pequena que não podemos realmente vê-la na foto. Essa área da cauda inferior corresponde ao p-valor.Como o p-valor é tão pequeno - especificamente, menor que \\(\\alpha = 0.01\\) – isso fornece evidência suficientemente forte para rejeitar hipótese nula em favor da alternativa. Os dados fornecem evidências estatisticamente significativas de que o preço médio Ebay é menor que o preço pedido pela Amazon.O que há de tão especial em 0.05?: É comum usar um limite de 0.05 para determinar se um resultado é estatisticamente significativo, mas por que o valor mais comum é 0.05? Talvez o nível de significância padrão deva ser maior ou talvez deva ser menor. Se você está um pouco intrigado, isso provavelmente significa que você está lendo com um olhar crítico – bom trabalho! Fizemos uma tarefa de 5 minutos para ajudar esclarecer por que 0.05: www.openintro.org/why05.Às vezes também é uma boa ideia desviar-se padrão. Discutiremos quando escolher um limite diferente de 0.05 mais adiante.","code":"\nggplot() + geom_histogram(aes(x), bins = 14, \n                          color = \"white\", fill = \"#EAB217\") + \n  labs(y = \"Frequência\", x = \"Sono noturno (horas)\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nset.seed(1)\nm <- 0; s <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X >2,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\", alpha = 0.6) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + geom_hline(yintercept = 0) +\n  annotate(geom = \"text\", x = 0, y = -0.02, \n           label = expression(H[0]*': '*mu*' = 7  '), size = 3) + \n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 0.4), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2, y = -0.02, \n           label = expression(bar(x)*' = 7.42'), size = 3) + \n  geom_segment(aes(x = 2, y = 0, xend = 2, yend = 0.055), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2.3, y = 0.15, \n           label = \"p-valor de \\n 0.007\", size = 3, color = \"#EAB217\") + \n  geom_segment(aes(x = 2.3, xend = 2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#EAB217\") + \n  annotate(geom = \"text\", x = 0, y = 0.15, \n           label = \"0.993\", size = 6) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X >2,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\", alpha = 0.6) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + geom_hline(yintercept = 0) +\n  geom_path(size = 1) +\n  annotate(geom = \"text\", x = 0, y = -0.02, \n           label = expression(H[0]), size = 3) + \n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 0.4), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2, y = -0.02, \n           label = expression(bar(x)*' observado'), size = 3) + \n  geom_segment(aes(x = 2, y = 0, xend = 2, yend = 0.055), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2.2, y = 0.23, \n           label = \"\n           chance da média \n           observada ou \n           outra média que é \n           mais favorável a H1, \n           se H0 é verdade.\", \n           size = 3, color = \"#E97C31\") + \n  geom_segment(aes(x = 2.3, xend = 2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#E97C31\") +\n  annotate(geom = \"text\", x = -2.7, y = 0.23, \n           label = \"\n           Distribuição da \n           média, se H0 é\n           verdade\", size = 3) + \n  geom_segment(aes(x = -2.5, xend = -2.3, y = 0.15, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\"))) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\ndata(marioKart)\nd <- marioKart[marioKart$totalPr < 100,]\nd <- d$totalPr[d$wheels == 1]\n\nggplot() + \n  geom_histogram(aes(d), bins = 12, color = \"white\", fill = \"#E6205F\") + \n  labs(x = \"Preço total do leilão (US$)\", y = \"Frequência\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nset.seed(1)\nm <- 0\ns <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nlibrary(ggplot2)\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_path() +\n  xlim(-10, 4) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.line.y = element_blank(), axis.text = element_blank(), \n        axis.ticks = element_blank()) + \n  geom_segment(aes(x = -10, y = 0, xend = 4, yend = 0)) + \n  annotate(geom = \"text\", x = -7, y = 0.19, \n           label = \"\n           O p-valor é representado\n           pela área à esquerda.\n           A área é tão fina que\n           não conseguimos vê-la\", size = 3, color = \"red\") + \n  geom_segment(aes(x = -6.9, xend = -6.9, y = 0.08, yend = 0.01),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"red\") + \n  annotate(geom = \"text\", x = 0, y = -0.02, \n           label = expression(H[0]*': '*mu*' = 46.99  '), size = 3) + \n  annotate(geom = \"text\", x = -7, y = -0.02, \n           label = expression(bar(x)*' = 44.17'), size = 3) + \n  geom_segment(aes(x = -10, y = 0, xend = -7, yend = 0), color = \"red\", size = 1) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"HTTwoSidedPValue","chapter":"4 Fundamentos para Inferência","heading":"4.3.5 Teste de hipóteses de dois lados com p-valores","text":"Consideramos agora como calcular um p-valor para um teste bilateral. Nos testes unilaterais, sombreamos cauda única na direção da hipótese alternativa. Por exemplo, quando alternativa tinha forma \\(\\mu > 7\\), então o p-valor foi representado pela cauda superior (Figura 4.11). Quando alternativa era \\(\\mu<46.99\\), o p-valor era cauda inferior. Em um teste bilateral, somamos duas caudas porque evidências em qualquer direção são favoráveis \\(H_1\\).Primeiro, devemos verificar suposições.Uma amostra aleatória simples de pelo menos de 10% corpo discente significa que observações são independentes.\r\nUma amostra aleatória simples de pelo menos de 10% corpo discente significa que observações são independentes.O tamanho da amostra é 122, que é maior que 30.\r\nO tamanho da amostra é 122, que é maior que 30.Com base na distribuição anterior e que já sabemos sobre os hábitos de sono dos estudantes universitários, o tamanho da amostra será aceitável.\r\nCom base na distribuição anterior e que já sabemos sobre os hábitos de sono dos estudantes universitários, o tamanho da amostra será aceitável.Em seguida, podemos calcular o erro padrão (\\(EP_{\\bar{x}} = \\frac{s}{\\sqrt{n}} = 0.16\\)) da estimativa e criar uma imagem para representar o p-valor, mostrado na Figura 4.13. Ambas caudas estão sombreadas. Uma estimativa de 7.17 ou mais fornece pelo menos uma evidência tão forte contra hipótese nula e em favor da alternativa como estimativa observada, \\(\\bar{x} = 6.83\\).Podemos calcular áreas da cauda, primeiro encontrando cauda inferior correspondente \\(\\bar{x}\\):\\[\\begin{eqnarray*}\r\nZ = \\frac{6.83 – 7}{0.16} = -1.06 \\quad\\stackrel{table}{\\rightarrow}\\quad \\text{cauda da esquerda} = 0.1446\r\n\\end{eqnarray*}\\]Como o modelo normal é simétrico, cauda direita terá mesma área da cauda esquerda. O p-valor é encontrado como soma das duas caudas sombreadas:\\[\\begin{eqnarray*}\r\n\\text{p-valor} = \\text{cauda da esquerda} + \\text{cauda da direita} = 2\\times(\\text{cauda esquerda}) = 0.2892\r\n\\end{eqnarray*}\\]Este p-valor é relativamente grande (maior que \\(\\alpha = 0.05\\)), portanto, não devemos rejeitar \\(H_0\\). Ou seja, se \\(H_0\\) verdadeiro, não seria muito incomum ver uma amostra com uma média de 7 horas, simplesmente devido à variação amostral. Assim, não temos evidências suficientes para concluir que média é diferente de 7 horas.\r\nFigura 4.13: H1 é bilateral então ambas caudas devem ser contadas para o p-valor\r\nExemplo 4.6  Há problema em alterar os testes bilaterais para testes unilaterais após observar os dados!Suponha que média da amostra fosse maior que o valor nulo, \\(\\mu_0\\) (por exemplo, \\(\\mu_0\\) representaria 7 se \\(H_0\\): \\(\\mu = 7\\)). Então, se pudermos passar para um teste unilateral, usaremos \\(H_1\\): \\(\\mu > \\mu_0\\). Agora, se obtivermos qualquer observação com um Z-escore maior que 1.65, rejeitaríamos \\(H_0\\). Se hipótese nula é verdadeira, nós rejeitamos incorretamente hipótese nula sobre 5% tempo quando média da amostra está acima valor nulo, como mostrado Figura 4.14.Suponha que média da amostra fosse menor que o valor nulo. Então, se mudarmos para um teste unilateral, usaríamos \\(H_1\\): \\(\\mu < \\mu_0\\). Se \\(\\bar{x}\\) Se o Z-escore fosse menor que -1.65, rejeitaríamos \\(H_0\\). Se hipótese nula verdadeira, então observaríamos um caso desses aproximadamente 5% tempo.Examinando esses dois cenários, podemos determinar que faremos um erro tipo \\(5\\%+5\\%=10\\%\\) tempo se formos autorizados trocar para o “melhor” teste unilateral para os dados. Isso é o dobro da taxa de erro que prescrevemos com nosso nível de significância: \\(\\alpha=0.05\\) (!).\r\nFigura 4.14: regiões sombreadas representam áreas onde rejeitaríamos H0 sob más práticas consideradas exemplo\r\nHipóteses unilaterais são permitidas somente antes de ver dados: Depois de observar os dados, é tentador transformar um teste bilateral em um teste unilateral. Evite essa tentação. hipóteses devem ser configuradas antes de observado os dados. Se não forem, o teste deve ser bilateral.","code":"\nset.seed(1)\nm <- 0; s <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 1 | gg$X < -1,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\", alpha = 0.6) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  geom_path(size = 1) +\n  labs(x = NULL, y = NULL) + \n  theme(axis.text = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + geom_hline(yintercept = 0) +\n  annotate(geom = \"text\", x = 0, y = -0.02, \n           label = expression(H[0]*': '*mu*' = 7  '), size = 3) + \n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 0.4), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = -1, y = -0.02, \n           label = expression(bar(x)*' = 6.83'), size = 3) + \n  geom_segment(aes(x = 1, y = 0, xend = 1, yend = 0.25), linetype = \"dashed\") + \n  geom_segment(aes(x = -1, y = 0, xend = -1, yend = 0.25), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2.85, y = 0.15, \n           label = \"observações tão usuais \\n quanto a média amostral \\n sob H0\", \n           size = 3, color = \"#E97C31\") + \n  geom_segment(aes(x = 2.3, xend = 2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#E97C31\") +\n  annotate(geom = \"text\", x = -2.85, y = 0.15, \n           label = \"cauda esquerda\", \n           size = 3, color = \"#E97C31\") + \n  geom_segment(aes(x = -2.3, xend = -2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#E97C31\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 2 | gg$X < -2,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\", alpha = 0.6) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + geom_hline(yintercept = 0) +\n  annotate(geom = \"text\", x = 0, y = -0.02, \n           label = expression(mu*' = '*mu[0]), size = 3) + \n  geom_path(size = 1) +\n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 0.4), linetype = \"dashed\") + \n  geom_segment(aes(x = 2, y = 0, xend = 2, yend = 0.05), linetype = \"dashed\") + \n  geom_segment(aes(x = -2, y = 0, xend = -2, yend = 0.05), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2.3, y = 0.15, label = \"5%\", size = 3, color = \"#E97C31\") + \n  geom_segment(aes(x = 2.3, xend = 2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#E97C31\") +\n  annotate(geom = \"text\", x = -2.3, y = 0.15, label = \"5%\", size = 3, color = \"#E97C31\") + \n  geom_segment(aes(x = -2.3, xend = -2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#E97C31\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"chosingLevelConfidence","chapter":"4 Fundamentos para Inferência","heading":"4.3.6 Escolhendo um nível de significância","text":"Escolher um nível de significância para um teste é importante em muitos contextos, e o nível tradicional é de 0.05. entanto, geralmente é útil ajustar o nível de significância com base na aplicação. Podemos selecionar um nível menor ou maior que 0.05, dependendo das consequências de quaisquer conclusões obtidas teste.Se fazer um erro tipo perigoso ou especialmente caro, devemos escolher um nível de significância pequeno (por exemplo, 0.01). Sob este cenário, queremos ser muito cautelosos ao rejeitar hipótese nula, então exigimos evidências muito fortes favorecendo \\(H_1\\) antes de rejeitarmos \\(H_0\\).Se um erro tipo II relativamente mais perigoso ou muito mais caro que um erro tipo , então devemos escolher um nível de significância mais alto (por exemplo, 0.10). Aqui, queremos ter cautela ao não rejeitar \\(H_0\\) quando o valor nulo realmente falso.Níveis de significância devem refletir consequências de erros: O nível de significância selecionado para um teste deve refletir consequências associadas aos erros tipo e tipo II.hipótese nula é que partes mais caras não duram mais que 12% mais, enquanto alternativa é que elas duram mais de 12% mais. Esta decisão é apenas um dos muitos fatores regulares que têm um impacto marginal carro e na empresa. Um nível de significância de 0.05 parece razoável, já que nem um erro tipo ou tipo II deve ser perigoso ou (relativamente) muito mais caro.hipótese nula seria que partes dos fornecedores são igualmente confiáveis. Como segurança está envolvida, montadora deve estar ansiosa para mudar para o fabricante um pouco mais caro (rejeitar \\(H_0\\)), mesmo que evidência de maior segurança seja apenas moderadamente forte. Um nível de significância ligeiramente maior, como \\(\\alpha = 0.10\\), pode ser apropriado.","code":""},{"path":"ch4-fund-inf.html","id":"examiningCentralLimitTheorem","chapter":"4 Fundamentos para Inferência","heading":"4.4 Examinando o Teorema Central do Limite","text":"O modelo normal para média da amostra tende ser muito bom quando amostra consiste em pelo menos 30 observações independentes e os dados da população não são fortemente distorcidos. O Teorema Central Limite fornece teoria que nos permite fazer essa suposição.Teorema Central Limite, definição informal: distribuição de \\(\\bar{x}\\) é aproximadamente normal. aproximação pode ser ruim se o tamanho da amostra pequeno, mas melhora com tamanhos de amostra maiores.O Teorema Central Limite afirma que, quando o tamanho da amostra é pequeno, aproximação normal pode não ser muito boa. entanto, à medida que o tamanho da amostra se torna grande, aproximação normal melhora. Vamos investigar três casos para ver mais ou menos quando aproximação é razoável.Consideramos três conjuntos de dados: um de uma distribuição uniforme, um de uma distribuição exponencial e outro de uma distribuição log-normal. Estas distribuições são mostradas nos painéis superiores na Figura 4.15. distribuição uniforme é simétrica, distribuição exponencial pode ser considerada como tendo inclinação moderada, pois sua cauda direita é relativamente curta (alguns outliers), e distribuição log-normal é fortemente distorcida e tenderá produzir outliers mais aparentes.\r\nFigura 4.15: Distribuições amostral para média em diferentes tamanhos de amostra e para três distribuições diferentes. linhas vermelhas tracejadas mostram distribuições normais.\r\nO painel esquerdo na linha \\(n = 2\\) representa distribuição amostral de \\(\\bar{x}\\) se média da amostra de duas observações da distribuição uniforme mostrada. linha tracejada representa aproximação mais próxima da distribuição normal. Da mesma forma, os painéis central e direito da linha \\(n = 2\\) representam respectivas distribuições de \\(\\bar{x}\\) para dados de distribuições exponencial e log-normal.Não necessariamente. Por exemplo, aproximação normal para o exemplo log-normal é questionável para um tamanho de amostra de 30. Geralmente, quanto mais distorcida uma distribuição populacional ou quanto mais comum freqüência de outliers, maior amostra necessária para garantir distribuição da média da amostra seja quase normal.Com maior \\(n\\), distribuição amostral de \\(\\bar{x}\\) torna-se mais normal: À medida que o tamanho da amostra aumenta, o modelo normal para \\(\\bar{x}\\) torna-se mais razoável. Também podemos relaxar nossa condição quando o tamanho da amostra é muito grande.Nós discutimos em seções anteriores que o desvio padrão da amostra, \\(s\\), poderia ser usado como um substituto desvio padrão da população, \\(\\sigma\\), ao calcular o erro padrão. Esta estimativa tende ser razoável quando \\(n\\geq30\\). Encontraremos distribuições alternativas para amostras menores mais frente.Devemos considerar cada uma das condições exigidas.[(1)] Estes são referidos como dados da série temporal, porque os dados chegaram em uma determinada sequência. Se o jogador ganhar em um dia, isso pode influenciar forma como ela joga o próximo. Para fazer suposição de independência, devemos realizar verificações cuidadosas de tais dados. Enquanto análise de apoio não é mostrada, nenhuma evidência foi encontrada para indicar que observações não são independentes.[(1)] Estes são referidos como dados da série temporal, porque os dados chegaram em uma determinada sequência. Se o jogador ganhar em um dia, isso pode influenciar forma como ela joga o próximo. Para fazer suposição de independência, devemos realizar verificações cuidadosas de tais dados. Enquanto análise de apoio não é mostrada, nenhuma evidência foi encontrada para indicar que observações não são independentes.[(2)] O tamanho da amostra é 50, satisfazendo condição de tamanho da amostra.[(2)] O tamanho da amostra é 50, satisfazendo condição de tamanho da amostra.[(3)] Existem dois outliers, um muito extremo, o que sugere que os dados são muito fortemente distorcidos ou outliers muito distantes podem ser comuns para este tipo de dados. Os outliers podem desempenhar um papel importante e afetar distribuição da média amostral e estimativa erro padrão.[(3)] Existem dois outliers, um muito extremo, o que sugere que os dados são muito fortemente distorcidos ou outliers muito distantes podem ser comuns para este tipo de dados. Os outliers podem desempenhar um papel importante e afetar distribuição da média amostral e estimativa erro padrão.Uma vez que deveríamos ser céticos quanto à independência das observações e o extremo superior extremo é um desafio, não devemos usar o modelo normal para média amostral dessas 50 observações. Se pudermos obter uma amostra muito maior, talvez várias centenas de observações, então preocupações sobre distorção e outliers não mais se aplicam.\r\nFigura 4.16: Amostra de distribuição de ganhos de poker. Esses dados incluem alguns outliers muito claros. Estes são problemáticos quando se considera normalidade da média da amostra. Por exemplo, os outliers são frequentemente um indicador de distorção muito forte\r\nExamine estrutura de dados ao considerar independência: Alguns conjuntos de dados são recolhidos de tal forma que eles têm uma estrutura subjacente natural entre observações, por exemplo, quando observações ocorrem consecutivamente. Seja especialmente cauteloso sobre suposições de independência em relação esses conjuntos de dados.Cuidado com o fortes distorções e outliers: Fortes distorções são frequentemente identificadas pela presença de outliers claros. Se um conjunto de dados tem outliers proeminentes, ou tais observações são um tanto comuns para o tipo de dados em estudo, então é útil coletar uma amostra com muitas mais de 30 observações se o modelo normal usado para \\(\\bar{x}\\).Você não será um profissional em avaliar distorção até o final deste livro, então apenas use seu bom senso e continue aprendendo. À medida que você desenvolve suas habilidades estatísticas e enfrenta situações difíceis, considere também aprender sobre melhores maneiras de analisar dados distorcidos, como o bootstrap estudantilizado (bootstrap-t), ou consulte um estatístico mais experiente.","code":"\nknitr::include_graphics('images/c4/cltSimulations.png')\ndata(poker)\n\nggplot(data = poker) + \n  geom_histogram(aes(x = winnings), color = \"white\", bins = 9, fill = \"#EAB217\") + \n  labs(x = \"Ganhos e perdas de poker (US$)\", y = \"Frequência\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"inferenceOtherEstimators","chapter":"4 Fundamentos para Inferência","heading":"4.5 Inferência para outros estimadores","text":"média amostral não é única estimativa pontual para qual distribuição amostral é quase normal. Por exemplo, distribuição amostral das proporções da amostra é muito semelhante à distribuição normal quando o tamanho da amostra é suficientemente grande. Nesta seção, introduzimos vários exemplos em que aproximação normal é razoável para estimativa pontual. próximas aulas revisitarão cada uma das estimativas pontuais que você vê nesta seção junto com outras novas estatísticas.Fazemos outra suposição importante sobre cada estimativa pontual encontrada nesta seção: estimativa é imparcial. Uma estimativa pontual é imparcial se distribuição amostral da estimativa estiver centrada parâmetro estimado. Ou seja, uma estimativa imparcial não supera ou subestima o parâmetro naturalmente. Pelo contrário, ele tende fornecer uma estimativa “boa.” média da amostra é um exemplo de uma estimativa pontual imparcial, assim como cada um dos exemplos que introduzimos nesta seção.Finalmente, discutiremos o caso geral em que uma estimativa pontual pode seguir alguma distribuição diferente da distribuição normal. Também fornecemos orientação sobre como lidar com cenários em que técnicas estatísticas com quais você está familiarizado são insuficientes para o problema em questão.","code":""},{"path":"ch4-fund-inf.html","id":"CIPointEstimatesAlmostNormal","chapter":"4 Fundamentos para Inferência","heading":"4.5.1 Intervalos de confiança para estimativas pontuais quase normais","text":"Anteriormente, nós usamos estimativa pontual \\(\\bar{x}\\) com um erro padrão \\(EP_{\\bar{x}}\\) para criar um intervalo de confiança de 95 % para média da população:\\[\\begin{align}\r\n  \\bar{x}\\ \\pm\\ 1.96 \\times EP_{\\bar{x}}\r\n  \\tag{4.5}\r\n\\end{align}\\]Construímos este intervalo observando que média da amostra está dentro de 1.96 erros padrão da média real de cerca de 95% tempo. Essa mesma lógica generaliza para qualquer estimativa pontual imparcial que seja quase normal. Também podemos generalizar o nível de confiança usando um marcador de posição \\(z^{\\star}\\).Intervalo de confiança geral para o caso de distribuição amostral normal: Um intervalo de confiança baseado em uma estimativa pontual imparcial e quase normal é\\[\\begin{eqnarray}\r\n\\text{estimativa pontual}\\ \\pm\\ z^{\\star}EP\r\n\\tag{4.6}\r\n\\end{eqnarray}\\]onde \\(z^{\\star}\\) é selecionado para corresponder ao nível de confiança e \\(EP\\) representa o erro padrão. O valor que \\(z^{\\star}EP\\) é chamado de margem de erro.Geralmente, o erro padrão para uma estimativa pontual é estimado partir dos dados e calculado usando uma fórmula. Por exemplo, o erro padrão para média da amostra é\\[\\begin{eqnarray*}\r\nEP_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\r\n\\end{eqnarray*}\\]Nesta seção, fornecemos o erro padrão computado para cada exemplo e o exercício sem detalhar de onde os valores vieram. Nos próximos capítulos, você aprenderá preencher esses e outros detalhes para cada situação.aproximação normal é dita como válida, então aplicamos Equação (4.6):\\[\\begin{eqnarray*}\r\n\\text{estimativa pontual}\\ \\pm\\ z^{\\star} EP\r\n    \\quad\\rightarrow\\quad 1.1\\ \\pm\\ 1.96\\times 0.5\r\n    \\quad\\rightarrow\\quad (0.12, 2.08)\r\n\\end{eqnarray*}\\]Temos 95% de confiança de que os estudantes sexo masculino, em média, estavam fisicamente ativos 0.12 2.08 dias mais que os estudantes sexo feminino YRBSS cada semana. Ou seja, diferença média real é plausível entre 0.12 e 2.08 dias por semana com 95% de confiança.Nosso intervalo de confiança não diz absolutamente nada sobre observações individuais. Ele apenas faz uma declaração sobre um intervalo plausível de valores para diferença média entre todos os alunos sexo masculino e feminino que participaram YRBSS.","code":""},{"path":"ch4-fund-inf.html","id":"HTPointEstimatesAlmostNormal","chapter":"4 Fundamentos para Inferência","heading":"4.5.2 Teste de hipóteses para estimativas pontuais quase normais","text":"Assim como o método intervalo de confiança funciona com muitas outras estimativas pontuais, podemos generalizar nossos métodos de teste de hipóteses para novas estimativas pontuais. Aqui, consideramos apenas abordagem p-valor, introduzido antes, já que é técnica mais comumente usada e também se estende casos não normais.Teste de hipóteses usando o modelo normal:Primeiro, escreva hipóteses em linguagem simples e, em seguida, configure-em notação matemática.Primeiro, escreva hipóteses em linguagem simples e, em seguida, configure-em notação matemática.Identifique uma estimativa pontual apropriada parâmetro de interesse.Identifique uma estimativa pontual apropriada parâmetro de interesse.Verifique condições para garantir que estimativa erro padrão seja razoável e estimativa pontual seja quase normal e imparcial.Verifique condições para garantir que estimativa erro padrão seja razoável e estimativa pontual seja quase normal e imparcial.Calcule o erro padrão. Desenhe uma figura descrevendo distribuição da estimativa sob idéia de que \\(H_0\\) é verdadeira. Sombreie área que representa o p-valor.Calcule o erro padrão. Desenhe uma figura descrevendo distribuição da estimativa sob idéia de que \\(H_0\\) é verdadeira. Sombreie área que representa o p-valor.Usando figura e modelo normal, calcule o teste estatístico (Z-escore) e identifique o p-valor para avaliar hipóteses. Escreva uma conclusão em linguagem simples.Usando figura e modelo normal, calcule o teste estatístico (Z-escore) e identifique o p-valor para avaliar hipóteses. Escreva uma conclusão em linguagem simples.Podemos formalizar hipóteses da Prática Orientada deixando \\(p_{controle}\\) e \\(p_{tratamento}\\) representam proporção de pacientes que morreram nos grupos controle e tratamento, respectivamente. Então hipóteses podem ser escritas como\\[\\begin{eqnarray*}\r\n&&H_0: p_{controle} = p_{tratamento} \\quad\\text{(droga não funciona)} \\quad \\\\\r\n&&H_1: p_{controle} > p_{tratamento} \\quad\\text{(droga funciona)}\r\n\\end{eqnarray*}\\]ou equivalentemente,\\[\\begin{eqnarray*}\r\n&&H_0: p_{controle} - p_{tratamento} = 0 \\quad\\text{(droga não funciona)} \\quad \\\\\r\n&&H_1: p_{controle} - p_{tratamento} > 0 \\quad\\text{(droga funciona)}\r\n\\end{eqnarray*}\\]Evidência forte contra hipótese nula e favor da alternativa corresponderia uma diferença observada nas taxas de mortalidade,\\[\\begin{eqnarray*}\r\n\\text{estimativa pontual} = \\hat{p}_{controle} - \\hat{p}_{tratamento}\r\n\\end{eqnarray*}\\]sendo maior que poderíamos esperar acaso sozinho. Esta diferença nas proporções da amostra representa uma estimativa pontual que é útil na avaliação das hipóteses.Prática Orientada 4.30  Queremos avaliar configuração da hipótese da Prática Orientada usando dados estudo atual.192 grupo de controle Exemplo, 60 de 742 pacientes morreram. grupo de tratamento, 41 dos 733 pacientes morreram. diferença amostral nas taxas de mortalidade pode ser resumida como\\[\\begin{eqnarray*}\r\n\\text{estimativa pontual} = \\hat{p}_{controle} - \\hat{p}_{tratamento} = \\frac{60}{742} - \\frac{41}{733} = 0.025\r\n\\end{eqnarray*}\\]Esta estimativa pontual é quase normal e é uma estimativa imparcial da diferença real nas taxas de mortalidade. O erro padrão desta diferença de amostra é \\(EP = 0.013\\). Avaliar o teste de hipótese em um nível de significância de 5%: \\(\\alpha=0.05\\).\r\nFigura 4.17: distribuição da diferença da amostra se hipótese nula verdadeira.\r\nO p-valor pode ser calculado usando o Z-escore da estimativa pontual e tabela probabilística normal.\\[\\begin{eqnarray}\r\nZ = \\frac{\\text{estimativa pontual} - \\text{valor nulo}}{EP_{\\text{estimativa pontual}}}\r\n    = \\frac{0,025 - 0}{0,013} = 1,92\r\n\\tag{4.7}\r\n\\end{eqnarray}\\]Examinando Z na tabela probabilística normal, descobrimos que cauda não-sombreada inferior é de aproximadamente 0.973. Assim, cauda sombreada superior representando o p-valor é\\[\\begin{eqnarray*}\r\n\\text{p-valor} = 1-0,973 = 0,027\r\n\\end{eqnarray*}\\]Como o p-valor é menor que o nível de significância (\\(\\alpha = 0.05\\)), dizemos que hipótese nula é implausível. Ou seja, rejeitamos hipótese nula em favor da alternativa e concluímos que droga é eficaz na redução de mortes em pacientes com ataque cardíaco.O Z-escore na Equação (4.7) é chamado de teste estatístico. Na maioria dos testes de hipóteses, uma estatística de teste é um resumo de dados específico que é especialmente útil para calcular o p-valor e avaliar o teste de hipóteses. caso de estimativas pontuais quase normais, estatística de teste é o Z-escore.Teste estatísticos: Um teste estatístico é uma estatística resumida que é particularmente útil para avaliar um teste de hipótese ou identificar o p-valor. Quando uma estimativa pontual é quase normal, usamos pontuação Z da estimativa pontual como estatística teste. Nos capítulos posteriores, encontramos situações em que outras estatísticas de teste são úteis.","code":"\nset.seed(1)\nm <- 0; s <- 1\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X >2,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\", alpha = 0.6) + \n  scale_x_continuous(breaks = seq(m - 3*s, m + 3*s, s)) + \n  labs(x = NULL, y = NULL) + \n  geom_path(size = 1) +\n  theme(axis.text = element_blank(), axis.ticks.y = element_blank(), \n        axis.line.y = element_blank()) + geom_hline(yintercept = 0) +\n  annotate(geom = \"text\", x = 0, y = -0.02, label = (\"null diff. = 0\"), size = 3) + \n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 0.4), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2, y = -0.02, label = \"obs diff. = 0.025\", size = 3) + \n  geom_segment(aes(x = 2, y = 0, xend = 2, yend = 0.055), linetype = \"dashed\") + \n  annotate(geom = \"text\", x = 2.3, y = 0.15, label = \"p-valor de \\n 0.027\", size = 3, color = \"#EAB217\") +\n  geom_segment(aes(x = 2.3, xend = 2.3, y = 0.11, yend = 0.05),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#EAB217\") + \n  annotate(geom = \"text\", x = 0, y = 0.15, label = \"0.973\", size = 6) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch4-fund-inf.html","id":"PointEstimatesNotNormal","chapter":"4 Fundamentos para Inferência","heading":"4.5.3 Estimativas pontuais não normais","text":"Podemos aplicar ideias de intervalos de confiança e testes de hipóteses aos casos em que estimativa pontual ou estatística de teste não é necessariamente normal. Existem muitas razões pelas quais tal situação pode surgir:o tamanho da amostra é muito pequeno para aproximação normal ser válida;o tamanho da amostra é muito pequeno para aproximação normal ser válida;estimativa erro padrão pode ser pobre; oua estimativa erro padrão pode ser pobre; oua estimativa pontual tende para alguma distribuição que não é distribuição normal.estimativa pontual tende para alguma distribuição que não é distribuição normal.Para cada caso em que aproximação normal não é válida, nossa primeira tarefa é sempre entender e caracterizar distribuição amostral da estimativa pontual ou estatística de teste. Em seguida, podemos aplicar estruturas gerais para intervalos de confiança e testes de hipóteses essas distribuições alternativas.","code":""},{"path":"ch4-fund-inf.html","id":"whenToRetreat","chapter":"4 Fundamentos para Inferência","heading":"4.5.4 Quando recuar","text":"Ferramentas estatísticas dependem de condições. Quando condições não são satisfeitas, essas ferramentas não são confiáveis e tirar conclusões delas é traiçoeiro. condições para essas ferramentas normalmente vêm em duas formas.observações individuais devem ser independentes: Uma amostra aleatória de menos de 10% da população assegura que observações sejam independentes. Em experimentos, geralmente exigimos que os sujeitos sejam randomizados em grupos. Se independência falhar, técnicas avançadas devem ser usadas e, em alguns casos, inferência pode não ser possível.Outras condições concentram-se tamanho da amostra e na inclinação: Por exemplo, se o tamanho da amostra muito pequeno, inclinação muito forte ou valores extremos estiverem presentes, o modelo normal para média da amostra falhará.verificação de condições para ferramentas estatísticas é sempre necessária. Sempre que condições não forem satisfeitas para uma técnica estatística, existem três opções. primeira é aprender novos métodos apropriados para os dados. segunda rota é consultar um estatístico.193 terceira via é ignorar falha das condições. Esta última opção efetivamente invalida qualquer análise e pode desacreditar descobertas novas e interessantes.Finalmente, advertimos que talvez não haja ferramentas de inferência úteis ao considerar dados que incluam vieses desconhecidos, como amostras de conveniência. Por esta razão, existem livros, cursos e pesquisadores dedicados às técnicas de amostragem e design experimental.","code":""},{"path":"ch4-fund-inf.html","id":"statisticalSignificancePracticalSignificance","chapter":"4 Fundamentos para Inferência","heading":"4.5.5 Significância estatística versus significância prática","text":"Quando o tamanho da amostra se torna maior, estimativas pontuais tornam-se mais precisas e quaisquer diferenças reais na média e valor nulo tornam-se mais fáceis de detectar e reconhecer. Mesmo uma diferença muito pequena provavelmente seria detectada se pegássemos uma amostra grande o suficiente. Às vezes, os pesquisadores coletam amostras tão grandes que até mesmo menor diferença é detectada. Embora ainda digamos que diferença é estatisticamente significante, ela pode não ser praticamente significativa.Diferenças estatisticamente significativas são às vezes tão pequenas que não são praticamente relevantes. Isso é especialmente importante para pesquisa: se conduzirmos um estudo, queremos nos concentrar em encontrar um resultado significativo. Não queremos gastar muito dinheiro encontrando resultados que não têm valor prático.O papel de um estatístico na condução de um estudo geralmente inclui o planejamento tamanho estudo. O estatístico pode primeiro consultar especialistas ou literatura científica para saber qual seria menor diferença significativa valor nulo. Ele também obteria alguma estimativa razoável para o desvio padrão. Com essas informações importantes, ele escolheria um tamanho de amostra suficientemente grande para que robustez para diferença significativa seja talvez de 80% ou 90%. Embora amostras maiores ainda possam ser usadas, ele pode desaconselhar o uso delas em alguns casos, especialmente em áreas sensíveis de pesquisa.","code":""},{"path":"ch5-inf-num.html","id":"ch5-inf-num","chapter":"5 Inferência para dados numéricos","heading":"5 Inferência para dados numéricos","text":"O capítulo anterior introduziu uma estrutura para inferência estatística baseada em intervalos de confiança e hipóteses. Neste capítulo, encontramos várias novas estimativas pontuais e cenários. Em cada caso, idéias de inferência permanecem mesmas:Determine qual estimativa pontual ou estatística de teste é útil.Determine qual estimativa pontual ou estatística de teste é útil.Identifique uma distribuição apropriada para estimativa pontual ou estatística de teste.Identifique uma distribuição apropriada para estimativa pontual ou estatística de teste.Aplique ideias de Capítulo anterior usando distribuição da etapa 2.Aplique ideias de Capítulo anterior usando distribuição da etapa 2.","code":""},{"path":"ch5-inf-num.html","id":"oneSampleMeanTDistribution","chapter":"5 Inferência para dados numéricos","heading":"5.1 Uma média amostral com a distribuição-\\(t\\)","text":"Nós exigimos uma grande amostra Capítulo anterior por dois motivos:distribuição amostral de \\(\\overline{x}\\) tende ser mais normal quando amostra é grande.distribuição amostral de \\(\\overline{x}\\) tende ser mais normal quando amostra é grande.O erro padrão calculado é normalmente muito preciso ao usar uma amostra grande.O erro padrão calculado é normalmente muito preciso ao usar uma amostra grande.Então, o que devemos fazer quando o tamanho da amostra é pequeno? Como vamos discutir mais frente, se os dados da população forem quase normais, \\(\\overline{x}\\) também seguirá uma distribuição normal, que trata primeiro problema. precisão erro padrão é mais complicada e, para esse desafio, apresentaremos uma nova distribuição chamada distribuição \\(t\\). Embora enfatizemos o uso da distribuição \\(t\\) para amostras pequenas, essa distribuição também é geralmente usada para amostras grandes, onde produz resultados semelhantes aos da distribuição normal.","code":""},{"path":"ch5-inf-num.html","id":"normalityCondition","chapter":"5 Inferência para dados numéricos","heading":"5.1.1 A condição de normalidade","text":"Um caso especial Teorema Central Limite terá que ser um dos meios de comunicação de que amostra será quase normal, enquanto o tamanho da amostra, de acordo com os dados da amostra será quase normal.Teorema Central Limite para dados normais: distribuição amostral da média é quase normal quando observações da amostra são independentes e veem de uma distribuição quase normal. Isso vale para qualquer tamanho de amostra.Embora isso pareça um caso especial muito útil, há um pequeno problema. É inerentemente difícil verificar normalidade em pequenos conjuntos de dados.Verificando condição de normalidade: Devemos ter cautela ao verificar condição de normalidade para amostras pequenas. É importante não só examinar os dados, mas também pensar sobre origem dos dados. Por exemplo, pergunte: eu esperaria que essa distribuição fosse simétrica e estou confiante de que outliers são raros?Você pode relaxar condição de normalidade à medida que o tamanho da amostra aumenta. Se o tamanho da amostra 10 ou mais, uma ligeira inclinação não é problemática. Quando o tamanho da amostra atinge cerca de 30, inclinação moderada é razoável. Dados com forte inclinação ou outliers exigem uma análise mais cautelosa.","code":""},{"path":"ch5-inf-num.html","id":"introTDistribution","chapter":"5 Inferência para dados numéricos","heading":"5.1.2 Introduzindo a distribuição -\\(t\\)","text":"Nos casos em que usaremos uma amostra pequena para calcular o erro padrão, será útil confiar em uma nova distribuição para cálculos de inferência: distribuição \\(t\\). distribuição-\\(t\\), mostrada como uma linha sólida na Figura 5.1, tem um formato de sino. entanto, suas caudas são mais grossas que modelo normal. Isso significa que observações têm maior probabilidade de cair além de dois desvios padrão da média que sob distribuição normal.194\r\nFigura 5.1: Comparação de uma distribuição \\(t\\) (linha sólida) e uma distribuição normal (linha pontilhada).\r\ndistribuição-\\(t\\), sempre centrada em zero, tem um único parâmetro: os graus de liberdade. O grau de liberdade (df) descreve forma precisa da distribuição-\\(t\\) em forma de sino. Várias distribuições-\\(t\\) são mostradas na Figura 5.2. Quando há mais graus de liberdade, distribuição-\\(t\\) parece muito com distribuição normal padrão.\r\nFigura 5.2: Quanto maiores os graus de liberdade, mais próxima distribuição t se assemelha ao modelo normal padrão.\r\nGraus de liberdade (gl): Os graus de liberdade descrevem forma da distribuição-\\(t\\). Quanto maiores os graus de liberdade, mais próxima distribuição se aproxima modelo normal.Quando os graus de liberdade são cerca de 30 ou mais, distribuição \\(t\\) é quase indistinguível da distribuição normal. Mais frente, relacionamos graus de liberdade com o tamanho da amostra. É muito útil familiarizar-se com distribuição-\\(t\\), porque nos permite maior flexibilidade que distribuição normal ao analisar dados numéricos.Nós usamos uma tabela-t, parcialmente mostrado na tabela abaixo, lugar da tabela de probabilidade normal. Na prática, é mais comum usar software estatístico em vez de uma tabela, e você pode utilizar o R, por exemplo, através da função195:qt(p, df, ncp, lower.tail = TRUE, log.p = FALSE)Cada linha na tabela-\\(t\\) representa uma distribuição-\\(t\\) com diferentes graus de liberdade. colunas correspondem probabilidades de cauda. Por exemplo, se sabemos que estamos trabalhando com distribuição-\\(t\\) com \\(df = 18\\), podemos examinar linha 18, pela tabela abaixo. Se queremos o valor nesta linha que identifica o limite para uma cauda superior de 10%, podemos procurar na coluna onde uma cauda é 0.100. Esse limite é 1.33. Se tivéssemos desejado o corte para os 10% inferiores, usaríamos -1.33. Assim como distribuição normal, todas distribuições-\\(t\\) são simétricas.Uma olhada abreviada na tabela \\(t\\). Cada linha representa um distribuição-\\(t\\) diferente. colunas descrevem os pontos de corte para áreas específicas da cauda.Assim como um problema de probabilidade normal, primeiro desenhamos distribuição (Figura 5.3) e sombreamos área abaixo de -2.10. Para encontrar esta área, identificamos linha apropriada: \\(df=18\\). Em seguida, identificamos coluna contendo o valor absoluto de -2.10; é terceira coluna. Como estamos procurando apenas uma cauda, examinamos linha superior da tabela, que mostra que uma área de cauda para um valor na terceira linha corresponde 0.025. Cerca de 2.5% da distribuição está abaixo de -2.10. próximo exemplo, encontramos um caso em que o valor exato de \\(t\\) não está listado na tabela.\r\nFigura 5.3: distribuição-t com 18 graus de liberdade. área abaixo de -2,10 foi sombreada.\r\nExemplo 5.2  distribuição-\\(t\\) com 20 graus de liberdade é mostrada painel esquerdo da Figura 5.4. Estimar proporção da distribuição caindo acima de 1.65.Identificamos linha na tabela \\(t\\) usando os graus de liberdade: \\(df = 20\\). Então procuramos 1.65; não está listado. Ela fica entre primeira e segunda coluna. Uma vez que esses valores limitam 1.65, suas áreas de cauda irão ligar área da cauda correspondente 1.65. Identificamos área de cauda da primeira e segunda colunas, 0.050 e 0.10, e concluímos que entre 5% e 10% da distribuição é mais que 1.65 desvios-padrão acima da média. Se quisermos, podemos identificar área exata usando software estatístico: 0.0573.Como antes, primeiro identifique linha apropriada: \\(df = 2\\). Em seguida, encontre colunas que capturam 3 unidades: \\(2.92 < 3 < 4.30\\). Usamos segunda e terceira coluna. Finalmente, encontramos os limites para áreas da cauda observando os dois valores finais: 0.05 e 0.10. Usamos os dois valores finais porque estamos procurando por duas caudas (simétricas).\r\nFigura 5.4: Esquerda: distribuição-t com 20 graus de liberdade, com área acima de 1,65 sombreada. Direita: distribuição-t com 2 graus de liberdade, com área além de 3 unidades sombreada\r\n","code":"\nX <- seq(-5, 5, 0.01)\nY <- dnorm(X)\nYt <- dt(X, 2)\n\nggplot() + \n  geom_line(aes(X,Y), color = \"skyblue3\", linetype = \"dashed\", size=1) + #linha da normal\n  geom_line(aes(X,Yt), color = \"red\", size=1) + #linha da t\n  scale_x_continuous(breaks = seq(-4, 4, 2)) + # arrumar a escala\n  theme(axis.title = element_blank(), axis.line.y = element_blank(), \n        axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nX <- seq(-5, 10, 0.02)\nconv <- data.frame(X,\n                   dnorm(X), \n                   dt(X, 8), \n                   dt(X, 4),\n                   dt(X, 2),\n                   dt(X, 1))\n\ncolnames(conv) <- c(\"X\", \"N\", \"t8\", \"t4\", \"t2\", \"t1\")\n\nrequire(tidyr)\nconv_long <- gather(conv, dist, Y, N:t1, factor_key=TRUE)\n\nnames <- c(\n  `N` = \"N(0,1)\",\n  `t8` = \"t(8)\",\n  `t4` = \"t(4)\",\n  `t2` = \"t(2)\",\n  `t1` = \"t(1)\")\n\nggplot(data = conv_long) + \n  geom_line(aes(X, Y, color = dist), size = 1) + \n  scale_x_continuous(breaks = seq(-5, 10, 2)) + \n  theme(axis.title = element_blank(), axis.line.y = element_blank(), \n        axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  labs(color = \"Distribuição\") + \n  scale_color_discrete(labels = names) + \n  theme(legend.position = \"bottom\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nX <- seq(-5, 10, 0.01)\nY <- dt(X, 18)\n\ndata = data.frame(X,Y)\n\nggplot(data = data) + \n  geom_linerange(data = data[data$X < -2.1,], aes(X, ymin = -0.001, ymax = Y), colour=\"#E6205F\") +\n  geom_path(aes(X,Y), size = 1) + \n  xlim(-4, 4) + \n  theme(axis.title = element_blank(), axis.line.y = element_blank(), \n        axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_hline(yintercept = -0.001, size = 1, color = \"white\") + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1))\npt(q = 1.65, df = 20, lower.tail = FALSE)\nX <- seq(-5, 10, 0.02)\nY <- dt(X, 12)\ndata = data.frame(X,Y)\n\np1<- ggplot(data = data) + \n  geom_linerange(data = data[data$X > 1.65,], aes(X, ymin = -0.001, ymax = Y), colour=\"#EAB217\") +\n  geom_path(aes(X,Y), size = 1) + \n  xlim(-4, 4) + \n  theme(axis.title = element_blank(), axis.line.y = element_blank(), \n        axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_hline(yintercept = -0.001, size = 1, color = \"white\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nY <- dt(X, 2.3)\ndata = data.frame(X,Y)\n\np2 <- ggplot(data = data) + \n    geom_linerange(data = data[data$X > 3 | data$X < -3,], \n                 aes(X, ymin = -0.001, ymax = Y), colour=\"#EAB217\") + \n  geom_path(aes(X,Y), size = 1) + \n  xlim(-4, 4) + \n  theme(axis.title = element_blank(), axis.line.y = element_blank(), \n        axis.text.y = element_blank(), axis.ticks.y = element_blank()) + \n  geom_hline(yintercept = -0.001, size = 1, color = \"white\") + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n\nrequire(gridExtra)\ngrid.arrange(p1, p2, ncol = 2)"},{"path":"ch5-inf-num.html","id":"conditionTDistributionOneMean","chapter":"5 Inferência para dados numéricos","heading":"5.1.3 Condições para usar a distribuição-t para inferência de uma média","text":"Para prosseguir com distribuição-\\(t\\) para inferência sobre uma única média, primeiro verificamos duas condições.Independência das observações. Verificamos essa condição como fizemos antes. Coletamos uma amostra aleatória simples de menos 10% da população, ou se os dados são de um experimento ou processo aleatório, nós verificamos com o melhor de nossas habilidades que observações eram independentes.Independência das observações. Verificamos essa condição como fizemos antes. Coletamos uma amostra aleatória simples de menos 10% da população, ou se os dados são de um experimento ou processo aleatório, nós verificamos com o melhor de nossas habilidades que observações eram independentes.observações vêm de uma distribuição quase normal. Essa segunda condição é difícil de ser verificada com pequenos conjuntos de dados. Muitas vezes () observamos uma plotagem dos dados para desvios óbvios modelo normal e (ii) consideramos se quaisquer experiências anteriores nos alertam que os dados podem não estar quase normais.observações vêm de uma distribuição quase normal. Essa segunda condição é difícil de ser verificada com pequenos conjuntos de dados. Muitas vezes () observamos uma plotagem dos dados para desvios óbvios modelo normal e (ii) consideramos se quaisquer experiências anteriores nos alertam que os dados podem não estar quase normais.Ao examinar uma média amostral e erro padrão estimado de uma amostra de observações independentes e quase normais de \\(n\\), usamos uma distribuição \\(t\\) com \\(n-1\\) graus de liberdade (df). Por exemplo, se o tamanho da amostra fosse 19, então usaríamos distribuição-\\(t\\) com \\(df =19-1=18\\) graus de liberdade e prosseguiríamos exatamente como fizemos Capítulo anterior, exceto que agora usamos distribuição-\\(t\\).Quando usar distribuição-\\(t\\): Use distribuição t para inferência da média da amostra quando observações são independentes e quase normais. Você pode relaxar condição de normalidade à medida que o tamanho da amostra aumenta. Por exemplo, distribuição de dados pode ser moderadamente distorcida quando o tamanho da amostra é de pelo menos 30.","code":""},{"path":"ch5-inf-num.html","id":"oneSampleTConfidenceIntervals","chapter":"5 Inferência para dados numéricos","heading":"5.1.4 Uma amostra t - Intervalos de Confiança","text":"Os golfinhos estão topo da cadeia alimentar oceânica, o que faz com que substâncias perigosas, como o mercúrio, se concentrem em seus órgãos e músculos. Este é um problema importante para os golfinhos e outros animais, como os humanos, que ocasionalmente os comem. Por exemplo, isso é particularmente relevante Japão, onde refeições escolares incluem golfinhos às vezes197.\r\nFigura 5.5: Um golfinho de risso\r\nAqui nós identificamos um intervalo de confiança para o conteúdo médio de mercúrio músculo de golfinhos usando uma amostra de 19 golfinhos da região de Taiji, Japão.198 Os dados estão resumidos na Tabela 5.1. Os valores mínimo e máximo observados podem ser usados para avaliar se existem ou não valores óbvios ou outliers.Tabela 5.1: Resumo conteúdo de mercúrio músculo de 19 golfinhos de Risso da área de Taiji. medições são em mu/wet g (microgramas de mercúrio por grama úmida de músculo).observações são uma amostra aleatória simples, portanto independência é razoável. estatísticas resumidas na Tabela 5.1 não sugerem qualquer distorção ou outliers, todas observações estão dentro de 2.5 desvios padrão da média. Com base nessa evidência, suposição de normalidade parece razoável.modelo normal, usamos \\(z ^ {\\star}\\) e o erro padrão para determinar largura de um intervalo de confiança. Revisamos fórmula intervalo de confiança quando usamos distribuição-\\(t\\):\\[\\begin{eqnarray*}\r\n\\bar{x} \\ \\pm\\  t^{\\star}_{df}EP\r\n\\tag{5.1}\r\n\\end{eqnarray*}\\]média da amostra e o erro padrão estimado são computados como antes (\\(\\bar{x} = 4.4\\) e \\(EP = s/\\sqrt{n} = 0.528\\)). O valor \\(t^{\\star}_{df}\\) é um corte que obtemos com base nível de confiança e na distribuição \\(t\\) com \\(df\\) graus de liberdade. Antes de determinar esse corte, primeiro precisamos dos graus de liberdade.Graus de liberdade para uma amostra única: Se amostra tem \\(n\\) observações e estamos examinando uma única média, então usamos uma distribuição-\\(t\\) com \\(df = n-1\\) graus de liberdade.Em nosso exemplo atual, devemos usar distribuição \\(t\\) com \\(df = 19-1 = 18\\) graus de liberdade. Em seguida, identificando que o \\(t_{18}^{\\star}\\) é semelhante ao que encontramos como \\(z^{\\star}\\).Para um intervalo de confiança de 95%, queremos encontrar o limite \\(t^{\\star}_{18}\\) tal que 95% da distribuição-\\(t\\) é entre -\\(t^{\\star}_{18}\\) e \\(t^{\\star}_{18}\\).Para um intervalo de confiança de 95%, queremos encontrar o limite \\(t^{\\star}_{18}\\) tal que 95% da distribuição-\\(t\\) é entre -\\(t^{\\star}_{18}\\) e \\(t^{\\star}_{18}\\).Na tabela-\\(t\\), encontre coluna com área totalizando 0.05 nas duas caudas (terceira coluna) e, em seguida, linha com 18 graus de liberdade: \\(t^{\\star}_{18} = 2.10\\).Na tabela-\\(t\\), encontre coluna com área totalizando 0.05 nas duas caudas (terceira coluna) e, em seguida, linha com 18 graus de liberdade: \\(t^{\\star}_{18} = 2.10\\).Geralmente o valor de \\(t^{\\star}_{df}\\) é um pouco maior que o que obteríamos sob o modelo normal com \\(z^{\\star}\\).Finalmente, podemos substituir todos os nossos valores na Equação (5.1) para criar o intervalo de confiança de 95% para o conteúdo médio de mercúrio nos músculos dos golfinhos de Risso que passam pela área de Taiji.:\\[\\begin{eqnarray*}\r\n\\bar{x} \\ \\pm\\  t^{\\star}_{18}EP\r\n    \\quad \\\\quad\r\n4.4 \\ \\pm\\  2.10 \\times 0.528\r\n    \\quad \\\\quad\r\n(3.29, 5.51)\r\n\\end{eqnarray*}\\]Temos 95% de confiança de que o teor médio de mercúrio nos músculos dos golfinhos de Risso está entre 3.29 e 5.51 \\(\\mu\\) g/grama, o que é considerado extremamente alto.Encontrando um intervalo de confiança \\(t\\) para média: Com base em uma amostra de observações independentes e quase normais de \\(n\\), um intervalo de confiança para média populacional é\\[\\begin{eqnarray*}\r\n\\bar{x} \\ \\pm\\  t^{\\star}_{df}EP\r\n\\end{eqnarray*}\\]onde \\(\\bar{x}\\) é média da amostra, \\(t^{\\star}_{df}\\) corresponde ao nível de confiança e graus de liberdade, e \\(EP\\) é o erro padrão estimado pela amostra.O erro padrão:\\(EP = \\frac{0.069}{\\sqrt{15}} = 0.0178\\). Graus de liberdade: \\(df = n - 1 = 14\\).Olhando na coluna onde duas caudas é de 0.100 (para um intervalo de confiança de 90%) e linha \\(df=14\\), nós identificamos \\(t^{\\star}_{14} = 1.76\\).","code":"\nrequire(knitr)\nknitr::include_graphics('images/c5/rissosDolphin.jpg')\nnum <- c(19, 4.4, 2.3, 1.7, 9.2)\nnames(num) <- c(\"n\", \"média\", \"s\", \"mínimo\", \"máximo\")\n\nknitr::kable(t(num), \n             caption = \"Resumo do conteúdo de mercúrio no músculo de 19 golfinhos de Risso da área de Taiji. As medições são em mu/wet g (microgramas de mercúrio por grama úmida de músculo).\")"},{"path":"ch5-inf-num.html","id":"testsTOneSample","chapter":"5 Inferência para dados numéricos","heading":"5.1.5 Uma amostra de testes-t","text":"O corredor típico dos EUA está ficando mais rápido ou mais lento com o tempo? Consideramos essa questão contexto da Corrida das Flores de Cerejeira, que é uma corrida de 10 milhas em Washington, DC cada primavera.202O tempo médio de todos os corredores que terminaram corrida Cherry Blossom em 2006 foi de 93.29 minutos (93 minutos e cerca de 17 segundos). Queremos determinar o uso de dados de 100 participantes na Corrida das Floradas de Cerejeira de 2012 para descobrir se os corredores nesta corrida estão ficando mais rápidos ou mais lentos contra outra possibilidade de que não houve nenhuma mudança.\r\nFigura 5.6: Um histograma de tempo para os dados da amostra Cherry Blossom Race.\r\nCom independência satisfeita e ligeira inclinação que não é uma preocupação para uma amostra desse tamanho, podemos prosseguir com realização de um teste de hipótese usando distribuição-\\(t\\).Quando usamos uma distribuição-\\(t\\), usamos um T-escore (igual ao Z-escore): Para nos ajudar lembrar de usar distribuição-\\(t\\), usamos \\(T\\) para representar estatística de teste, e geralmente chamamos isso de T-escore. O escore Z e o escore T são calculados exatamente da mesma maneira e são conceitualmente idênticos: cada um representa quantos erros-padrão o valor observado é valor nulo.","code":"\nrequire(openintro)\ndata(run10Samp)\nd <- run10Samp\n\nggplot(data = d) + \n  geom_histogram(aes(time), bins = 10, color = 'white', fill = \"skyblue2\") + \n  labs(x = \"Tempo (em minutos)\", y = \"Frequência\")+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"pairedData","chapter":"5 Inferência para dados numéricos","heading":"5.2 Dados pareados","text":"Os livros didáticos são realmente mais baratos online? Aqui nós comparamos o preço dos livros didáticos na livraria da Universidade da Califórnia, Los Angeles (UCLA) e os preços na Amazon.com. Setenta e três cursos da UCLA foram amostrados aleatoriamente na primavera de 2010.206 Uma parte conjunto de dados é mostrada na Tabela 5.2.Tabela 5.2: Seis casos conjunto de dados ‘livros texto.’","code":"\nlibrary(openintro)\ndata(textbooks)\n\nknitr::kable(head(textbooks), align = \"c\", \n             caption = \"Seis casos do conjunto de dados 'livros texto'.\")"},{"path":"ch5-inf-num.html","id":"pairedObservations","chapter":"5 Inferência para dados numéricos","heading":"5.3 Observações Pareadas","text":"Cada livro-texto tem dois preços correspondentes conjunto de dados: um para livraria da UCLA e outro para Amazon. Portanto, cada preço de livro didático da livraria da UCLA tem uma correspondência natural com um preço de livro didático da Amazon. Quando dois conjuntos de observações têm essa correspondência especial, eles são pareados.Dados pareados: Dois conjuntos de observações são pareados se cada observação em um conjunto tiver uma correspondência especial ou conexão com exatamente uma observação outro conjunto de dados.Para analisar dados pareados, é frequentemente útil observar diferença nos resultados de cada par de observações. conjunto de dados livro texto, olhamos para diferenças nos preços, que é representado como variável dif nos dados livro texto. Aqui diferenças são tomadas como\\[\\begin{eqnarray*}\r\n\\text{preço UCLA} - \\text{preço Amazon}\r\n\\end{eqnarray*}\\]para cada livro. É importante que subtraímos sempre usando uma ordem consistente; aqui os preços da Amazon são sempre subtraídos dos preços da UCLA. Um histograma dessas diferenças é mostrado na Figura 5.7. Usar diferenças entre observações pareadas é uma maneira comum e útil de analisar dados pareados.\r\nFigura 5.7: Histograma da diferença de preço para cada livro amostrado. Estes dados são fortemente distorcidos.\r\n","code":"\nggplot2::ggplot(data = textbooks) + \n  geom_histogram(aes(x = diff), bins = 8, color = \"white\", fill = \"#E97C31\") + \n  labs(x = \"Preço UCLA - Preço Amazon (USD)\", y = \"Frequência\")+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"inferencePairedData","chapter":"5 Inferência para dados numéricos","heading":"5.3.1 Inferência para dados pareados","text":"Para analisar um conjunto de dados pareados, simplesmente analisamos diferenças. Podemos usar mesmas técnicas de distribuição-\\(t\\) que aplicamos na última seção.Tabela 5.3: Estatísticas resumidas para diferenças de preço. Havia 73 livros, então há 73 diferenças.Estamos considerando dois cenários: não há diferença ou há alguma diferença nos preços médios.distribuição-\\(t\\) pode ser usada para essa aplicação? observações são baseadas em uma amostra aleatória simples de menos de 10% de todos os livros vendidos na livraria, portanto independência é razoável. Enquanto distribuição é fortemente distorcida, amostra é razoavelmente grande (\\(n = 73\\)), para que possamos prosseguir. Como condições são razoavelmente satisfeitas, podemos aplicar distribuição-\\(t\\) essa configuração.Calculamos o erro padrão associado \\(\\bar{x}_{dif}\\) usando o desvio padrão das diferenças (\\(s_{_{dif}}=14.26\\)) e o número de diferenças (\\(n_{_{dif}}=73\\)):\r\n\\[EP_{\\bar{x}_{dif}} = \\frac{s_{dif}}{\\sqrt{n_{dif}}} = \\frac{14.26}{\\sqrt{73}} = 1.67\\].Para visualizar o p-valor, distribuição amostral de \\(\\bar{x}_{dif}\\) é desenhado como se \\(H_0\\) fosse verdadeira, que é mostrado na Figura 5.8. O p-valor é representado pelas duas caudas (muito) pequenas. Para encontrar áreas de cauda, calculamos estatística de teste, que é o T-escore de \\(\\bar{x}_{dif}\\) sob condição nula de que diferença média real é 0:\\[\\begin{align*}\r\nT = \\frac{\\bar{x}_{dif} - 0}{EP_{x_{dif}}} = \\frac{12.76 - 0}{1.67} = 7.65\r\n\\end{align*}\\]Os graus de liberdade são \\(df = 73 - 1 = 72\\). Esse valor é maior que qualquer outro na linha de 70 GL (arredondamos para baixo para \\(GL\\) ao usar tabela), significando que o p-valor bilateral é menor que 0.01. Se usássemos software estatístico, descobriríamos que o p-valor é menor que 1 em 10 bilhões!Como o p-valor é menor que 0.05, rejeitamos hipótese nula. Nós encontramos evidências convincentes de que Amazon era, em média, mais barata que livraria da UCLA para os livros didáticos da UCLA.\r\nFigura 5.8: Distribuição da amostragem para diferença média dos preços dos livros, se diferença média real zero.\r\n","code":"\nsum.estat <- c(length(textbooks$diff), \n               mean(textbooks$diff), \n               sd(textbooks$diff))\nnames(sum.estat) <- c(\"n\", \"média\", \"devio padrão\")\n\nknitr::kable(t(sum.estat), align = \"c\", \n             caption = \"Estatísticas resumidas para as diferenças de preço. Havia 73 livros, então há 73 diferenças.\")\npt(q = 7.65, df = 72, lower.tail = FALSE)\nX <- seq(-15, 15, 0.01)\nYt <- dt(X, 72)\n\nggplot() + \n  geom_line(aes(X,Yt), size = 1) + #linha da t\n  theme(axis.title = element_blank(), axis.line.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(), axis.text.x = element_blank()) +\n  scale_x_continuous(breaks = seq(-12.76, 12.76, 12.76)) +\n    annotate(geom = \"text\", x = -12.76, y = 0.15, \n             label = \"cauda a \\n esquerda\", size = 3, color = \"#EAB217\") +\n      annotate(geom = \"text\", x = 12.76, y = 0.15, \n             label = \"cauda a \\n direita\", size = 3, color = \"#EAB217\") + \n    geom_segment(aes(x = -12.76, xend = -12.76, y = 0.10, yend = 0.01),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#EAB217\") + \n      geom_segment(aes(x = 12.76, xend = 12.76, y = 0.10, yend = 0.01),\n               arrow = arrow(length = unit(0.1, \"cm\")), color = \"#EAB217\") + \n    annotate(geom = \"text\", x = 0, y = -0.02, label = expression(mu[0]*' = 0'), size = 3) +\n    annotate(geom = \"text\", x = 12.76, y = -0.02, \n             label = expression(bar(x)[diff]*\" = 12.76\"), size = 3) + \n    geom_segment(aes(x = -15, y = 0, xend = -12.76, yend = 0), color = \"#EAB217\", size = 1) +\n  geom_segment(aes(x = 12.76, y = 0, xend = 15, yend = 0), color = \"#EAB217\", size = 1)+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"differenceTwoMeans","chapter":"5 Inferência para dados numéricos","heading":"5.4 Diferença entre duas médias","text":"Nesta seção, consideramos uma diferença em duas médias populacionais, \\(\\mu_1 - \\mu_2\\), sob condição de que os dados não estejam pareados. Assim como com uma única amostra, identificamos condições para garantir que podemos usar distribuição-\\(t\\) com uma estimativa pontual da diferença, \\(\\bar{x}_1 - \\bar{x}_2\\).Aplicamos esses métodos em três contextos: determinando se células-tronco podem melhorar função cardíaca, explorando o impacto hábito de fumar das mulheres grávidas em recém-nascidos e investigando se há evidência estatisticamente significativa de que uma variação de um exame é mais difícil que outra variação. Esta seção é motivada por questões como “Existem evidências convincentes de que recém-nascidos de mães que fumam têm um peso médio ao nascer diferente que recém-nascidos de mães que não fumam?”","code":""},{"path":"ch5-inf-num.html","id":"confidenceIntervalsMeanDifference","chapter":"5 Inferência para dados numéricos","heading":"5.4.1 Intervalo de confiança para diferença de médias","text":"O tratamento com células-tronco embrionárias (CTE) ajuda melhorar função cardíaca após um ataque cardíaco? Tabela 5.4 contém estatísticas resumidas de um experimento para testar CTE em ovelhas que tiveram um ataque cardíaco. Cada uma dessas ovelhas foi aleatoriamente designada para o grupo CTE ou controle, e mudança na capacidade de bombeamento dos corações foi medida estudo. Um valor positivo corresponde ao aumento da capacidade de bombeamento, o que geralmente sugere uma recuperação mais forte. Nosso objetivo será identificar um intervalo de confiança de 95% para o efeito de CTE na mudança na capacidade de bombeamento coração em relação ao grupo controle.Uma estimativa pontual da diferença na variável de bombeamento coração pode ser encontrada usando diferença nas médias da amostra:\\[\\begin{eqnarray*}\r\n\\bar{x}_{cte} - \\bar{x}_{con}\\ =\\ 3.50 - (-4.33)\\ =\\ 7.83\r\n\\end{eqnarray*}\\]Tabela 5.4: Estatísticas resumidas estudo com células-tronco embrionárias.Usando distribuição-\\(t\\) para diferença nas médias: distribuição-\\(t\\) pode ser usada para inferência quando se trabalha com diferença padronizada de duas médias se (1) cada amostra satisfizer condições para usar distribuição-\\(t\\) e (2) amostras são independentes.Verificamos duas condições exigidas:Neste estudo, ovelhas eram independentes umas das outras. Além disso, distribuições na Figura 5.9 não mostram nenhum desvio claro da normalidade, onde observamos exceções proeminentes em particular para amostras tão pequenas. Estes achados implicam que cada média amostral poderia ser modelada usando uma distribuição-\\(t\\).Neste estudo, ovelhas eram independentes umas das outras. Além disso, distribuições na Figura 5.9 não mostram nenhum desvio claro da normalidade, onde observamos exceções proeminentes em particular para amostras tão pequenas. Estes achados implicam que cada média amostral poderia ser modelada usando uma distribuição-\\(t\\).ovelhas em cada grupo também eram independentes umas das outras.ovelhas em cada grupo também eram independentes umas das outras.Como ambas condições são atendidas, podemos usar distribuição-\\(t\\) para modelar diferença das duas médias amostrais.\r\nFigura 5.9: Histogramas para o grupo de células-tronco embrionárias e o grupo controle. Valores mais altos estão associados uma melhoria maior. Não vemos qualquer evidência de distorção nesses dados; entanto, vale pena notar que distorção seria difícil de detectar com uma amostra tão pequena.\r\nPodemos quantificar variabilidade na estimativa pontual, \\(\\bar{x}_{cte} - \\bar{x}_{con}\\), usando seguinte fórmula para seu erro padrão:\\[\\begin{eqnarray*}\r\nEP_{\\bar{x}_{cte} - \\bar{x}_{con}} = \\sqrt{\\frac{\\sigma_{cte}^2}{n_{cte}} + \\frac{\\sigma_{con}^2}{n_{con}}}\r\n\\end{eqnarray*}\\]Geralmente estimamos esse erro padrão usando estimativas de desvio padrão com base nas amostras:\\[\\begin{align*}\r\nEP_{\\bar{x}_{cte} - \\bar{x}_{con}}\r\n    &= \\sqrt{\\frac{\\sigma_{cte}^2}{n_{cte}} + \\frac{\\sigma_{con}^2}{n_{con}}} \\\\\r\n    &\\approx \\sqrt{\\frac{s_{cte}^2}{n_{cte}} + \\frac{s_{con}^2}{n_{con}}}\r\n    = \\sqrt{\\frac{5.17^2}{9} + \\frac{2.76^2}{9}} = 1.95\r\n\\end{align*}\\]Como usaremos distribuição-\\(t\\), também devemos identificar os graus de liberdade apropriados. Isso pode ser feito usando um software de computador. Uma técnica alternativa é usar o \\(min[n_1 - 1, n_2 - 1]\\), que é o método que normalmente aplicaremos nos exemplos e na prática orientada.209Distribuição de uma diferença de médias amostrais: diferença amostral de duas médias, \\(\\bar{x}_1 - \\bar{x}_2\\), pode ser modelado usando o distribuição-\\(t\\) e o erro padrão\\[\\begin{eqnarray}\r\n\\textstyle\r\nEP_{\\bar{x}_{1} - \\bar{x}_{2}} = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\r\n\\tag{5.2}\r\n\\end{eqnarray}\\]quando cada amostra média pode ser modelada usando uma distribuição-\\(t\\) e amostras são independentes. Para calcular os graus de liberdade, use um software estatístico ou o menor de \\(n_1 - 1\\) e \\(n_2 - 1\\).Usaremos diferença de amostra e o erro padrão para essa estimativa pontual de nossos cálculos anteriores:\\[\\begin{align*}\r\n& \\bar{x}_{cte} - \\bar{x}_{con} = 7.83 \\\\\r\n& EP = \\sqrt{\\frac{5.17^2}{9} + \\frac{2.76^2}{9}} = 1.95\r\n\\end{align*}\\]Usando \\(GL = 8\\), podemos identificar o \\(t^{\\star}_{df}\\) apropriado, \\(t^{\\star}_{8}\\) para intervalo de confiança de 95% que é 2,31. Finalmente, podemos inserir os valores na fórmula intervalo de confiança:\\[\\begin{align*}\r\n\\text{estimativa pontual} \\ \\pm\\ t^{\\star}EP \\quad\\rightarrow\\quad\r\n7.83 \\ \\pm\\ 2.31\\times 1.95 \\quad\\rightarrow\\quad (3.32, 12.34)\r\n\\end{align*}\\]Temos 95% de confiança de que células-tronco embrionárias melhoram função de bombeamento coração em ovelhas que sofreram um ataque cardíaco de 3.32% 12.34%.","code":"\ndados <- matrix(NA, ncol = 3, nrow = 2)\ndados[1,] <- c(9, 3.5, 5.17); dados[2,] <- c(9, -4.33, 2.76)\ncolnames(dados) <- c(\"n\", \"média\", \"desvio\")\nrownames(dados) <- c(\"CTEs\", \"Controle\")\n\nknitr::kable(dados, align = \"c\", caption = \"Estatísticas resumidas do estudo com células-tronco embrionárias.\")\ndata(stem.cells)\nstem.cells$dif = stem.cells$after - stem.cells$before #diferença\n\nlabs <- c(\n  ctrl = \"Controle \\n (sem tratamento)\",\n  esc = \"Transplante de células-tronco \\n embrionárias\"\n)\n\nggplot(data = stem.cells) + \n  geom_histogram(aes(x = dif), color = \"white\", bins = 11, fill = \"#E6205F\") + \n  facet_grid(~trmt, labeller = as_labeller(labs)) + \n  labs(x = \"Mudança na função de bombeamento do coração\", y = NULL)+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"HTBasedMeanDifference","chapter":"5 Inferência para dados numéricos","heading":"5.4.2 Testes de hipóteses baseados em uma diferença de médias","text":"Um conjunto de dados chamado bebe_fumo representa uma amostra aleatória de 150 casos de mães e seus recém-nascidos na Carolina Norte durante um ano. Quatro casos deste conjunto de dados são representados na Tabela 5.5. Estamos particularmente interessados em duas variáveis: peso e fumo. variável peso representa os pesos dos recém-nascidos e variável fumo descreve quais mães fumaram durante gravidez.Gostaríamos de saber se há evidências convincentes de que os recém-nascidos de mães que fumam têm um peso médio ao nascer diferente que os recém-nascidos de mães que não fumam? Usaremos o exemplo da Carolina Norte para tentar responder essa pergunta. O grupo de fumantes inclui 50 casos e o grupo de não fumantes contém 100 casos, representados na Figura 5.10.Tabela 5.5: Quatro casos conjunto de dados bebe_fumo.\r\nFigura 5.10: O painel superior representa pesos de nascimento para bebês cujas mães fumaram. O painel inferior representa os pesos ao nascimento de bebês cujas mães não fumaram. distribuições exibem moderada forte e forte inclinação, respectivamente\r\nhipótese nula representa o caso de nenhuma diferença entre os grupos.onde \\(\\mu_{n}\\) representa mães não fumantes e \\(\\mu_s\\) representa mães que fumavam.Verificamos duas condições necessárias para aplicar distribuição-\\(t\\) à diferença nas médias amostrais. (1) Como os dados provêm de uma amostra aleatória simples e consistem em menos de 10% de todos os casos, observações são independentes. Além disso, embora cada distribuição seja fortemente distorcida, os tamanhos de amostra de 50 e 100 tornariam razoável modelar cada um separadamente usando uma distribuição-\\(t\\). inclinação é razoável para esses tamanhos de amostra de 50 e 100. (2) O raciocínio de independência aplicado em (1) também garante que observações em cada amostra sejam independentes. Como ambas condições são satisfeitas, diferença nas médias da amostra pode ser modelada usando uma distribuição-\\(t\\).Tabela 5.6: Estatísticas resumidas para o conjunto de dadosPrática Orientada 5.9  estatísticas resumidas na Tabela 5.6 pode ser útil para este exercício.210Qual é estimativa pontual da diferença de população?, \\(\\mu_{n} - \\mu_{s}\\)?\r\nQual é estimativa pontual da diferença de população?, \\(\\mu_{n} - \\mu_{s}\\)?Calcule o erro padrão da estimativa pontual da parte ().\r\nCalcule o erro padrão da estimativa pontual da parte ().\r\nPara descrever o p-valor, desenhamos distribuição da estimativa pontual como se \\(H_0\\) fosse verdadeiro e áreas de sombra representando pelo menos tanta evidência contra \\(H_0\\) quanto o que foi observado. Ambas caudas estão sombreadas porque é um teste bilateral.Exemplo 5.11  \r\nCalcule o p-valor teste de hipótese usando figura Exemplo 5.10 e avalie hipóteses usando um nível de significância de \\(\\alpha=0.05\\).Começamos calculando o T-escore:\\[\\begin{eqnarray*}\r\nT = \\frac{\\ 0.40 - 0\\ }{0.26} = 1.54\r\n\\end{eqnarray*}\\]Em seguida, comparamos esse valor com valores na tabela \\(T\\), onde usamos o menor de \\(n_n-1 = 99\\) e \\(n_s - 1 = 49\\) como os graus de liberdade: \\(GL = 49\\). O T-escore fica entre primeira e segunda colunas na linha \\(GL = 49\\) da tabela \\(t\\), o que significa que o p-valor bilateral fica entre 0.10 e 0.20. Este p-valor é maior que o valor de significância, 0.05, então nós falhamos em rejeitar hipótese nula. Não há evidências suficientes para dizer que há uma diferença peso médio ao nascer de recém-nascidos de mães da Carolina Norte que fumaram durante gravidez e recém-nascidos de mães da Carolina Norte que não fumaram durante gravidez.Embora tenhamos usado esse conjunto de dados relativamente pequeno como exemplo, conjuntos de dados maiores mostram que mulheres que fumam tendem ter recém-nascidos menores. De fato, algumas pessoas na indústria tabaco realmente tiveram audácia de citar benefícios em fumar:É verdade. Os bebês nascidos de mulheres que fumam são menores, mas são tão saudáveis quanto os bebês nascidos de mulheres que não fumam. E algumas mulheres preferem ter bebês menores. - Joseph Cullman.Checagem de fatos: os bebês de mulheres que fumam não são tão saudáveis quanto os bebês de mulheres que não fumam.213","code":"\ndata(births)\n\nknitr::kable(head(births[,c(1:3, 7:9)], 4), align = \"c\", \n             caption = \"Quatro casos do conjunto de dados bebe_fumo.\")\nlabs <- c(\n  smoker = \"Mães Fumantes\",\n  nonsmoker = \"Mães Não-Fumantes\"\n)\n\nggplot(data = births) + \n  geom_histogram(aes(x = weight), color = \"white\", bins = 11, fill = \"#EAB217\") + \n  facet_grid(~smoke, labeller = as_labeller(labs)) + \n  scale_x_continuous(breaks = seq(0, 10, 2)) + \n  theme(axis.ticks.y = element_blank(), axis.line.y = element_blank(), axis.text.y = element_blank()) +\n  labs(x = \"Peso (em libras) dos recém nascidos\", y = NULL)+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nsm <- matrix(NA, ncol = 2, nrow = 3)\nsm[1,] <- as.numeric(aggregate(births$weight, list(births$smoke), mean)[,2])\nsm[2,] <- as.numeric(aggregate(births$weight, list(births$smoke), sd)[,2])\nsm[3,] <- c(50,100)\n\ncolnames(sm) <- c('Não Fumante', 'Fumante')\nrownames(sm) <- c('média', 'desvio', 'n')\n\nknitr::kable(round(sm,2), align = \"c\", caption = \"Estatísticas resumidas para o conjunto de dados\")\nset.seed(1)\nX <- seq(-4, 4, 0.01)\nY <- dnorm(X)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < -1.54 | gg$X > 1.54,], aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") + \n  geom_path(size =  1) +\n  geom_hline(yintercept = 0, size = 1, color = \"white\") + labs(x  = NULL) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank()) +\n  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) + \n  annotate(geom = \"text\", x = 0, y = 0, label = expression(mu[n]-mu[s]*' = 0'), size = 4) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"caseStudyTwoVersions","chapter":"5 Inferência para dados numéricos","heading":"5.4.3 Estudo de caso: duas versões de um exame","text":"Uma instrutor decidiu executar duas pequenas variações mesmo exame. Antes de distribuir os exames, ele misturou os exames para garantir que cada aluno recebesse uma versão aleatória. estatísticas resumidas de como os alunos se saíram nesses dois exames são mostradas na Tabela 5.7. Antecipando reclamações dos alunos que fizeram o exame da versão B, ela gostaria de avaliar se diferença observada nos grupos é tão grande que fornece evidências convincentes de que versão B era mais difícil (em média) que versão .Tabela 5.7: Estatísticas resumidas das pontuações para cada versão exame.Prática Orientada 5.13  Avaliar hipóteses na Prática Orientada 5.12 usando distribuição-\\(t\\), devemos primeiro verificar suposições.215Parece razoável que pontuações sejam independentes dentro de cada grupo?\r\nParece razoável que pontuações sejam independentes dentro de cada grupo?E sobre condição de normalidade/ inclinação das observações em cada grupo?\r\nE sobre condição de normalidade/ inclinação das observações em cada grupo?Você acha que os escores dos dois grupos seriam independentes um outro, ou seja, duas amostras são independentes?\r\nVocê acha que os escores dos dois grupos seriam independentes um outro, ou seja, duas amostras são independentes?Depois de verificar condições de cada amostra e confirmar que amostras são independentes uma da outra, estamos prontos para realizar o teste usando distribuição-\\(t\\). Neste caso, estamos estimando verdadeira diferença nas pontuações médias dos testes usando os dados da amostra, então estimativa pontual é \\(\\bar{x}_A - \\bar{x}_B = 5.3\\). O erro padrão da estimativa pode ser calculado como\\[\\begin{eqnarray*}\r\nEP = \\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}} = \\sqrt{\\frac{14^2}{30} + \\frac{20^2}{27}} = 4.62\r\n\\end{eqnarray*}\\]Finalmente, construímos estatística de teste:\\[\\begin{eqnarray*}\r\nT = \\frac{\\text{estimativa pontual} - \\text{valor nulo}}{EP} = \\frac{(79.4-74.1) - 0}{4.62} = 1.15\r\n\\end{eqnarray*}\\]Se tivermos um computador à mão, podemos identificar os graus de liberdade como 45.97. Caso contrário, usamos o menor de \\(n_1-1\\) e \\(n_2-1\\): \\(GL=26\\).\r\nFigura 5.11: distribuição-t com 26 graus de liberdade.\r\nExaminamos linha \\(GL = 26\\) na tabela-\\(t\\). Como esse valor é menor que o valor na coluna da esquerda, o p-valor é maior que 0,200 (duas caudas!). Como o p-valor é tão grande, não rejeitamos hipótese nula. Ou seja, os dados não mostram convincentemente que uma versão de exame é mais difícil que outra, e professora não deve ser convencida de que deve adicionar pontos aos resultados exame da Versão B.","code":"\nest_res <- matrix(c(30, 79.4, 14, 45, 100, 27, 74.1, 20, 32, 100), \n                  ncol = 5, nrow = 2, byrow = TRUE)\n\nrownames(est_res) <- c(\"A\", \"B\")\ncolnames(est_res) <- c(\"n\", \"média\", \"desvio\", \"min\", \"max\")\n\nknitr::kable(est_res, align = \"c\", \n             caption = \"Estatísticas resumidas das pontuações para cada versão do exame.\")\nset.seed(1)\nX <- seq(-4, 4, 0.01)\nY <- dt(X, df = 26)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < -1.15 | gg$X > 1.15,], aes(X, ymin = 0, ymax = Y), \n                 colour=\"#E6205F\") + \n  geom_path(size = 1) +\n  geom_hline(yintercept = 0, color = \"white\", size = 1) + labs(x  = NULL) + \n  scale_x_continuous(breaks = seq(-3, 3, 1)) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"inferenceSummaryTDistribution","chapter":"5 Inferência para dados numéricos","heading":"5.4.4 Resumo da inferência usando a distribuição-\\(t\\)","text":"Testes de hipótese: Ao aplicar distribuição-\\(t\\) para um teste de hipótese, procedemos da seguinte forma:Escreva hipóteses apropriadas.Escreva hipóteses apropriadas.Verificar condições para usar o distribuição-\\(t\\).\r\nUma amostra ou diferenças de dados pareados: observações (ou diferenças) devem ser independentes e quase normais. Para tamanhos de amostra maiores, podemos relaxar o requisito quase normal, e não é problemática uma ligeira inclinação para tamanhos de amostra de 15, inclinação moderada para tamanhos de amostra de 30 e inclinação forte para tamanhos de amostra de 60.\r\nPara uma diferença de médias, quando os dados não estão pareados: cada média de amostra deve satisfazer separadamente condições de uma amostra para distribuição-\\(t\\), e os dados nos grupos também devem ser independentes.\r\nVerificar condições para usar o distribuição-\\(t\\).Uma amostra ou diferenças de dados pareados: observações (ou diferenças) devem ser independentes e quase normais. Para tamanhos de amostra maiores, podemos relaxar o requisito quase normal, e não é problemática uma ligeira inclinação para tamanhos de amostra de 15, inclinação moderada para tamanhos de amostra de 30 e inclinação forte para tamanhos de amostra de 60.Uma amostra ou diferenças de dados pareados: observações (ou diferenças) devem ser independentes e quase normais. Para tamanhos de amostra maiores, podemos relaxar o requisito quase normal, e não é problemática uma ligeira inclinação para tamanhos de amostra de 15, inclinação moderada para tamanhos de amostra de 30 e inclinação forte para tamanhos de amostra de 60.Para uma diferença de médias, quando os dados não estão pareados: cada média de amostra deve satisfazer separadamente condições de uma amostra para distribuição-\\(t\\), e os dados nos grupos também devem ser independentes.Para uma diferença de médias, quando os dados não estão pareados: cada média de amostra deve satisfazer separadamente condições de uma amostra para distribuição-\\(t\\), e os dados nos grupos também devem ser independentes.Calcule estimativa pontual de interesse, o erro padrão e os graus de liberdade. Para \\(GL\\), use \\(n-1\\) para uma amostra, e para duas amostras use um software estatístico ou o menor entre \\(n_1 - 1\\) e \\(n_2 - 1\\).Calcule estimativa pontual de interesse, o erro padrão e os graus de liberdade. Para \\(GL\\), use \\(n-1\\) para uma amostra, e para duas amostras use um software estatístico ou o menor entre \\(n_1 - 1\\) e \\(n_2 - 1\\).Calcular o T-escore e o p-valor.Calcular o T-escore e o p-valor.Faça uma conclusão com base p-valor e escreva uma conclusão contexto e em linguagem simples para que qualquer pessoa possa entender o resultado.Faça uma conclusão com base p-valor e escreva uma conclusão contexto e em linguagem simples para que qualquer pessoa possa entender o resultado.Intervalos de Confiança: Da mesma forma, o seguinte é como geralmente calculamos um intervalo de confiança usando um distribuição-\\(t\\):Verifique condições para usar distribuição-\\(t\\). (Veja acima.)Verifique condições para usar distribuição-\\(t\\). (Veja acima.)Calcule estimativa pontual de interesse, o erro padrão, os graus de liberdade e \\(t^{\\star}_{GL}\\).Calcule estimativa pontual de interesse, o erro padrão, os graus de liberdade e \\(t^{\\star}_{GL}\\).Calcule o intervalo de confiança usando fórmula geral, estimativa pontual \\(\\pm\\ t_{GL}^{\\star} EP\\).Calcule o intervalo de confiança usando fórmula geral, estimativa pontual \\(\\pm\\ t_{GL}^{\\star} EP\\).Coloque conclusões contexto e em linguagem clara, para que até mesmo os não estatísticos possam entender os resultados.Coloque conclusões contexto e em linguagem clara, para que até mesmo os não estatísticos possam entender os resultados.","code":""},{"path":"ch5-inf-num.html","id":"examiningSEFormula","chapter":"5 Inferência para dados numéricos","heading":"5.4.5 Examinando a fórmula do erro padrão (tópico especial)","text":"fórmula para o erro padrão da diferença entre duas médias é semelhante à fórmula para outros erros padrões. Lembre-se de que o erro padrão de uma única média,\\(\\bar{x}_1\\), pode ser aproximado por\\[\\begin{align*}\r\nEP_{\\bar{x}_1} = \\frac{s_1}{\\ \\sqrt{n_1}\\ }\r\n\\end{align*}\\]onde \\(s_1\\) e \\(n_1\\) representam o desvio padrão amostral e o tamanho da amostra.O erro padrão da diferença de duas médias amostrais pode ser construído partir dos erros padrão das amostras separadas:\\[\\begin{eqnarray}\r\nEP_{\\bar{x}_{1} - \\bar{x}_{2}}\r\n    = \\sqrt{EP_{\\bar{x}_1}^2 + EP_{\\bar{x}_2}^2}\r\n    = \\sqrt{\\frac{s_1^2}{{n_1}} + \\frac{s_2^2}{{n_2}}}\r\n\\tag{5.3}\r\n\\end{eqnarray}\\]Esta relação especial segue da teoria da probabilidade.Prática Orientada 5.14  Nós podemos reescrever Equação ((5.3)) de uma maneira diferente:\\[\\begin{eqnarray*}\r\nEP_{\\bar{x}_{1} - \\bar{x}_{2}}^2 = EP_{\\bar{x}_1}^2 + EP_{\\bar{x}_2}^2\r\n\\end{eqnarray*}\\]","code":""},{"path":"ch5-inf-num.html","id":"estimateSDGrouped","chapter":"5 Inferência para dados numéricos","heading":"5.4.6 Estimativa de desvio padrão agrupada (tópico especial)","text":"Ocasionalmente, duas populações terão desvios padrão tão semelhantes que podem ser tratados como idênticos. Por exemplo, dados históricos ou um mecanismo biológico bem compreendido podem justificar essa forte suposição. Nesses casos, podemos tornar abordagem distribuição-\\(t\\) um pouco mais precisa usando um desvio padrão agrupado.\r\nO desvio padrão agrupado de dois grupos é uma maneira de usar dados de ambas amostras para melhor estimar o desvio padrão e o erro padrão. Se \\(s_1^{}\\) e \\(s_2^{}\\) são os desvios padrão dos grupos 1 e 2 e há boas razões para acreditar que os desvios padrão da população são iguais, então podemos obter uma estimativa melhorada das variâncias grupo agrupando seus dados:\\[\\begin{align*}\r\ns_{agrupado}^2 = \\frac{s_1^2\\times (n_1-1) + s_2^2\\times (n_2-1)}{n_1 + n_2 - 2}\r\n\\end{align*}\\]onde \\(n_1\\) e \\(n_2\\) são os tamanhos das amostras, como antes. Para usar essa nova estatística, nós substituímos \\(s_{agrupado}^2\\) lugar de \\(s_1^2\\) e \\(s_2^2\\) na fórmula de erro padrão, e usamos uma fórmula atualizada para os graus de liberdade:\\[\\begin{align*}\r\nGL = n_1 + n_2 - 2\r\n\\end{align*}\\]Os benefícios de agrupar o desvio padrão são obtidos através da obtenção de uma estimativa melhor desvio padrão para cada grupo e usando um parâmetro maior de graus de liberdade para distribuição-\\(t\\). Ambas mudanças podem permitir um modelo mais preciso da distribuição amostral de \\(\\bar{x}_1 - \\bar{x}_2\\), se os desvios padrão dos dois grupos forem iguais.Desvios padrão agrupados somente após uma consideração cuidadosa: Um desvio padrão agrupado é apropriado apenas quando pesquisa indica que os desvios padrão da população são quase iguais. Quando o tamanho da amostra é grande e condição pode ser adequadamente verificada com os dados, os benefícios de agrupar os desvios padrão diminuem muito.","code":""},{"path":"ch5-inf-num.html","id":"powerCalculationsDifferenceMeans","chapter":"5 Inferência para dados numéricos","heading":"5.5 Cálculos de potência para uma diferença de médias (tópico especial)","text":"Muitas vezes, planejamento de experimentos, há duas considerações concorrentes:Queremos coletar dados suficientes para detectar efeitos importantes.Queremos coletar dados suficientes para detectar efeitos importantes.coleta de dados pode ser cara e, em experimentos envolvendo pessoas, pode haver algum risco para os pacientes.coleta de dados pode ser cara e, em experimentos envolvendo pessoas, pode haver algum risco para os pacientes.Nesta seção, nos concentramos contexto de um ensaio clínico, que é um experimento relacionado à saúde, qual o sujeito é uma pessoa, e determinaremos um tamanho de amostra apropriado, em que possamos ter \\(80\\%\\) de certeza de que detectaríamos qualquer problema importante.217","code":""},{"path":"ch5-inf-num.html","id":"passingTestProposal","chapter":"5 Inferência para dados numéricos","heading":"5.5.1 Passando pelas propostas de um teste","text":"Nós vamos passar pelos passos de um teste de hipótese. Isso nos ajudará enquadrar nossos cálculos para determinar um tamanho de amostra apropriado para o estudo.Geralmente, os ensaios clínicos usam uma hipótese alternativa bilateral, então abaixo estão hipóteses adequadas para este contexto:\\[\r\n\\begin{cases}\r\n  H_0: \\mbox{O novo medicamento funciona tão bem quanto o medicamento padrão} \\\\\r\n  H_1: \\mbox{O desempenho novo medicamento difere medicamento padrão.}\r\n\\end{cases}\r\n\\]Ou equivalentemente:\\[\r\n\\begin{cases}\r\n  H_0: \\mu_{trmt} - \\mu_{ctrl} = 0 \\\\\r\n  H_1: \\mu_{trmt} - \\mu_{ctrl} \\neq 0\r\n\\end{cases}\r\n\\]Alguns pesquisadores podem argumentar favor de um teste unilateral aqui, onde alternativa consideraria apenas se o novo medicamento funciona melhor que o medicamento padrão. entanto, seria muito informativo saber se o novo medicamento tem um desempenho pior que o medicamento padrão, por isso, usamos um teste bilateral para considerar essa possibilidade durante análise.O erro padrão é calculado da seguinte forma:\\[\\begin{align*}\r\nEP_{\\bar{x}_{trmt} - \\bar{x}_{ctrl}}\r\n  = \\sqrt{\\frac{s_{trmt}^2}{n_{trmt}} + \\frac{s_{ctrl}^2}{n_{ctrl}}}\r\n  = \\sqrt{\\frac{12^2}{100} + \\frac{12^2}{100}}\r\n  = 1.70\r\n\\end{align*}\\]Esta pode ser uma estimativa imperfeita \\(EP_{\\bar{x}_{trmt} - \\bar{x}_{ctrl}}\\), já que estimativa desvio padrão que usamos pode não ser correta para esse grupo de pacientes. entanto, é suficiente para nossos propósitos.Os graus de liberdade são maiores que 30, então distribuição de \\(\\bar{x}_{trmt} - \\bar{x}_{ctrl}\\) será aproximadamente normal. O desvio padrão dessa distribuição (o erro padrão) seria de cerca de 1,70 e, sob hipótese nula, sua média seria 0.Para \\(\\alpha = 0.05\\), nós rejeitaríamos \\(H_0\\) se diferença na parte inferior 2.5% ou superior 2.5%:Inferior 2.5%: Para o modelo normal, isso é 1.96 erros padrão abaixo de 0, portanto, qualquer diferença menor que \\(-1.96 \\times 1.70 = -3.332\\) mmHg.Superior 2.5%: Para o modelo normal, isso é 1.96 erros padrão acima de 0, portanto, qualquer diferença maior que \\(1.96 \\times 1.70 = 3.332\\) mmHg.Os limites dessas regiões de rejeição são mostrados abaixo:Em seguida, realizaremos alguns cálculos hipotéticos para determinar probabilidade de rejeitarmos hipótese nula, se hipóteses alternativas fossem realmente verdadeiras.","code":"\nset.seed(1)\nX <- seq(-10, 10, 0.01)\nY <- dnorm(X, sd = 1.70)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_hline(yintercept = 0, color = \"white\", size = 1) +\n  geom_path(color = '#E97C31', size = 1) +\n  labs(x  = NULL) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) +\n  scale_x_continuous(breaks = seq(-9, 9, 3)) + \n  geom_vline(xintercept = 0, linetype = 'dashed', color = '#E97C31') +\n  annotate(geom = \"text\", x = 0, y = 0.01, label = expression(bar(x)[trmt] - bar(x)[ctrl]), \n           size = 4) +\n  annotate(geom = \"text\", x = 4, y = 0.2, label = 'Hipótese \\nNula', size = 3, color = '#E97C31')+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_hline(yintercept = 0, color = \"white\", size = 1) +\n  geom_path(color = '#E97C31', size = 1) +\n  labs(x  = NULL) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) +\n  scale_x_continuous(breaks = seq(-9, 9, 3)) + \n  geom_vline(xintercept = 0, linetype = 'dashed', color = '#E97C31') +\n  annotate(geom = \"text\", x = 0, y = 0.01, \n           label = expression(bar(x)[trmt] - bar(x)[ctrl]), size = 4) +\n  annotate(geom = \"text\", x = 0, y = 0.1, label = 'Hipótese Nula \\nNão rejeita H0', \n           size = 3, color = '#E97C31') +\n  geom_vline(xintercept = 3.332, linetype = 'dashed', color = 'black') +\n  geom_vline(xintercept = -3.332, linetype = 'dashed', color = 'black') +\n  annotate(geom = \"text\", x = 5, y = 0.1, label = 'Rejeita H0', size = 3, color = 'black') +\n  annotate(geom = \"text\", x = -5, y = 0.1, label = 'Rejeita H0', size = 3, color = 'black')+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"calculatingEnergyTestTwoSamples","chapter":"5 Inferência para dados numéricos","heading":"5.5.2 Calculando a energia para um teste de 2 amostras","text":"Ao planejar um estudo, queremos saber probabilidade de detectarmos um efeito que nos interessa. Em outras palavras, se houver um efeito real, e esse efeito grande o suficiente para ter valor prático, qual é probabilidade de detectarmos esse efeito? Esta probabilidade é chamada de poder, e podemos calculá-lo para diferentes tamanhos de amostra ou para diferentes tamanhos efetivos.Primeiro determinamos o que é um resultado praticamente significativo. Suponha que os pesquisadores da empresa se preocupem em encontrar qualquer efeito sobre pressão arterial que seja de 3mmHg ou maior em relação à medicação padrão. Aqui, 3mmHg é o mínimo tamanho efetivo de interesse, e queremos saber qual probabilidade de detectarmos esse tamanho efetivo estudo.Antes mesmo de fazer qualquer cálculo, observe que se \\(\\bar{x}_{trmt} - \\bar{x}_{ctrl} = -3\\) mmHg, não haveria provas suficientes para rejeitar \\(H_0\\). Isso não é um bom sinal.Para calcular probabilidade de rejeitarmos \\(H_0\\), precisamos determinar algumas coisas:distribuição amostral para \\(\\bar{x}_{trmt} - \\bar{x}_{ctrl}\\) quando verdadeira diferença é -3mmHg. Isto é o mesmo que distribuição nula, exceto que é deslocado para esquerda por 3:regiões de rejeição, que estão fora das linhas pontilhadas acima.regiões de rejeição, que estão fora das linhas pontilhadas acima.fração da distribuição que cai na região de rejeição.fração da distribuição que cai na região de rejeição.Em suma, precisamos calcular probabilidade de que \\(x < -3.332\\) para uma distribuição normal com média -3 e desvio padrão 1.7. Para fazer isso, primeiro sombreamos área que queremos calcular:Então, calculamos o escore Z e encontramos área da cauda usando tabela de probabilidades normal ou o software estatístico:\\[\\begin{align*}\r\nZ = \\frac{-3.332 - (-3)}{1.7} = -0.20 \\qquad \\\\qquad 0.4207\r\n\\end{align*}\\]O poder para o teste é 42% quando \\(\\mu_{trmt} - \\mu_{ctrl} = -3\\) e cada grupo tem um tamanho de amostra de 100.Exemplo 5.17, ignoramos região de rejeição superior cálculo, que estava na direção oposta da verdade hipotética, ou seja, -3. O raciocínio? Não haveria nenhum valor em rejeitar hipótese nula e concluir que houve um aumento quando de fato houve uma diminuição.","code":"\nset.seed(1)\n\nggplot() + \n  geom_hline(yintercept = 0, color = \"white\", size = 1) +\n  geom_path(data = data.frame(X = seq(-10, 10, 0.01),Y = dnorm(X, sd = 1.70)),\n            mapping = aes(x = X, y = Y), color = '#E97C31', size = 1) +\n  geom_path(data = data.frame(X = seq(-10, 10, 0.01),Y = dnorm(X, mean = -3, sd = 1.70)),\n            mapping = aes(x = X, y = Y), color = '#EAB217', size = 1) +\n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) +\n  scale_x_continuous(breaks = seq(-9, 9, 3)) + \n  geom_vline(xintercept = -3, linetype = 'dashed', color = '#EAB217') +\n  geom_vline(xintercept = 0, linetype = 'dashed', color = '#E97C31') + \n  labs(x  = NULL) + \n  annotate(geom = \"text\", x = 0, y = 0.01, \n           label = expression(bar(x)[trmt] - bar(x)[ctrl]), size = 4) +\n  annotate(geom = \"text\", x = 2.3, y = 0.2, label = 'Hipótese \\nNula', size = 3, color = '#E97C31') +\n  annotate(geom = \"text\", x = -6, y = 0.2, label = c(\"Distribuição com \\n\",\n                            expression(mu[trmt] - mu[ctrl]*\" = -3\")), size = 3, color = '#EAB217') +\n  geom_vline(xintercept = 3.332, linetype = 'dashed', color = 'black') +\n  geom_vline(xintercept = -3.332, linetype = 'dashed', color = 'black')+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nset.seed(1)\n\ngg = data.frame(X = seq(-10, 10, 0.01),Y = dnorm(X, mean = -3, sd = 1.70))\n\nggplot() + \n  geom_linerange(data = gg[gg$X < -3.332,], aes(X, ymin = -0.003, ymax = Y), \n                 colour=\"palegoldenrod\") + \n  geom_path(data = data.frame(X = seq(-10, 10, 0.01),Y = dnorm(X, sd = 1.70)),\n            mapping = aes(x = X, y = Y), color = '#E97C31', size = 1) +\n  geom_path(data = gg,\n            mapping = aes(x = X, y = Y), color = '#EAB217', size = 1) +\n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) +\n  scale_x_continuous(breaks = seq(-9, 9, 3)) + \n  geom_hline(yintercept = -0.003, color = 'white', size = 1) +\n  geom_vline(xintercept = -3, linetype = 'dashed', color = '#EAB217') +\n  geom_vline(xintercept = 0, linetype = 'dashed', color = '#E97C31') + \n  labs(x  = NULL) + \n  annotate(geom = \"text\", x = 0, y = 0.01, \n           label = expression(bar(x)[trmt] - bar(x)[ctrl]), size = 4) +\n  annotate(geom = \"text\", x = 1.5, y = 0.05, label = 'Hipótese \\nNula', \n           size = 3, color = '#E97C31') +\n  annotate(geom = \"text\", x = -8.5, y = 0.05, label = c(\"Distribuição com \\n\",\n                            expression(mu[trmt] - mu[ctrl]*\" = -3\")), size = 3, color = '#EAB217') +\n  geom_vline(xintercept = 3.332, linetype = 'dashed', color = 'black') +\n  geom_vline(xintercept = -3.332, linetype = 'dashed', color = 'black') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"determiningAppropriateSampleSize","chapter":"5 Inferência para dados numéricos","heading":"5.5.3 Determinando um tamanho de amostra adequado","text":"último exemplo, descobrimos que, se temos um tamanho de amostra de 100 em cada grupo, só podemos detectar um tamanho efetivo de 3mmHg com uma probabilidade de cerca de 0,42. Suponha que os pesquisadores avançassem e usassem apenas 100 pacientes por grupo, e os dados não sustentaram hipótese alternativa, ou seja, os pesquisadores não rejeitaram \\(H_0\\). Esta é uma situação muito ruim por algumas razões:Na mente dos pesquisadores, todos estariam se perguntando, talvez haja uma diferença real e significativa, mas não conseguimos detectá-lo com uma amostra tão pequena.Na mente dos pesquisadores, todos estariam se perguntando, talvez haja uma diferença real e significativa, mas não conseguimos detectá-lo com uma amostra tão pequena.empresa provavelmente investiu centenas de milhões de dólares desenvolvimento novo medicamento, então agora eles ficam com uma grande incerteza sobre seu potencial, já que o experimento não teve uma grande chance de detectar efeitos que ainda poderiam ser importantes.empresa provavelmente investiu centenas de milhões de dólares desenvolvimento novo medicamento, então agora eles ficam com uma grande incerteza sobre seu potencial, já que o experimento não teve uma grande chance de detectar efeitos que ainda poderiam ser importantes.Os pacientes foram submetidos à droga, e não podemos dizer com muita certeza que droga não ajuda (ou prejudica) os pacientes.Os pacientes foram submetidos à droga, e não podemos dizer com muita certeza que droga não ajuda (ou prejudica) os pacientes.Outro ensaio clínico pode precisar ser executado para obter uma resposta mais conclusiva sobre se o medicamento possui algum valor prático, e realização de um segundo teste clínico pode levar anos e muitos milhões de dólares.Outro ensaio clínico pode precisar ser executado para obter uma resposta mais conclusiva sobre se o medicamento possui algum valor prático, e realização de um segundo teste clínico pode levar anos e muitos milhões de dólares.Queremos evitar essa situação, por isso precisamos determinar um tamanho de amostra apropriado para garantir que possamos ter certeza de que detectaremos quaisquer efeitos que sejam importantes. Como mencionado anteriormente, uma mudança de 3mmHg foi considerada diferença mínima que era importante. Como primeiro passo, poderíamos calcular potência para vários tamanhos de amostras diferentes. Por exemplo, vamos tentar 500 pacientes por grupo.Prática Orientada 5.15  Calcule o poder de detectar uma mudança de -3 mmHg ao usar um tamanho de amostra de 500 por grupo.219(). Determine o erro padrão (lembre-se que o desvio padrão dos pacientes deveria ser de cerca de 12mmHg).(). Determine o erro padrão (lembre-se que o desvio padrão dos pacientes deveria ser de cerca de 12mmHg).(b). Identifique regiões de distribuição e rejeição nula.(b). Identifique regiões de distribuição e rejeição nula.(c). Identifique distribuição alternativa quando \\(\\mu_{trmt} - \\mu_{ctrl} = -3\\).(c). Identifique distribuição alternativa quando \\(\\mu_{trmt} - \\mu_{ctrl} = -3\\).(d). Calcule probabilidade de rejeitarmos hipótese nula.\r\n(d). Calcule probabilidade de rejeitarmos hipótese nula.Os pesquisadores decidiram que 3 mmHg foi diferença mínima que era importante, e com um tamanho de amostra de 500, podemos estar muito certos (97,7% ou melhor) de que vamos detectar qualquer diferença. Passamos agora para outro extremo em que estamos expondo um número desnecessário de pacientes ao novo medicamento ensaio clínico. Isso não só é eticamente questionável, como também custaria muito mais dinheiro que o necessário para ter certeza de que detectaríamos quaisquer efeitos importantes.prática mais comum é identificar o tamanho da amostra em que potência está em torno de 80% e, às vezes, 90%. Outros valores podem ser razoáveis para um contexto específico, mas 80% e 90% são mais comumente direcionados como um bom equilíbrio entre alta potência e não expor muitos pacientes um novo tratamento (ou desperdiçar muito dinheiro). Poderíamos calcular o poder teste em vários outros tamanhos de amostra possíveis até encontrarmos um que esteja próximo de 80%, mas isso é ineficiente. Em vez disso, devemos resolver o problema de trás para frente.Começamos por identificar o escore Z que nos daria uma cauda inferior de 80 %: seria cerca de 0.84:Além disso, região de rejeição sempre se estende \\(1.96\\times EP\\) centro da distribuição nula para \\(\\alpha = 0.05\\). Isso nos permite calcular distância alvo entre o centro das distribuições nula e alternativa em termos erro padrão:\\[\\begin{align*}\r\n0.84 \\times EP + 1.96 \\times EP = 2.8 \\times EP\r\n\\end{align*}\\]Em nosso exemplo, também queremos que distância entre os centros de distribuição nula e alternativa seja igual ao tamanho efetivo mínimo de interesse, 3mmHg, que nos permite configurar uma equação entre essa diferença e o erro padrão:\\[\\begin{align*}\r\n3 &= 2.8 \\times EP \\\\\r\n3 &= 2.8 \\times \\sqrt{\\frac{12^2}{n} + \\frac{12^2}{n}} \\\\\r\n% 3^2 &= 2.8^2 \\times \\left( \\frac{12^2}{n} + \\frac{12^2}{n} \\right) \\\\\r\nn &= \\frac{2.8^2}{3^2} \\times \\left( 12^2 + 12^2 \\right) = 250.88 \\\\\r\n\\end{align*}\\]Devemos visar cerca de 251 pacientes por grupo.diferença de erro padrão de \\(2.8 \\times EP\\) é específico para um contexto em que potência alvo é de 80% e o nível de significância é \\(\\alpha = 0.05\\). Se potência desejada é de 90% ou se usarmos um nível de significância diferente, usaremos algo um pouco diferente \\(2.8 \\times EP\\).Figura 5.12 mostra o poder para tamanhos de amostra de 20 5.000 pacientes quando \\(\\alpha = 0.05\\) e verdadeira diferença é -3. Esta curva foi construída escrevendo um programa para calcular potência para muitos tamanhos de amostras diferentes.\r\nFigura 5.12: curva mostra potência para diferentes tamanhos de amostra contexto exemplo da pressão arterial quando diferença real é -3. Ter mais de cerca de 250 350 observações não fornece muito valor adicional na detecção de um efeito quando alfa = 0.05.\r\nCálculos de energia para experimentos caros ou arriscados são críticos. entanto, o que acontece com experimentos que são baratos e onde considerações éticas são mínimas? Por exemplo, se estamos realizando testes finais em um novo recurso em um site popular, como nossas considerações sobre tamanho de amostra mudariam? Como antes, queremos ter certeza de que amostra é grande o suficiente. entanto, se o recurso foi submetido alguns testes e sabe-se que funciona bem (ou seja, não frustra muitos usuários site), podemos executar um experimento muito maior que o necessário para detectar os efeitos mínimos de interesse. razão é que pode haver benefícios adicionais em ter uma estimativa ainda mais precisa efeito novo recurso. Podemos até realizar um grande experimento como parte lançamento novo recurso.","code":"\nset.seed(1)\n\ngg = data.frame(X = seq(-10, 10, 0.01),Y = dnorm(X, mean = -3, sd = 1.70))\nggplot() + \n  geom_linerange(data = gg[gg$X < -3+(0.84),], \n                 aes(X, ymin = -0.003, ymax = Y), colour=\"palegoldenrod\")  +\n  geom_hline(yintercept = -0.003, color = 'white', size = 1) +\n  geom_path(data = data.frame(X = seq(-10, 10, 0.01),Y = dnorm(X, sd = 1.70)),\n            mapping = aes(x = X, y = Y), color = '#E97C31', size = 1) +\n  geom_path(data = gg, mapping = aes(x = X, y = Y), color = '#EAB217', size = 1) +\n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) +\n  scale_x_continuous(breaks = seq(-9, 9, 3)) + \n  geom_vline(xintercept = -3, linetype = 'dashed', color = '#EAB217') +\n  geom_vline(xintercept = 0, linetype = 'dashed', color = '#E97C31') + \n  labs(x  = NULL) + \n  annotate(geom = \"text\", x = 1.5, y = 0.05, \n           label = 'Hipótese \\nNula', size = 3, color = '#E97C31') +\n  annotate(geom = \"text\", x = -8.5, y = 0.05, label = c(\"Distribuição com \\n\",\n                            expression(mu[trmt] - mu[ctrl]*\" = -3\")), size = 3, color = '#EAB217') +\n  geom_vline(xintercept = 3.332, linetype = 'dashed', color = 'black') +\n  geom_vline(xintercept = -3.332, linetype = 'dashed', color = 'black')+ \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\nn <- c(10:500, seq(510, 2000, 10), seq(2100, 10000, 100))\nse <- sapply(n, function(x) sqrt(2 * 12^2 / x))\nleft.reject <- -1.96 * se\nx <- (left.reject - (-3)) / se\np <- pt(x, 2 * n - 2)\n\nggplot(data = data.frame(n,p), aes(x = n, y = p)) +\n  scale_x_log10() +\n  geom_line(color = '#E6205F', size = 1) +\n  geom_hline(yintercept = c(0, 1), linetype = 2) + \n  labs(x = \"Tamanho de Amostra por grupo\", y = \"Poder\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"comparingAveragesANOVA","chapter":"5 Inferência para dados numéricos","heading":"5.6 Comparando muitas médias com ANOVA (tópico especial)","text":"Às vezes, queremos comparar médias em muitos grupos. Poderíamos inicialmente pensar em fazer comparações pareadas; por exemplo, se houvesse três grupos, poderíamos ser tentados comparar primeira média com segunda, depois com terceira e, finalmente, comparar segunda e terceira médias para um total de três comparações. entanto, essa estratégia pode ser traiçoeira. Se tivermos muitos grupos e fizermos muitas comparações, é provável que acabemos por encontrar uma diferença apenas por acaso, mesmo que não haja diferença nas populações.Nesta seção, vamos aprender um novo método chamado análise de variância (ANOVA) e uma nova estatística de teste chamada \\(F\\). ANOVA usa um teste de hipótese único para verificar se médias em muitos grupos são iguais:onde \\(\\mu_i\\) representa média resultado para observações na categoria .Geralmente, devemos verificar três condições nos dados antes de executar ANOVA:observações são independentes dentro e entre grupos,observações são independentes dentro e entre grupos,os dados dentro de cada grupo são quase normais, eos dados dentro de cada grupo são quase normais, ea variabilidade entre os grupos é aproximadamente igual.variabilidade entre os grupos é aproximadamente igual.Quando essas três condições forem satisfeitas, podemos executar uma ANOVA para determinar se os dados fornecem evidências fortes contra hipótese nula de que \\(\\mu_i\\) são iguais.hipóteses podem ser escritas da seguinte forma:\\(H_0\\): pontuação média é idêntica em todas classes. Qualquer diferença observada é devida ao acaso. Notoriamente, nós escrevemos \\(\\mu_A=\\mu_B=\\mu_C\\).\\(H_0\\): pontuação média é idêntica em todas classes. Qualquer diferença observada é devida ao acaso. Notoriamente, nós escrevemos \\(\\mu_A=\\mu_B=\\mu_C\\).\\(H_1\\): pontuação média varia de acordo com classe. Iríamos rejeitar hipótese nula em favor da hipótese alternativa se houvesse maiores diferenças entre médias de classe que o que poderíamos esperar acaso sozinho.\\(H_1\\): pontuação média varia de acordo com classe. Iríamos rejeitar hipótese nula em favor da hipótese alternativa se houvesse maiores diferenças entre médias de classe que o que poderíamos esperar acaso sozinho.Fortes evidências favorecendo hipótese alternativa na ANOVA são descritas por diferenças incomumente grandes entre médias grupo. Em breve aprenderemos que avaliar variabilidade das médias grupo em relação à variabilidade entre observações individuais dentro de cada grupo é fundamental para o sucesso da ANOVA.Qualquer diferença real nas médias dos grupos , II e III é difícil de discernir, porque os dados dentro de cada grupo são muito voláteis em relação quaisquer diferenças resultado médio. Por outro lado, parece haver diferenças nos centros dos grupos IV, V e VI. Por exemplo, o grupo V parece ter uma média maior que dos outros dois grupos. Investigando os grupos IV, V e VI, vemos que diferenças nos centros dos grupos são perceptíveis, porque essas diferenças são grandes em relação à variabilidade nas observações individuais dentro de cada grupo.\r\nFigura 5.13: Gráfico de pontos lado lado para os resultados de seis grupos.\r\n","code":"\ngps <- c(\"I\", \"II\", \"III\")\ng <- as.factor(rep(gps, c(20, 10, 40)))\ng2 <- as.factor(rep(c(\"IV\", \"V\", \"VI\"), c(20, 10, 40)))\nM <- c(1, 2, 1.5)\nnames(M) <- gps\n\nset.seed(7)\nX1 <- rnorm(length(g), M[g], 1.5)\nX2 <- rnorm(length(g), M[g], 0.5)\n\nggplot() + \n  geom_point(aes(x = g, y = X1), alpha = 0.5, color = '#E6205F') + \n  geom_point(aes(x = g2, y = X2), alpha = 0.5, color = '#EAB217') + \n  labs(x = NULL, y = 'Outcome') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"hittingPerformancePositionMLB","chapter":"5 Inferência para dados numéricos","heading":"5.6.1 O desempenho de rebatidas está relacionado à posição do jogador na MLB?","text":"Gostaríamos de discernir se há diferenças reais entre o desempenho de rebatedores de jogadores de beisebol de acordo com sua posição: outfielder (), infielder (), designated hitter (DH), e apanhador (). Vamos usar um conjunto de dados chamado bat10, que inclui registros de rebatidas de 327 jogadores da Major League Baseball (MLB) da temporada de 2010. Seis dos 327 casos representados em bat10 são mostrados na Tabela 5.8, e descrições para cada variável são fornecidas em Tabela 5.9. medida que usaremos para o desempenho de rebatimento jogador (variável de resultado) é porcentagem básica OBP. porcentagem na base representa aproximadamente fração tempo que um jogador obtém com sucesso na base ou atinge um home run.Tabela 5.8: Seis casos da matriz de dados bat10.Tabela 5.9: Variáveis e suas descrições para o conjunto de dados bat10.Tabela 5.10 fornece estatísticas resumidas para cada grupo. Um gráfico de caixa lado--lado para porcentagem na base é mostrado na Figura 5.14. Observe que variabilidade parece ser aproximadamente constante entre os grupos; variação quase constante entre os grupos é uma suposição importante que deve ser satisfeita antes de considerarmos abordagem ANOVA.Tabela 5.10: Estatísticas resumidas da porcentagem na base, dividida pela posição jogador\r\nFigura 5.14: Gráfico de boxplot da porcentagem na base para 327 jogadores em quatro grupos. Há um outlier proeminente visível grupo infield, mas com 154 observações grupo infield, esse outlier não é uma preocupação.\r\n\\[\r\n\\begin{cases}\r\nH_0: & \\mu_{} = \\mu_{} = \\mu_{DH} = \\mu_{C} \\\\ \r\nH_1: & \\mbox{porcentagem média na base } (\\mu_i) \\mbox{ varia entre alguns (ou todos) grupos.}\r\n\\end{cases}\r\n\\]Por que seria inadequado executar o teste simplesmente estimando se diferença de \\(\\mu_{DH}\\) e \\(\\mu_{C}\\) é estatisticamente significativa um nível de significância de 0,05?principal questão aqui é que estamos inspecionando os dados antes de escolher os grupos que serão comparados. Não é apropriado examinar todos os dados olho nu (testes informais) e só depois decidir quais partes testar formalmente. Isso é chamado bisbilhotando dados ou pescando dados. Naturalmente, escolheríamos os grupos com grandes diferenças para o teste formal, levando uma inflação na taxa de erro tipo~1. Para entender isso melhor, vamos considerar um problema ligeiramente diferente.Suponha que estamos medir aptidão para os alunos em 20 turmas de uma escola primária início ano. Nesta escola, todos os alunos são aleatoriamente designados para salas de aula, portanto, quaisquer diferenças que observamos entre classes início ano são completamente devidas ao acaso. entanto, com tantos grupos, provavelmente observaremos alguns grupos que parecem bastante diferentes um outro. Se selecionarmos apenas essas classes que parecem tão diferentes, provavelmente faremos conclusão errada de que tarefa não foi aleatória. Embora possamos apenas testar formalmente diferenças para alguns pares de classes, avaliamos informalmente outras classes de olho antes de escolher os casos mais extremos para uma comparação.Para informações adicionais sobre idéias expressas Exemplo 5.22, eecomendamos ler sobre falácia promotor.Na próxima seção, aprenderemos como usar estatística \\(F\\) e ANOVA para testar se diferenças observadas nas médias da amostra poderiam ter acontecido apenas por acaso, mesmo que não houvesse diferença nas respectivas médias populacionais.","code":"\ndata(mlbBat10)\n\nknitr::kable(head(mlbBat10), align = \"c\", \n             caption = \"Seis casos da matriz de dados bat10.\")\nres <- matrix(NA, ncol = 2, nrow = 9)\nres[,1] <- c('nome', 'time', 'posição', 'AB', 'H', 'HR', 'RBI', 'AVG', 'OBP')\nres[,2] <- c('Nome do jogador', \n             'O nome abreviado da equipe do jogador',\n             'A posição do campo principal do jogador (OF, IF, DH, A)',\n             'Número de oportunidades no taco',\n             'Número de batidas',\n             'Número de home runs',\n             'Número de corridas em batidas',\n             'Média de rebatidas, que é igual a H/AB',\n             'Porcentagem na base, que é aproximadamente igual à fração de vezes que um jogador fica na base ou atinge um home run')\n\ncolnames(res) <- c('variável','descrição')\n\nknitr::kable(res, align = \"c\", \n             caption = \"Variáveis e suas descrições para o conjunto de dados bat10.\")\ndesc <- matrix(NA, ncol = 5, nrow = 3)\ndesc[1,] <- c('Tamanho da amostra', 120, 154, 14, 39)\ndesc[2,] <- c('Média da amostra', 0.334, 0.332, 0.348, 0.323)\ndesc[3,] <- c('DP amostral', 0.029, 0.037, 0.036, 0.045)\n\ncolnames(desc) <- c('','OF', 'IF', 'DH', 'A')\n\nknitr::kable(desc, align = \"c\", \n             caption = \"Estatísticas resumidas da porcentagem na base, dividida pela posição do jogador\")\nlibrary(openintro)\ndata(COL)\ndata(mlbBat10)\nd   <- mlbBat10[mlbBat10$AB > 200,]\npos <- list(c(\"OF\"), c(\"1B\", \"2B\", \"3B\", \"SS\"), \"DH\", \"C\")\nPOS <- c(\"OF\", \"IF\", \"DH\", \"C\")\n\nout <- c()\ngp  <- c()\nfor (i in 1:length(pos)) {\n  these <- which(d$pos %in% pos[[i]])\n  out   <- c(out, d[these,\"OBP\"])\n  gp    <- c(gp, rep(POS[i], length(these)))\n}\nDF  <- data.frame(d, gp = gp)\n\n\nggplot() + \n  geom_boxplot(aes(x = gp, y = out, fill = gp)) +\n  theme(legend.position = \"none\") + \n  labs(x = 'Posição', y = 'Porcentagem na base') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  scale_y_continuous(labels = scales::percent_format())"},{"path":"ch5-inf-num.html","id":"ANOVAFTest","chapter":"5 Inferência para dados numéricos","heading":"5.6.2 Análise de variância (ANOVA) e o teste F","text":"O método de análise de variância neste contexto se concentra em responder uma questão: variabilidade na amostra é tão grande que parece improvável que seja apenas por acaso? Esta questão é diferente dos procedimentos de teste anteriores, uma vez que, simultaneamente, considera muitos grupos e avalia se suas médias amostrais diferem mais que esperávamos da variação natural. Nós chamamos isso de variabilidade média quadrada entre os grupos (\\(MSG\\)), e tem graus de liberdade associados, \\(GL_{G}=k-1\\) quando há \\(k\\) grupos. \\(MSG\\) pode ser pensado como uma fórmula de variância escalonada para médias. Se hipótese nula verdadeira, qualquer variação na amostra significa devido ao acaso e não deve ser muito grande. Detalhes dos cálculos de \\(MSG\\) são fornecidos na nota de rodapé,223 entanto, normalmente usamos software para esses cálculos.MSG é, por si só, completamente inútil em um teste de hipótese. Precisamos de um valor de referência para quantidade de variabilidade esperada entre médias da amostra, se hipótese nula verdadeira. Para este fim, calculamos uma estimativa de variância agrupada, frequentemente abreviada como erro quadrático médio (\\(MEP\\)), que tem um grau de liberdade associado \\(GL_E=n-k\\). É útil pensar em \\(MEP\\) como uma medida da variabilidade dentro dos grupos. Detalhes dos cálculos \\(MEP\\) são fornecidos na nota de rodapé224 para leitores interessados.Quando hipótese nula é verdadeira, quaisquer diferenças entre médias amostrais são devidas apenas ao acaso, e \\(MSG\\) e \\(MEP\\) devem ser aproximadamente iguais. Como estatística de teste para ANOVA, examinamos fração de \\(MSG\\) e \\(MEP\\):\\[\\begin{align} \r\nF = \\frac{MSG}{MEP}\r\n\\tag{5.4}\r\n\\end{align}\\]\\(MSG\\) representa uma medida da variabilidade entre grupos, e \\(MEP\\) mede variabilidade dentro de cada um dos grupos.Podemos usar estatística \\(F\\) para avaliar hipóteses que é chamado de Teste F. Um p-valor pode ser calculado partir da estatística \\(F\\) usando uma distribuição \\(F\\), que possui dois parâmetros associados: \\(GL_{1}\\) e \\(GL_{2}\\). Para estatística \\(F\\) em ANOVA, \\(GL_{1} = GL_{G}\\) e \\(GL_{2}= GL_{E}\\). Uma distribuição \\(F\\) com 3 e 323 graus de liberdade, correspondente à estatística \\(F\\) para o teste de hipótese de beisebol, é mostrada na Figura 5.15.\r\nFigura 5.15: Uma distribuição F com GL1 = 3 e GL2 = 323.\r\nQuanto maior variabilidade observada nas médias amostrais (\\(MSG\\)) em relação às observações dentro grupo (\\(MEP\\)), maior será \\(F\\) e mais forte será evidência contra hipótese nula. Como valores maiores de \\(F\\) representam evidências mais fortes contra hipótese nula, usamos cauda superior da distribuição para calcular um p-valor. estatística \\(F\\) e o teste \\(F\\): análise de variância (ANOVA) é usada para testar se o resultado médio difere em 2 ou mais grupos. ANOVA usa uma estatística de teste \\(F\\), que representa uma relação padronizada de variabilidade nas médias da amostra em relação à variabilidade dentro dos grupos. Se \\(H_0\\) verdadeiro e suposições modelo forem satisfeitas, estatística \\(F\\) segue uma distribuição \\(F\\) com parâmetros \\(GL_{1}=k-1\\) e \\(GL_{2}=n-k\\). cauda superior da distribuição \\(F\\) é usada para representar o p-valor.O p-valor é maior que 0.05, indicando que evidência não é forte o suficiente para rejeitar hipótese nula em um nível de significância de 0.05. Ou seja, os dados não fornecem evidências fortes de que porcentagem média na base varia de acordo com posição primária jogador.","code":"\nggplot(data = data.frame(x = c(0, 6)), aes(x)) +\n  geom_hline(yintercept = -0.008, size = 1, color = \"white\") + \n  stat_function(fun = df, n = 1001, args = list(df1 = 3, df2 = 323), size = 1)  +\n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  scale_x_continuous(breaks = seq(0, 6, 1)) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))"},{"path":"ch5-inf-num.html","id":"readingANOVATable","chapter":"5 Inferência para dados numéricos","heading":"5.6.3 Lendo uma tabela ANOVA do software","text":"Os cálculos necessários para executar uma ANOVA à mão são tediosos e propensos erros humanos. Por essas razões, é comum usar um software estatístico para calcular estatística e o p-valor \\(F\\).Uma ANOVA pode ser resumida em uma tabela muito semelhante à de um resumo de regressão, que veremos mais adiante. Tabela 5.11 mostra um resumo da ANOVA para testar se média da porcentagem na base varia de acordo com posições dos jogadores na MLB. Muitos desses valores devem parecer familiares; em particular, estatística de teste \\(F\\) e o p-valor podem ser recuperados das últimas colunas.Tabela 5.11: Resumo da ANOVA para testar se porcentagem média na base difere entre posições dos jogadores.","code":"\nmod <- lm(out ~ as.factor(gp))\n\nknitr::kable(round(anova(mod), 4), align = \"c\", \n             caption = 'Resumo da ANOVA para testar se a porcentagem média na base difere entre as posições dos jogadores.')"},{"path":"ch5-inf-num.html","id":"graphicalDiagnosisANOVAAnalysis","chapter":"5 Inferência para dados numéricos","heading":"5.6.4 Diagnóstico gráfico para uma análise ANOVA","text":"Existem três condições que devemos verificar para uma análise de ANOVA: todas observações devem ser independentes, os dados em cada grupo devem ser quase normais e variação dentro de cada grupo deve ser aproximadamente igual.Independência: Se os dados são uma amostra aleatória simples de menos de 10% da população, esta condição é satisfeita. Para processos e experimentos, considere cuidadosamente se os dados podem ser independentes (por exemplo, sem pareamento). Por exemplo, nos dados da MLB, os dados não foram amostrados. entanto, não existem razões óbvias pelas quais independência não seria válida para maioria ou para todas observações.Independência: Se os dados são uma amostra aleatória simples de menos de 10% da população, esta condição é satisfeita. Para processos e experimentos, considere cuidadosamente se os dados podem ser independentes (por exemplo, sem pareamento). Por exemplo, nos dados da MLB, os dados não foram amostrados. entanto, não existem razões óbvias pelas quais independência não seria válida para maioria ou para todas observações.Aproximadamente normal: Como teste de uma e duas amostras para médias, suposição de normalidade é especialmente importante quando o tamanho da amostra é muito pequeno. Os gráficos de probabilidade normal para cada grupo dos dados da MLB são mostrados na Figura 5.16; há algum desvio da normalidade para os que estão em campo, mas isso não é uma preocupação substancial, pois há cerca de 150 observações nesse grupo e os outliers não são extremos. Às vezes, na ANOVA, há tantos grupos ou tão poucas observações por grupo que verificar normalidade para cada grupo não é razoável. Veja nota de rodapé226 para obter orientação sobre como lidar com tais instâncias.Aproximadamente normal: Como teste de uma e duas amostras para médias, suposição de normalidade é especialmente importante quando o tamanho da amostra é muito pequeno. Os gráficos de probabilidade normal para cada grupo dos dados da MLB são mostrados na Figura 5.16; há algum desvio da normalidade para os que estão em campo, mas isso não é uma preocupação substancial, pois há cerca de 150 observações nesse grupo e os outliers não são extremos. Às vezes, na ANOVA, há tantos grupos ou tão poucas observações por grupo que verificar normalidade para cada grupo não é razoável. Veja nota de rodapé226 para obter orientação sobre como lidar com tais instâncias.\r\nFigura 5.16: Gráfico de probabilidade normal OBP para cada posição de campo.\r\nVariação constante: última suposição é que variação nos grupos é aproximadamente igual de um grupo para o próximo. Esta suposição pode ser verificada examinando uma caixa lado lado dos resultados entre os grupos, como na Figura 5.14. Nesse caso, variabilidade é semelhante nos quatro grupos, mas não é idêntica. Nós vemos na Tabela 5.10 que o desvio padrão varia um pouco de um grupo para o outro. Se essas diferenças são de variação natural não é claro, então devemos relatar essa incerteza com os resultados finais.Diagnóstico para uma análise ANOVA: Independência é sempre importante para uma análise ANOVA. condição de normalidade é muito importante quando os tamanhos de amostra para cada grupo são relativamente pequenos. condição de variância constante é especialmente importante quando os tamanhos das amostras diferem entre os grupos.","code":"\nrequire(qqplotr)\n\nggplot(data = data.frame(out, gp), aes(sample = out)) + \n  stat_qq(color = '#E6205F') +\n  labs(x = \"Quantis Teóricos\",y = \"\") + facet_wrap(~gp) + \n  theme(legend.position = \"none\") +\n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1))"},{"path":"ch5-inf-num.html","id":"multipleComparisonsTypeIError","chapter":"5 Inferência para dados numéricos","heading":"5.6.5 Múltiplas comparações e controle da Taxa de erro Tipo I","text":"Quando rejeitamos hipótese nula em uma análise ANOVA, poderíamos nos perguntar: quais desses grupos têm diferentes meios? Para responder essa pergunta, comparamos médias de cada par de grupos possível. Por exemplo, se existem três grupos e há fortes evidências de que existem algumas diferenças nas médias grupo, há três comparações fazer: grupo 1 para grupo 2, grupo 1 para grupo 3 e grupo 2 para grupo 3. comparações podem ser realizadas usando um teste-\\(t\\) de duas amostras, mas usamos um nível de significância modificado e uma estimativa agrupada desvio padrão entre os grupos. Normalmente, este desvio padrão agrupado pode ser encontrado na tabela ANOVA, e ao longo fundo da Tabela 5.11.Neste caso (como muitos outros), é difícil verificar independência de forma rigorosa. Em vez disso, o melhor que podemos fazer é usar o bom senso para considerar razões pelas quais suposição de independência pode não ser válida. Por exemplo, suposição de independência pode não ser razoável se houver um assistente de ensino que somente metade dos alunos possa acessar; tal cenário dividiria uma classe em dois subgrupos. Nenhuma dessas situações foi evidente para esses dados específicos e acreditamos que independência é aceitável.distribuições gráfico de caixa lado lado parecem ser mais ou menos simétricas e não mostram outliers perceptíveis. Os gráficos de caixa mostram uma variabilidade aproximadamente igual, que pode ser verificada na Tabela 5.12, apoiando suposição de variância constante.Tabela 5.12: Estatísticas resumidas para primeiras pontuações intermediárias em três classes diferentes mesmo curso.\r\nFigura 5.17: Gráfico de boxplot para primeiras pontuações intermediárias em três classes diferentes mesmo curso.\r\nTabela 5.13: Tabela resumo ANOVA para os dados de exames parciais.Há fortes evidências de que diferentes médias em cada uma das três classes não se devem simplesmente ao acaso. Podemos nos perguntar, quais das classes são realmente diferentes? Como discutido nos capítulos anteriores, um teste-\\(t\\) de duas amostras poderia ser usado para testar diferenças em cada par de grupos possível. entanto, uma armadilha foi discutida Exemplo 5.22: quando executamos tantos testes, taxa de erro tipo~1 aumenta. Esse problema é resolvido usando um nível de significância modificado.Comparações múltiplas e correção de Bonferroni para \\(\\alpha\\): O cenário de testar muitos pares de grupos é chamado comparações múltiplas. Correção de Bonferroni sugere que um nível de significância mais rigoroso é mais apropriado para esses testes:\\[\\begin{align*}\r\n\\alpha^* = \\alpha / K\r\n\\end{align*}\\]onde \\(K\\) é o número de comparações consideradas (formal ou informalmente). Se existem \\(k\\) grupos, então todos os pares possíveis são comparados e \\(K=\\frac{k(k-1)}{2}\\).Nós usamos um nível de significância modificado de \\(\\alpha^* = 0.05/3 = 0.0167\\). Além disso, usamos estimativa combinada desvio padrão: \\(s_{agrupados}=13.61\\) com \\(GL=161\\), que é fornecido na tabela de resumo ANOVA.Aula versus Aula B: diferença estimada e o erro padrão são, respectivamente,\\[\\begin{align*}\r\n\\bar{x}_A - \\bar{x}_{B} &= 75.1 - 72 = 3.1\r\n    &EP = \\sqrt{\\frac{13.61^2}{58} + \\frac{13.61^2}{55}} &= 2.56\r\n\\end{align*}\\]Isso resulta em um \\(T\\)-escore de 1.21 com \\(GL = 161\\) (usamos o \\(GL\\) associado \\(s_{agrupado}\\)). O software estatístico foi utilizado para identificar precisamente o p-valor bilateral, uma vez que significância modificada de 0,0167 não é encontrada na tabela-\\(t\\). O p-valor (0,228) é maior que \\(\\alpha^*=0.0167\\), então não há forte evidência de diferença nas médias das classes e B.\r\nAula versus Aula C: diferença estimada e o erro padrão são 3,8 e 2,61, respectivamente. Isso resulta em uma pontuação de \\(T\\) de 1,46 com \\(GL=161\\) e um p-valor bilateral de 0,1462. Este p-valor é maior que \\(\\alpha^*\\), então não há evidência forte de uma diferença nas médias das classes e C.Aula B versus Aula C: diferença estimada e erro padrão são 6,9 e 2,65, respectivamente. Isso resultando em uma pontuação de \\(T\\) de 2,60 com \\(GL= 161\\) e um p-valor bilateral de 0,0102. Este p-valor é menor que \\(\\alpha^*\\). Aqui encontramos fortes evidências de uma diferença nas médias das classes B e C.Podemos resumir descobertas da análise de Exemplo 5.25 usando seguinte notação:\\[\\begin{align*}\r\n\\mu_A &\\stackrel{?}{=} \\mu_B\r\n    &\\mu_A &\\stackrel{?}{=} \\mu_C\r\n    &\\mu_B &\\neq \\mu_C\r\n\\end{align*}\\]média exame parcial na aula não é estatisticamente distinta daquelas das aulas B ou C. entanto, há fortes evidências de que aulas B e C são diferentes. Nas duas primeiras comparações entre pares, não tivemos evidência suficiente para rejeitar hipótese nula. Lembre-se de que não rejeitar \\(H_0\\) não implica \\(H_0\\) ser verdade.Às vezes, uma ANOVA rejeitará nula, mas nenhum grupo terá diferenças estatisticamente significativas: É possível rejeitar hipótese nula usando ANOVA e depois não identificar diferenças nas comparações pareadas. Contudo, isso não invalida conclusão da ANOVA. Significa apenas que não conseguimos identificar com sucesso quais grupos diferem em suas médias.O procedimento ANOVA examina o quadro geral: considera todos os grupos simultaneamente para decifrar se há evidência de que existe alguma diferença. Mesmo que o teste indique que há fortes evidências de diferenças nas médias dos grupos, identificar com alta confiança uma diferença específica como estatisticamente significativa é mais difícil.Considere seguinte analogia: observamos uma empresa de Wall Street que faz grandes quantias de dinheiro com base na previsão de fusões. Fusões são geralmente difíceis de prever, e se taxa de sucesso da previsão é extremamente alta, isso pode ser considerado evidência suficientemente forte para justificar investigação pela Comissão de Valores Mobiliários e Câmbio (CVM). Embora CVM possa ter certeza de que há negociações com base em informações privilegiadas ocorrendo na empresa, evidências contra um único operador podem não ser muito fortes. É somente quando CVM considera todos os dados que identificam o padrão. Esta é efetivamente estratégia da ANOVA: recuar e considerar todos os grupos simultaneamente.","code":"\nclass <- matrix(NA, ncol = 4, nrow = 3)\nclass[1,] <- c('Tamanho da amostra', 58, 55, 51)\nclass[2,] <- c('Média da amostra', 75.1, 72.0, 78.9)\nclass[3,] <- c('DP amostral', 13.9, 13.8, 13.1)\n\ncolnames(class) <- c('Classe', 'A', 'B', 'C')\n\nknitr::kable(class, align = \"c\", \n             caption = \"Estatísticas resumidas para as primeiras pontuações intermediárias em três classes diferentes do mesmo curso.\")\ndata(classData)\n\nggplot(data = classData) + \n  geom_boxplot(aes(x = lecture, y = m1, fill = lecture)) +\n  theme(legend.position = \"none\") + \n  labs(x = 'Classes', y = 'Pontuações') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  scale_fill_manual(values = c('#E6205F', '#E97C31', \"#EAB217\"))\naj <- anova(lm(m1 ~ lecture, classData))\n\nknitr::kable(aj, align = \"c\", caption = 'Tabela resumo ANOVA para os dados de exames parciais.')"},{"path":"ch6-inf-cat.html","id":"ch6-inf-cat","chapter":"6 Inferência para dados categóricos","heading":"6 Inferência para dados categóricos","text":"Este capítulo introduz inferência na configuração de dados categóricos. Usamos esses métodos para responder perguntas como seguintes:Que proporção público americano aprova o trabalho que Suprema Corte está fazendo?Que proporção público americano aprova o trabalho que Suprema Corte está fazendo?O Pew Research Center conduziu uma pesquisa sobre o apoio à lei de saúde de 2010 e eles usaram duas formas da pergunta da pesquisa. Cada entrevistado recebeu aleatoriamente uma das duas perguntas. Qual é diferença suporte para os respondentes sob duas questões?O Pew Research Center conduziu uma pesquisa sobre o apoio à lei de saúde de 2010 e eles usaram duas formas da pergunta da pesquisa. Cada entrevistado recebeu aleatoriamente uma das duas perguntas. Qual é diferença suporte para os respondentes sob duas questões?Os métodos que aprendemos nos capítulos anteriores continuarão sendo úteis nessas configurações. Por exemplo, proporções da amostra são bem caracterizadas por uma distribuição quase normal quando certas condições são satisfeitas, tornando possível empregar o intervalo de confiança usual e ferramentas de teste de hipóteses. Em outros casos, como aqueles com tabelas de contingência ou quando condições de tamanho da amostra não são atendidas, usaremos uma distribuição diferente, embora ideias centrais permaneçam mesmas.","code":""},{"path":"ch6-inf-cat.html","id":"inferenceSingleProportion","chapter":"6 Inferência para dados categóricos","heading":"6.1 Inferência para uma única proporção","text":"Na cidade de Nova York, em 23 de outubro de 2014, um médico que recentemente tratava de pacientes com ebola na Guiné foi ao hospital com uma leve febre e foi posteriormente diagnosticado com Ebola. Logo depois, uma jornalista da NBC de Nova York/Wall Street Journal descobriu que 82% dos nova-iorquinos defendiam uma “quarentena obrigatória de 21 dias para qualquer pessoa que tenha entrado em contato com um paciente com ebola.” Esta pesquisa incluiu respostas de 1.042 adultos de Nova York entre 26 e 28 de outubro de 2014.","code":""},{"path":"ch6-inf-cat.html","id":"identifySampleProportionAlmostNormal","chapter":"6 Inferência para dados categóricos","heading":"6.1.1 Identificar quando a proporção da amostra é quase normal","text":"Uma proporção da amostra pode ser descrita como uma média da amostra. Se representarmos cada “sucesso” como 1 e cada “falha” como 0, proporção da amostra é média desses resultados numéricos:\\[\\begin{eqnarray*}\r\n\\hat{p} = \\frac{\\ 0 + 1 + 1 + \\cdots + 0\\ }{1042} = 0.82\r\n\\end{eqnarray*}\\]distribuição de \\(\\hat{p}\\) é quase normal quando distribuição de 0s e 1s não é muito distorcida para o tamanho da amostra. diretriz mais comum para tamanho de amostra e inclinação quando trabalhando com proporções é garantir que esperamos observar um número mínimo de sucessos (1s) e falhas (0s), tipicamente pelo menos 10 de cada. Os rótulos sucesso e falha não precisam significar algo positivo ou negativo. Esses termos são apenas palavras convenientes que são frequentemente usadas quando se discute proporções.Condições para distribuição amostral de \\(\\hat{p}\\) sendo quase normal: distribuição amostral para \\(\\hat{p}\\), tirada de uma amostra de tamanho \\(n\\) de uma população com uma proporção real \\(p\\), é quase normal quando:observações da amostra são independentes eas observações da amostra são independentes eesperávamos ver pelo menos 10 sucessos e 10 falhas em nossa amostra, ou seja,\\(np\\geq10\\) e \\(n(1-p)\\geq10\\). Isso é chamado de condição de falha ou sucesso.esperávamos ver pelo menos 10 sucessos e 10 falhas em nossa amostra, ou seja,\\(np\\geq10\\) e \\(n(1-p)\\geq10\\). Isso é chamado de condição de falha ou sucesso.Se essas condições forem atendidas, distribuição amostral de \\(\\hat{p}\\) é quase normal com média de \\(p\\) e erro padrão\\[\\begin{eqnarray}\r\nEP_{\\hat{p}} = \\sqrt{\\frac{\\ p(1-p)\\ }{n}}\r\n\\tag{6.1}\r\n\\end{eqnarray}\\]Normalmente não sabemos verdadeira proporção, \\(p\\), por isso, substituímos algum p-valorara verificar condições e estimar o erro padrão. Para intervalos de confiança, geralmente proporção da amostra \\(\\hat{p}\\) é usado para verificar condição de falha-sucesso e calcular o erro padrão. Para testes de hipóteses, normalmente o valor nulo - isto é, proporção reivindicada na hipótese nula – é usado lugar de \\(p\\). Exemplos são apresentados para cada um desses casos nas próximas seções.Lembrete sobre verificação da independência das observações: Se os dados provêm de uma amostra aleatória simples e consistem em menos de 10% da população, então hipótese de independência é razoável. Alternativamente, se os dados vierem de um processo aleatório, devemos avaliar condição de independência com mais cuidado.","code":""},{"path":"ch6-inf-cat.html","id":"confidenceIntervalsOneProportion","chapter":"6 Inferência para dados categóricos","heading":"6.1.2 Intervalos de confiança para uma proporção","text":"Podemos querer um intervalo de confiança para proporção de adultos de Nova York que favorecem quarentena obrigatória de qualquer pessoa que tenha tido contato com um paciente com Ebola. Nossa estimativa pontual, baseada em uma amostra de tamanho \\(n = 1042\\), é \\(\\hat{p} = 0.82\\). Gostaríamos de usar fórmula geral de intervalo de confiança aprendido anteriormente. entanto, primeiro devemos verificar que distribuição amostral de \\(\\hat{p}\\) é quase normal e calcular o erro padrão de \\(\\hat{p}\\).observações são independentes: pesquisa é baseada em uma amostra aleatória simples e consiste em menos de 10% da população adulta de Nova York, que verifica independência.observações são independentes: pesquisa é baseada em uma amostra aleatória simples e consiste em menos de 10% da população adulta de Nova York, que verifica independência.Condição de falha ou sucesso: O tamanho da amostra também deve ser suficientemente grande, o que é verificado usando condição de falha ou sucesso. Havia \\(1042 \\times \\hat{p} \\approx 854\\) “sucessos” e \\(1042 \\times (1 - \\hat{p}) \\approx 188\\) ``falhas’’ na amostra, ambos facilmente maiores que 10.Condição de falha ou sucesso: O tamanho da amostra também deve ser suficientemente grande, o que é verificado usando condição de falha ou sucesso. Havia \\(1042 \\times \\hat{p} \\approx 854\\) “sucessos” e \\(1042 \\times (1 - \\hat{p}) \\approx 188\\) ``falhas’’ na amostra, ambos facilmente maiores que 10.Com condições atendidas, temos certeza de que distribuição amostral \\(\\hat{p}\\) é quase normal. Em seguida, um erro padrão para \\(\\hat{p}\\) é necessário, e então podemos empregar o método usual para construir um intervalo de confiança.Usando o erro padrão \\(EP = 0,012\\) da Prática Orientada 6.1, estimativa pontual de 0.82 e \\(z^{\\star} = 1.96\\) para um intervalo de confiança de 95%, o intervalo de confiança é\\[\\begin{eqnarray*}\r\n\\text{estimativa pontual} \\ \\pm\\ z^{\\star}EP \\quad\\\\quad 0.82 \\ \\pm\\ 1.96\\times 0.012 \\quad\\\\quad (0.796, 0.844)\r\n\\end{eqnarray*}\\]Temos 95% de confiança de que proporção real de adultos de Nova York em outubro de 2014 que apoiaram uma quarentena para qualquer pessoa que tenha entrado em contato com um paciente com ebola estava entre 0.796 e 0.844.Observe que, como pesquisa ocorreu por volta da época em que um médico em Nova York foi diagnosticado com Ebola, os resultados podem não ser tão aplicáveis hoje quanto momento em que pesquisa foi realizada. Isso destaca um detalhe importante sobre pesquisas: eles fornecem dados sobre opinião pública em um único ponto tempo.Construindo um intervalo de confiança para uma proporção:Verifique se observações são independentes e também verifique condição de falha-sucesso usando \\(\\hat{p}\\) e \\(n\\).Verifique se observações são independentes e também verifique condição de falha-sucesso usando \\(\\hat{p}\\) e \\(n\\).Se condições forem atendidas, distribuição amostral de \\(\\hat{p}\\) pode ser bem aproximado pelo modelo normal.Se condições forem atendidas, distribuição amostral de \\(\\hat{p}\\) pode ser bem aproximado pelo modelo normal.Construa o erro padrão usando \\(\\hat{p}\\) lugar de \\(p\\) e aplique fórmula geral intervalo de confiança.Construa o erro padrão usando \\(\\hat{p}\\) lugar de \\(p\\) e aplique fórmula geral intervalo de confiança.","code":""},{"path":"ch6-inf-cat.html","id":"HTOneProportion","chapter":"6 Inferência para dados categóricos","heading":"6.1.3 Teste de hipóteses para uma proporção","text":"Para aplicar estrutura de distribuição normal contexto de um teste de hipótese para uma proporção, condições de independência e falha-sucesso devem ser satisfeitas. Em um teste de hipótese, condição de sucesso-falha é verificada usando proporção nula: nós verificamos que \\(np_0\\) e \\(n(1-p_0)\\) são pelo menos 10, onde \\(p_0\\) é o valor nulo.pesquisa foi de uma amostra aleatória simples que inclui menos dos 10% de adultos dos EUA, o que significa que observações são independentes. Em um teste de hipótese de uma proporção, condição de sucesso-falha é verificada usando proporção nula, que é \\(p_0 = 0.5\\) neste contexto: \\(n p_0 = n (1 - p_0) = 1028 \\times 0.5 = 514 > 10\\). Com estas condições verificadas, o modelo normal pode ser aplicado \\(\\hat{p}\\).Em seguida, o erro padrão pode ser calculado. O valor nulo \\(p_0\\) é usado novamente aqui, porque este é um teste de hipótese para uma única proporção.\\[\\begin{align*}\r\nEP = \\sqrt{\\frac{p_0 (1 - p_0)}{n}} = \\sqrt{\\frac{0.5 (1 – 0.5)}{1028}} = 0.016\r\n\\end{align*}\\]Uma imagem modelo normal é mostrada na Figura~ com o p-valor representado pela região sombreada. Com base modelo normal, estatística de teste pode ser calculada como pontuação Z da estimativa pontual:\\[\\begin{align*}\r\nZ = \\frac{\\text{estimativa pontual} - \\text{valor nulo}}{EP} = \\frac{0.56 – 0.50}{0.016} = 3.75\r\n\\end{align*}\\]área da cauda superior, representando o p-valor, é de cerca de 0,0001. Como o p-valor é menor que 0.05, rejeitamos \\(H_0\\). pesquisa fornece evidências convincentes de que maioria dos americanos apoiou os esforços de redução de armas nucleares em março de 2013.\r\nFigura 6.1: Distribuição amostral para o Exemplo\r\nTeste de hipótese para uma proporção: Configure hipóteses e verifique condições usando o valor nulo, \\(p_0\\), para garantir que \\(\\hat{p}\\) seja quase normal em \\(H_0\\). Se condições se mantiverem, construa o erro padrão, novamente usando \\(p_0\\), e mostre o p-valor em um desenho. Por último, calcule o p-valor e avalie hipóteses.","code":"\nrequire(ggplot2)\n\nggplot(data = data.frame(x = c(-2, 6)), aes(x)) +\n  stat_function(fun = dnorm, n = 1001, args = list(mean = 0.5, sd = sqrt(0.5)), size = 1)  +\n  theme(axis.title = element_blank(), axis.line = element_blank(), \n        axis.text = element_blank(), axis.ticks = element_blank()) + \n  geom_hline(yintercept = -0.008, size = 1, color = 'white') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_segment(aes(x = 0.5, y = -0.008, xend = 0.5, yend = 0.55), \n               linetype = \"dotted\", color = '#EAB217', size = 1) +\n  annotate(\"text\", x = 0.5, y = -0.03, label = \"0.5\") + \n  annotate(\"text\", x = 4, y = -0.03, label = \"0.56\") +\n  geom_segment(aes(x = 4, y = 0, xend = 6, yend = 0), color = \"#EAB217\", size = 1) + \n  annotate(\"text\", x = 4.5, y = 0.07, label = \"p-valor\", color = '#EAB217')"},{"path":"ch6-inf-cat.html","id":"choosingSampleSizeEstimatingProportion","chapter":"6 Inferência para dados categóricos","heading":"6.1.4 Escolhendo um tamanho de amostra ao estimar uma proporção","text":"Ao coletar dados, escolhemos um tamanho de amostra adequado para o objetivo estudo. Muitas vezes, isso significa escolher um tamanho de amostra grande o suficiente para que margem de erro – que é parte que adicionamos e subtraímos da estimativa pontual em um intervalo de confiança – seja suficientemente pequena para que amostra seja útil. Mais explicitamente, nossa tarefa é encontrar um tamanho de amostra \\(n\\) para que proporção da amostra esteja dentro de uma margem de erro de \\(m\\) da proporção real com um certo nível de confiança.margem de erro para uma proporção da amostra é\\[\\begin{align*}\r\nz^{\\star} \\sqrt{\\frac{p (1 - p)}{n}}\r\n\\end{align*}\\]Nosso objetivo é encontrar o menor tamanho de amostra \\(n\\) para que essa margem de erro seja menor que \\(m = 0.04\\). Para um nível de confiança de 95%, o valor \\(z^{\\star}\\) corresponde à 1.96:\\[\\begin{align*}\r\n1.96\\times \\sqrt{\\frac{p(1-p)}{n}} \\ < \\ 0.04\r\n\\end{align*}\\]Existem duas incógnitas na equação: \\(p\\) e \\(n\\). Se tivermos uma estimativa de \\(p\\), talvez de uma pesquisa semelhante, poderíamos inserir esse valor e resolver por \\(n\\). Se não tivermos tal estimativa, devemos usar algum outro valor para \\(p\\). Acontece que margem de erro é maior quando \\(p\\) é 0.5, então normalmente usamos esse valor pior caso se nenhuma estimativa da proporção estiver disponível:\\[\\begin{align*}\r\n    1.96\\times \\sqrt{\\frac{0.5(1-0.5)}{n}} &\\ < \\ 0.04 \\\\\r\n    1.96^2\\times \\frac{0.5(1-0.5)}{n} &\\ < \\ 0.04^2 \\\\\r\n    1.96^2\\times \\frac{0.5(1-0.5)}{0.04^2} &\\ < \\ n \\\\\r\n    600.25 &\\ < \\  n\r\n\\end{align*}\\]Precisamos de mais de 600.25 participantes, o que significa que precisamos de 601 participantes ou mais, para garantir que proporção da amostra esteja dentro de 0.04 da proporção real com 95% de confiança.Quando uma estimativa da proporção está disponível, nós usamos lugar valor da proporção pior caso, 0,5.(). Existem três taxas de falha diferentes para escolher. Realize o cálculo tamanho da amostra para cada um separadamente e identifique três tamanhos de amostra considerar.Para um intervalo de confiança de 90%, \\(z^{\\star} = 1,65\\), e uma vez que uma estimativa da proporção 0.017 está disponível, vamos usá-la na fórmula da margem de erro:\\[\\begin{align*}\r\n1.65\\times \\sqrt{\\frac{0.017(1-0.017)}{n}} &\\ < \\ 0.02 \\\\\r\n113.7 &\\ < \\ n\r\n\\end{align*}\\]Para cálculos de tamanho de amostra, nós sempre arredondamos para cima, assim o primeiro modelo de pneu sugere que 114 pneus seriam suficientes.Um cálculo semelhante pode ser realizado usando 0.062 e 0.013 para \\(p\\), e você deve verificar que o uso dessas proporções resulta em tamanhos de amostra mínimos de 396 e 88 pneus, respectivamente.(b). Os tamanhos das amostras variam muito. Qual dos três você sugeriria usar? O que influenciaria sua escolha?Poderíamos examinar qual dos modelos antigos é mais parecido com o novo modelo, depois escolher o tamanho de amostra correspondente. Ou, se duas das estimativas anteriores são baseadas em pequenas amostras, enquanto outra é baseada em uma amostra maior, devemos considerar o valor correspondente à amostra maior. Existem também outras abordagens razoáveis.Também deve ser notado que condição de falha-sucesso não é atendida com \\(n = 114\\) ou \\(n = 88\\). Ou seja, precisaríamos de métodos adicionais ao que cobrimos até agora para analisar os resultados com base nesses tamanhos de amostra.","code":""},{"path":"ch6-inf-cat.html","id":"twoProportionsDifference","chapter":"6 Inferência para dados categóricos","heading":"6.2 Diferença de duas proporções","text":"Devemos verificar duas condições antes de aplicar o modelo normal para \\(\\hat{p}_1 - \\hat{p}_2\\). Primeiro, distribuição de amostragem para cada proporção da amostra ser quase normal e, em segundo lugar, amostras devem ser independentes. Nestas duas condições, distribuição amostral de \\(\\hat{p}_1 - \\hat{p}_2\\) pode ser bem aproximado usando o modelo normal.Condições para distribuição amostral de \\(\\hat{p}_1 - \\hat{p}_2\\) ser normal: diferença \\(\\hat{p}_1 - \\hat{p}_2\\) tende seguir um modelo normal quandocada proporção segue separadamente um modelo normal, ecada proporção segue separadamente um modelo normal, eas duas amostras são independentes umas das outras.duas amostras são independentes umas das outras.O erro padrão da diferença nas proporções da amostra é\\[\\begin{eqnarray}\r\nEP_{\\hat{p}_1 - \\hat{p}_2}\r\n    = \\sqrt{EP_{\\hat{p}_1}^2 + EP_{\\hat{p}_2}^2}\r\n    = \\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}\r\n\\tag{6.2}\r\n\\end{eqnarray}\\]onde \\(p_1\\) e \\(p_2\\) representam proporções da população e \\(n_1\\) e \\(n_2\\) representam os tamanhos das amostras.Para diferença nas proporções, fórmula de erro padrão tomou seguinte forma:\\[\\begin{eqnarray*}\r\nEP_{\\bar{x}_{1} - \\bar{x}_{2}} = \\sqrt{EP_{\\bar{x}_1}^2 + EP_{\\bar{x}_2}^2}\r\n\\end{eqnarray*}\\]O erro padrão para diferença em duas proporções assume uma forma semelhante. razões por trás desta semelhança estão enraizadas na teoria da probabilidade da, que é descrito para este contexto.","code":""},{"path":"ch6-inf-cat.html","id":"CIDifference","chapter":"6 Inferência para dados categóricos","heading":"6.2.1 Intervalos de confiança para \\(p_1-p_2\\)","text":"ajuste de intervalos de confiança para uma diferença de duas proporções, duas proporções da amostra são usadas para verificar condição de falha-sucesso e também calcular o erro padrão, assim como foi o caso com uma única proporção.Como você deve saber, até 2014 quase todos os americanos serão obrigados ter seguro de saúde. [pessoas que não compram seguros pagarão uma multa] enquanto [pessoas que não podem pagar receberão ajuda financeira governo]. Você aprova ou desaprova esta política?233Para cada entrevistado amostrado aleatoriamente, afirmações entre parênteses foram randomizadas: ou elas foram mantidas na ordem dada acima, ou duas afirmações foram invertidas. Tabela 6.1 mostra os resultados desta experiência. Criar e interpretar um intervalo de confiança de 90% da diferença na aprovação.Tabela 6.1:  Resultados de uma pesquisa Centro de Pesquisas Pew onde ordenação de duas afirmações em uma questão relacionada à saúde foi randomizada.Primeiramente condições devem ser verificadas. Como cada grupo é uma amostra aleatória simples de menos de 10% da população, observações são independentes, tanto dentro das amostras quanto entre amostras. condição de falha-sucesso também é válida para cada amostra. Como todas condições são atendidas, o modelo normal pode ser usado para estimativa pontual da diferença suporte, em que \\(p_1\\) corresponde ao pedido original e \\(p_2\\) para ordem inversa:\\[\\hat{p}_{1} - \\hat{p}_{2} = 0,47 – 0,34 = 0,13\\]O erro padrão pode ser calculado partir da Equação~ usando proporções da amostra:\\[EP \\approx \\sqrt{\\frac{0,47(1-0,47)}{771} + \\frac{0,34(1-0,34)}{732}} = 0,025\\]Para um intervalo de confiança de 90%, usamos \\(z^{\\star} = 1.65\\):\\[\\text{estimativa pontual} \\ \\pm\\ z^{\\star}EP \\quad \\\\quad 0.13 \\ \\pm\\ 1.65 \\times  0.025 \\quad \\\\quad (0,09, 0,17)\\]Temos 90% de confiança de que o índice de aprovação para lei de saúde de 2010 muda entre 9% e 17% devido à ordenação das duas declarações na pergunta da pesquisa. O Pew Research Center relatou que essa diferença modesta sugere que opiniões de grande parte público ainda são fluidas em relação essa lei.","code":"\ndesc1 <- matrix(NA, ncol = 4, nrow = 2)\ndesc1[1,] <- c(771, 47, 49, 3)\ndesc1[2,] <- c(732, 34, 63, 3)\nrownames(desc1) <- c('pessoas que não podem pagar vão receber ajuda financeira do governo', \n                     'pessoas que não comprarem irão pagar uma multa')\ncolnames(desc1) <- c('Tamanho amostral', 'Concordam com a lei', 'Discordam da lei', 'Outros')\n\n\nknitr::kable(desc1, align = 'c', \n             caption = ' Resultados de uma pesquisa do Centro de Pesquisas Pew onde a ordenação de duas afirmações em uma questão relacionada à saúde foi randomizada.')"},{"path":"ch6-inf-cat.html","id":"HTDifference","chapter":"6 Inferência para dados categóricos","heading":"6.2.2 Testes de hipóteses para \\(p_1-p_2\\)","text":"Uma mamografia é um procedimento de raio X usado para verificar o câncer de mama. Se mamografia deve ser usada é parte de uma discussão controversa, e é o tópico nosso próximo exemplo, onde examinamos o teste de hipóteses de 2 proporções quando \\(H_0: p_1 - p_2 = 0\\) (ou equivalente, \\(p_1 = p_2\\)).Um estudo de 30 anos foi realizado com quase 90.000 participantes sexo feminino.234 Durante um período de triagem de 5 anos, cada mulher foi aleeatorizada para um dos dois grupos: primeiro grupo, mulheres receberam mamografias regulares para rastrear o câncer de mama, e segundo grupo, mulheres receberam exames regulares de câncer de mama que não eram mamografias. Nenhuma intervenção foi feita durante os 25 anos seguintes estudo, e consideraremos morte resultante câncer de mama ao longo de todo o período de 30 anos. Os resultados estudo estão resumidos na Tabela 6.2.Se mamografias são muito mais eficazes que os exames de câncer de mama que não são mamografia, então esperamos ver mortes adicionais de câncer de mama grupo controle. Por outro lado, se mamografias não são tão eficazes quanto os exames regulares de câncer de mama, nós esperamos ver um aumento nas mortes por câncer de mama grupo de mamografia.Tabela 6.2: Resultados resumidos para o estudo de morte por câncer de mama.Exemplo 6.6, Vamos verificar condições de utilização modelo normal para analisar os resultados estudo. Os detalhes são muito semelhantes aos dos intervalos de confiança. entanto, desta vez usamos uma proporção especial chamada proporção combinada para verificar condição de falha-sucesso:\\[\\begin{align*}\r\n\\hat{p} &= \\frac{\\text{\\# de pacientes que morreram de câncer de mama em todo o estudo }}{\\text{\\# de pacientes em todo o estudo }} \\\\\r\n    &= \\frac{500 + 505}{500 + \\text{44425} + 505 + \\text{44405}} \\\\\r\n    &= 0.0112\r\n\\end{align*}\\]Esta proporção é uma estimativa da taxa de mortalidade por câncer de mama em todo o estudo, e é nossa melhor estimativa das proporções \\(p_{mgm}\\) e \\(p_{ctrl}\\) se hipótese nula é verdade que \\(p_{mgm} = p_{ctrl}\\). Também usaremos essa proporção combinada ao calcular o erro padrão.Como os pacientes são randomizados, eles podem ser tratados como independentes.Também devemos verificar condição de falha-sucesso para cada grupo. Sob hipótese nula, proporções \\(p_{mgm}\\) e \\(p_{ctrl}\\) são iguais, então checamos condição de sucesso-falha com nossa melhor estimativa desses valores sob \\(H_0\\), proporção combinada das duas amostras, \\(\\hat{p} = 0.0112\\):\\[\\begin{align*}\r\n\\hat{p} \\times n_{mgm} &= 0.0112 \\times \\text{44925} = 503\r\n    & (1 - \\hat{p}) \\times n_{mgm} &= 0.9888 \\times \\text{44925} = \\text{44422} \\\\\r\n\\hat{p} \\times n_{ctrl} &= 0.0112 \\times \\text{44910} = 503\r\n    & (1 - \\hat{p}) \\times n_{ctrl} &= 0.9888 \\times \\text{44910} = \\text{44407}\r\n\\end{align*}\\]condição de sucesso-falha é satisfeita desde que todos os valores sejam pelo menos 10, então podemos aplicar com segurança o modelo normal.Use estimativa de proporção combinada quando \\(\\mathbf{H_0}\\) é \\(\\mathbf{p_1 - p_2 = 0}\\): Quando hipótese nula é que proporções são iguais, use proporção agrupada (\\(\\hat{p}\\)) para verificar condição de falha-sucesso e estimar o erro padrão:\\[\\begin{eqnarray*}\r\n\\hat{p}_1 = \\frac{\\text{ número de sucessos}}{\\text{número de casos}} = \\frac{\\hat{p}_1n_1 + \\hat{p}_2n_2}{n_1 + n_2}\r\n\\end{eqnarray*}\\]Aqui \\(\\hat{p}_1n_1\\) representa o número de sucessos na amostra 1 já que\\[\\begin{eqnarray*}\r\n\\hat{p}_1 = \\frac{\\text{ número de sucessos na amostra 1}}{n_1}\r\n\\end{eqnarray*}\\]Similarmente, \\(\\hat{p}_2n_2\\) representa o número de sucessos na amostra 2.Exemplo 6.6, proporção agrupada foi usada para verificar condição de falha-sucesso. próximo exemplo, vemos o segundo lugar em que proporção agrupada entra em ação: o cálculo erro padrão.estimativa pontual da diferença nas taxas de mortalidade por câncer de mama é\\[\\begin{align*}\r\n\\hat{p}_{mgm} - \\hat{p}_{ctrl}\r\n    &= \\frac{500}{500 + 44425} - \\frac{505}{505 + 44405} \\\\\r\n    &= 0.01113 – 0.01125 \\\\\r\n    &= -0.00012\r\n\\end{align*}\\]taxa de mortalidade por câncer de mama grupo de mamografia foi de 0.012% menor que grupo controle. Em seguida, o erro padrão é calculado usando proporção combinada, \\(\\hat{p}\\):\\[\\begin{align*}\r\nEP = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_{mgm}}\r\n        + \\frac{\\hat{p}(1-\\hat{p})}{n_{ctrl}}}\r\n    = 0.00070\r\n\r\n\\end{align*}\\]Assim como nos testes anteriores, primeiro calculamos uma estatística de teste e desenhamos uma figura:\\[\\begin{align*}  \r\nZ = \\frac{\\text{estimativa pontual } - \\text{ valor nulo}}{EP}\r\n    = \\frac{-0.00012 - 0}{0.00070}\r\n    = -0.17\r\n\\end{align*}\\]área da cauda inferior é 0.4325, que dobramos para obter o p-valor: 0.8650. Como esse p-valor é maior que 0.05, não rejeitamos hipótese nula. Ou seja, diferença nas taxas de mortalidade por câncer de mama é razoavelmente explicada pelo acaso, e não observamos benefícios ou danos de mamografias em relação um exame de mama regular.Podemos concluir que mamografias não trazem benefícios ou danos? Aqui estão algumas considerações importantes serem lembradas ao revisar o estudo da mamografia, bem como qualquer outro estudo médico:Se mamografias forem úteis ou prejudiciais, os dados sugerem que o efeito não é muito grande. Portanto, embora não aceitemos hipótese nula, também não temos evidências suficientes para concluir que mamografias reduzem ou aumentam mortes por câncer de mama.Se mamografias forem úteis ou prejudiciais, os dados sugerem que o efeito não é muito grande. Portanto, embora não aceitemos hipótese nula, também não temos evidências suficientes para concluir que mamografias reduzem ou aumentam mortes por câncer de mama.mamografias são mais ou menos caras que um exame de mama não mamográfico? Se uma opção é muito mais cara que outra e não oferece benefícios claros, então devemos nos inclinar para opção menos cara.mamografias são mais ou menos caras que um exame de mama não mamográfico? Se uma opção é muito mais cara que outra e não oferece benefícios claros, então devemos nos inclinar para opção menos cara.Os autores estudo também descobriram que mamografias levaram ao sobre-diagnóstico câncer de mama, o que significa que alguns cânceres de mama foram encontrados (ou pensados que tinham sido encontrados), mas que esses cânceres não causariam sintomas durante vida dos pacientes. Ou seja, outra coisa mataria o paciente antes que os sintomas câncer de mama aparecessem. Isso significa que alguns pacientes podem ter sido tratados para câncer de mama desnecessariamente, e esse tratamento é outro custo ser considerado. Também é importante reconhecer que o sobre-diagnóstico pode causar danos físicos ou emocionais desnecessários aos pacientes.Os autores estudo também descobriram que mamografias levaram ao sobre-diagnóstico câncer de mama, o que significa que alguns cânceres de mama foram encontrados (ou pensados que tinham sido encontrados), mas que esses cânceres não causariam sintomas durante vida dos pacientes. Ou seja, outra coisa mataria o paciente antes que os sintomas câncer de mama aparecessem. Isso significa que alguns pacientes podem ter sido tratados para câncer de mama desnecessariamente, e esse tratamento é outro custo ser considerado. Também é importante reconhecer que o sobre-diagnóstico pode causar danos físicos ou emocionais desnecessários aos pacientes.Essas considerações destacam complexidade em torno de recomendações de cuidados médicos e tratamento. Especialistas e médicos que estudam tratamentos médicos usam considerações como acima para fornecer sua melhor recomendação com base nas evidências atuais.","code":"\ndesc2 <- matrix(c(500, 44425, 505, 44405), ncol = 2, nrow = 2, byrow = TRUE)\ncolnames(desc2) <- c(\"Sim\", \"Não\")\nrownames(desc2) <- c('Mamografia', 'Controle')\n\nknitr::kable(desc2, align = 'c', caption = 'Resultados resumidos para o estudo de morte por câncer de mama.')\nX = seq(-2, 3, 0.01)\nY = dnorm(X, 0.5, sqrt(0.5))\n\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < 0.4 | gg$X > 0.6,], \n                 aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") + \n  geom_path(size = 1) +\n  theme(axis.title = element_blank(), axis.line = element_blank(), \n        axis.text = element_blank(), axis.ticks = element_blank()) + \n  geom_hline(yintercept = -0.008, size = 1, color = 'white') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  annotate(\"text\", x = 0.5, y = -0.03, label = \"0\") + \n  annotate(\"text\", x = c(-1,2), y = -0.03, label = c(\"-0.0014\",\"0.0014\")) + \n  geom_segment(aes(x = -2, y = 0, xend = 3, yend = 0), size = 1)"},{"path":"ch6-inf-cat.html","id":"moreHTTwoProportions","chapter":"6 Inferência para dados categóricos","heading":"6.2.3 Mais sobre testes de hipóteses de duas proporções (tópico especial)","text":"Quando realizamos um teste de hipótese de 2 proporções, geralmente \\(H_0\\) é \\(p_1 - p_2 = 0\\). entanto, existem situações raras em que queremos verificar se há alguma diferença em \\(p_1\\) e \\(p_2\\) que seja algum valor diferente de 0. Por exemplo, talvez nos preocupemos em verificar uma hipótese nula em que $ p_1 - p_2 = 0,1 $.237 Em contextos como esses, geralmente usamos \\(\\hat{p}_1\\) e \\(\\hat{p}_2\\) para verificar condição de falha ou sucesso e construir o erro padrão.Primeiro, nós verificamos condições. amostra não é necessariamente aleatória, então, para prosseguir, devemos assumir que lâminas são todas independentes; Para esta amostra, vamos supor que essa suposição é razoável, mas o engenheiro teria mais conhecimento sobre se essa suposição é apropriada. condição de falha-sucesso também é válida para cada amostra. Assim, pode-se dizer que diferença nas proporções da amostra, \\(0.958 - 0.899 = 0.059\\), é proveniente de uma distribuição quase normal.O erro padrão é calculado usando duas proporções de amostra, pois não usamos uma proporção agrupada para este contexto:\\[\\begin{align*}\r\nEP = \\sqrt{\\frac{0.958(1-0.958)}{1000} + \\frac{0.899(1-0.899)}{1000}} = 0.0114\r\n\\end{align*}\\]Neste teste de hipótese, porque o valor nulo é \\(p_1 - p_2 = 0.03\\), proporções da amostra foram usadas para o cálculo erro padrão em vez de uma proporção agrupada.Em seguida, calculamos estatística de teste e usamos para encontrar o p-valor, que é descrito na Figura 6.2.\\[Z = \\frac{\\text{estimativa pontual} - \\text{valor nulo}}{EP} = \\frac{0,059 – 0,03}{0,0114} = 2,54\\]Usando o modelo normal para esta estatística de teste, identificamos área da cauda direita como 0.006. Como esse é um teste unilateral, essa área de cauda única também é o p-valor e rejeitamos hipótese nula porque 0.006 é menor que 0.05. Ou seja, temos evidências estatisticamente significativas de que lâminas de maior qualidade realmente passam pela inspeção mais de 3% com mesma frequência das lâminas usadas atualmente. Com base nesses resultados, gerência aprovará mudança para o novo fornecedor.\r\nFigura 6.2: Distribuição da estatística de teste se hipótese nula verdadeira. O p-valor é representado pela área sombreada.\r\n","code":"\nX = seq(-3, 3, 0.01)\nY = dnorm(X)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X > 2.3,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") + \n  geom_path(size = 1) +\n  theme(axis.title = element_blank(), axis.line = element_blank(), \n        axis.text = element_blank(), axis.ticks = element_blank()) + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  annotate(\"text\", x = c(0.13, 2.3), y = -0.01, \n           label = c(\"0.13 (valor nulo)\",\"0.059\"), size = 3) + \n  geom_segment(aes(x = -3.2, y = 0, xend = 3.2, yend = 0), size = 1, color = 'white') + \n  annotate(\"text\", x = 2.7, y = 0.07, label = 'p-valor', color = '#EAB217') "},{"path":"ch6-inf-cat.html","id":"testingQualityFitChiSquare","chapter":"6 Inferência para dados categóricos","heading":"6.3 Testando a qualidade do ajuste usando a qui-quadrado (tópico especial)","text":"Nesta seção, desenvolvemos um método para avaliar um modelo nulo quando os dados são armazenados de forma binária. Esta técnica é comumente usada em duas circunstâncias:Dada uma amostra de casos que podem ser classificados em vários grupos, determine se amostra é representativa da população em geral.Dada uma amostra de casos que podem ser classificados em vários grupos, determine se amostra é representativa da população em geral.Avaliar se os dados se assemelham uma distribuição específica, como uma distribuição normal ou uma distribuição geométrica.Avaliar se os dados se assemelham uma distribuição específica, como uma distribuição normal ou uma distribuição geométrica.Cada um desses cenários pode ser tratado usando o mesmo teste estatístico: um teste qui-quadrado.primeiro caso, consideramos dados de uma amostra aleatória de 275 jurados em um pequeno município. Os jurados identificaram seu grupo racial, como mostrado na Tabela 6.3, e gostaríamos de determinar se esses jurados são racialmente representativos da população. Se o júri representativo da população, proporções da amostra deverão refletir aproximadamente população de jurados elegíveis, ou seja, eleitores registrados.Tabela 6.3: Representação por raça em júris e população de uma cidade.Embora proporções nos júris não representem precisamente proporções da população, não está claro se esses dados fornecem evidências convincentes de que amostra não é representativa. Se os jurados realmente fossem aleatoriamente amostrados dos eleitores registrados, poderíamos esperar pequenas diferenças devido ao acaso. entanto, diferenças extraordinariamente grandes podem fornecer evidências convincentes de que os júris não eram representativos.Uma segunda aplicação, avaliando o ajuste de uma distribuição, é apresentada final desta seção. Os retornos diários das ações da S&P500 para os anos 1990-2011 são usados para avaliar se atividade de estoque por dia é independente comportamento da ação nos dias anteriores.Nesses problemas, gostaríamos de examinar todos os intervalos simultaneamente, e não simplesmente comparar um ou dois intervalos por vez, o que exigirá que desenvolvamos uma nova estatística de teste.","code":"\ndesc3 <- matrix(c(205, 26, 25, 19, 275, \n                  0.72, 0.07, 0.12, 0.09, 1.00), nrow = 2, ncol = 5, byrow = TRUE)\ncolnames(desc3) <- c('Branco','Negro','Hispânico','Outro','Total')\nrownames(desc3) <- c('Representação em juris','Eleitores registrados')\n\nknitr::kable(desc3, align = 'c', \n             caption = 'Representação por raça em júris e população de uma cidade.')"},{"path":"ch6-inf-cat.html","id":"testStatisticUnidirectionalTables","chapter":"6 Inferência para dados categóricos","heading":"6.3.1 Criando uma estatística de teste para tabelas unidirecionais","text":"Cerca de 72% da população é branca, então esperamos que cerca de 72% dos jurados sejam brancos: \\(0.72\\times 275 = 198\\).Da mesma forma, esperaríamos que cerca de 7% dos jurados fossem negros, o que corresponderia cerca de \\(0.07\\times 275 = 19.25\\) jurados negros.Tabela 6.4: Composição real e esperada dos jurados.proporção da amostra representada de cada raça entre os 275 jurados não foi uma correspondência precisa para qualquer grupo étnico. Enquanto alguma variação de amostragem é esperada, esperamos que proporções da amostra sejam bastante semelhantes às proporções da população, se não houver viés nos júris. Precisamos testar se diferenças são fortes o suficiente para fornecer evidências convincentes de que os jurados não são uma amostra aleatória. Essas ideias podem ser organizadas em hipóteses:\\(H_0\\): Os jurados são uma amostra aleatória, ou seja, não há viés racial em quem atua em um júri, e contagens observadas refletem flutuação amostral natural.\\(H_0\\): Os jurados são uma amostra aleatória, ou seja, não há viés racial em quem atua em um júri, e contagens observadas refletem flutuação amostral natural.\\(H_1\\): Os jurados não são amostrados aleatoriamente, ou seja, há viés racial na seleção de jurados.\\(H_1\\): Os jurados não são amostrados aleatoriamente, ou seja, há viés racial na seleção de jurados.Para avaliar essas hipóteses, quantificamos quão diferentes são contagens observadas das contagens esperadas. Fortes evidências para hipótese alternativa viriam na forma de desvios anormalmente grandes nos grupos que seria esperado com base apenas na variação da amostragem.","code":"\ndesc4 <- matrix(c(205, 26, 25, 19, 275, \n                  198, 19.25, 33, 24.75, 275), nrow = 2, ncol = 5, byrow = TRUE)\ncolnames(desc4) <- c('Branco', 'Negro', 'Hispânico', 'Outro', 'Total')\nrownames(desc4) <- c('Dados observados', 'Contagem esperada')\n\nknitr::kable(desc4, align = 'c', caption = 'Composição real e esperada dos jurados.')"},{"path":"ch6-inf-cat.html","id":"chiSquareTestStatistics","chapter":"6 Inferência para dados categóricos","heading":"6.3.2 A estatística do teste qui-quadrado","text":"Em testes de hipóteses anteriores, construímos uma estatística de teste da seguinte forma:\\[ \\frac{\\text{estimativa pontual } - \\text{valor nulo}}{\\text{EP da estimativa pontual}} \\]Essa construção foi baseada em (1) identificar diferença entre uma estimativa pontual e um valor esperado se hipótese nula fosse verdadeira, e (2) padronizar essa diferença usando o erro padrão da estimativa pontual. Essas duas ideias ajudarão na construção de uma estatística de teste apropriada para dados de contagem.Nossa estratégia será calcular primeiro diferença entre contagens observadas e contagens que esperaríamos se hipótese nula fosse verdadeira, então padronizaríamos diferença:\\[\\begin{align*}\r\nZ_{1} = \\frac{\\text{ contagem branca observada } - \\text{ contagem branca nula }}\r\n                {\\text{EP da contagem branca observada}}\r\n\\end{align*}\\]O erro padrão para estimativa pontual da contagem em dados representados em intervalos é raiz quadrada da contagem sob o valor nulo.239 Portanto:\\[\\begin{align*}\r\nZ_1 = \\frac{205 - 198}{\\sqrt{198}} = 0.50\r\n\\end{align*}\\]fração é muito semelhante às estatísticas de teste anteriores: primeiro calcule uma diferença e padronize-. Esses cálculos também devem ser concluídos para os grupos negro, hispânico e outros:\\[\\begin{align*}\r\n&Negro && Hispânicos    &&Outros \\\\\r\n& Z_2 = \\frac{26-19.25}{\\sqrt{19.25}}=1.54\\ \\ \\ \\ \r\n    && Z_3 = \\frac{25-33}{\\sqrt{33}}=-1.39\\ \\ \\ \\ \r\n    && Z_4 = \\frac{19-24.75}{\\sqrt{24.75}}=-1.16 \\\\\r\n\\end{align*}\\]Gostaríamos de usar uma única estatística de teste para determinar se essas quatro diferenças padronizadas estão irregularmente distantes de zero. Ou seja, \\(Z_1\\), \\(Z_2\\), \\(Z_3\\) e \\(Z_4\\) devem ser combinados de alguma forma para ajudar determinar se eles – como um grupo – tendem estar incomumente longe de zero. Um primeiro pensamento pode ser pegar o valor absoluto dessas quatro diferenças padronizadas e adicioná-las:\\[\\begin{align*}\r\n|Z_1| + |Z_2| + |Z_3| + |Z_4| = 4.58\r\n\\end{align*}\\]Na verdade, isso dá um número resumindo até que ponto contagens reais são que era esperado. entanto, é mais comum adicionar os valores ao quadrado:\\[\\begin{align*}\r\nZ_1^2 + Z_2^2 + Z_3^2 + Z_4^2 = 5.89\r\n\\end{align*}\\]Elevando ao quadrado cada diferença padronizada antes de adicioná-los juntos faz duas coisas:Qualquer diferença padronizada que seja negativa será agora positiva.Qualquer diferença padronizada que seja negativa será agora positiva.Diferenças que já parecem incomuns – por exemplo uma diferença padronizada de 2.5 – se tornará muito maior depois de ser elevada ao quadrado.Diferenças que já parecem incomuns – por exemplo uma diferença padronizada de 2.5 – se tornará muito maior depois de ser elevada ao quadrado.estatística de teste \\(\\chi^2\\), que é é soma dos valores de \\(Z^2\\), é geralmente usada por esses motivos. Também podemos escrever uma equação para \\(\\chi^2\\) usando contagens observadas e contagens nulas:\\[\\begin{align*}\r\n\\chi^2 &=\r\n  \\frac{(\\text{contagem observada}_1 - \\text{contagem nula}_1)^2)}{\\text{contagem nula}_1} + \\dots + \\frac{(\\text{contagem observada}_4 - \\text{contagem nula}_4)^2)}{\\text{contagem nula}_4}\r\n\\end{align*}\\]O número final \\(\\chi^2\\) resume quão fortemente contagens observadas tendem se desviar das contagens nulas. Mais frente veremos que, se hipótese nula verdadeira, \\(\\chi^2\\) segue uma nova distribuição chamada distribuição qui-quadrado. Usando esta distribuição, poderemos obter um p-valor para avaliar hipóteses.","code":""},{"path":"ch6-inf-cat.html","id":"chiSquareDistribution","chapter":"6 Inferência para dados categóricos","heading":"6.3.3 A distribuição qui-quadrado","text":"Às vezes, distribuição qui-quadrado é usada para caracterizar conjuntos de dados e estatísticas que são sempre positivos e geralmente estão inclinados para direita. Lembre-se de que distribuição normal tinha dois parâmetros – média e desvio padrão – que poderiam ser usados para descrever suas características exatas. distribuição qui-quadrado tem apenas um parâmetro chamado graus de liberdade (gl), que influencia forma, o centro e distribuição da distribuição.Prática Orientada 6.7  Figura 6.3 mostra três distribuições qui-quadrado.240Como o centro da distribuição muda quando os graus de liberdade são maiores?\r\nComo o centro da distribuição muda quando os graus de liberdade são maiores?E quanto à variabilidade?\r\nE quanto à variabilidade?Como forma muda?\r\nComo forma muda?\r\n\r\nFigura 6.3: Três distribuições de qui-quadrado com diferentes graus de liberdade.\r\nFigura 6.3 e Prática Orientada 6.7 demonstram três propriedades gerais de distribuições qui-quadrado à medida que os graus de liberdade aumentam: distribuição se torna mais simétrica, o centro se move para direita e variabilidade aumenta.Nosso principal interesse na distribuição qui-quadrado é o cálculo dos p-valores, que (como vimos anteriormente) está relacionado encontrar área relevante na cauda de uma distribuição. Para fazer isso, uma nova tabela é necessária: tabela qui-quadrado, parcialmente mostrada na Tabela 6.5. Esta tabela é muito semelhante à tabela \\(t\\): examinamos uma linha específica para distribuições com diferentes graus de liberdade e identificamos um intervalo para área. Uma diferença importante da tabela \\(t\\) é que tabela qui-quadrado só fornece valores de cauda superiores.Tabela 6.5: Uma parte da tabela qui-quadrado. linhas são os graus de liberdade e colunas cauda superior.\r\nFigura 6.4: Distribuição qui-quadrado com 3 graus de liberdade e com região acima de 6.25 sombreada\r\nEsta distribuição possui três graus de liberdade, portanto somente linha com 3 graus de liberdade (gl) é relevante. Em seguida, vemos que o valor – 6,25 – cai na coluna com área da cauda superior 0,1. Ou seja, cauda superior sombreada.\r\nFigura 6.5: Distribuição qui-quadrado com 2 graus de liberdade e com região acima de 4.3 sombreada\r\nO ponto de corte 4.3 cai entre segunda e terceira coluna na fila de 2 graus de liberdade. Como essas colunas correspondem áreas de cauda de 0.2 e 0.1, podemos ter certeza de que área sombreada na Figura 6.5 está entre 0.1 e 0.2.\r\nFigura 6.6: Distribuição qui-quadrado com 5 graus de liberdade e com região acima de 5.1 sombreada\r\nOlhando na linha com 5 gl, 5.1 cai abaixo menor limite para esta linha (6.06). Isso significa que só podemos dizer que área é maior que 0.3.\r\nFigura 6.7: Distribuição qui-quadrado com 7 graus de liberdade e com região acima de 11.7 sombreada\r\n\r\n(#fig:chiSquareAreaAbove10WithDF4_)Distribuição qui-quadrado com 4 graus de liberdade e com região acima de 10 sombreada\r\n\r\nFigura 6.8: Distribuição qui-quadrado com 3 graus de liberdade e com região acima de 9.21 sombreada\r\n","code":"\nx = seq(0, 25, 0.005)\ndados_chi <- data.frame(x = seq(0, 25, 0.005), \n                        df2 = dchisq(x, 2), \n                        df4 = dchisq(x, 4), \n                        df9 = dchisq(x, 9))\n\nchi <- tidyr::gather(dados_chi, df, chi, df2:df9, factor_key=TRUE)\n\nggplot(data = chi, mapping = aes(x = x, y = chi, color = df)) + \n  geom_line(size = 1) + \n  scale_color_manual(values = c('#EAB217', '#E97C31', '#E6205F'), \n                     labels = c('gl = 2', 'gl = 4', 'gl = 9')) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL, color = \"graus de \\nliberdade:\") +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  theme(legend.position = 'left') \ndesc5 <- matrix(c(2.41, 3.22, 4.61, 5.99, 7.82, 9.21, 10.60, 13.82,\n                  3.66, 4.64, 6.25, 7.81, 9.84, 11.34, 12.84, 16.27,\n                  4.88, 5.99, 7.78, 9.49, 11.67, 13.28, 14.86, 18.47,\n                  6.06, 7.29, 9.24, 11.07, 13.39, 15.09, 16.75, 20.52,\n                  7.23, 8.56, 10.64, 12.59, 15.03, 16.81, 18.55, 22.46,\n                  8.38, 9.80, 12.02, 14.07, 16.62, 18.48, 20.28, 24.32), \n                ncol = 8, nrow = 6, byrow = TRUE)\n\nrownames(desc5) <- 2:7\ncolnames(desc5) <- c(0.3, 0.2, 0.1, 0.05, 0.02, 0.01, 0.005, 0.001)\n\nknitr::kable(desc5, align = 'c', caption = \"Uma parte da tabela qui-quadrado. As linhas são os graus de liberdade e as colunas a cauda superior.\")\nX = seq(0, 15, 0.005)\nY = dchisq(X, 3)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 6.25,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)\nX = seq(0, 12, 0.005)\nY = dchisq(X, 2)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 4.3,], aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)\nX = seq(0, 20, 0.005)\nY = dchisq(X, 5)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 5.1,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)\nX = seq(0, 25, 0.005)\nY = dchisq(X, 7)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 11.7,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)\nX = seq(0, 20, 0.005)\nY = dchisq(X, 4)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 10,], aes(X, ymin = 0, ymax = Y), colour=\"#E6205F\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)\nX = seq(0, 15, 0.005)\nY = dchisq(X, 3)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 9.21,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)"},{"path":"ch6-inf-cat.html","id":"findPValueChiSquare","chapter":"6 Inferência para dados categóricos","heading":"6.3.4 Encontrar um p-valor para uma distribuição qui-quadrado","text":"Nas Seções anteriores, identificamos uma nova estatística de teste de (\\(\\chi^2\\)) dentro contexto de avaliar se havia evidência de viés racial na forma como os jurados foram amostrados. hipótese nula representou alegação de que os jurados foram amostrados aleatoriamente e não houve viés racial. hipótese alternativa era que havia preconceito racial em como os jurados foram amostrados.Determinamos que um grande valor \\(\\chi^2\\) sugeriria fortes evidências favorecendo hipótese alternativa: que havia viés racial. entanto, não foi possível quantificar chance de observar uma estatística de teste tão grande (\\(\\chi^2 = 5.89\\)) se hipótese nula fosse verdadeira. É aqui que distribuição qui-quadrado se torna útil. Se hipótese nula fosse verdadeira e não houvesse viés racial, \\(\\chi^2\\) seguiria uma distribuição qui-quadrado, com três graus de liberdade nesse caso. Sob certas condições, estatística \\(\\chi^2\\) segue uma distribuição qui-quadrado com \\(k - 1\\) graus de liberdade, onde \\(k\\) é o número de posições.exemplo dos jurados, havia categorias de \\(k = 4\\): branco, preto, hispânico e outros. De acordo com regra acima, estatística de teste \\(\\chi^2\\) deve seguir uma distribuição qui-quadrado com \\(k-1 = 3\\) graus de liberdade se \\(H_0\\) verdadeiro.Assim como verificamos condições de tamanho de amostra para usar o modelo normal nas seções anteriores, também devemos verificar uma condição de tamanho de amostra para aplicar com segurança distribuição de qui-quadrado para \\(\\chi^2\\). Cada contagem esperada deve ser de pelo menos 5. exemplo júri, contagens esperadas eram 198, 19, 25, 33 e 24.75, todas facilmente acima de 5, então podemos aplicar o modelo qui-quadrado à estatística de teste, \\(\\chi^2 = 5.89\\).distribuição qui-quadrado e o p-valor são mostrados na Figura 6.9. Como valores maiores de qui-quadrado correspondem evidências mais fortes contra hipótese nula, nós sombreamos cauda superior para representar o p-valor. Usando tabela, podemos determinar que área está entre 0.1 e 0.2. Ou seja, o p-valor é maior que 0.1 mas menor que 0.2. Geralmente, não rejeitamos hipótese nula com um p-valor tão grande. Em outras palavras, os dados não fornecem evidências convincentes de viés racial na escolha jurado. O p-valor exato pode ser calculado através de um software, como por exemplo o R.pchisq(5.89, 3, lower.tail = FALSE)\r\nFigura 6.9: Distribuição qui-quadrado com 3 graus de liberdade e com região acima de 5.89 sombreada para o exemplo viés racial\r\nTeste de qui-quadrado para tabela de sentido único: Suponha que devemos avaliar se há evidências convincentes de que um conjunto de categorias de \\(O_1\\), \\(O_2\\), …, \\(O_k\\) em \\(k\\) contagens são extraordinariamente diferentes que se poderia esperar sob uma hipótese nula. Descubra contagens esperadas com base nas hipóteses nulas \\(E_1\\), \\(E_2\\), …, \\(E_k\\). Se cada contagem esperada é pelo menos 5 e hipótese nula é verdadeira, então estatística de teste abaixo segue uma distribuição qui-quadrado com \\(k-1\\) graus de liberdade:\\[\\begin{align*}\r\n\\chi^2 = \\frac{(O_1 - E_1)^2}{E_1} + \\frac{(O_2 - E_2)^2}{E_2} + \\cdots + \\frac{(O_k - E_k)^2}{E_k}\r\n\r\n\\end{align*}\\]\r\nO p-valor para esta estatística de teste é encontrado observando cauda superior dessa distribuição qui-quadrada. Consideramos cauda superior porque valores maiores de \\(\\chi^2\\) forneceriam maior evidência contra hipótese nula.Dica: Condições para o teste qui-quadrado: Existem duas condições que devem ser verificadas antes de realizar um teste de qui-quadrado:Independência: Cada caso que contribui com uma contagem para tabela deve ser independente de todos os outros casos na tabela.Independência: Cada caso que contribui com uma contagem para tabela deve ser independente de todos os outros casos na tabela.Tamanho/distribuição da amostra: Cada cenário particular (ou seja, contagem de células) deve ter pelo menos 5 casos esperados.Tamanho/distribuição da amostra: Cada cenário particular (ou seja, contagem de células) deve ter pelo menos 5 casos esperados.Não verificar condições pode afetar taxas de erro teste.","code":"\nX = seq(0, 15, 0.005)\nY = dchisq(X, 3)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 5.89,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)"},{"path":"ch6-inf-cat.html","id":"goodnessFitChiSquare","chapter":"6 Inferência para dados categóricos","heading":"6.3.5 Avaliando a qualidade do ajuste para uma distribuição qui-quadrado","text":"Podemos aplicar nossa nova estrutura de teste de qui-quadrado ao segundo problema nesta seção: avaliar se um determinado modelo estatístico ajusta um conjunto de dados. Retornos diários das ações da S&P500 para 1990-2011 pode ser usado para avaliar se atividade de estoque cada dia é independente comportamento da ação nos dias anteriores. Isso soa como uma questão muito complexa, e é, mas um teste qui-quadrado pode ser usado para estudar o problema. Vamos rotular cada dia como Alta ou Baixa dependendo se o mercado estava em alta ou baixa naquele dia. Por exemplo, considere seguintes alterações preço, seus novos rótulos de para cima e para baixo e, em seguida, o número de dias que devem ser observados antes de cada dia em Alta:Se os dias forem realmente independentes, o número de dias até um dia de negociação positivo deve seguir uma distribuição geométrica. distribuição geométrica descreve probabilidade de esperar pelo k julgamento para observar o primeiro sucesso. Aqui cada dia em (Alta) representa um sucesso, e dias em (Baixa) representam falhas. Nos dados acima, demorou apenas um dia até o mercado subir, então o primeiro tempo de espera foi de 1 dia. Demorou mais dois dias antes de observarmos nosso próximo dia de negociação em alta, e mais dois para o terceiro dia em Alta. Nós gostaríamos de determinar se essas contagens (1, 2, 2, 1, 4 e assim por diante) seguem distribuição geométrica. Tabela 6.6 mostra o número de dias de espera para um dia de negociação positivo em 1990-2011 para o S&P500.Tabela 6.6: Distribuição observada dos dias de espera até que ocorra um dia de negociação positivoConsideramos quantos dias é preciso esperar até observar um dia em alta índice de ações S&P500. Se atividade de estoque fosse independente de um dia para o outro e probabilidade de um dia de negociação positivo fosse constante, esperaríamos que esse tempo de espera seguisse uma distribuição geométrica. Podemos organizar isso em uma estrutura de hipóteses:\\(H_0\\): O mercado de ações que está em alta ou em baixa em um determinado dia é independente de todos os outros dias. Vamos considerar o número de dias que passam até que um dia alta seja observado. Sob esta hipótese, o número de dias até que um dia alta deve seguir uma distribuição geométrica.\\(H_0\\): O mercado de ações que está em alta ou em baixa em um determinado dia é independente de todos os outros dias. Vamos considerar o número de dias que passam até que um dia alta seja observado. Sob esta hipótese, o número de dias até que um dia alta deve seguir uma distribuição geométrica.\\(H_1\\): O mercado de ações está em alta ou em baixa em um determinado dia não é independente de todos os outros dias. Como sabemos que o número de dias até um dia em alta seguiria uma distribuição geométrica sob hipótese nula, procuramos desvios da distribuição geométrica, o que apoiaria hipótese alternativa.\\(H_1\\): O mercado de ações está em alta ou em baixa em um determinado dia não é independente de todos os outros dias. Como sabemos que o número de dias até um dia em alta seguiria uma distribuição geométrica sob hipótese nula, procuramos desvios da distribuição geométrica, o que apoiaria hipótese alternativa.Há implicações importantes nosso resultado para os corretores de ações: se informações de dias de pregações anteriores são úteis para dizer o que acontecerá hoje, essas informações podem fornecer uma vantagem sobre os outros corretores.Consideramos dados para o S&P500 de 1990 2011 e resumimos os tempos de espera na Tabela 6.7 e na Figura 6.10. O S&P500 foi positivo em 53.2% desses dias.Tabela 6.7: Distribuição tempo de espera até um dia de negociação positivo. contagens esperadas baseadas modelo geométrico são mostradas na última linha.Para encontrar cada contagem esperada, identificamos probabilidade de esperar \\(D\\) dias com base modelo geométrico (\\(P(D) = (1-0.532)^{D-1}(0.532)\\)) e multiplicar pelo número total de listras, 2948. Por exemplo, espera por três dias ocorre sob o modelo geométrico sobre \\(0.468^2\\times 0.532 = 11.65\\%\\) tempo, o que corresponde \\(0.11165\\times2948 = 343\\) listras.\r\nFigura 6.10: Gráfico de barras lado lado das contagens observadas e esperadas para cada tempo de espera.\r\nComo aplicação da estrutura da qui-quadrado exige que contagens esperadas sejam pelo menos 5, reunimos em conjunto todos os casos em que o tempo de espera foi de pelo menos 7 dias para garantir que cada contagem esperada esteja bem acima desse mínimo. Os dados reais, mostrados na linha Observado na Tabela 6.7, pode ser comparado com contagens esperadas da linha Modelo Geométrico. O método para calcular contagens esperadas é discutido na Tabela 6.7. Em geral, contagens esperadas são determinadasidentificando proporção nula associada cada intervalo e, em seguida,\r\nidentificando proporção nula associada cada intervalo e, em seguida,multiplicando cada proporção nula pela contagem total para obter contagens esperadas. Ou seja, essa estratégia identifica proporção da contagem total que esperamos estar em cada caixa.\r\nmultiplicando cada proporção nula pela contagem total para obter contagens esperadas. Ou seja, essa estratégia identifica proporção da contagem total que esperamos estar em cada caixa.Não é óbvio se diferenças nas contagens observadas e contagens esperadas da distribuição geométrica são significativamente diferentes. Isto é, não está claro se esses desvios podem ser devidos ao acaso ou se são tão fortes que os dados fornecem evidências convincentes contra hipótese nula. entanto, podemos realizar um teste qui-quadrado usando contagens na Tabela 6.7.Prática Orientada 6.12  Como contagens esperadas são todas pelo menos 5, podemos aplicar com segurança distribuição qui-quadrado, \\(\\chi^2\\). entanto, quantos graus de liberdade devemos usar?245A Figura 6.11 mostra distribuição qui-quadrado, o ponto de corte e o p-valor sombreado. Se nós procurarmos estatística \\(\\chi^2=15.08\\), descobrimos que o p-valor está entre 0.01 e 0.02. Em outras palavras, temos evidências suficientes para rejeitar noção de que os tempos de espera seguem uma distribuição geométrica, ou seja, os dias de negociação não são independentes e os dias passados podem ajudar prever o que o mercado de ações fará hoje.pchisq(6, 15.08, lower.tail = TRUE)\r\nFigura 6.11: Distribuição chi-quadrado com 6 graus de liberdade. O p-valor para análise de estoque está sombreado.\r\nComo os dados forneceram fortes evidências de que distribuição geométrica não é apropriada, rejeitamos alegação de que os dias de negociação são independentes. Embora não seja óbvio como explorar essa informação, ela sugere que há alguns padrões ocultos nos dados que podem ser interessantes e possivelmente úteis para um negociador de ações.","code":"\nres <- matrix(c(2.52,-1.46,0.51,-4.07,3.36,1.10,-5.46,-1.03,-2.99,1.71,\n                'Alta', 'Baixa', 'Alta', 'Baixa', 'Alta', \n                'Alta', 'Baixa', 'Baixa', 'Baixa', 'Alta', \n                1, '-', 2, '-', 2, 1, '-', '-', '-', 4), \n              ncol = 10, nrow = 3, byrow = TRUE)\n\nrownames(res) <- c('Mudança no preço', 'Resultado','Dias para aumentar')\n\nknitr::kable(res, align = 'c')\ndesc6 <- matrix(c('Observado', 1532, 760, 338, 194, 74, 33, 17, 2948), \n                nrow = 1, ncol = 9)\ncolnames(desc6) <- c('Dias', 1:6, '7+', 'Total')\n\nknitr::kable(desc6, align = 'c', caption = \"Distribuição observada dos dias de espera até que ocorra um dia de negociação positivo\")\ndesc7 <- matrix(c(1, 2, 3, 4, 5, 6, '7+', 'Total', \n                  1532, 760, 338, 194, 74, 33, 17, 2948,\n                  1569, 734, 343, 161, 75, 35, 31, 2948), ncol = 8, nrow = 3, byrow = TRUE)\n\nrownames(desc7) <- c('Dias', 'Observado', 'Modelo Geométrico')\n\nknitr::kable(desc7, align = 'c', caption = 'Distribuição do tempo de espera até um dia de negociação positivo. As contagens esperadas baseadas no modelo geométrico são mostradas na última linha.')\nbar_plot <- data.frame(quantidade = c(1532, 760, 338, 194, 74, 33, 17,\n                  1569, 734, 343, 161, 75, 35, 31), \n                  tipo = sort(rep(c('Observado', 'Esperado'), 7), decreasing = TRUE), \n                  dias = rep(c(1:6, '7+'), 2)) \n\nggplot(data = bar_plot, mapping = aes(x = dias, y = quantidade, fill = tipo)) + \n  labs(x = \"Espera até um dia positivo\", y = \"Frequência\", fill = NULL) + \n  geom_bar(position = \"dodge\", stat=\"identity\", color = 'black') + \n  theme(legend.position = 'bottom') + \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  scale_fill_manual(values = c('#EAB217', '#E6205F')) + \n  geom_hline(yintercept = 0, color = 'black')\nX = seq(0, 22, 0.005)\nY = dchisq(X, 6)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 15.08,], aes(X, ymin = 0, ymax = Y), colour=\"#E97C31\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)"},{"path":"ch6-inf-cat.html","id":"independenceTestBidirectionalTables","chapter":"6 Inferência para dados categóricos","heading":"6.4 Teste de independência em tabelas bidirecionais (tópico especial)","text":"O Google está constantemente executando experimentos para testar novos algoritmos de pesquisa. Por exemplo, o Google pode testar três algoritmos usando uma amostra de 10.000 consultas de pesquisa google.com. Tabela 6.8 mostra um exemplo de 10.000 consultas divididas em três grupos de algoritmos.246 Os tamanhos dos grupos foram especificados antes início experimento para ser 5000 para o algoritmo atual e 2500 para cada algoritmo de teste.Tabela 6.8: Divisão dos objetos de estudo experimento Google em três grupos de procura.O objetivo final é ver se há uma diferença desempenho dos algoritmos. hipóteses podem ser descritas como seguintes:\\(H_0\\): Os algoritmos executam igualmente bem.\\(H_0\\): Os algoritmos executam igualmente bem.\\(H_1\\): Os algoritmos não funcionam igualmente bem.\\(H_1\\): Os algoritmos não funcionam igualmente bem.Neste experimento, variável explicativa é o algoritmo de busca. entanto, uma variável de resultado também é necessária. Essa variável de resultado deve, de alguma forma, refletir se os resultados da pesquisa se alinham aos interesses usuário. Uma maneira possível de quantificar isso é determinar seo usuário clicou em um dos links fornecidos e não tentou uma nova pesquisa, ou\r\no usuário clicou em um dos links fornecidos e não tentou uma nova pesquisa, ouo usuário realizou uma pesquisa relacionada.\r\no usuário realizou uma pesquisa relacionada.cenário (1), podemos pensar que o usuário ficou satisfeito com os resultados da pesquisa. cenário (2), os resultados da pesquisa provavelmente não eram relevantes, então o usuário tentou uma segunda pesquisa.Tabela 6.9 fornece os resultados da experiência. Esses dados são muito semelhantes aos dados de contagem da Seção anterior. entanto, agora combinações diferentes de duas variáveis são categorizadas em uma tabela bidirecional. Ao examinar esses dados, queremos avaliar se há fortes evidências de que pelo menos um algoritmo apresenta um desempenho melhor que os outros. Para isso, aplicamos um teste de qui-quadrado essa tabela bidirecional. ideias deste teste são semelhantes àquelas idéias caso de uma tabela unidirecional. entanto, graus de liberdade e contagens esperadas são calculados de forma um pouco diferente que antes.Tabela 6.9: Resultados experimento algoritmo de pesquisa Google.O que é tão diferente entre tabelas unidirecionais e bidirecionais: Uma tabela unidirecional descreve contagens de cada resultado em uma única variável. Uma tabela bidirecional descreve contagens de combinações de resultados para duas variáveis. Quando consideramos uma tabela de bidirecional, muitas vezes gostaríamos de saber se essas variáveis estão relacionadas de alguma forma. Ou seja, eles são dependentes (versus independentes).O teste de hipótese para este experimento Google é realmente avaliar se há evidência estatisticamente significativa de que escolha algoritmo afeta se um usuário realiza uma segunda pesquisa. Em outras palavras, o objetivo é verificar se variável perquisa é independente da variável algorítimo.","code":"\ndesc8 <- matrix(c(5000, 2500, 2500, 10000), ncol = 4, nrow = 1)\n\ncolnames(desc8) <- c('atual', 'teste 1', 'teste 2', 'Total')\n\nknitr::kable(desc8, align = 'c', caption = 'Divisão dos objetos de estudo do experimento do Google em três grupos de procura.')\ndesc9 <- matrix(c(3511, 1749, 1818, 7078, \n                  1489, 751, 682, 2922, \n                  5000, 2500, 2500, 10000), ncol = 4, nrow = 3, byrow = TRUE)\n\ncolnames(desc9) <- c('atual', 'teste 1', 'teste 2', 'Total')\nrownames(desc9) <- c('Nenhuma nova procura', 'Nova procura', 'Total')\n\nknitr::kable(desc9, align = 'c', caption = 'Resultados do experimento do algoritmo de pesquisa do Google.')"},{"path":"ch6-inf-cat.html","id":"expectedCountsBidirectionalTables","chapter":"6 Inferência para dados categóricos","heading":"6.4.1 Contagens esperadas em tabelas bidirecionais","text":"Cerca de 70.78% dos 5.000 ficariam satisfeitos com pesquisa inicial:\\[ 0.7078 \\times 5000 = 3539 \\text{ usuários} \\]Ou seja, se não houvesse diferença entre os três grupos, esperaríamos que 3539 dos usuários atuais algoritmo não realizassem uma nova pesquisa.Podemos calcular o número esperado de usuários que realizariam uma nova pesquisa para cada grupo usando mesma estratégia empregada Exemplo 6.21 e na Prática Orientada 6.13. Essas contagens esperadas foram usadas para construir Tabela 6.10, que é o mesmo que Tabela 6.9, exceto agora, contagens esperadas foram adicionadas entre parênteses.Tabela 6.10: contagens observadas e contagens esperadas.Os exemplos e exercícios acima forneceram alguma ajuda cálculo das contagens esperadas. Em geral, contagens esperadas para uma tabela bidirecional podem ser calculadas usando os totais de linha, totais de coluna e o total da tabela. Por exemplo, se não houve diferença entre os grupos, cerca de 70.78% de cada coluna deve estar na primeira linha:\\[\\begin{align*}\r\n0.7078\\times (\\text{coluna 1 total}) &= 3539 \\\\\r\n0.7078\\times (\\text{coluna 2 total}) &= 1769.5 \\\\\r\n0.7078\\times (\\text{coluna 3 total}) &= 1769.5\r\n\\end{align*}\\]Olhando para trás, como fração 0.7078 foi computada - como fração de usuários que não realizaram uma nova busca (\\(7078/10000\\)) - estas três contagens esperadas poderiam ter sido computadas como\\[\\begin{align*}\r\n\\left(\\frac{\\text{linha 1 total}}{\\text{tabela total}}\\right)\\text{(coluna 1 total)} &= 3539 \\\\\r\n\\left(\\frac{\\text{linha 1 total}}{\\text{tabela total}}\\right)\\text{(coluna 2 total)} &= 1769.5 \\\\\r\n\\left(\\frac{\\text{linha 1 total}}{\\text{tabela total}}\\right)\\text{(coluna 3 total)} &= 1769.5\r\n\\end{align*}\\]Isso nos leva uma fórmula geral para calcular contagens esperadas em uma tabela bidirecional quando gostaríamos de testar se há fortes evidências de uma associação entre variável coluna e variável linha.Contagem esperada em uma tabela bidirecional: Para identificar contagem esperada para \\(\\) linha e \\(j\\) coluna, calcule\r\n\\[\\text{ Contagem esperada }_{\\text{linha },\\text{ col }j} = \\frac{(\\text{linha $$ total}) \\times  (\\text{coluna $j$ total})}{\\text{tabela total}}\\]","code":"\ndesc10 <- matrix(c('3511 (3539)', '1749 (1769.5)', '1818 (1769.5)', '7078', \n                  '1489 (1461)', '751 (730.5)', '682 (730.5)', '2922', \n                  5000, 2500, 2500, 10000), ncol = 4, nrow = 3, byrow = TRUE)\n\ncolnames(desc10) <- c('atual', 'teste 1', 'teste 2', 'Total')\nrownames(desc10) <- c('Nenhuma nova procura', 'Nova procura', 'Total')\n\nknitr::kable(desc10, align = 'c', caption = 'As contagens observadas e as contagens esperadas.')"},{"path":"ch6-inf-cat.html","id":"chiSquareTestBidirectionalTables","chapter":"6 Inferência para dados categóricos","heading":"6.4.2 O teste qui-quadrado para tabelas bidirecionais","text":"estatística de teste qui-quadrado para uma tabela bidirecional é encontrada da mesma maneira que é encontrada para uma tabela unidirecional. Para cada contagem de tabela, calcule\\[\\begin{align*}\r\n&\\text{ Fórmula geral }& &\\frac{(\\text{ contagem observada } - \\text{ contagem esperada})^2}{\\text{contagem esperada}} \\\\\r\n&\\text{Linha 1, Coluna 1}& &\\frac{(3511 - 3539)^2}{3539} = 0.222 \\\\\r\n&\\text{Linha 1, Coluna 2}& &\\frac{(1749 – 1769.5)^2}{1769.5} = 0.237 \\\\\r\n& \\hspace{9mm}\\vdots & &\\hspace{13mm}\\vdots \\\\\r\n&\\text{Linha 2, Coluna 3}& &\\frac{(682 – 730.5)^2}{730.5} = 3.220\r\n\\end{align*}\\]Adicionar o valor computado para cada célula fornece estatística de teste de qui-quadrado \\(\\chi^2\\):\\[\\chi^2 = 0.222 + 0.237 + \\dots + 3.220 = 6.120\\]Assim como antes, esta estatística de teste segue uma distribuição qui-quadrado. entanto, os graus de liberdade são calculados de forma um pouco diferente para uma tabela bidirecional.248 Para tabelas bidirecionais, os graus de liberdade é igual \\[\\begin{align*}\r\ngl = \\text{(número de linha menos 1)}\\times \\text{(número de colunas menos 1)}\r\n\\end{align*}\\]Em nosso exemplo, o parâmetro graus de liberdade é\\[\\begin{align*}\r\ngl = (2-1)\\times (3-1) = 2\r\n\\end{align*}\\]Se hipótese nula é verdadeira (ou seja, os algoritmos são igualmente úteis), então estatística de teste \\(\\chi^2 = 6.12\\) segue de perto uma distribuição qui-quadrado com 2 graus de liberdade. Usando esta informação, podemos calcular o p-valor para o teste, que é representado na Figura 6.12.\r\nFigura 6.12: Calculando o p-valor para o teste de hipóteses Google.\r\nGraus de computação de liberdade para uma tabela bidirecional: Ao aplicar o teste qui-quadrado uma tabela bidirecional, usamos\\[gf = (R-1)\\times (C-1)\\]onde \\(R\\) é o número de linhas na tabela e $ C $ é o número de colunas.Use métodos de duas proporções para tabelas de contingência de 2 por 2: Ao analisar tabelas de contingência \\(2\\times 2\\), use os métodos de duas proporções introduzidos anteriormente.Pela tabela da distribuição \\(\\chi^2\\), examinamos linha correspondente 2 graus de liberdade. estatística de teste, \\(\\chi^2 = 6.120\\), fica entre quarta e quinta colunas, o que significa que o valor p está entre 0.02 e 0.05. Como normalmente testamos em um nível de significância de \\(\\alpha = 0.05\\) e o p-valor é menor que 0.05, hipótese nula é rejeitada. Ou seja, os dados fornecem evidências convincentes de que há alguma diferença desempenho entre os algoritmos.\\(H_0\\): Não há diferença nas classificações de aprovação entre os três grupos.\\(H_1\\): Existe alguma diferença nas classificações de aprovação entre os três grupos, .é., talvez aprovação de Obama seja diferente dos democratas Congresso.Tabela 6.11: Resultados da pesquisa Pew Research de março de 2012.","code":"\nX = seq(0, 15, 0.005)\nY = dchisq(X, 2)\ngg <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) +\n  geom_linerange(data = gg[gg$X > 6.12,], aes(X, ymin = 0, ymax = Y), colour=\"#EAB217\") +\n  geom_path(size = 1) + \n  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), \n        axis.ticks.y = element_blank()) + labs(x = NULL) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) +\n  geom_hline(yintercept = 0, color = 'white', size = 1)\ndem_table <- rbind(c(842, 736, 541, 2119),\n                   c(616, 646, 842, 2104),\n                   c(1458, 1382, 1382, 4223))\n  \ncolnames(dem_table) <- c('Obama','Democratas','Republicanos','Total')\nrownames(dem_table) <- c('Aprovam', 'Desaprovam', 'Total')\n\n\nknitr::kable(dem_table, align = \"c\", \n             caption = 'Resultados da pesquisa Pew Research de março de 2012.')"},{"path":"ch6-inf-cat.html","id":"smallSampleHTForProportion","chapter":"6 Inferência para dados categóricos","heading":"6.5 Teste de hipótese em amostra pequena para uma proporção (tópico especial)","text":"Nesta seção, desenvolvemos métodos inferenciais para uma única proporção que são apropriados quando o tamanho da amostra é muito pequeno para aplicar o modelo normal \\(\\hat{p}\\). Assim como os métodos relacionados à distribuição-\\(t\\), esses métodos também podem ser aplicados grandes amostras.","code":""},{"path":"ch6-inf-cat.html","id":"failureSuccessConditionNotMet","chapter":"6 Inferência para dados categóricos","heading":"6.5.1 Quando a condição de falha ou sucesso não é atendida","text":"pessoas que fornecem um órgão para doação às vezes procuram ajuda de um “consultor médico” especial. Esses consultores auxiliam o paciente em todos os aspectos da cirurgia, com o objetivo de reduzir possibilidade de complicações durante o procedimento médico e recuperação. Os pacientes podem escolher um consultor com base, em parte, na taxa de complicações históricas dos clientes consultor. Um consultor tentou atrair pacientes observando que taxa média de complicações para cirurgias de doadores de fígado nos EUA é de cerca de 10%, mas seus clientes só tiveram 3 complicações nas 62 cirurgias de doação de fígado que ele facilitou. Ele afirma que isso é uma forte evidência de que seu trabalho contribui significativamente para reduzir complicações (e, portanto, ele deve ser contratado!).Não. alegação é de que existe uma conexão causal, mas os dados são observacionais. Pacientes que contratam esse consultor médico podem apresentar menores taxas de complicações por outras razões.Embora não seja possível avaliar essa alegação causal, ainda é possível testar uma associação usando esses dados. Para esta questão, perguntamos, poderia baixa taxa de complicações de \\(\\hat{p} = 0.048\\) ser devida ao acaso?suposição de independência pode ser razoável se cada uma das cirurgias de uma equipe cirúrgica diferente. entanto, condição de falha-sucesso não é satisfeita. Sob hipótese nula, nós anteciparíamos ver \\(62 \\times 0.1=6.2\\) complicações, não 10 necessárias para aproximação normal.incerteza associada à proporção da amostra não deve ser modelada usando distribuição normal. entanto, ainda gostaríamos de avaliar hipóteses da Prática Orientada 6.18 na ausência quadro normal. Para fazer isso, precisamos avaliar possibilidade de um valor de amostra (\\(\\hat{p}\\)) estar muito abaixo valor nulo, \\(p_0 = 0.10\\). Essa possibilidade é geralmente medida com um p-valor.O p-valor é calculado com base na distribuição nula, que é distribuição da estatística de teste se hipótese nula verdadeira. Supondo que hipótese nula é verdadeira, podemos calcular o p-valor identificando chance de observar uma estatística de teste que favoreça hipótese alternativa pelo menos tão fortemente quanto estatística de teste observada. Isso pode ser feito usando simulação.","code":""},{"path":"ch6-inf-cat.html","id":"simulationNullDistribution","chapter":"6 Inferência para dados categóricos","heading":"6.5.2 Gerando a distribuição nula e o p-valor por simulação","text":"Queremos identificar distribuição amostral da estatística de teste (\\(\\hat{p}\\)) se hipótese nula verdadeira. Em outras palavras, queremos ver como proporção da amostra muda apenas pelo acaso. Então, planejamos usar essa informação para decidir se há evidência suficiente para rejeitar hipótese nula.Sob hipótese nula, 10% dos doadores de fígado apresentam complicações durante ou após cirurgia. Suponha que essa taxa realmente não fosse diferente para os clientes consultor. Se este fosse o caso, poderíamos simular 62 clientes para obter uma proporção de amostra para taxa de complicação da distribuição nula.Cada cliente pode ser simulado usando um baralho de cartas. Pegue uma carta vermelha, nove cartas pretas e misture-. Então, pegar uma carta baralho é uma maneira de simular chance de um paciente ter uma complicação, se taxa de complicação verdadeira 10% para os dados. Se fizermos isso 62 vezes e calcularmos proporção de pacientes com complicações na simulação, \\(\\hat{p}_{sim}\\), então essa proporção de amostra é exatamente uma amostra da distribuição nula.Um estudante de graduação foi pago $2 para concluir esta simulação. Houve 5 casos simulados com uma complicação e 57 casos simulados sem uma complicação, ou seja, \\(\\hat{p}_{sim}=5/6 =0.081\\).Não. Para avaliar hipóteses, precisamos ver uma distribuição de muitos \\(\\hat{p _{sim}}\\), não apenas um sorteio único dessa distribuição amostral.Uma simulação não é suficiente para ter uma noção da distribuição nula; muitos estudos de simulação são necessários. Aproximadamente 10.000 parecem suficientes. entanto, pagar alguém para simular 10 mil estudos à mão é perda de tempo e dinheiro. Em vez disso, simulações são geralmente programadas em um computador, o que é muito mais eficiente.Figura 6.13 mostra os resultados de 10.000 estudos simulados. proporções iguais ou inferiores \\(\\hat{p}=0.048\\) estão sombreadas. áreas sombreadas representam proporções de amostra sob distribuição nula que fornecem pelo menos tanta evidência quanto \\(\\hat{p}\\) favorecendo hipótese alternativa. Houve 1222 proporções de amostras simuladas com \\(\\hat{p _{sim}} \\leq 0.048\\). Usamos isso para construir área da cauda esquerda da distribuição nula e encontrar o p-valor:\\[\\begin{align}\r\n\\text{cauda esquerda }\r\n    &= \\frac{\\text{ Número de simulações observadas com }\\hat{p}_{sim}\\leq\\text{ 0.048}}{10000}\r\n    \\tag{6.3}\r\n\\end{align}\\]Dos 10.000 simulados \\(\\hat{p}_{sim}\\), 1222 eram iguais ou menores que \\(\\hat{p}\\). Como o teste de hipótese é unilateral, o p-valor estimado é igual essa área de cauda: 0.1222.\r\nFigura 6.13: distribuição nula, criado partir de 10.000 estudos simulados. cauda esquerda, representando o p-valor para o teste de hipótese, contém 12.22% das simulações.\r\nTeste de hipótese unilateral para \\(p\\) com uma amostra pequena: O p-valor é sempre derivado, analisando distribuição nula da estatística de teste. O modelo normal se aproxima pouco da distribuição nula de \\(\\hat{p}\\) quando condição de falha-sucesso não é satisfeita. Como substituto, podemos gerar distribuição nula usando proporções de amostra simuladas (\\(\\hat{p}_{sim}\\)) e usar essa distribuição para calcular área final, ou seja, o p-valor.Continuamos usar mesma regra de antes ao calcular o p-valor para um teste bilateral: o dobro da área de cauda única, que permanece uma abordagem razoável mesmo quando distribuição de amostragem é assimétrica. entanto, isso pode resultar em p-valores maiores que 1 quando estimativa pontual estiver muito próxima da média na distribuição nula; em tais casos, escrevemos que o p-valor é 1. Além disso, p-valores muito grandes calculados dessa maneira (por exemplo, 0.85) também podem ser levemente inflados.Prática Orientada 6.19 disse que o p-valor é estimado. Não é exato porque distribuição nula simulada em si não é exata, apenas uma aproximação aproximada. entanto, podemos gerar uma distribuição nula e um p-valor exatos usando o modelo binomial.","code":"\nset.seed(2)\npHat <- rbinom(10^4, 62, 0.1) / 62\nM    <- max(pHat) * 62\n\nggplot() + \n  stat_bin(aes(x = pHat), breaks = (-1:(2 * M) + 0.75) / 2 / 62) + \n  labs(x = expression(hat(p)[sim]*\"    \"), y = 'Número de Simulações') + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  scale_x_continuous(breaks = seq(0, 0.25, 0.05)) + \n  stat_bin(aes(x = pHat[pHat < 0.05]), breaks = (-1:(2 * M) + 0.75) / 2 / 62, fill = 'skyblue3') "},{"path":"ch6-inf-cat.html","id":"exactNullDistributionUsingBinomialModel","chapter":"6 Inferência para dados categóricos","heading":"6.5.3 Gerando a distribuição nula e o p-valor exatos","text":"O número de sucessos em \\(n\\) casos independentes pode ser descrito usando o modelo binomial, que foi introduzido anteriormente. Lembre-se que probabilidade de observar exatamente \\(k\\) sucessos é dada por\\[\\begin{align} \r\nP(k\\text{ successos}) = {n\\choose k} p^{k}(1-p)^{n-k} = \\frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k}\r\n\\tag{6.4}\r\n\\end{align}\\]onde \\(p\\) é verdadeira probabilidade de sucesso. expressão \\({n\\choose k}\\) é lida como \\(n\\) escolhe \\(k\\), e os pontos de exclamação representam fatoriais. Por exemplo, \\(3!\\) é igual $   = 6$, \\(4!\\) é igual \\(4 \\times 3 \\times 2 \\times 1 = 24\\), e assim por diante.área final da distribuição nula é calculada somando probabilidade na Equação (6.4) para cada \\(k\\) que fornece pelo menos uma evidência tão forte que favorece hipótese alternativa quanto os dados. Se o teste de hipótese unilateral, o p-valor é representado por uma única área de cauda. Se o teste bilateral, calcule área de cauda única e duplique para obter o p-valor, como fizemos passado.Exatamente \\(k = 3\\) complicações foram observadas nos casos \\(n = 62\\) citados pelo consultor. Como estamos testando contra média nacional de 10%, nossa hipótese nula é \\(p = 0.10\\). Podemos calcular o p-valor somando os casos em que há 3 ou menos complicações:\\[\\begin{align*}\r\n\\text{p-value}\r\n    &= \\sum_{j=0}^{3} {n\\choose j} p^{j}(1-p)^{n-j} \\\\\r\n    &= \\sum_{j=0}^{3} {62\\choose j} 0.1^{j}(1-0.1)^{62-j} \\\\\r\n    &= {62\\choose 0} 0.1^{0}(1-0.1)^{62-0} +\r\n        {62\\choose 1} 0.1^{1}(1-0.1)^{62-1} \\\\\r\n    & \\qquad + {62\\choose 2} 0.1^{2}(1-0.1)^{62-2} +\r\n        {62\\choose 3} 0.1^{3}(1-0.1)^{62-3} \\\\\r\n    &= 0.0015 + 0.0100 + 0.0340 + 0.0755 \\\\\r\n    &= 0.1210\r\n\\end{align*}\\]Esse p-valor exato está muito próximo p-valor baseado nas simulações (0.1222), e chegamos à mesma conclusão. Não rejeitamos hipótese nula e não há evidências estatisticamente significativas para apoiar associação.Se fosse plotada, distribuição nula exata seria quase idêntica à distribuição nula simulada mostrada na Figura 6.13.","code":""},{"path":"ch6-inf-cat.html","id":"simulationFitnessTests","chapter":"6 Inferência para dados categóricos","heading":"6.5.4 Usando simulação para testes de adequação","text":"Métodos de simulação também podem ser usados para testar adequação ajuste. Em suma, simulamos uma nova amostra com base nas probabilidades de intervalo supostas e, em seguida, calculamos uma estatística de teste de qui-quadrado \\(X_{sim}^2\\). Fazemos isso muitas vezes (por exemplo, 10.000 vezes) e, em seguida, examinamos distribuição dessas estatísticas de teste de qui-quadrado simuladas. Esta distribuição será uma distribuição nula muito precisa para estatística de teste \\(\\chi^2\\). Se probabilidades forem precisas, podemos encontrar cauda superior dessa distribuição nula, usando um corte da estatística de teste observada, para calcular o p-valor.Como condição de contagem de intervalo mínimo foi satisfeita, distribuição qui-quadrado é uma excelente aproximação da distribuição nula, o que significa que os resultados devem ser muito semelhantes. Figura 6.14 mostra distribuição nula simulada usando 100.000 valores de \\(X_{sim}^2\\) com uma curva sobreposta da distribuição qui-quadrado. distribuições são quase idênticas e os p-valores são essencialmente indistinguíveis: 0.115 para distribuição nula simulada e 0.117 para distribuição nula teórica.\r\nFigura 6.14: distribuição nula precisa para o exemplo é mostrado como um histograma de simulação estatística e distribuição teórica qui-quadrado também é mostrada.\r\n","code":"\nset.seed(2)\np  <- c(0.72, 0.07, 0.12, 0.09)\nN  <- 1e5\nCC <- rmultinom(N, 275, p)\nEE <- p * 275\nX2 <- colSums((CC - EE)^2/EE)\n\nX <- c(seq(0, 1, 0.01),\n       seq(1.1, 50, 0.1))\nY <- dchisq(X, 3)\n\nggplot() + \n  geom_histogram(aes(x = X2, y=..density..), bins = 50, color = 'white') + \n  geom_line(aes(X,Y), color = 'skyblue3', size = 1) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  labs(expression(\"Chi-square test statistic (\"*X^2*\")\")) + \n  theme(axis.line.y = element_blank(), axis.ticks.y = element_blank(), \n        axis.title.y = element_blank(), axis.text.y = element_blank()) + \n  annotate(geom = \"text\", x = 12, y = 0.12, label = expression(X^2* ' Observado'), color = 'skyblue3')"},{"path":"ch6-inf-cat.html","id":"smallSampleHTForTwoOrMoreProportion","chapter":"6 Inferência para dados categóricos","heading":"6.6 Teste de randomização (tópico especial)","text":"ressuscitação cardiopulmonar (RCP) é um procedimento comumente usado em indivíduos que sofrem um ataque cardíaco quando outros recursos de emergência não estão disponíveis. Este procedimento é útil para manter alguma circulação sanguínea, mas compressões torácicas envolvidas também podem causar lesões internas. Sangramento interno e outras lesões complicam os esforços adicionais de tratamento após chegada ao hospital. Por exemplo, os anticoagulantes podem ser usados para liberar um coágulo responsável por um ataque cardíaco. entanto, o sangue mais fino afetaria negativamente o sangramento interno.Consideramos um experimento para pacientes que sofreram RCP por um ataque cardíaco e foram posteriormente internados em um hospital257. Esses pacientes foram divididos aleatoriamente em um grupo de tratamento em que receberam um anticoagulante ou o grupo de controle onde não receberam um anticoagulante. variável resultante de interesse foi se os pacientes sobreviveram por pelo menos 24 horas.Estamos interessados em saber se os anticoagulantes são úteis ou prejudiciais, portanto, um teste bilateral é apropriado.\\(H_0\\): Anti-coagulantes não têm um efeito de sobrevivência global, ou seja, proporções de sobrevivência são mesmas em cada grupo. \\(p_t - p_c = 0\\).\\(H_0\\): Anti-coagulantes não têm um efeito de sobrevivência global, ou seja, proporções de sobrevivência são mesmas em cada grupo. \\(p_t - p_c = 0\\).\\(H_1\\):]Anti-coagulantes têm um impacto na sobrevivência. \\(p_t - p_c \\neq 0\\).\\(H_1\\):]Anti-coagulantes têm um impacto na sobrevivência. \\(p_t - p_c \\neq 0\\).","code":""},{"path":"ch6-inf-cat.html","id":"largeSampleStructureDifferenceTwoProportions","chapter":"6 Inferência para dados categóricos","heading":"6.6.1 Estrutura de amostra grande para uma diferença em duas proporções","text":"Havia 50 pacientes experimento que não receberam o anti-coagulante e 40 pacientes que o fizeram. Os resultados estudo são mostrados na Tabela 6.12.Tabela 6.12: Resultados para o estudo RCP. Os pacientes grupo de tratamento receberam um anticoagulante e os pacientes grupo de controle não.De acordo com estimativa pontual, para pacientes que sofreram RCP fora hospital, 13% adicionais sobrevivem quando são tratados com anticoagulantes. entanto, essa diferença pode ser explicada pelo acaso. Gostaríamos de investigar isso usando uma estrutura de amostra grande, mas primeiro precisamos verificar condições de tal abordagem.Vamos supor que os pacientes sejam independentes, o que provavelmente é razoável. condição de falha-sucesso também é satisfeita. Como proporções são iguais sob distribuição nula, podemos calcular proporção combinada, \\(\\hat{p} = (11+14)/(50+40) = 0.278\\), para verificar condições. Encontramos o número esperado de sucessos (13.9, 11.1) e falhas (36.1, 28.9) acima de 10. O modelo normal é razoável.Embora possamos aplicar uma estrutura normal como uma aproximação para encontrar um p-valor, podemos ter em mente que o número esperado de sucessos é de apenas 13.9 em um grupo e 11.1 outro. Abaixo, conduzimos uma análise com base na teoria normal da amostra grande. Vamos acompanhar com uma pequena amostra de análise e comparar os resultados.Supomos que distribuição nula da diferença amostral segue uma distribuição normal com média 0 (o valor nulo) e um desvio padrão igual ao erro padrão da estimativa. hipótese nula neste caso seria que duas proporções são mesmas, então calculamos o erro padrão usando proporção combinada:\\[\\begin{align*}\r\nEP = \\sqrt{\\frac{p(1-p)}{n_t} + \\frac{p(1-p)}{n_c}}\r\n    \\approx \\sqrt{\\frac{0,278(1-0,278)}{40} + \\frac{0,278(1-0,278)}{50}} = 0,095\r\n\\end{align*}\\]onde usamos estimativa combinada \\(\\left( \\hat{p} = \\frac{11+14}{50 + 40} = 0.278 \\right)\\) lugar da proporção verdadeira, \\(p\\).distribuição nula com média zero e desvio padrão de 0.095 é mostrada na Figura 6.15. Calculamos áreas finais para identificar o p-valor. Para fazer isso, usamos o escore Z da estimativa pontual:\\[\\begin{align*}\r\nZ = \\frac{(\\hat{p}_t - \\hat{p}_c) - \\text{valor nulo}}{EP} = \\frac{0.13 - 0}{0.095} = 1.37\r\n\\end{align*}\\]Se olharmos este Z-escore, vemos que cauda direita tem área 0.0853. O p-valor é duas vezes área da cauda única: 0.1706. Este p-valor não fornece evidências convincentes de que o anticoagulante ajuda. Assim, não há evidências suficientes para concluir se ele ajuda ou atrapalha. (Lembre-se, nós nunca “aceitamos” hipótese nula – só podemos rejeitar ou deixar de rejeitar.)\r\nFigura 6.15: distribuição nula da estimativa pontual sob estrutura de amostra grande é uma distribuição normal com média de 0 e desvio padrão igual ao erro padrão, neste caso EP = 0.095. O p-valor é representado pelas áreas sombreadas.\r\nO p-valor, 0.176, depende da aproximação normal. Sabemos que quando os tamanhos das amostras são grandes, essa aproximação é muito boa. entanto, quando os tamanhos das amostras são relativamente pequenos, como neste exemplo, aproximação pode ser apenas adequada. Em seguida, desenvolvemos uma técnica de simulação, aplicamos esses dados e comparamos nossos resultados. Em geral, o método de amostra pequena que desenvolvemos pode ser usado para qualquer tamanho de amostra, pequeno ou grande, e deve ser considerado mais preciso que técnica de amostra grande correspondente.","code":"\ncpr_table <- rbind(c(11, 39, 50),\n                   c(14, 26, 40),\n                   c(26, 65, 90))\n\ncolnames(cpr_table) <- c('Sobreviveu','Morreu','Total')\nrownames(cpr_table) <- c('Controle', 'Tratamento', 'Total')\n\nknitr::kable(cpr_table, align = 'c', \n             caption = 'Resultados para o estudo RCP. Os pacientes do grupo de tratamento receberam um anticoagulante e os pacientes do grupo de controle não.')\nset.seed(1)\nm <- 0\ns <- 0.0955\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < -0.0853 | gg$X > 0.0853,], \n                 aes(X, ymin = 0, ymax = Y), color = \"skyblue3\") +\n  geom_path(size = 1) + ylim(0, 5) +\n  scale_x_continuous(breaks = round(seq(m - 3*s, m + 3*s, s),2)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1)) + \n  geom_segment(aes(x = 0.0853, y = 0, xend = 0.0853, yend = 2.8), linetype = 'dashed') +\n  annotate(geom = \"text\", x = 0.16, y = 2.9, label = expression(hat(p)[t]-hat(p)[c]) , color = 'black')"},{"path":"ch6-inf-cat.html","id":"simulatingDifferenceNullDistribution","chapter":"6 Inferência para dados categóricos","heading":"6.6.2 Simulando uma diferença sob a distribuição nula","text":"Suponha que hipótese nula seja verdadeira. Então o sangue mais fino não tem impacto na sobrevivência e diferença de 13% foi devida ao acaso. Neste caso, podemos simular diferenças nulas que são devidas ao acaso usando uma técnica de randomização259. Ao atribuir aleatoriamente adesivos “tratamento falso” e “controle falso”\" aos arquivos dos pacientes, poderíamos obter um novo agrupamento - um que é completamente devido ao acaso. diferença esperada entre duas proporções sob esta simulação é zero.Nós executamos esta simulação levando 40 rótulos tratamento\\_falso e 50 rótulos controle\\_falso e atribuindo-os aleatoriamente aos pacientes. contagens de rótulos de 40 e 50 correspondem ao número de tarefas de tratamento e controle estudo atual. Usamos um programa de computador para atribuir aleatoriamente esses rótulos aos pacientes, e organizamos os resultados da simulação na Tabela 6.13.Tabela 6.13:  Resultados simulados para o estudo RPC sob hipótese nula. Os rótulos foram distribuídos aleatoriamente e são independentes resultado paciente.diferença calculada na Prática Orientada 6.22 representa um empate da distribuição nula com diferenças de amostra. Em seguida, geramos muitos experimentos simulados para construir distribuição nula, para construir uma distribuição nula para uma proporção de uma amostra.simulação caso de duas proporções requer que diferença nula seja zero: técnica descrita aqui para simular uma diferença da distribuição nula depende de uma condição importante na hipótese nula: não há conexão entre duas variáveis consideradas. Em alguns casos especiais, diferença nula pode não ser zero, e métodos mais avançados (ou uma grande aproximação de amostra, se apropriado) seriam necessários.","code":"\ncpr_small <- rbind(c(15, 35, 50),\n                   c(10, 30, 40),\n                   c(25, 65, 90))\n\ncolnames(cpr_small) <- c('Sobreviveu','Morreu','Total')\nrownames(cpr_small) <- c('controle_falso','tratamento_falso','Total')\n\nknitr::kable(cpr_small, align = 'c', caption = ' Resultados simulados para o estudo RPC sob a hipótese nula. Os rótulos foram distribuídos aleatoriamente e são independentes do resultado do paciente.')"},{"path":"ch6-inf-cat.html","id":"nullDistributionDifferenceTwoProportions","chapter":"6 Inferência para dados categóricos","heading":"6.6.3 Distribuição nula para a diferença em duas proporções","text":"Construímos uma aproximação para distribuição nula criando repetidamente tabelas como mostrada na Tabela 6.13 e calcular diferenças de amostra. distribuição nula de 10.000 simulações é mostrada na Figura 6.16.\r\nFigura 6.16: Uma aproximação da distribuição nula da estimativa pontual. O p-valor é o dobro da área da cauda direita.\r\nformas são semelhantes, mas os resultados simulados mostram que aproximação contínua da distribuição normal não é muito boa. Podemos nos perguntar, quão próximos estão os p-valores?Em geral, métodos de amostragem pequena produzem resultados mais precisos, pois dependem de menos suposições. entanto, eles geralmente exigem algum trabalho extra ou simulações. Por esse motivo, muitos estatísticos usam métodos de amostra pequena somente quando condições para métodos de amostra grande não são satisfeitas.","code":"\nset.seed(1)\ntr <- rep(1:2, c(50, 40))\nsu <- c(rep(c(\"s\", \"d\"), c(11, 39)),\n        rep(c(\"s\", \"d\"), c(14, 26)))\n\nN <- 10^5\nd <- rep(NA, N)\nfor (i in 1:N) {\n  trf  <- sample(tr)\n  p1   <- sum(su[trf == 1] == \"s\") / 50\n  p2   <- sum(su[trf == 2] == \"s\") / 40\n  d[i] <- p2 - p1\n}\n\nggplot() + \n  stat_bin(aes(x = d), breaks = seq(-0.4, 0.4, 0.02)) + \n  labs(x = 'Diferenças sob a hipótese nula', y = NULL) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  scale_x_continuous(breaks = seq(-.4, 0.4, 0.2)) + \n  stat_bin(aes(x = d[d > 0.1299]), breaks = seq(-0.4, 0.4, 0.02), fill = 'skyblue3') +\n  annotate(geom = \"text\", x = 0.18, y = 10000, label = '0.13') + \n  geom_segment(aes(x = 0.13, y = 0, xend = 0.13, yend = 10000), \n               linetype = 'dashed')"},{"path":"ch6-inf-cat.html","id":"randomizationBidirectionalChiSquareTables","chapter":"6 Inferência para dados categóricos","heading":"6.6.4 Randomização para tabelas bidirecionais e qui-quadrado","text":"Métodos de randomização também podem ser usados para tabelas de contingência. Em suma, criamos uma tabela de contingência aleatória e, em seguida, calculamos uma estatística de teste de qui-quadrado \\(X_ {sim}^2\\). Repetimos isso várias vezes usando um computador e examinamos distribuição dessas estatísticas de teste simuladas. Essa abordagem de randomização é válida para qualquer amostra de tamanho e será mais precisa para casos em que uma ou mais contagens esperadas de intervalo não atinjam o limite mínimo de 5. Quando o limite mínimo é atingido, distribuição nula simulada se assemelhará muito com distribuição qui-quadrado. Como antes, usamos cauda superior da distribuição nula para calcular o p-valor.","code":""},{"path":"ch7-reg-simples.html","id":"ch7-reg-simples","chapter":"7 Introdução à Regressão Linear","heading":"7 Introdução à Regressão Linear","text":"regressão linear é uma técnica estatística muio poderosa. Muitas pessoas têm alguma familiaridade com regressão apenas lendo notícias, onde gráficos com linhas retas são sobrepostos em gráficos de dispersão. Modelos lineares podem ser usados para previsão ou para avaliar se existe uma relação linear entre duas variáveis numéricas.Figura 7.1 mostra duas variáveis cuja relação pode ser modelada perfeitamente com uma linha reta. equação da linha é\\[\\begin{eqnarray*}\r\ny = 5 + 57.49x\r\n\\end{eqnarray*}\\]Imagine o que um relacionamento linear perfeito significaria: você saberia o valor exato de \\(y\\) apenas conhecendo o valor de \\(x\\). Isso não é realista em quase todos os processos naturais. Por exemplo, se tomarmos renda familiar \\(x\\), esse valor fornecerá algumas informações úteis sobre quanto apoio financeiro \\(y\\) que faculdade pode oferecer um aluno em potencial. entanto, ainda haveria variabilidade apoio financeiro, mesmo quando se comparasse alunos cujas famílias tivessem históricos financeiros semelhantes.\r\nFigura 7.1: Solicitações de doze compradores separados foram colocadas simultaneamente com uma empresa comercial para comprar ações da Target Corporation (ticker TGT, April 26th, 2012), e o custo total das ações foram relatados. Porque o custo é calculado usando uma fórmula linear, o ajuste linear é perfeito.\r\nregressão linear assume que o relacionamento entre duas variáveis, \\(x\\) e \\(y\\), pode ser modelado por uma linha reta:\\[\\begin{eqnarray}\r\ny = \\beta_0 + \\beta_1x\r\n\\tag{7.1}\r\n\\end{eqnarray}\\]\r\nonde \\(\\beta_0\\) e \\(\\beta_1\\) representam dois parâmetros modelo (\\(\\beta\\) é letra grega beta). Esses parâmetros são estimados usando dados e escrevemos suas estimativas pontuais como \\(b_0\\) e \\(b_1\\). Quando usamos \\(x\\) para prever \\(y\\), geralmente chamamos \\(x\\) da variável explicativa ou preditora, e chamamos \\(y\\) de resposta.É raro que todos os dados caiam em linha reta, como visto nos três diagramas de dispersão na Figura 7.2. Em cada caso, os dados caem em uma linha reta, mesmo que nenhuma das observações caia exatamente na linha. O primeiro gráfico mostra uma tendência linear descendente relativamente forte, em que variabilidade restante nos dados ao redor da linha é menor em relação à força relacionamento entre \\(x\\) e \\(y\\). O segundo gráfico mostra uma tendência ascendente que, embora evidente, não é tão forte quanto primeira. O último gráfico mostra uma tendência de queda muito fraca nos dados, tão pequena que mal podemos notar. Em cada um desses exemplos, teremos alguma incerteza em relação às nossas estimativas dos parâmetros modelo, \\(\\beta_0\\) e \\(\\beta_1\\). Por exemplo, podemos nos perguntar, devemos mover linha para cima ou para baixo um pouco, ou devemos incliná-la mais ou menos? À medida que avançamos neste capítulo, aprenderemos diferentes critérios de ajuste linear e também aprenderemos sobre incerteza associada às estimativas dos parâmetros modelo.\r\nFigura 7.2:  Três conjuntos de dados em que um modelo linear pode ser útil, mesmo que os dados não caiam exatamente na linha.\r\nTambém veremos exemplos neste capítulo em que encaixar uma linha reta nos dados, mesmo que haja uma relação clara entre variáveis, não é útil. Um desses casos é mostrado na Figura 7.3 onde há uma relação muito forte entre variáveis, embora tendência não seja linear. Vamos discutir tendências não-lineares neste capítulo e próximo, mas os detalhes da montagem de modelos não lineares são salvos para um curso posterior.\r\nFigura 7.3: Um modelo linear não é útil neste caso não linear. Esses dados são de um experimento de física introdutória.\r\n","code":"\nset.seed(4)\nx <- sample(33, 12, prob = c(33:24, 11:33))\ny <- 5 + 57.49 * x\n\n\nggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) +\n  labs(x = 'Número de ações da Target Corporation para comprar', \n       y = 'Custo total das ações (dólares)') + \n  geom_smooth(aes(x, y), color = 'black', se = FALSE, \n              method = 'lm', formula = y ~ x, linetype = 'dashed') + \n  geom_point(aes(x, y), color = 'skyblue3', size = 2) \nlibrary(openintro)\ndata(COL)\n\nn <- c(75, 49, 376)\n\nset.seed(3)\n\n\nx1 <- rnorm(n[1], 16, 33)\ny1 <- 14 - 0.8 * x1 + rnorm(n[1], sd = 12)\n\nx2 <- rnorm(n[2], 1052, 300)\ny2 <- 1400 + 7 * x2 + rnorm(n[2], sd = 4020)\n\nx3 <- c(rnorm(100, 20, 8), runif(n[3] - 100, -10, 52))\ny3 <- 140 - 0.15 * x3 + rnorm(n[3], sd = 102)\n\ng1 <- ggplot(mapping = aes(x1, y1)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(x = NULL, y = NULL) + \n  geom_smooth(formula = y ~ x, se = FALSE, method = 'lm', color = 'black')\n\ng2 <- ggplot(mapping = aes(x2, y2)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(x = NULL, y = NULL) + \n  geom_smooth(formula = y ~ x, se = FALSE, method = 'lm', color = 'black')\n\ng3 <- ggplot(mapping = aes(x3, y3)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(x = NULL, y = NULL) + \n  geom_smooth(formula = y ~ x, se = FALSE, method = 'lm', color = 'black')\n\ngridExtra::grid.arrange(g1, g2, g3, ncol = 3)\nlibrary(openintro)\ndata(COL)\n\nset.seed(3)\ntheta <- seq(0, pi / 2, length.out = 25)\nv <- 12\nnoise <- rnorm(length(theta), sd = 0)\nx <- 2 * v^2 * sin(theta) * cos(theta) / 9.8 + noise\n\nggplot(mapping = aes(theta / pi * 2 * 90, x)) +\n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(x = 'Ângulo de inclinação (graus)', y = 'Distância viajada (m)') +\n  geom_smooth(formula = y ~ x, se = FALSE, method = 'lm', color = 'black') + \n  annotate(geom = \"text\", x = 45, y = 7.5, \n           label = 'A melhor reta para os dados é plana (!)', color = 'red', size = 3)"},{"path":"ch7-reg-simples.html","id":"lineFittingResidualsCorrelation","chapter":"7 Introdução à Regressão Linear","heading":"7.1 Ajuste linear, resíduos e correlação","text":"É útil pensar profundamente sobre o processo de ajuste linear. Nesta seção, examinamos os critérios para identificar um modelo linear e introduzir uma nova estatística, correlação.","code":""},{"path":"ch7-reg-simples.html","id":"startingWithStraightLines","chapter":"7 Introdução à Regressão Linear","heading":"7.1.1 Começando com linhas retas","text":"Os diagramas de dispersão foram introduzidos começo como técnica gráfica para apresentar duas variáveis numéricas simultaneamente. Tais gráficos permitem que relação entre variáveis seja examinada com facilidade. Figura 7.4 mostra um gráfico de dispersão para o comprimento da cabeça e comprimento total de 104 gambás brushtail da Austrália. Cada ponto representa um único gambá.\r\nFigura 7.4: Um gráfico de dispersão mostrando o comprimento da cabeça em relação ao comprimento total para 104 gambás brushtail. Um ponto representando um gambá com comprimento de cabeça de 94,1 mm e comprimento total de 89 cm é destacado.\r\n\r\n(#fig:brushtail_possum)O gambá brushtail comum da Austrália. Foto: Greg Schechter\r\nvariáveis comprimento de cabeça e total estão associadas. Os gambás com um comprimento total acima da média também tendem ter comprimentos de cabeça acima da média. Embora o relacionamento não seja perfeitamente linear, pode ser útil explicar parcialmente conexão entre essas variáveis com uma linha reta.\r\nFigura 7.5: figura à esquerda mostra o comprimento da cabeça versus comprimento total e revela que muitos dos pontos podem ser capturados por uma faixa reta. À direita, vemos que uma faixa curva é mais apropriada gráfico de dispersão para peso e milhas por galão conjunto de dados carros.\r\nLinhas retas só devem ser usadas quando os dados parecem ter um relacionamento linear, como o caso mostrado gráfico esquerdo da Figura 7.5. O gráfico direito da Figura 7.5 mostra um caso em que uma linha curva seria mais útil para entender relação entre duas variáveis.Cuidado com tendências curvas: Consideramos apenas modelos baseados em linhas retas neste capítulo. Se os dados mostram uma tendência não linear, como gráfico direito da Figura 7.5, técnicas mais avançadas devem ser usadas.","code":"\nlibrary(openintro)\ndata(possum)\n\nggplot(data = possum) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(aes(totalL, headL), color = 'skyblue3') + \n  labs(x = 'Comprimento Total (cm)', y = 'Comprimento da Cabeça (cm)') + \n  geom_point(aes(89, 94.1), color = 'red') +\n  geom_segment(aes(x = 89, y = min(headL), xend = 89, yend = 94.1), \n               linetype = 'dashed', color = 'red') +\n  geom_segment(aes(x = min(totalL), y = 94.1, xend = 89, yend = 94.1), \n               linetype = 'dashed', color = 'red')\nknitr::include_graphics('images/c7/brushtail_possum.jpg')\nlibrary(openintro)\n\ndata(possum)\ndata(cars)\n\ngr1 <- ggplot(data = possum, mapping = aes(totalL, headL)) + \n  geom_point(color = 'skyblue3') + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Comprimento Total (cm)', y = 'Comprimento da Cabeça (mm)') + \n  geom_smooth(formula = y ~ x, method = 'lm', color = 'black')\n\ngr2 <- ggplot(data = cars, mapping = aes(weight, mpgCity)) + \n  geom_point(color = 'skyblue3') + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = 'Peso (libras)', y = 'Milhas por galão (condução na cidade)') + \n  geom_smooth(formula = y ~ x, method = 'auto', color = 'black')\n\ngridExtra::grid.arrange(gr1, gr2, ncol = 2)"},{"path":"ch7-reg-simples.html","id":"visuallySuperimposeLine","chapter":"7 Introdução à Regressão Linear","heading":"7.1.2 Sobrepor uma linha visualmente","text":"Queremos descrever relação entre variáveis comprimento da cabeça e comprimento total conjunto de dados gambá usando uma linha. Neste exemplo, usaremos o comprimento total como variável preditora, \\(x\\), para prever o comprimento da cabeça de um gambá, \\(y\\). Poderíamos ajustar relação linear olho, como na Figura 7.6. equação para esta linha é\\[\\begin{eqnarray}\r\n\\hat{y} = 41 + 0.59x\r\n\\tag{7.2}\r\n\\end{eqnarray}\\]Podemos usar essa linha para discutir propriedades de gambás. Por exemplo, equação prevê que um gambá com um comprimento total de 80 cm terá um comprimento de cabeça\\[\\begin{align*}\r\n\\hat{y} &= 41 + 0,59\\times 80 \\\\\r\n    &= 88,2 % mm\r\n\\end{align*}\\]Um “chapéu” em \\(y\\) é usado para significar que isso é uma estimativa. Esta estimativa pode ser vista como uma média: equação prevê que gambás com um comprimento total de 80cm terão um comprimento médio da cabeça de 88,2mm. Ausente mais informações sobre um gambá de 80cm, previsão para o comprimento da cabeça que usa média é uma estimativa razoável.\r\nFigura 7.6: Um modelo linear razoável foi ajustado para representar relação entre comprimento da cabeça e comprimento total.\r\n","code":"\nrequire(openintro)\ndata(possum)\n\nthese <- c(48, 42, 3)\n\ntemp1 = matrix(NA, nrow = 3, ncol = 2)\ntemp2 = matrix(NA, nrow = 3, ncol = 2)\n\nfor(i in 1:3){\n  y2 <- 41 + 0.59 * possum$totalL[these[i]]\n  \n  temp1[i,] <- rep(possum$totalL[these[i]], 2)\n  temp2[i,] <- c(possum$headL[these[i]], y2)\n}\n\nggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(data = possum, aes(totalL, headL), color = 'skyblue3') + \n  labs(x = 'Comprimento Total (cm)', y = 'Comprimento da Cabeça (cm)') + \n  geom_abline(intercept = 41, slope = 0.59) + \n  geom_point(aes(possum$totalL[these] + rnorm(3,0,0.02),\n                 possum$headL[these] + rnorm(3,0,0.02)), shape = c(3, 4, 2), size = 3, color = 'red') + \n  geom_segment(aes(x = temp1[,1], y = temp2[,1], xend = temp1[,2], yend = temp2[,2]), \n               linetype = 'dashed', color = 'red')"},{"path":"ch7-reg-simples.html","id":"residue","chapter":"7 Introdução à Regressão Linear","heading":"7.1.3 Resíduos","text":"Resíduos são variações restantes nos dados após contabilização ajuste modelo:\\[\\begin{align*}\r\n\\text{Dados} = \\text{Ajuste} + \\text{Resíduos}\r\n\\end{align*}\\]Cada observação terá um resíduo. Se uma observação estiver acima da linha de regressão, então seu resíduo, distância vertical da observação até linha, é positivo. Observações abaixo da linha têm resíduos negativos. Um objetivo ao escolher o modelo linear correto é que esses resíduos sejam tão pequenos quanto possível.Três observações são anotadas especialmente na Figura 7.6. observação marcada por um \\(\\times\\) tem um pequeno resíduo negativo de cerca de -1; observação marcada por \\(+\\) tem um grande resíduo de cerca de +7; e observação marcada por \\(\\triangle\\) tem um resíduo moderado de cerca de -4. O tamanho de um resíduo é geralmente discutido em termos de seu valor absoluto. Por exemplo, o resíduo de \\(\\triangle\\) é maior que o de \\(\\times\\) porque \\(|-4|\\) é maior que \\(|-1|\\).Resíduos: diferença entre observado e esperado: O resíduo da observação \\((x_i, y_i)\\) é diferença da resposta observada (\\(y_i\\)) e resposta que preveríamos com base ajuste modelo (\\(\\hat{y} _i\\)):\\[\\begin{eqnarray*}\r\ne_i = y_i - \\hat{y}_i\r\n\\end{eqnarray*}\\]Nós tipicamente identificamos \\(\\hat{y}_i\\) conectando \\(x_i\\) modelo.}Primeiro calculamos o valor previsto ponto \\(\\times\\) baseado modelo:\\[\\begin{eqnarray*}\r\n\\hat{y}_{\\times} = 41+0,59x_{\\times} = 41+0,59\\times 77,0 = 86,4\r\n\\end{eqnarray*}\\]Em seguida, calculamos diferença entre o comprimento real da cabeça e o comprimento da cabeça previsto:\\[\\begin{eqnarray*}\r\ne_{\\times} = y_{\\times} - \\hat{y}_{\\times} = 85,3 -  86,4 = -1,1\r\n\\end{eqnarray*}\\]Isso é muito próximo da estimativa visual de -1.Resíduos são úteis para avaliar quão bem um modelo linear se ajusta um conjunto de dados. Costumamos exibi-los em um gráfico de resíduos como o mostrado na Figura 7.7 para linha de regressão da Figura 7.6. Os resíduos são plotados em seus locais horizontais originais, mas com coordenada vertical como resíduo. Por exemplo, o ponto \\((85,0,98,6)_{+}\\) tinha um resíduo de 7,45, então gráfico de resíduos ele é colocado em \\((85,0, 7,45)\\). Criar um gráfico de resíduos é como derrubar o gráfico de dispersão para que linha de regressão seja horizontal.\r\nFigura 7.7: Gráfico resíduo para o modelo comprimento total x comprimento da cabeça\r\n\r\nFigura 7.8: Dados amostrais com suas melhores linhas de ajuste (linha superior) e seus gráficos de resíduos correspondentes (linha inferior).\r\nprimeiro conjunto de dados (primeira coluna), os resíduos não mostram padrões óbvios. Os resíduos parecem estar espalhados aleatoriamente ao redor da linha tracejada que representa o 0.O segundo conjunto de dados mostra um padrão nos resíduos. Há alguma curvatura gráfico de dispersão, que é mais óbvia gráfico de resíduos. Não devemos usar uma linha reta para modelar esses dados. Em vez disso, uma técnica mais avançada deve ser usada.O último gráfico mostra muito pouca tendência ascendente e os resíduos também não mostram padrões óbvios. É razoável tentar ajustar um modelo linear aos dados. entanto, não está claro se há evidências estatisticamente significativas de que o parâmetro de inclinação é diferente de zero. estimativa pontual parâmetro de inclinação, rotulado \\(b_1\\), não é zero, mas podemos nos perguntar se isso pode ser devido ao acaso. Vamos abordar esse tipo de cenário na Seção 7.4.","code":"\nlibrary(openintro)\ndata(possum)\n\nthese <- c(48, 42, 3)\ny.extra <- 0.59 * possum$totalL[these] + rnorm(1,0,0.01)\n\ng <- lm(headL ~ totalL, possum)\n\nggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(aes(possum$totalL, g$residuals), color = 'skyblue3') + \n  labs(x = 'Comprimento Total (cm)', y = 'Residuals') + \n  geom_hline(yintercept = 0, linetype = 'dashed') + \n  geom_point(aes(possum$totalL[these] + rnorm(1, 0, 0.01),\n                 possum$headL[these] - (41 + y.extra)), shape = c(3, 4, 2), size = 3, color = 'red')\nset.seed(1)\n\nn1 <- 25\nx1 <- runif(n1[1])\ny1 <- -8 * x1 + rnorm(n1[1])\n\nn2 <- 30\nx2 <- c(runif(n2[1] - 2, 0, 4), 2, 2.1)\ny2 <- -2 * x2^2 + rnorm(n2[1])\n\nn3 <- 40\nx3 <- runif(n3[1])\ny3 <- 0.2 * x3 + rnorm(n3[1])\ny3[y3 < -2] <- -1.5\n\n\np1 <- ggplot(mapping = aes(x1,y1)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\np2 <- ggplot(mapping = aes(x2,y2)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\np3 <- ggplot(mapping = aes(x3,y3)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\ng1 <- lm(y1 ~ x1)\ng2 <- lm(y2 ~ x2)\ng3 <- lm(y3 ~ x3)\n\np4 <- ggplot(mapping = aes(x1,g1$residuals)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_hline(yintercept = 0, linetype = 'dashed') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\np5 <- ggplot(mapping = aes(x2,g2$residuals)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_hline(yintercept = 0, linetype = 'dashed') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\np6 <- ggplot(mapping = aes(x3,g3$residuals)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_hline(yintercept = 0, linetype = 'dashed') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\nrequire(gridExtra)\ngrid.arrange(p1, p2, p3, p4, p5, p6, ncol = 3)"},{"path":"ch7-reg-simples.html","id":"describingLinearRelationshipCorrelation","chapter":"7 Introdução à Regressão Linear","heading":"7.1.4 Descrevendo relacionamentos lineares com correlação","text":"Correlação: força de um relacionamento linear: correlação, que sempre recebe valores entre -1 e 1, descreve força relacionamento linear entre duas variáveis. Denotamos correlação por \\(R\\).Podemos calcular correlação usando uma fórmula, assim como fizemos com média e o desvio padrão da amostra. entanto, esta fórmula é bastante complexa,264 então geralmente executamos os cálculos em um computador ou calculadora.Figura 7.9 mostra oito gráficos e suas correlações correspondentes. Somente quando o relacionamento é perfeitamente linear correlação é -1 ou 1. Se o relacionamento forte e positivo, correlação será próxima de +1. Se forte e negativo, será próximo de -1. Se não houver relação linear aparente entre variáveis, correlação será próxima de zero.\r\nFigura 7.9: Amostra de gráficos de dispersão e suas correlações. primeira linha mostra variáveis com um relacionamento positivo, representado pela tendência para cima e para direita. segunda linha mostra variáveis com tendência negativa, em que um grande valor em uma variável é associado um valor baixo na outra.\r\ncorrelação destina-se quantificar força de uma tendência linear. Tendências não-lineares, mesmo quando fortes, às vezes produzem correlações que não refletem força relacionamento. Veja três desses exemplos na Figura 7.10.\r\nFigura 7.10: Amostra de gráficos de dispersão e suas correlações. Em cada caso, existe uma forte relação entre variáveis. entanto, correlação não é muito forte e relação não é linear.\r\n","code":"\nlibrary(openintro)\ndata(possum)\n\nplots_  <- function(x,y){\n  \n  ggplot() + \n    geom_point(aes(x, y), color = 'skyblue3') + \n    theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n    theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) + \n    annotate(geom = \"text\", x = mean(x), y = min(y), \n             label = paste0('R = ', round(cor(x,y),2)), color = 'black')\n  \n}\n\nset.seed(1)\n\nn <- 50\n# _____ Line 1 _____ #\nx <- c(runif(n[1] - 2, 0, 4), 2, 2.1)\ny <- 0.8 * x + rnorm(n[1], sd = 5)\n\nx2 <- c(runif(n[1] - 2, 0, 4), 2, 2.1)\ny2 <- 2 * x2 + rnorm(n[1], sd = 0.5)\n\n\nx3 <- runif(n[1])\ny3 <- x3\ny3[y3 < -2] <- -1.5\n\n# _____ Line 2 _____ #\n\nx4 <- c(runif(n[1]-2, 0, 4), 2, 2.1)\ny4 <- -0.5 * x4 + rnorm(n[1], sd = 5)\n\nx5 <- runif(n[1], -4.8, 4.8)\ny5 <- -x5 + rnorm(n[1], sd = 3)\n\nx6 <- runif(n[1])\ny6 <- -9 * x6 + rnorm(n[1])\n\nx7 <- runif(n[1])\ny7 <- -x7\ny7[y7 < -2] <- -1.5\n\n\n# plots \n\ngridExtra::grid.arrange(plots_(x,y), plots_(possum$totalL, possum$headL), \n                        plots_(x2, y2), plots_(x3, y3), plots_(x4, y4), \n                        plots_(x5, y5), plots_(x6, y6), plots_(x7, y7), ncol = 4)\nplots_  <- function(x,y){\n  \n    ggplot() + \n    geom_point(aes(x, y), color = 'skyblue3') + \n    theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n    theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) + \n    annotate(geom = \"text\", x = mean(x), y = min(y), \n             label = paste0('R = ', round(cor(x,y),2)), color = 'black')\n  \n}\n\nset.seed(1)\n\nn <- 50\nx <- c(runif(n[1] - 2, -2, 2.2), 2, 2.1)\ny <- -10 * x^2 + rnorm(n[1], sd = 5)\n\nx2 <- c(runif(n[1] - 2, -20, 10.2), 2, 2.1)\ny2 <- -x2^3 - 10 * x2^2 + 100 * x2 + rnorm(n[1], sd = 120)\n\nx3 <- runif(n[1], -1, 4)\ny3 <- 0.25 * (x3 > 3) - 0.5 * (x3 > 2) + 1.7 * (x3 > 1) + (x3 < 0)\nx3 <- c(x3, 0, 0, 1, 1)\nnoise <- rnorm(n[1] + 4, sd = 0.071)\ny3 <- c(y3, rep(0.5, 2), rep(1, 2)) + noise\n\n\n\ngridExtra::grid.arrange(plots_(x,y), plots_(x2,y2), plots_(x3,y3), ncol = 3)"},{"path":"ch7-reg-simples.html","id":"fittingALineByLSR","chapter":"7 Introdução à Regressão Linear","heading":"7.2 Ajustando uma linha pela regressão de mínimos quadrados","text":"adaptação de modelos lineares visualmente está aberta críticas, pois se baseia em uma preferência individual. Nesta seção, usamos regressão por mínimos quadrados como uma abordagem mais rigorosa.Esta seção considera os dados da renda familiar e gift aid de uma amostra aleatória de cinquenta alunos da turma de calouros de 2011 Elmhurst College em Illinois266. Gift Aid é uma ajuda financeira que não precisa ser paga de volta, ao contrário de um empréstimo. Um gráfico de dispersão dos dados é mostrado na Figura 7.11 junto com dois ajustes lineares. linhas seguem uma tendência negativa nos dados; os alunos que têm maior renda familiar tendem ter menor ajuda da universidade.\r\nFigura 7.11: Auxílio presente e renda familiar para uma amostra aleatória de 50 alunos iniciantes Elmhurst College. Duas linhas são ajustadas aos dados, sendo linha sólida regressão por mínimos quadrados.\r\n","code":"\nlibrary(openintro)\ndata(COL)\ndata(elmhurst)\nd <- elmhurst\n\ng <- lm(d$gift_aid ~ d$family_income)\n\n\nloss <- function(a, b, d) {\n  p <- a + b * d$family_income\n  sum(abs(d$gift_aid - p))\n}\na      <- round(g$coef[1], 2) + seq(-0.5, 0.5, 0.001)\nb      <- round(g$coef[2], 3) + seq(-0.01, 0.01, 0.0001)\nmins   <- c(a[1], b[1])\ntheMin <- loss(a[1], b[1], d)\npb     <- txtProgressBar(1, length(a), style=3)\nfor (i in 1:length(a)) {\n  for (j in 1:length(b)) {\n    hold <- loss(a[i], b[j], d)\n    if (hold < theMin) {\n      mins <- c(a[i],b[j])\n      theMin <- hold\n    }\n  }\n}\n\n# elmhurstScatterW2Lines\n\nggplot(data = d, mapping = aes(family_income, gift_aid)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(x = 'Renda Familiar ($1000s)', y = 'Auxílio-presente da \\nuniversidade ($1000s)') + \n  geom_abline(slope = mins[2], intercept = mins[1], linetype = 'dashed', size = 1) + \n  geom_smooth(formula = y ~ x, se = FALSE, method = 'lm', color = 'black')"},{"path":"ch7-reg-simples.html","id":"objectiveMeasureToFindBestLine","chapter":"7 Introdução à Regressão Linear","heading":"7.2.1 Uma medida objetiva para encontrar a melhor linha","text":"Começamos por pensar sobre o que queremos dizer com “melhor.” Matematicamente, queremos uma linha que tenha pequenos resíduos. Talvez nosso critério possa minimizar soma das magnitudes residuais:\\[\\begin{eqnarray}\r\n|e_1| + |e_2| + \\dots + |e_n|\r\n\\tag{7.3}\r\n\\end{eqnarray}\\]o que poderíamos realizar com um programa de computador. linha tracejada resultante mostrada na Figura 7.11 demonstra que esse ajuste pode ser bastante razoável. entanto, uma prática mais comum é escolher linha que minimiza soma dos resíduos quadrados:\\[\\begin{eqnarray}\r\ne_{1}^2 + e_{2}^2 + \\dots + e_{n}^2\r\n\\tag{7.4}\r\n\\end{eqnarray}\\]linha que minimiza os mínimos quadrados é representada como linha sólida na Figura 7.11. Isso é comumente chamado de linha de mínimos quadrados. seguir estão três possíveis razões para escolher Critério (7.4) sobre o Critério (7.3):É o método mais comumente usado.É o método mais comumente usado.Computar linha com base Critério (7.4) é muito mais fácil à mão e tem implementado na maioria dos softwares estatísticos.Computar linha com base Critério (7.4) é muito mais fácil à mão e tem implementado na maioria dos softwares estatísticos.Em muitas aplicações, um resíduo duas vezes maior que outro é quatro vezes mais problemático. Por exemplo, estar desviado por 4 é geralmente mais que duas vezes pior quanto estar desviado por 2. Usar o quadrado dos resíduos responde por essa discrepância.Em muitas aplicações, um resíduo duas vezes maior que outro é quatro vezes mais problemático. Por exemplo, estar desviado por 4 é geralmente mais que duas vezes pior quanto estar desviado por 2. Usar o quadrado dos resíduos responde por essa discrepância.duas primeiras razões são em grande parte por tradição e conveniência; última razão explica por que Critério (7.4) é geralmente mais útil.268","code":""},{"path":"ch7-reg-simples.html","id":"conditionsLeastSquareLine","chapter":"7 Introdução à Regressão Linear","heading":"7.2.2 Condições para a linha de mínimos quadrados","text":"Ao encaixar uma linha de mínimos quadrados, geralmente exigimosLinearidade. Os dados devem mostrar uma tendência linear. Se houver uma tendência não linear (por exemplo, gráfico esquerdo da Figura 7.12), um método de regressão avançado de outro livro ou curso posterior deve ser aplicado.Linearidade. Os dados devem mostrar uma tendência linear. Se houver uma tendência não linear (por exemplo, gráfico esquerdo da Figura 7.12), um método de regressão avançado de outro livro ou curso posterior deve ser aplicado.Resíduos quase normais. Geralmente os resíduos devem ser quase normais. Quando esta condição é considerada irracional, geralmente é por causa de discrepâncias ou preocupações sobre pontos influentes, que discutiremos com mais profundidade na Seção 7.3. Um exemplo de resíduos não normais é mostrado segundo gráfico da Figura 7.12.Resíduos quase normais. Geralmente os resíduos devem ser quase normais. Quando esta condição é considerada irracional, geralmente é por causa de discrepâncias ou preocupações sobre pontos influentes, que discutiremos com mais profundidade na Seção 7.3. Um exemplo de resíduos não normais é mostrado segundo gráfico da Figura 7.12.Variabilidade constante. variabilidade de pontos ao redor da linha dos mínimos quadrados permanece praticamente constante. Um exemplo de variabilidade não constante é mostrado terceiro gráfico da Figura 7.12.Variabilidade constante. variabilidade de pontos ao redor da linha dos mínimos quadrados permanece praticamente constante. Um exemplo de variabilidade não constante é mostrado terceiro gráfico da Figura 7.12.Observações independentes. Seja cauteloso ao aplicar regressão dados de séries temporais, que são observações sequenciais tempo, como o preço de uma ação por dia. Tais dados podem ter uma estrutura subjacente que deve ser considerada em um modelo e análise. Um exemplo de um conjunto de dados em que observações sucessivas não são independentes é mostrado quarto gráfico da Figura 7.12. Existem também outros casos em que correlações dentro dos dados são importantes.Observações independentes. Seja cauteloso ao aplicar regressão dados de séries temporais, que são observações sequenciais tempo, como o preço de uma ação por dia. Tais dados podem ter uma estrutura subjacente que deve ser considerada em um modelo e análise. Um exemplo de um conjunto de dados em que observações sucessivas não são independentes é mostrado quarto gráfico da Figura 7.12. Existem também outros casos em que correlações dentro dos dados são importantes.\r\nFigura 7.12: Quatro exemplos mostrando quando os métodos neste capítulo são insuficientes para aplicar aos dados. gráfico esquerdo, uma linha reta não se ajusta aos dados. segundo gráfico, existem outliers; dois pontos à esquerda estão relativamente distantes resto dos dados, e um desses pontos está muito longe da linha. terceiro gráfico, variabilidade dos dados ao redor da linha aumenta com valores maiores de x. último gráfico, é mostrado um conjunto de dados de séries temporais, em que observações sucessivas são altamente correlacionadas.\r\n","code":"\npls <- function(x, y){\n  g <- lm(y ~ x)\n  \n  ggplot(mapping = aes(x,g$residuals)) + \n    theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n    geom_point(color = 'skyblue3') + \n    geom_hline(yintercept = 0, linetype = 'dashed') + \n    theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n  \n}\n\n\n# load the makeTube function (ch7 folder)\n\nset.seed(1)\nx <- runif(100)\ny <- 25 * x - 20 * x^2 + rnorm(length(x), sd = 1.5)\n\np1 <- ggplot(mapping = aes(x,y)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_smooth(method = 'lm', se = FALSE, formula = y ~ x, color = 'black') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\nset.seed(2)\nx2 <- c(-0.6, -0.46, -0.091, runif(97))\ny2 <- 25 * x2 + rnorm(length(x2))\ny2[2] <- y2[2] + 8\ny2[1] <- y2[1] + 1\n\np2 <- ggplot(mapping = aes(x2,y2)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_smooth(method = 'lm', se = FALSE, formula = y ~ x, color = 'black', linetype = 'dashed') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\nset.seed(3)\nx3 <- runif(100)\ny3 <- 5 * x3 + rnorm(length(x3), sd = x3)\n\np3 <- ggplot(mapping = aes(x3,y3)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_smooth(method = 'lm', se = FALSE, formula = y ~ x, color = 'black', linetype = 'dashed') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\nrequire(Ecdat)\ndata(Macrodat)\n\n\np4 <- ggplot(mapping = aes(1:length(Macrodat[,1]),as.numeric(Macrodat[,1]))) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  geom_smooth(method = 'lm', se = FALSE, formula = y ~ x, color = 'black', linetype = 'dashed') + \n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n\n\ngridExtra::grid.arrange(p1, p2, p3, p4, pls(x,y), pls(x2,y2), pls(x3,y3), \n                        pls(x = 1:length(Macrodat[,1]),y = as.numeric(Macrodat[,1])), ncol = 4)"},{"path":"ch7-reg-simples.html","id":"findingTheLeastSquaresLineSection","chapter":"7 Introdução à Regressão Linear","heading":"7.2.3 Encontrar a linha dos mínimos quadrados","text":"Para os dados de Elmhurst, poderíamos escrever equação da linha de regressão de mínimos quadrados como\\[\\begin{eqnarray*}\r\n\\widehat{ajuda} = \\beta_0 + \\beta_{1}\\times ganho\\_\\hspace{0.3mm}familiar\r\n\\end{eqnarray*}\\]Aqui, equação é configurada para prever o gift-aid com base na renda familiar de um aluno, o que seria útil para os alunos que considerassem Elmhurst. Esses dois valores, \\(\\beta_0\\) e \\(\\beta_1\\), são os parâmetros da linha de regressão.Como nos Capítulos 4-6, os parâmetros são estimados usando dados observados. Na prática, essa estimativa é feita usando um computador da mesma forma que outras estimativas, como uma média amostral, podem ser estimadas usando um computador ou uma calculadora. entanto, também podemos encontrar estimativas dos parâmetros aplicando duas propriedades da linha de mínimos quadrados:inclinação da linha dos mínimos quadrados pode ser estimada por\\[\\begin{eqnarray}\r\nb_1 = \\frac{s_y}{s_x} R\r\n\\tag{7.5}\r\n\\end{eqnarray}\\]onde \\(R\\) é correlação entre duas variáveis, e \\(s_x\\) e \\(s_y\\) são os desvios padrão da amostra da variável explicativa (variável eixo horizontal) e resposta (variável eixo vertical), respectivamente.Se \\(\\bar{x}\\) média da variável horizontal (dos dados) e \\(\\bar{y}\\) é média da variável vertical, então o ponto \\((\\bar{x}, \\bar{y})\\) está nos mínimos quadrados linha.Usamos \\(b_0\\) e \\(b_1\\) para representar estimativas pontuais dos parâmetros \\(\\beta_0\\) e \\(\\beta_1\\).Tabela 7.1: Estatísticas resumidas para renda familiar e gift aid.Você pode se lembrar da forma de uma linha da aula de matemática (outra forma comum é com coeficiente linear e angular). Dada inclinação de uma linha e um ponto na linha, \\((x_0, y_0)\\), equação da linha pode ser escrita como\\[\\begin{eqnarray}\r\ny - y_0 = Inclinação \\times (x - x_0)\r\n\\tag{7.6}\r\n\\end{eqnarray}\\]Um exercício comum para se tornar mais familiarizado com os fundamentos da regressão de mínimos quadrados é usar estatísticas de resumo básicas e forma ponto e inclinação para produzir linha de mínimos quadrados.Identificando linha dos mínimos quadrados partir das estatísticas de resumo: Passos para identificar linha de mínimos quadrados partir das estatísticas de resumo:Estimar o parâmetro de inclinação, \\(b_1\\), usando Equação (7.5).Estimar o parâmetro de inclinação, \\(b_1\\), usando Equação (7.5).Observando que o ponto \\((\\bar{x}, \\bar{y})\\) está na linha de mínimos quadrados, use \\(x_0=\\bar{x}\\) e \\(y_0=\\bar{y}\\) junto com inclinação \\(b_1\\) na equação da reta: \\[y - \\bar{y} = b_1 (x - \\bar{x})\\]Observando que o ponto \\((\\bar{x}, \\bar{y})\\) está na linha de mínimos quadrados, use \\(x_0=\\bar{x}\\) e \\(y_0=\\bar{y}\\) junto com inclinação \\(b_1\\) na equação da reta: \\[y - \\bar{y} = b_1 (x - \\bar{x})\\]Simplifique equação.Simplifique equação.Aplique equação da reta usando \\((101.8, 19.94)\\) e inclinação \\(b_1 = -0,0431\\):\\[\\begin{align*}\r\ny - y_0     &= b_1 (x - x_0) \\\\\r\ny - 19.94  &= -0.0431(x - 101.8)\r\n\\end{align*}\\]Expandindo o lado direito e, em seguida, adicionando 19,94 para cada lado, equação simplifica:\r\n\\[\\widehat{auxilio} = 24.3 - 0.0431 \\times renda\\_\\hspace{0.3mm}familiar\\]\r\nAqui nós substituímos \\(y\\) por \\(\\widehat{auxilio}\\) e \\(x\\) por \\(renda\\_\\hspace{0.3mm}familiar\\) para colocar equação contexto.Mencionamos anteriormente que um computador é geralmente usado para calcular linha de mínimos quadrados. Uma tabela de resumo baseada na saída computador é mostrada na Tabela 7.2 para os dados Elmhurst. primeira coluna de números fornece estimativas para \\({b} _0\\) e \\({b} _1\\), respectivamente. Compare-os com o resultado Exemplo 7.3.Tabela 7.2: Resumo dos mínimos quadrados adequados aos dados Elmhurst.Vamos descrever o significado das colunas usando segunda linha, que corresponde \\(\\beta_1\\). primeira coluna fornece estimativa pontual para \\(\\beta_1\\), como calculamos em um exemplo anterior: -0,0431. segunda coluna é um erro padrão para esta estimativa pontual: 0,0108. terceira coluna é uma estatística teste-\\(t\\) para hipótese nula de que \\(\\beta_1=0\\): \\(T = -3,98\\). última coluna é o p-valor para estatística teste-\\(t\\) para hipótese nula \\(\\beta_1=0\\) e uma hipótese alternativa bilateral: 0,0002. Vamos entrar em mais desses detalhes na Seção 7.4.Ele pode usá-lo como uma estimativa, embora alguns qualificadores sobre essa abordagem sejam importantes. Primeiro, todos os dados são provenientes de uma turma de primeiro ano, e forma como ajuda é determinada pela universidade pode mudar de ano para ano. Em segundo lugar, equação fornecerá uma estimativa imperfeita. Enquanto equação linear é boa em capturar tendência nos dados, nenhuma ajuda individual aluno será perfeitamente prevista.","code":"\ntable1 <- matrix(c(101.8, 19.94, 63.2, 5.46, ' ', 'R = -0.499'), ncol = 2, nrow = 3, byrow = TRUE)\ncolnames(table1) <- c('renda familiar, em $1000s (x)', 'gift aid, em $1000s (y)')\nrownames(table1) <- c('média', 'dp', '')\n\nknitr::kable(table1, align = 'r', caption = 'Estatísticas resumidas para renda familiar e gift aid.')\ng <- lm(d$gift_aid ~ d$family_income)\n\ntemp <- data.frame(summary(g)$coefficients)\ncolnames(temp) <- c('Estimativa', 'Erro Padrão', 'valor t', 'Pr(>|t|)')\nrownames(temp) <- c('(Interceptio)', 'Renda Familiar')\nknitr::kable(temp, align = 'c', caption = 'Resumo dos mínimos quadrados adequados aos dados do Elmhurst.')"},{"path":"ch7-reg-simples.html","id":"interpretingRegressionLineParameterEstimates","chapter":"7 Introdução à Regressão Linear","heading":"7.2.4 Interpretando estimativas de parâmetros da linha de regressão","text":"interpretação de parâmetros em um modelo de regressão é frequentemente uma das etapas mais importantes da análise.Interpretar o parâmetro de inclinação é útil em quase qualquer aplicação. Para cada adicional de $1,000 de renda familiar, esperamos que um aluno receba uma diferença líquida de \\(\\$\\text{1,000}\\times (-0.0431) = -\\$43.10\\) em ajuda, em média, ou seja, $43,10 menos. Note que uma renda familiar maior corresponde menos ajuda, pois o coeficiente de renda familiar é negativo modelo. Devemos ser cautelosos nessa interpretação: embora exista uma associação real, não podemos interpretar uma conexão causal entre variáveis porque esses dados são observacionais. Ou seja, aumentar renda familiar de um aluno pode não causar queda da ajuda ao aluno. (Seria razoável entrar em contato com faculdade e perguntar se relação é causal, ou seja, se decisões de ajuda da Elmhurst College são parcialmente baseadas na renda familiar dos alunos.)O intercepto estimado em \\(b_0=24,3\\) (em $1000s) descreve ajuda média se família de um aluno não tiver renda. O significado intercepto é relevante para esta aplicação, uma vez que renda familiar para alguns alunos Elmhurst é de $0. Em outras aplicações, o intercepto pode ter pouco ou nenhum valor prático se não houver observações em que \\(x\\) é próximo de zero.Interpretando parâmetros estimados por mínimos quadrados: inclinação descreve diferença estimada na variável \\(y\\) se variável explicativa \\(x\\) para o aumento de uma unidade. O intercepto descreve o resultado médio de \\(y\\) se \\(x=0\\) e o modelo linear é válido até \\(x = 0\\), o que em muitas aplicações não é o caso.","code":""},{"path":"ch7-reg-simples.html","id":"extrapolationTricky","chapter":"7 Introdução à Regressão Linear","heading":"7.2.5 A extrapolação é traiçoeira","text":"Quando aquelas tempestades de neve atingiram costa leste neste inverno, provou para minha satisfação que o aquecimento global era uma fraude. Aquela neve estava gelada. Mas em uma tendência alarmante, temperaturas nesta primavera aumentaram. Considere isto: em 6 de fevereiro foi de 10 graus. Hoje atingiu quase 80. este ritmo, até agosto será de 220 graus. Então, claramente pessoal, o debate sobre o clima continua. - Stephen Colbert, 6 de Abril de 2010.272Modelos lineares podem ser usados para aproximar o relacionamento entre duas variáveis. entanto, esses modelos têm limitações reais. regressão linear é simplesmente uma estrutura de modelagem. verdade é quase sempre muito mais complexa que nossa linha simples. Por exemplo, não sabemos como os dados fora da nossa janela limitada se comportarão.Lembre-se que unidades de renda familiar estão em $1000s, então queremos calcular o auxílio para \\(renda\\_\\hspace{0.3mm}familiar = 1000\\):\\[\\begin{align*}\r\n24,3 – 0,0431\\times renda\\_\\hspace{0.3mm}familiar  = 24,3 – 0,0431\\times 1000 = -18,8\r\n\\end{align*}\\]O modelo prevê que esse aluno irá ter -$18,800 em auxílio (!). O Elmhurst College não pode exigir que os estudantes paguem uma taxa adicional para pagar matrícula.aplicação de uma estimativa de modelo valores fora domínio dos dados originais é denominada extrapolação. Geralmente, um modelo linear é apenas uma aproximação da relação real entre duas variáveis. Se extrapolarmos, estamos apostando que relação linear aproximada será válida em lugares onde não foi analisada.","code":""},{"path":"ch7-reg-simples.html","id":"usingR2DescribeStrengthAdjustment","chapter":"7 Introdução à Regressão Linear","heading":"7.2.6 Usando \\(R^2\\) para descrever a força de um ajuste","text":"Avaliamos força da relação linear entre duas variáveis anteriormente usando correlação, \\(R\\). entanto, é mais comum explicar força de um ajuste linear usando \\(R^2\\), chamado R-quadrado (\\(R^2\\)). Se fornecido com um modelo linear, gostaríamos de descrever o quão próximo o conjunto de dados está ajuste linear.\r\nFigura 7.13: Gift aid e renda familiar para uma amostra aleatória de 50 estudantes calouros Elmhurst College, mostrada com linha de regressão de mínimos quadrados.\r\nO \\(R^2\\) de um modelo linear descreve quantidade de variação na resposta que é explicada pela linha de mínimos quadrados. Por exemplo, considere os dados de Elmhurst, mostrados na Figura 7.13. variância da variável resposta, ajuda recebida, é \\(s_{aid}^2=29,8\\). entanto, se aplicarmos nossa linha de mínimos quadrados, esse modelo reduz nossa incerteza na previsão de ajuda usando renda familiar de um aluno. variabilidade nos resíduos descreve quanta variação permanece após o uso modelo: \\(s_{_{RES}}^2 = 22.4\\). Em suma, houve uma redução de\\[\\frac{s_{aid}^2 - s_{_{RES}}^2}{s_{aid}^2}\r\n    = \\frac{29,8 – 22,4}{29,8} = \\frac{7,5}{29,8}\r\n    = 0,25\\]ou cerca de 25% na variação dos dados usando informações sobre renda familiar para prever ajuda usando um modelo linear. Isso corresponde exatamente ao valor de R-quadrado:\\[\\begin{align*}\r\nR &= -0,499 &R^2 &= 0,25\r\n\\end{align*}\\]","code":"\nggplot(data = d, mapping = aes(family_income, gift_aid)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(x = 'Renda Familiar ($1000s)', y = 'Auxílio-presente da \\nuniversidade ($1000s)') + \n  geom_smooth(formula = y ~ x, se = FALSE, method = 'lm', color = 'black')"},{"path":"ch7-reg-simples.html","id":"categoricalPredictorsWithTwoLevels","chapter":"7 Introdução à Regressão Linear","heading":"7.2.7 Preditores categóricos com dois níveis","text":"Variáveis categóricas também são úteis na previsão de resultados. Aqui nós consideramos um preditor categórico com dois níveis (lembre-se que um nível é o mesmo que uma categoria). Vamos considerar os leilões Ebay para um videogame, Mario Kart para o Nintendo Wii, onde foram registrados o preço total leilão e condições jogo274. Aqui, queremos prever o preço total com base na condição jogo, que recebe valores usado (0) e novo (1). Um gráfico dos dados leilão é mostrado na Figura 7.14.\r\nFigura 7.14: Preços totais de leilão para o videogame Mario Kart, divididos em jogos de condição usados (x = 0) e novos (x = 1). linha de regressão dos mínimos quadrados também é mostrada.\r\nPara incorporar variável de condição de jogo em uma equação de regressão, devemos converter categorias em uma forma numérica. Faremos isso usando uma variável indicadora chamada cond_nova, que leva valor 1 quando o jogo é novo e 0 quando o jogo é usado. Usando esta variável indicadora, o modelo linear pode ser escrito como\\[\\begin{align*}\r\n\\widehat{preço} = \\beta_0 + \\beta_1 \\times cond\\_\\hspace{0.3mm}nova\r\n\\end{align*}\\]O modelo ajustado está resumido na Tabela 7.3, e o modelo com seus parâmetros estimados é dado como\\[\\begin{align*}\r\n\\widehat{preço} = 42.87 + 10.90 \\times cond\\_\\hspace{0.3mm}nova\r\n\\end{align*}\\]Para preditores categóricos com apenas dois níveis, suposição de linearidade será sempre satisfeita. entanto, devemos avaliar se os resíduos em cada grupo são aproximadamente normais e têm variância aproximadamente igual. Como pode ser visto na Figura 7.14, ambas condições são razoavelmente satisfeitas pelos dados leilão.Tabela 7.3: Resumo de regressão por mínimos quadrados para o preço final leilão em relação à condição jogo.O intercepto é o preço estimado quando condição jogo leva o valor 0, ou seja, quando o jogo está em condição usada. Ou seja, o preço médio de venda de uma versão usada jogo é $42,87.inclinação indica que, em média, os novos jogos são vendidos por cerca de $10,90 mais que os jogos usados.Interpretando estimativas modelo para preditores categóricos.: intersecção estimada é o valor da variável de resposta para primeira categoria (ou seja, categoria correspondente um valor indicativo de 0). inclinação estimada é mudança média na variável de resposta entre duas categorias.Vamos elaborar mais sobre os dados leilão Ebay próximo capítulo, onde examinamos influência de muitas variáveis preditoras simultaneamente usando regressão múltipla. Na regressão múltipla, consideraremos associação preço de leilão em relação cada variável enquanto controlamos influência de outras variáveis. Isso é especialmente importante, já que alguns dos preditores estão associados. Por exemplo, leilões com jogos novos também costumam vir com mais acessórios.","code":"\nlibrary(openintro)\ndata(COL)\ndata(marioKart)\nmk      <- marioKart[marioKart$totalPr < 100, ]\nmk$cond <- relevel(mk$cond, \"used\")\ncond <- as.numeric(ifelse(mk$cond == \"new\", 1, 0))\n\nggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(aes(as.factor(cond), mk$totalPr), color = 'skyblue3') + \n  labs(y = 'Preço Total', x = NULL) + \n  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + \n  annotate(geom = \"text\", x = 1.6, y = 35, \n           label = expression(widehat(price) *\" = 42.87 + 10.90 x cond_new\"))\ng <- lm(mk$totalPr ~ cond)\n\ntemp <- data.frame(summary(g)$coefficients)\ncolnames(temp) <- c('Estimativa', 'Erro Padrão', 'valor t', 'Pr(>|t|)')\nrownames(temp) <- c('(Interceptio)', 'Condição do Jogo')\nknitr::kable(temp, align = 'c', \n             caption = 'Resumo de regressão por mínimos quadrados para o preço final do leilão em relação à condição do jogo.', digits = 2)"},{"path":"ch7-reg-simples.html","id":"typesOfOutliersInLinearRegression","chapter":"7 Introdução à Regressão Linear","heading":"7.3 Tipos de outliers em regressão linear","text":"Nesta seção, identificamos critérios para determinar quais outliers são importantes e influentes. Outliers na regressão são observações que estão longe da “nuvem” de pontos. Esses pontos são especialmente importantes porque podem ter uma forte influência na linha de mínimos quadrados.\r\nFigura 7.15: Seis gráficos, cada uma com uma linha de mínimos quadrados e gráfico de resíduos. Todos os conjuntos de dados têm pelo menos um outlier.\r\n(1) Existe um outlier longe dos outros pontos, embora pareça apenas influenciar levemente reta.(1) Existe um outlier longe dos outros pontos, embora pareça apenas influenciar levemente reta.(2) Há um outlier à direita, embora esteja bem próximo da linha de mínimos quadrados, o que sugere que não foi muito influente.(2) Há um outlier à direita, embora esteja bem próximo da linha de mínimos quadrados, o que sugere que não foi muito influente.(3) Há um ponto longe da nuvem, e este outlier parece puxar linha de mínimos quadrados para direita; examine como linha ao redor da nuvem primária não parece se encaixar muito bem.(3) Há um ponto longe da nuvem, e este outlier parece puxar linha de mínimos quadrados para direita; examine como linha ao redor da nuvem primária não parece se encaixar muito bem.(4) Existe uma nuvem primária e uma pequena nuvem secundária de quatro outliers. nuvem secundária parece estar influenciando fortemente linha, fazendo com que linha de mínimos quadrada se encaixe mal em quase todos os lugares. Pode haver uma explicação interessante para nuvens duplas, que é algo que poderia ser investigado.(4) Existe uma nuvem primária e uma pequena nuvem secundária de quatro outliers. nuvem secundária parece estar influenciando fortemente linha, fazendo com que linha de mínimos quadrada se encaixe mal em quase todos os lugares. Pode haver uma explicação interessante para nuvens duplas, que é algo que poderia ser investigado.(5) Não há uma tendência óbvia na nuvem principal de pontos e o outlier à direita parece controlar amplamente inclinação da linha de mínimos quadrados.(5) Não há uma tendência óbvia na nuvem principal de pontos e o outlier à direita parece controlar amplamente inclinação da linha de mínimos quadrados.(6) Existe um outlier longe da nuvem, entanto, cai bastante perto da linha de mínimos quadrados e não parece ser muito influente.(6) Existe um outlier longe da nuvem, entanto, cai bastante perto da linha de mínimos quadrados e não parece ser muito influente.Examine os gráficos de resíduos na Figura 7.15. Você provavelmente descobrirá que há alguma tendência nas nuvens principais de (3) e (4). Nestes casos, os outliers influenciaram inclinação das linhas de mínimos quadrados. Em (5), os dados sem tendência clara foram atribuídos uma linha com uma tendência grande simplesmente devido um outlier (!).Alavancas: Pontos que caem horizontalmente para longe centro da nuvem tendem puxar mais forte na linha, então nós os chamamos de pontos com alta alavancagem.Pontos que caem horizontalmente longe da linha são pontos de alta alavancagem; esses pontos podem influenciar fortemente inclinação da linha de mínimos quadrados. Se um desses pontos de alavancagem alta parece realmente influenciar na inclinação da linha – como nos casos (3), (4) e (5) Exemplo 7.9 – então chamamos de ponto influente. Normalmente, podemos dizer que um ponto é influente se, se tivéssemos ajustado linha sem ele, o ponto influente teria sido extraordinariamente distante da linha de mínimos quadrados.É tentador remover os outliers. Não faça isso sem um bom motivo. Modelos que ignoram casos excepcionais (e interessantes) geralmente apresentam desempenho insatisfatório. Por exemplo, se uma firma financeira ignorasse maiores oscilações mercado – os “outliers” – eles logo iriam à falência fazendo investimentos mal pensados.Não ignore outliers ao montar um modelo final: Se houver valores discrepantes nos dados, eles não devem ser removidos ou ignorados sem um bom motivo. Seja qual o modelo final adequado aos dados, não seria muito útil ignorar os casos mais excepcionais.Outliers para um preditor categórico com dois níveis: Seja cauteloso ao usar um preditor categórico quando um dos níveis tiver poucas observações. Quando isso acontece, essas poucas observações se tornam pontos influentes.","code":"\npls <- function(x, y){\n  g <- lm(y ~ x)\n  \n  ggplot(mapping = aes(x,g$residuals)) + \n    theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n    geom_point(color = 'skyblue3') + \n    geom_hline(yintercept = 0, linetype = 'dashed') + \n    theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank())\n  \n}\n\nn <- c(50, 25, 78, 55, 70, 150)\nm <- c(12, -4, 7, -19, 0, 40)\n\nxr <- list(0.3, 2, 1.42,\n           runif(4, 1.45, 1.55),\n           5.78, -0.6)\n\nyr <- list(-4, -8, 19,\n           c(-17, -20, -21, -19),\n           12, -23.2)\n\n\ngraf <- list()\nresf <- list()\n\nfor(i in 1:6){\n  x <- runif(n[i])\n  y <- m[i] * x + rnorm(n[i])\n  x <- c(x, xr[[i]])\n  y <- c(y, yr[[i]])\n\n  graf[[i]] <- ggplot(mapping = aes(x,y)) + \n    theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n    geom_point(color = 'skyblue3') + \n    theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) + \n    ggtitle(paste0('(',i,')')) +\n    theme(plot.title = element_text(hjust = 0.5))\n  \n  resf[[i]] <- pls(x,y)\n}\n\ngridExtra::grid.arrange(graf[[1]], graf[[2]], graf[[3]], \n                        resf[[1]], resf[[2]], resf[[3]], \n                        graf[[4]], graf[[5]], graf[[6]],\n                        resf[[4]], resf[[5]], resf[[6]], ncol = 3)"},{"path":"ch7-reg-simples.html","id":"inferenceForLinearRegression","chapter":"7 Introdução à Regressão Linear","heading":"7.4 Inferência para regressão linear","text":"Nesta seção, discutimos incerteza nas estimativas da inclinação e intercepto de y para uma linha de regressão. Assim como identificamos erros-padrão para estimativas pontuais nos capítulos anteriores, primeiro discutimos erros-padrão para essas novas estimativas. entanto, caso de regressão, identificaremos erros padrão usando software estatístico.","code":""},{"path":"ch7-reg-simples.html","id":"halftermElectionsUnemployment","chapter":"7 Introdução à Regressão Linear","heading":"7.4.1 Eleições de meio de mandato e desemprego","text":"eleições para os membros da Câmara dos Representantes dos Estados Unidos ocorrem cada dois anos, coincidindo cada quatro anos com eleição presidencial dos EUA. O conjunto de eleições da Câmara que ocorre durante o meio de um mandato presidencial é chamado de midterm elections. sistema bipartidário americano, uma teoria política sugere que quanto maior taxa de desemprego, pior o partido presidente fará nas eleições de meio de mandato.Para avaliar validade dessa afirmação, podemos compilar dados históricos e procurar uma conexão. Consideramos todas eleições intercalares de 1898 2010, com exceção das eleições durante Grande Depressão. Figura 7.16 mostra estes dados e linha de regressão de mínimos quadrados:\\[\\begin{align*}\r\n&\\text{% mudança em assentos da casa para o partido presidente}  \\\\\r\n&\\qquad\\qquad= -6,71 – 1,00\\times \\text{(taxa de desemprego)}\r\n\\end{align*}\\]Consideramos variação percentual número de assentos partido Presidente (por exemplo, variação percentual número de assentos para os democratas em 2010) em relação à taxa de desemprego.Examinando os dados, não há desvios evidentes da linearidade, da condição de variância constante ou da normalidade dos resíduos (embora não examinemos aqui um gráfico de probabilidade normal). Enquanto os dados são coletados sequencialmente, uma análise separada foi usada para verificar qualquer correlação aparente entre observações sucessivas; nenhuma correlação foi encontrada.\r\nFigura 7.16: porcentagem de mudança nas cadeiras da Câmara para o partido presidente em cada eleição de 1898 2010 foi traçada contra taxa de desemprego. Os dois pontos para Grande Depressão foram removidos e uma linha de regressão de mínimos quadrados foi ajustada aos dados.\r\nHá uma inclinação negativa na linha mostrada na Figura 7.16. entanto, esta inclinação (e intercepto) são apenas estimativas dos valores dos parâmetros. Poderíamos nos perguntar: essa evidência convincente de que o modelo linear “verdadeiro” tem uma inclinação negativa? Ou seja, os dados fornecem fortes evidências de que teoria política é exata? Podemos enquadrar essa investigação em um teste de hipótese estatística unilateral:\\(H_0\\): \\(\\beta_1 = 0\\). O verdadeiro modelo linear tem inclinação zero.\\(H_0\\): \\(\\beta_1 = 0\\). O verdadeiro modelo linear tem inclinação zero.\\(H_1\\): \\(\\beta_1 < 0\\). O modelo linear verdadeiro tem uma inclinação menor que zero. Quanto maior o desemprego, maior perda para o partido presidente na Câmara dos Representantes.\\(H_1\\): \\(\\beta_1 < 0\\). O modelo linear verdadeiro tem uma inclinação menor que zero. Quanto maior o desemprego, maior perda para o partido presidente na Câmara dos Representantes.Nós rejeitaríamos \\(H_0\\) em favor de \\(H_1\\) se os dados fornecerem fortes evidências de que o parâmetro de inclinação real é menor que zero. Para avaliar hipóteses, identificamos um erro padrão para estimativa, calculamos uma estatística de teste apropriada e identificamos o p-valor.","code":"\nlibrary(openintro)\ndata(unempl)\ndata(house)\ndata(president)\nh <- house\npres <- president\n\n\nyear   <- seq(1898, 2010, 4) + 1\nn      <- length(year)\nunemp  <- rep(0, n)\nchange <- rep(0, n)\npresid <- rep(\"\", n)\nparty  <- rep(\"\", n)\n\nfor (i in 1:n) {\n  urow <- which(unempl$year == year[i]-1)\n  if (i < n) {\n    prow <- which(pres$end > year[i])[1]\n  } else {\n    prow <- which(pres$potus == \"Barack Obama\")\n  }\n  hrow <- which(h$yearEnd >= year[i])[1]\n  party[i] <- as.character(pres$party[prow])\n  if (substr(h$p1[hrow], 1, 5) == substr(party[i], 1, 5)) {\n    oldHouse <- h$np1[hrow] / h$seats[hrow]\n  } else {\n    oldHouse <- h$np2[hrow] / h$seats[hrow]\n  }\n  if (substr(h$p1[hrow + 1], 1, 5) == substr(party[i], 1, 5)) {\n    newHouse <- h$np1[hrow + 1] / h$seats[hrow + 1]\n  } else {\n    newHouse <- h$np2[hrow + 1] / h$seats[hrow + 1]\n  }\n  change[i] <- (newHouse - oldHouse) / oldHouse * 100\n  presid[i] <- as.character(pres$potus[prow])\n  unemp[i]  <- unempl$unemp[urow]\n}\n\nunemployPres <- data.frame(year = year,\n                           potus = presid,\n                           party = party,\n                           unemp = unemp,\n                           change = change)\n\n\nth <- !year %in% c(1935, 1939)\nrepub <- (unemployPres$party[th] == \"Republican\")\n\nggplot(mapping = aes(unemployPres$unemp[th], unemployPres$change[th])) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = ifelse(repub == 'TRUE', 'tomato', 'skyblue3')) + \n  labs(x = 'Percentual de desemprego', y = 'Variação percentual de \n       assentos do partido do presidente \n       na Câmara dos Deputados') + \n  geom_smooth(formula = y ~ x, method = 'lm', se = FALSE, color = 'black')"},{"path":"ch7-reg-simples.html","id":"testStatisticForTheSlope","chapter":"7 Introdução à Regressão Linear","heading":"7.4.2 Entendendo a saída de regressão do software","text":"Assim como outras estimativas pontuais que vimos antes, podemos calcular um erro padrão e testar estatística para \\(b_1\\). Em geral, rotularemos estatística de teste usando um \\(T\\), já que ela segue distribuição \\(t\\).Contaremos com software estatístico para calcular o erro padrão e deixar explicação de como esse erro padrão é determinado para um segundo ou terceiro curso de estatística. Tabela 7.4 mostra saída de software para linha de regressão de mínimos quadrados na Figura 7.16. linha chamada desempregado representa informação para inclinação, que é o coeficiente da variável desemprego.Tabela 7.4: Saída software estatístico para linha de regressão que modela perdas eleitorais médio prazo para o partido Presidente como resposta ao desemprego.entradas na primeira coluna representam estimativas de mínimos quadrados, \\(b_0\\) e \\(b_1\\), e os valores na segunda coluna correspondem aos erros padrão de cada estimativa.Anteriormente, usamos uma estatística de teste-\\(t\\) para testes de hipóteses contexto de dados numéricos. Regressão é muito semelhante. Nas hipóteses que consideramos, o valor nulo para inclinação é 0, então podemos calcular estatística de teste usando fórmula teste T (ou Z):\\[\\begin{align*}\r\nT = \\frac{\\text{estimativa} - \\text{valor nulo}}{\\text{EP}} = \\frac{-1.0010 - 0}{0.8717} = -1.15\r\n\\end{align*}\\]Podemos procurar o p-valor unilateral – mostrado na Figura 7.17 – usando tabela de probabilidades para distribuição-\\(t\\).\r\nFigura 7.17: distribuição mostrada aqui é distribuição amostral para b1, se hipótese nula verdadeira. cauda sombreada representa o p-valor para o teste de hipótese que avalia se há evidência convincente de que o desemprego mais elevado corresponde uma maior perda de assentos na Câmara para o partido Presidente durante uma eleição de meio de mandato.\r\nOlhando na linha de 25 graus de liberdade, Vemos que o valor absoluto da estatística de teste é menor que qualquer valor listado, o que significa que área da cauda e, portanto, também o p-valor é maior que 0,100 (uma cauda!). Como o p-valor é tão grande, deixamos de rejeitar hipótese nula. Ou seja, os dados não fornecem evidências convincentes de que uma taxa de desemprego mais alta tenha qualquer relação com perdas menores ou maiores para o partido Presidente na Câmara dos Deputados nas eleições de meio de mandato.Poderíamos ter identificado o teste-\\(t\\) estatístico por software na Tabela 7.4, mostrado na segunda linha (desempregado) e terceira coluna (valor t). entrada na segunda linha e última coluna na Tabela 7.4 representa o p-valor para o teste de hipóteses bilateral, em que o valor nulo é zero. O teste unilateral correspondente metade p-valor listado.Inferência para regressão: Geralmente, utilizamos software estatístico para identificar estimativas pontuais e erros padrão para parâmetros de uma linha de regressão. Depois de verificar condições para ajustar uma reta, podemos usar os métodos aprendidos anteriormente para distribuição-\\(t\\) para criar intervalos de confiança para parâmetros de regressão ou para avaliar testes de hipóteses.Não use descuidadamente o p-valor da saída de regressão: última coluna na saída de regressão geralmente lista p-valores para uma hipótese particular: um teste bilateral onde o valor nulo é zero. Se o seu teste unilateral e estimativa pontual estiver na direção de \\(H_1\\), você poderá reduzir pela metade o p-valor software para obter área unilateral. Se nenhum desses cenários corresponder ao seu teste de hipótese, tenha cuidado ao usar saída de software para obter o p-valor.Enquanto relação entre variáveis não é perfeita, há uma evidente tendência decrescente nos dados. Isso sugere que o teste de hipótese rejeitará declaração nula de que inclinação é zero.Prática Orientada 7.10  Tabela 7.5 mostra saída de um software estatístico para o ajuste da linha de regressão de mínimos quadrados mostrada na Figura 7.13. Use essa saída para avaliar formalmente hipóteses seguir.\\(H_0\\): O verdadeiro coeficiente de renda familiar é zero.Tabela 7.5: Resumo dos mínimos quadrados adequados aos dados Elmhurst College.Sempre cheque suposições: Se condições para ajustar linha de regressão não forem válidas, os métodos apresentados aqui não deverão ser aplicados. O pressuposto padrão de erro ou distribuição da estimativa pontual – considerado normal ao aplicar o teste-\\(t\\) estatístico – pode não ser válido.","code":"\ntemp <- summary(lm(change ~ unemp, unemployPres))$coefficients\ncolnames(temp) <- c('Estimativa', 'Erro Padrão', 'valor t', 'Pr(>|t|)')\nrownames(temp) <- c('(Intercepto)', 'Desemprego')\n\nknitr::kable(temp, align = 'r', digits = 2, \n             caption = 'Saída do software estatístico para a linha de regressão que modela as perdas eleitorais a médio prazo para o partido do Presidente como resposta ao desemprego.')\nset.seed(1)\nm <- 0\ns <- 0.8717\nX <- m + s * seq(-4, 4, 0.01)\nY <- dnorm(X, m, s)\n\ngg   <- data.frame(X,Y)\n\nggplot(data = gg, mapping = aes(x = X, y = Y)) + \n  geom_linerange(data = gg[gg$X < -1.0010,], aes(X, ymin = 0, ymax = Y), color = \"skyblue3\") +\n  geom_path(size = 1) +\n  scale_x_continuous(breaks = round(seq(m - 3*s, m + 3*s, s),2)) + \n  labs(x = NULL, y = NULL) + \n  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +\n  geom_hline(yintercept = 0) +\n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\ng <- lm(gift_aid ~ family_income, d)\ntempor <- summary(g)$coefficients\ncolnames(tempor) <- c('Estimativa', 'Erro Padrão', 'Valor t', 'Pr(>|t|)')\nrownames(tempor) <- c('(Intercepto)', 'Renda Familiar')\n\nknitr::kable(tempor, align = 'r', digits = 2, caption = 'Resumo dos mínimos quadrados adequados aos dados do Elmhurst College.')"},{"path":"ch8-reg-mult-log.html","id":"ch8-reg-mult-log","chapter":"8 Regressão Múltipla e Logística","heading":"8 Regressão Múltipla e Logística","text":"Os princípios da regressão linear simples estabelecem base para métodos de regressão mais sofisticados usados em uma ampla gama de configurações desafiadoras. Neste capítulo, nós exploramos regressão múltipla, que introduz possibilidade de mais de um preditor; e regressão logística, uma técnica para prever resultados categóricos com duas categorias possíveis.","code":""},{"path":"ch8-reg-mult-log.html","id":"introductionToMultipleRegression","chapter":"8 Regressão Múltipla e Logística","heading":"8.1 Introdução à regressão múltipla","text":"regressão múltipla estende regressão simples de duas variáveis para o caso que ainda tem uma resposta, mas muitos preditores (denotado \\(X_1, X_2, X_3, \\dots\\)). O método é motivado por cenários em que muitas variáveis podem ser conectadas simultaneamente uma saída.Vamos considerar leilões Ebay de um videogame chamado Mario Kart para o Nintendo Wii. variável de interesse resultante é o preço total de um leilão, que é o lance mais alto, mais o custo de envio. Vamos tentar determinar como o preço total é relacionado cada característica em um leilão e simultaneamente controlar outras variáveis. Por exemplo, todas outras características mantidas constantes são leilões mais longos associados preços mais altos ou mais baixos? E, em média, quanto mais os compradores tendem pagar por rodas adicionais Wii (volantes de plástico que prendem ao controle Wii) em leilões? regressão múltipla nos ajudará responder essas e outras perguntas.O conjunto de dados inclui resultados de 141 leilões277. Quatro observações deste conjunto de dados são mostradas na Tabela 8.1 e descrições para cada variável são mostradas na Tabela 8.2. Observe que variáveis condição e foto stock são variáveis indicadoras. Por exemplo, variáveis cond_nova assume o valor 1 se o jogo em leilão novo e 0 se usado. utilização de variáveis indicadoras lugar de nomes de categorias permite que essas variáveis sejam usadas diretamente na regressão. regressão múltipla também permite variáveis categóricas com muitos níveis, embora não tenhamos essas variáveis nessa análise, e salvamos esses detalhes para um segundo ou terceiro curso.Tabela 8.1: Quatro observações conjunto de dados Mario KartTabela 8.2: Variáveis e suas descrições para o conjunto de dados Mario Kart","code":"\nrequire(openintro)\ndata(\"marioKart\")\n\ntemp <- marioKart[,c('totalPr', 'cond', 'stockPhoto', 'duration', 'wheels')]\n\ntemp$cond <- ifelse(temp$cond == 'used', 0, 1)\ntemp$stockPhoto <- ifelse(temp$stockPhoto == 'yes', 1, 0)\n\nnames(temp) <- c('preço', 'condição', 'foto', 'duração', 'rodas')\n\n\n\nknitr::kable(head(temp, 4), caption = 'Quatro observações do conjunto de dados Mario Kart')\ndescs <- c('preço do leilão final mais custo de transporte, em dólares americanos',\n           'a variável categória, que é 1 quando o jogo é novo e 0 se usado',\n           'a variável categórica, que é 1 se a foto principal do leilão era uma foto do estoque e 0 se fosse única para aquele leilão',\n           'duração do leilão em dias, valores entre 1 a 10', \n           'o número de rodas de Wii incluídas na seção (uma roda de wii é um acessório em formato de roda para auxiliar ao jogar Mario Kart Wii')\n\ntable2 <- data.frame(cbind(names(temp), descs))\nnames(table2) <- c('Variável', 'Descrição')\n\nknitr::kable(table2, align = 'r', \n             caption = 'Variáveis e suas descrições para o conjunto de dados Mario Kart')"},{"path":"ch8-reg-mult-log.html","id":"twoSingleVariableModelsForMarioKartData","chapter":"8 Regressão Múltipla e Logística","heading":"8.1.1 Um modelo de variável única para os dados do Mario Kart","text":"Vamos ajustar um modelo de regressão linear com condição jogo como um preditor preço leilão. O modelo pode ser escrito como\\[\\begin{align*}\r\n\\widehat{preço} &= 42.87 + 10.90\\times cond\\_\\hspace{0.3mm}nova\r\n\\end{align*}\\]Os resultados deste modelo são mostrados na Tabela 8.3 e um gráfico de dispersão por preço versus condição de jogo é mostrado na Figura 8.1.Tabela 8.3: Resumo de um modelo linear para prever o preço leilão com base na condição jogo.\r\nFigura 8.1: Gráfico de dispersão preço total leilão contra condição jogo. linha dos mínimos quadrados também é mostrada.\r\nNote que condição é uma variável categórica de dois níveis que recebe o valor 1 quando o jogo é novo e o valor 0 quando o jogo é usado. Então, 10.90 significa que o modelo prevê um extra de $10. 90 para aqueles jogos que são novos versus aqueles que são usados. Examinando saída de regressão na Tabela 8.3, podemos ver que o p-valor para condição é muito próximo de zero, indicando que há fortes evidências de que o coeficiente é diferente de zero ao usar esse modelo simples de uma variável.","code":"\ndata(marioKart)\nd <- marioKart[marioKart$totalPr < 100,]\nd$cond <- ifelse(d$cond == 'used', 0, 1)\ng <- lm(totalPr ~ cond, data = d)\n\ntable3 <- data.frame(summary(g)$coefficients)\nnames(table3) <- c('Estimativa', 'Erro Padrão', 'Valor t', 'Pr(>|t|)')\nrownames(table3) <- c('(Intercepto)', 'Condição')\n\nknitr::kable(table3, digits = 3, align = 'c', \n             caption = 'Resumo de um modelo linear para prever o preço do leilão com base na condição do jogo.')\nlibrary(openintro)\ndata(marioKart)\nmk      <- marioKart[marioKart$totalPr < 100, ]\nmk$cond <- relevel(mk$cond, \"used\")\ncond <- as.numeric(ifelse(mk$cond == \"new\", 1, 0))\n\ng <- lm(mk$totalPr ~ cond)\n\nggplot(mapping = aes(as.factor(cond), mk$totalPr)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(color = 'skyblue3') + \n  labs(y = 'Preço Total', x = 'Condição') + \n  geom_abline(slope = g$coefficients[2], intercept = g$coefficients[1])"},{"path":"ch8-reg-mult-log.html","id":"includingAndAssessingManyVariablesInAModel","chapter":"8 Regressão Múltipla e Logística","heading":"8.1.2 Incluindo e avaliando muitas variáveis em um modelo","text":"Às vezes, há estruturas subjacentes ou relacionamentos entre variáveis preditoras. Por exemplo, os novos jogos vendidos Ebay tendem vir com mais rodas Wii, o que pode ter levado preços mais altos para esses leilões. Gostaríamos de encaixar um modelo que inclua todas variáveis potencialmente importantes simultaneamente. Isso nos ajudaria avaliar relação entre uma variável preditora e o resultado enquanto controlamos influência potencial de outras variáveis. Essa é estratégia usada na regressão múltipla. Embora permaneçamos cautelosos em fazer quaisquer interpretações causais usando regressão múltipla, tais modelos são um primeiro passo comum fornecimento de evidências de uma conexão causal.Queremos construir um modelo que responda não apenas à condição jogo, mas simultaneamente responde por três outras variáveis: foto_stock, duração, e rodas.\\[\\begin{align}\r\n\\widehat{preço}\r\n    &= \\beta_0 + \\beta_1\\times cond\\_nova +\r\n        \\beta_2\\times foto\\_stock \\notag \\\\\r\n    &\\qquad\\  + \\beta_3 \\times  duração +\r\n        \\beta_4 \\times  rodas \\notag \\\\\r\n\\hat{y}\r\n    &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +\r\n        \\beta_3 x_3 + \\beta_4 x_4\r\n\\tag{8.1}\r\n\\end{align}\\]Nesta equação, \\(Y\\) representa o preço total, \\(X_1\\) indica se o jogo é novo, \\(X_2\\) indica se uma foto foi usada, \\(X_3\\) é duração leilão e \\(X_4\\) é o número de rodas de Wii incluídas jogo. Assim como caso preditor único, um modelo de regressão múltipla pode estar faltando componentes importantes ou pode não representar precisamente relação entre o resultado e variáveis explicativas disponíveis. Enquanto nenhum modelo é perfeito, nós desejamos explorar possibilidade de que este possa encaixar os dados razoavelmente bem.Nós estimamos os parâmetros \\(\\beta_0, \\beta_1,\\dots, \\beta_4\\) da mesma forma que fizemos caso de um único preditor. Nós selecionamos \\(b_0, b_1, \\dots, b_4\\) que minimizam soma dos resíduos quadrados:\\[\\begin{align}\r\nSSE = e_1^2 + e_2^2 + \\dots + e_{141}^2\r\n      = \\sum_{=1}^{141} e_i^2\r\n      = \\sum_{=1}^{141} \\left(y_i - \\hat{y}_i\\right)^2\r\n\\tag{8.2}\r\n\\end{align}\\]Aqui há 141 resíduos, um para cada observação. Normalmente usamos um computador para minimizar soma na Equação (8.2) e calcular estimativas pontuais, como mostrado na saída da amostra na Tabela 8.4. Usando essa saída, identificamos estimativas pontuais \\(b_i\\) de cada \\(\\beta_i\\), assim como fizemos caso de um preditor.Tabela 8.4: Saída para o modelo de regressão onde preço é o resultado e condição, foto, duração e rodas são os preditores.Modelo de Regressão Múltipla: Um modelo de regressão múltipla é um modelo linear com muitos preditores. Em geral, escrevemos o modelo como\\[\\begin{align*}\r\n\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k %+ \\epsilon\r\n\\end{align*}\\]quando há \\(k\\) preditores. Costumamos estimar os parâmetros \\(\\beta_i\\) usando um computador.Se examinássemos os dados cuidadosamente, veríamos que alguns preditores estão correlacionados. Por exemplo, quando estimamos conexão resultado preço e o preditor condição usando regressão linear simples, não conseguimos controlar outras variáveis, como o número de rodas Wii incluídas leilão. Esse modelo foi influenciado pela variável de confusão rodas. Quando usamos duas variáveis, esse viés subjacente e não intencional específico é reduzido ou eliminado (embora viés de outras variáveis confusas ainda possa permanecer).Exemplo 8.2 descreve um problema comum em regressão múltipla: correlação entre variáveis preditoras. Dizemos que duas variáveis preditoras são colineares (pronunciado como co-lineares) quando eles são correlacionados e essa colinearidade complica estimação modelo. Embora seja impossível evitar que colinearidade surja em dados observacionais, os experimentos geralmente são projetados para impedir que os preditores sejam colineares.","code":"\nd$stockPhoto <- ifelse(d$stockPhoto == 'yes', 1, 0)\n\ng <- lm(totalPr ~ cond + stockPhoto + duration + wheels, data = d)\n\ntable4 <- data.frame(summary(g)$coefficients)\nnames(table4) <- c('Estimativa', 'Erro Padrão', 'Valor t', 'Pr(>|t|)')\nrownames(table4) <- c('(Intercepto)', 'Condição', 'Foto', 'Duração', 'Rodas')\n\n\nknitr::kable(table4, align = 'c', digits = 4, caption = 'Saída para o modelo de regressão onde preço é o resultado e condição, foto, duração e rodas são os preditores.')"},{"path":"ch8-reg-mult-log.html","id":"R2adj","chapter":"8 Regressão Múltipla e Logística","heading":"8.1.3 \\(R^2\\) ajustado como melhor estimativa da variância explicada","text":"Nós usamos pela primeira vez \\(R^2\\) para determinar quantidade de variabilidade na resposta que foi explicada pelo modelo:\\[\\begin{align*}\r\nR^2 = 1 - \\frac{\\text{variabilidade nos resíduos}}{\\text{variabilidade resultado}}\r\n    = 1 - \\frac{Var(e_i)}{Var(y_i)}\r\n\\end{align*}\\]onde \\(e_i\\) representa os resíduos modelo e \\(y_i\\) os resultados. Esta equação permanece válida na estrutura de regressão múltipla, mas um pequeno aprimoramento pode ser ainda mais informativo.Essa estratégia para estimar \\(R^2\\) é aceitável quando há apenas uma única variável. entanto, torna-se menos útil quando existem muitas variáveis. O \\(R^2\\) regular é uma estimativa menor da quantidade de variabilidade explicada pelo modelo. Para obter uma estimativa melhor, usamos o valor ajustado de \\(R^2\\).\\(\\mathbf{R^2}\\) ajustado como uma ferramenta para avaliação de modelo: O \\(\\mathbf{R^2}\\) ajustado é calculado como\\[\\begin{align*}\r\nR_{aj}^{2} = 1-\\frac{Var(e_i) / (n-k-1)}{Var(y_i) / (n-1)}\r\n    = 1-\\frac{Var(e_i)}{Var(y_i)} \\times \\frac{n-1}{n-k-1}\r\n\\end{align*}\\]onde \\(n\\) é o número de casos usados para ajustar o modelo e \\(k\\) é o número de variáveis preditoras modelo.Como \\(k\\) nunca é negativo, o \\(R^2\\) ajustado será menor – muitas vezes um pouco menor – que o \\(R^2\\) não ajustado. O raciocínio por trás \\(R^2\\) ajustado está nos graus de liberdade associados cada variação.284\\(R^2\\) ajustado poderia ter sido usado na regressão linear simples. entanto, quando há apenas \\(k=1\\) preditores, o ajuste \\(R^2\\) está muito próximo valor normal de \\(R^2\\), portanto, essa nuance não é normalmente importante quando se considera apenas um preditor.","code":""},{"path":"ch8-reg-mult-log.html","id":"modelSelection","chapter":"8 Regressão Múltipla e Logística","heading":"8.2 Seleção de modelos","text":"O melhor modelo nem sempre é o mais complicado. Às vezes, incluir variáveis que não são evidentemente importantes pode reduzir precisão das previsões. Nesta seção, discutiremos estratégias de seleção de modelos, que nos ajudarão eliminar variáveis modelo que são consideradas menos importantes.Na prática, o modelo que inclui todas variáveis explicativas disponíveis é geralmente chamado de modelo completo. O modelo completo pode não ser o melhor modelo e, se não , queremos identificar um modelo menor que seja preferível.","code":""},{"path":"ch8-reg-mult-log.html","id":"notUsefulVariables","chapter":"8 Regressão Múltipla e Logística","heading":"8.2.1 Identificando variáveis no modelo que podem não ser úteis","text":"O \\(R^2\\) ajustado descreve força de um ajuste de modelo e é uma ferramenta útil para avaliar quais preditores estão adicionando valor ao modelo, em que adicionando valor significa que eles estão (provavelmente) melhorando precisão na previsão de resultados.Vamos considerar dois modelos, que são mostrados nas Tabelas 8.5 e 8.6. primeira tabela resume o modelo completo já que inclui todos preditores, enquanto segunda não inclui variável duração.Tabela 8.5: O ajuste para o modelo de regressão completo, incluindo o valor ajustado de R2Tabela 8.6: O ajuste para o modelo de regressão para preditores condição, foto e rodas.Nós comparamos o \\(R^2\\) ajustado de cada modelo para determinar qual escolher. O primeiro modelo tem um \\(R^2_{aj}\\) menor que o \\(R^2_{aj}\\) segundo modelo, então preferimos o segundo modelo ao primeiro.Será que o modelo sem duração é melhor que o modelo com duração? Nós não podemos ter certeza, mas com base \\(R^2\\) ajustado, esta é nossa melhor avaliação.","code":"\ntable5 <- table4\ntable5[6,] <- c(0.7108, '', '', '')\nrownames(table5) <- c(rownames(table4), 'R² adj'))\n\nknitr::kable(table5, digits = 3, \n             caption = 'O ajuste para o modelo de regressão completo, incluindo o valor ajustado de R2')\ng <- lm(totalPr ~ cond + stockPhoto + wheels, data = d)\n\ntable6 <- data.frame(round(summary(g)$coefficients,3))\ncolnames(table6) <- colnames(table5)\ntable6[5,] <- c(0.7128, '', '', '')\nrownames(table6) <- c('(Intercepto)', 'Condição', 'Foto', 'Rodas', 'R² adj'))\n\n\nknitr::kable(table6, caption = 'O ajuste para o modelo de regressão para preditores condição, foto e rodas.')"},{"path":"ch8-reg-mult-log.html","id":"twoStrategies","chapter":"8 Regressão Múltipla e Logística","heading":"8.2.2 Duas estratégias de seleção de modelo","text":"Duas estratégias comuns para adicionar ou remover variáveis em um modelo de regressão múltipla são chamadas de eliminação regressiva e seleção progressiva. Essas técnicas são frequentemente chamadas de estratégias de seleção de modelos gradual, porque elas adicionam ou excluem uma variável de cada vez, conforme elas “escalam” os preditores candidatos.Eliminação regressiva (backward elimination) começa com o modelo que inclui todas possíveis variáveis preditoras. variáveis são eliminadas uma por vez modelo até que não possamos melhorar o \\(R^2\\) ajustado. estratégia dentro de cada etapa de eliminação é eliminar variável que leva à maior melhoria \\(R^2\\) ajustado.Nossa linha de base para o \\(R^2\\) ajustado modelo completo é \\(R^2_{aj} = 0,7108\\), e precisamos determinar se descartar um preditor melhorará o \\(R^2\\) ajustado. Para verificar, ajustamos quatro modelos, cada um com um preditor diferente, e registramos os \\(R^2\\) ajustados de cada:O terceiro modelo sem duração tem o maior \\(R^2\\) ajustado de 0.7128, então nós o comparamos com o \\(R^2\\) ajustado para o modelo completo. Porque eliminando duração leva um modelo com um maior \\(R^2\\) ajustado, nóstiramos duração modelo.Como eliminamos um preditor modelo na primeira etapa, vemos se devemos eliminar quaisquer preditores adicionais. Nossa linha de base ajustada \\(R^2\\) é agora \\(R^2_{aj} = 0.7128\\). Agora, encaixamos três novos modelos, que consideram eliminação de cada um dos três preditores restantes:Nenhum desses modelos leva uma melhoria \\(R^2\\) ajustado, portanto, não eliminamos nenhum dos preditores restantes. Ou seja, após eliminação regressiva, ficamos com o modelo que mantém condição, foto e rodas, que podemos resumir usando os coeficientes da Tabela 8.6:\\[\\begin{align*}\r\n\\hat{y} \\ &= \\ b_0 + b_1x_1 + b_2x_2 + b_4x_4 \\\\\r\n\\widehat{preço} &= \\ 36,05 + 5,18 \\times \\text{cond\\_nova} + 1,12 \\times \\textfoto\\_stock} + 7,30 \\times \\text{rodas}\r\n\\end{align*}\\]estratégia de seleção progressiva é o reverso da técnica de eliminação regressiva. Em vez de eliminar variáveis uma por vez, adicionamos variáveis uma por vez até não encontrarmos nenhuma variável que melhore o modelo (medida pelo \\(R^2\\) ajustado).Começamos com o modelo que não inclui variáveis. Em seguida, ajustamos cada um dos modelos possíveis com apenas uma variável. Ou seja, nós ajustamos modelo incluindo apenas condição, então o modelo incluindo apenas foto, então um modelo com apenas duração, e um modelo com apenas rodas. Cada um dos quatro modelos fornece um valor ajustado de \\(R^2\\):Nesta primeira etapa, comparamos o \\(R^2\\) ajustado com um modelo de linha de base que não possui preditores. O modelo sem preditores sempre tem \\(R_{aj}^2 = 0\\). O modelo com um preditor que tem o maior \\(R^2\\) ajustado é o modelo com o preditor rodas, e porque esse \\(R^2\\) ajustado é maior que o \\(R^2\\) ajustado modelo sem preditores (\\(R_{aj}^2 = 0\\)), vamos adicionar essa variável ao nosso modelo.Repetimos o processo novamente, desta vez considerando modelos de 2 preditores onde um dos preditores é rodas e com uma nova linha de base \\(R^2_{aj} = 0.6390\\):O melhor preditor nesta fase, condição, tem um maior \\(R^2\\) ajustado (0.7124) que linha de base (0.6390), então também o adicionamos modelo.Como adicionamos novamente uma variável ao modelo, continuamos e verificamos se seria vantajoso adicionar uma terceira variável:O modelo adicionando foto tem maior \\(R^2\\) ajustado (0.7124 para 0.7128), então nós o adicionamos modelo.Porque nós adicionamos novamente um preditor, nós verificamos se adicionando última variável, duração, irá melhorar o \\(R^2\\) ajustado. Nós comparamos o \\(R^2\\) ajustado modelo com duração e os outros três preditores (0,7108) para o modelo que considera apenas rodas, condição, e foto (0,7128). Adicionar duração não melhora o \\(R^2\\) ajustado, por isso não o adicionamos ao modelo, e chegamos ao mesmo modelo que identificamos partir da eliminação regressiva.Estratégias de seleção de modelos: eliminação regressiva começa com o maior modelo e elimina variáveis uma uma até que estejamos satisfeitos de que todas variáveis restantes são importantes para o modelo. seleção progressiva começa sem nenhuma variável incluída modelo, depois adiciona variáveis de acordo com sua importância até que nenhuma outra variável importante seja encontrada.Não há garantia de que eliminação regressiva e seleção progressiva chegarão ao mesmo modelo final. Se ambas técnicas são testadas e chegam modelos diferentes, escolhemos o modelo com o maior \\(R_{aj}^2\\); Outras opções de escolha existem, mas estão além escopo deste livro.","code":"\nR <- matrix(c(0.6626, 0.7107, 0.7128, 0.3487), ncol = 4, nrow = 1)\nrownames(R) <- c('R² aj'))\ncolnames(R) <- c('condição', 'foto', 'duração', 'rodas')\n\nknitr::kable(R)\nR_v2 <- matrix(c(0.6587, 0.7124, 0.3414), ncol = 3, nrow = 1)\nrownames(R_v2) <- c('R² aj'))\ncolnames(R_v2) <- c('condição', 'foto', 'rodas')\n\nknitr::kable(R_v2)\nR_v3 <- matrix(c(0.3459, 0.0332, 0.1338, 0.6390), ncol = 4, nrow = 1)\nrownames(R_v3) <- c('R² aj'))\ncolnames(R_v3) <- c('condição', 'foto', 'duração', 'rodas')\n\nknitr::kable(R_v3)\nR_v4 <- matrix(c(0.7124, 0.6587, 0.6528), ncol = 3, nrow = 1)\nrownames(R_v4) <- c('R² aj'))\ncolnames(R_v4) <- c('condição', 'foto', 'duração')\n\nknitr::kable(R_v4)\nR_v5 <- matrix(c(0.7128, 0.7107), ncol = 2, nrow = 1)\nrownames(R_v5) <- c('R² aj'))\ncolnames(R_v5) <- c('foto', 'duração')\n\nknitr::kable(R_v5)"},{"path":"ch8-reg-mult-log.html","id":"pValueAlternativeToR2adj","chapter":"8 Regressão Múltipla e Logística","heading":"8.2.3 A abordagem do p-valor, uma alternativa para o \\(R^2\\) ajustado","text":"O p-valor pode ser usado como uma alternativa para o ajuste de \\(R^2\\) para seleção modelo.Na eliminação regressiva, identificaríamos o preditor correspondente ao maior p-valor. Se o p-valor estiver acima nível de significância, geralmente \\(\\alpha = 0,05\\), então abandonaríamos essa variável, reformaríamos o modelo e repetiríamos o processo. Se o maior p-valor menor que \\(\\alpha = 0,05\\), então não eliminaríamos nenhum preditor e o modelo atual seria nosso modelo de melhor ajuste.Na seleção direta com p-valores, invertemos o processo. Começamos com um modelo que não possui preditores, então ajustamos um modelo para cada possível preditor, identificando o modelo em que o p-valor preditor correspondente é o menor. Se esse p-valor menor que \\(\\alpha = 0,05\\), nós o adicionamos ao modelo e repetimos o processo, considerando se devemos adicionar mais variáveis uma por vez. Quando nenhum dos preditores restantes puder ser adicionado ao modelo e tiver um p-valor menor que 0,05, então paramos de adicionar variáveis e o modelo atual seria nosso modelo de melhor ajuste.Embora abordagens \\(R^2\\) ajustado e p-valor sejam semelhantes, elas às vezes levam modelos diferentes, com abordagem \\(R^2\\) ajustado tendendo incluir mais preditores modelo final. Por exemplo, se tivéssemos usado abordagem p-valor com os dados leilão, não teríamos incluído o preditor foto modelo final.Quando usar o \\(R^2\\) ajustado e quando usar abordagem p-valor: Quando o único objetivo é melhorar precisão da previsão, use \\(R^2\\) ajustado. Esse é comumente o caso em aplicativos de aprendizado de máquina.Quando nos preocupamos em entender quais variáveis são estatisticamente significantes preditores da resposta, ou se existe interesse em produzir um modelo mais simples ao custo potencial de uma pequena precisão de predição, então abordagem p-valor é preferida.Independentemente de você usar abordagem \\(R^2\\) ajustado ou p-valor, ou se você usar eliminação regressiva ou seleção progressiva, nosso trabalho não está feito após seleção de variáveis. Devemos ainda verificar se condições modelo são razoáveis.","code":""},{"path":"ch8-reg-mult-log.html","id":"multipleRegressionModelAssumptions","chapter":"8 Regressão Múltipla e Logística","heading":"8.3 Verificando os pressupostos do modelo usando gráficos","text":"Métodos de regressão múltipla usando o modelo\\[\\begin{align*}\r\n\\hat{y} &= \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k\r\n\\end{align*}\\]geralmente dependem dos seguintes quatro pressupostos:os resíduos modelo são quase normais,os resíduos modelo são quase normais,variabilidade dos resíduos é quase constante,variabilidade dos resíduos é quase constante,os resíduos são independentes, eos resíduos são independentes, ecada variável é linearmente relacionada ao resultado.cada variável é linearmente relacionada ao resultado.Os Gráficos de diagnóstico podem ser usados para verificar cada uma dessas suposições. Vamos considerar o modelo dos dados leilão Mario Kart, e verificar se há alguma preocupação notável:\\[\\begin{align*}\r\n\\widehat{preço} &= \\ 36,05 + 5,18 \\times \\text{cond\\_nova} + 1,12 \\times \\text{foto\\_stock} + 7,30 \\times \\text{rodas}\r\n\\end{align*}\\]Gráfico de probabilidade normal. Um gráfico de probabilidade normal dos resíduos é mostrado na Figura 8.2. Enquanto o enredo exibe algumas pequenas irregularidades, não há outliers que possam ser motivo de preocupação. Em um gráfico de probabilidade normal para resíduos, tendemos estar mais preocupados com resíduos que parecem ser outliers, uma vez que indicam caudas longas na distribuição de resíduos.\r\nFigura 8.2: Um gráfico de probabilidade normal dos resíduos é útil na identificação de observações que podem ser outliers.\r\nValores absolutos dos resíduos em relação aos valores ajustados. Um gráfico valor absoluto dos resíduos em relação aos seus valores ajustados correspondentes (\\(\\hat{y}_i\\)) é mostrado na Figura 8.3. Este gráfico é útil para verificar condição de que variação dos resíduos é aproximadamente constante. Não vemos desvios óbvios da variação constante neste exemplo.\r\nFigura 8.3: Comparando o valor absoluto dos resíduos com os valores ajustados é útil na identificação de desvios da suposição de variância constante.\r\nResíduos em ordem de coleta de dados. Um gráfico dos resíduos na ordem em que seus leilões correspondentes foram observados é mostrado na Figura 8.4. Tal enredo é útil para identificar qualquer ligação entre casos que estão próximos uns dos outros. Poderíamos procurar preços em queda ao longo tempo ou se houvesse uma hora dia em que os leilões tendiam obter um preço mais alto. Aqui não vemos nenhuma estrutura que indique um problema.~[Uma verificação especialmente rigorosa usaria os métodos de séries temporais. Por exemplo, podemos verificar se os resíduos consecutivos estão correlacionados. Fazer isso com esses resíduos não gera correlações estatisticamente significativas.]\r\nFigura 8.4: Plotar os resíduos na ordem em que observações correspondentes foram coletadas ajuda identificar conexões entre observações sucessivas. Se parece que observações consecutivas tendem estar próximas umas das outras, isso indica que suposição de independência das observações falharia.\r\nResiduos contra cada variável preditora. Consideramos um gráfico dos resíduos em relação à variável condição, os resíduos contra variável fotoe resíduos contra variável roda. Estes gráficos são mostradas na Figura 8.5. Para variável de condição de dois níveis, garantimos que não veremos nenhuma tendência restante e, em vez disso, estamos verificando se variabilidade não flutua entre os grupos, o que não acontece. entanto, olhando para variável estoque de fotos, descobrimos que há alguma diferença na variabilidade dos resíduos nos dois grupos. Adicionalmente, quando consideramos os resíduos contra variável rodas, nós vemos alguma estrutura possível. Parece haver curvatura nos resíduos, indicando que relação provavelmente não é linear.\r\nFigura 8.5: Para variáveis condição e foto, verificamos diferenças formato de distribuição ou na variabilidade dos resíduos. caso da variável foto, vemos um pouco menos de variabilidade grupo foto única que outro grupo. Para preditores numéricos, também verificamos tendências ou outras estruturas. Vemos uma ligeira reverência nos resíduos contra variável rodas na parte de baixo.\r\nÉ necessário resumir os diagnósticos para qualquer ajuste de modelo. Se os diagnósticos suportarem suposições modelo, isso melhoraria credibilidade nos resultados. Se avaliação diagnóstica mostrar estrutura subjacente remanescente nos resíduos, devemos tentar ajustar o modelo para considerar essa estrutura. Se não formos capazes de fazê-lo, poderemos ainda relatar o modelo, mas também observar suas deficiências. caso dos dados leilão, relatamos que parece haver uma variação não constante na variável fotos e que pode haver uma relação não linear entre o preço total e o número de rodas incluídas em um leilão. Esta informação seria importante para os compradores e vendedores que podem rever análise, e omitir esta informação pode ser um revés para pessoas que o modelo pode ajudar.“Todos os modelos estão errados, mas alguns são úteis”\" - George E.P. Box: verdade é que nenhum modelo é perfeito. entanto, até modelos imperfeitos podem ser úteis. Relatar um modelo falho pode ser razoável desde que seja claro e relate deficiências modelo. Não relate os resultados quando suposições forem totalmente violadas: Embora haja uma pequena margem de manobra nas suposições modelo, não vá longe demais. Se suposições modelo forem claramente violadas, considere um novo modelo, mesmo que isso signifique aprender mais métodos estatísticos ou contratar alguém que possa ajudar.Intervalos de confiança em regressão múltipla: Intervalos de confiança para coeficientes em regressão múltipla podem ser calculados usando mesma fórmula como modelo preditor único:\\[\\begin{align*}\r\nb_i \\ \\pm\\ t_{df}^{\\star}EP_{b_{}}\r\n\\end{align*}\\]onde \\(t_{df}^{\\star}\\) é o valor \\(t\\) apropriado correspondente ao nível de confiança e aos graus de liberdade modelo, \\(df=n-k-1\\).","code":"\nlibrary(openintro)\ndata(marioKart)\ntoss <- which(marioKart$totalPr > 80)\nkeep <- c(\"totalPr\",\n          \"cond\",\n          \"stockPhoto\",\n          \"duration\",\n          \"wheels\",\n          \"shipSp\")\nd <- marioKart[-toss, keep]\nd$stockPhoto <- (d$stockPhoto == \"yes\") + 0\nd$cond <- (d$cond == \"new\") + 0\nthisOne <- names(d) == \"cond\"\nnames(d)[thisOne] <- \"condNew\"\nd$shipSp <- as.character(d$shipSp)\nthese <- d$shipSp %in%\n         c(\"firstClass\", \"priority\", \"parcel\", \"media\")\nd$shipSp[these] <- \"usps\"\nd$shipSp[grep(\"ups\", d$shipSp)] <- \"ups\"\nthese <- d$shipSp %in% c(\"other\", \"standard\")\nd$shipSp[these] <- \"unknown\"\nd$shipSp <- as.factor(d$shipSp)\nd <- d[,-which(colnames(d) == \"shipSp\")]\n\nfit <- lm(totalPr ~ condNew + stockPhoto + wheels, data = d)\n\ne <- fit$res\nf <- fit$fit\n\n# mkDiagnosticNormalQuantilePlot.pdf\nggplot(data = data.frame(e), aes(sample = e)) + \n  stat_qq(color = 'skyblue3') +\n  stat_qq_line(color = 'skyblue3', linetype = 'dashed') + \n  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) +\n  labs(x = \"Quantis Teóricos\",y = \"Resíduos\")  +  \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, size=1))\n# mkDiagnosticEvsAbsF.pdf\nggplot() + \n  labs(x = \"Valores Ajustados\", y = \"Valores Absolutos dos Resíduos\")  +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(aes(x = f, y = abs(e)), color = 'skyblue3')\n# mkDiagnosticInOrder.pdf\nggplot() + \n  labs(x = \"Ordem de Coleta\", y = \"Resíduos\")  +  \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(aes(x = 1:length(e), y = e), color = 'skyblue3')\n# mkDiagnosticEvsVariables.pdf\ng1 <- ggplot(mapping = aes(as.factor(d$condNew), e)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = \"Condição\", y = \"Resíduos\")  +  \n  geom_boxplot() + \n  geom_point(aes(x = as.factor(0), y = e[d$condNew == 0]), color = 'skyblue3') + \n  geom_point(aes(x = as.factor(1), y = e[d$condNew == 1]), color = 'skyblue3') + \n  scale_x_discrete(breaks = seq(0, 1, by = 1), labels = c('Usado', 'Novo'))  \n\n\ng2 <- ggplot(mapping = aes(as.factor(d$stockPhoto), e)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = \"Tipo de Foto\", y = \"Resíduos\")  +  \n  geom_boxplot() + \n  geom_point(aes(x = as.factor(0), y = e[d$stockPhoto == 0]), color = 'skyblue3') + \n  geom_point(aes(x = as.factor(1), y = e[d$stockPhoto == 1]), color = 'skyblue3') + \n  scale_x_discrete(breaks = seq(0, 1, by = 1), labels = c('Única', 'Estoque'))  \n\ng3 <- ggplot(mapping = aes(d$wheels, e)) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  labs(x = \"Número de Rodas\", y = \"Resíduos\") + \n  geom_point(color = 'skyblue3')\n\ngridExtra::grid.arrange(g1, g2, g3, ncol = 1)"},{"path":"ch8-reg-mult-log.html","id":"logisticRegression","chapter":"8 Regressão Múltipla e Logística","heading":"8.4 Introdução à regressão logística","text":"Nesta seção, apresentamos regressão logística como uma ferramenta para construir modelos quando existe uma variável de resposta categórica com dois níveis. regressão logística é um tipo de modelo linear generalizado (MLG) para variáveis de resposta onde regressão múltipla regular não funciona muito bem. Em particular, variável resposta nessas configurações geralmente assume um formato em que os residuos parecem completamente diferentes da distribuição normal.Os MLG podem ser considerados como uma abordagem de modelagem de dois estágios. Primeiro modelamos variável de resposta usando uma distribuição de probabilidade, como distribuição binomial ou de Poisson. Segundo, modelamos o parâmetro da distribuição usando uma coleção de preditores e uma forma especial de regressão múltipla.Na Seção 8.4 vamos revisitar o conjunto de dados email. Esses e-mails foram coletados de uma única conta de e-mail e trabalharemos desenvolvimento de um filtro de spam básico usando esses dados. variável resposta, spam, foi codificado para ter valor 0 quando uma mensagem não é spam e 1 quando é spam. Nossa tarefa será criar um modelo apropriado que classifique mensagens como spam ou não spam, usando características de email codificadas como variáveis preditoras. Embora esse modelo não seja o mesmo daqueles usados em filtros de spam de grande escala, ele compartilha muitos dos mesmos recursos.","code":""},{"path":"ch8-reg-mult-log.html","id":"eMailData","chapter":"8 Regressão Múltipla e Logística","heading":"8.4.1 Dados e-mail","text":"O conjunto de dados email foi apresentado pela primeira vez Capítulo de introdução, com um número relativamente pequeno de variáveis. Na verdade, existem muitas outras variáveis disponíveis que podem ser úteis para classificar o spam. descrições dessas variáveis são apresentadas na Tabela 8.7. variável spam será o resultado, e outras 10 variáveis serão os preditores modelo. Embora tenhamos limitado que os preditores usados nesta seção sejam variáveis categóricas (em que muitos são representados como variáveis indicadoras), preditores numéricos também podem ser usados na regressão logística. Veja nota de rodapé para uma discussão adicional sobre este tópico.288Tabela 8.7: Descrições de 11 variáveis conjunto de dados email. Observe que todas variáveis são variáveis indicadoras, que tomam o valor 1 se característica especificada estiver presente e 0 caso contrário.","code":"\ndata(\"email\")\n\naux <- email[,c('spam', 'to_multiple', 'cc', 'attach', 'dollar', 'winner', \n                'inherit', 'password', 'format', 're_subj', 'exclaim_subj')]\n\nnames(aux) <- c('spam', 'a_multiplos', 'cc', 'anexo', 'dolar', 'ganhador',\n                'herdar', 'senha', 'formatacao', 're_assun', 'exclamacao_assun')\n\ndes_email <- c('Especifica se a mensagem era spam', \n               'uma variável indicadora de se mais de uma pessoa estava no campo A do email', \n               'um indicador se alguém estava no campo cc do email', \n               'um indicador se tinha um anexo, como um documento ou imagem', \n               'um indicador se a palavra dólar ou simbolo $ apareceu no email',\n               'um indicador se a palavra ganhador apareceu no email', \n               'um indicador se a palavra herdar (ou uma variação, como heranca), apareceu no email', \n               'um indicador se a palavra senha estava presente no email', \n               'indica se o email tinha formatação especial, como negritos, tabelas ou links', \n               'indica se re: estava incluida no começo do assunto do email',\n               'indica se tinha algum ponto de exclamação no assunto do email')\n\ntable7 <- data.frame(cbind(names(aux), des_email))\ncolnames(table7) <- c('Variável', 'Descrição')\n\nknitr::kable(table7, caption = 'Descrições de 11 variáveis no conjunto de dados email. Observe que todas as variáveis são variáveis indicadoras, que tomam o valor 1 se a característica especificada estiver presente e 0 caso contrário.')"},{"path":"ch8-reg-mult-log.html","id":"modelingTheProbabilityOfAnEvent","chapter":"8 Regressão Múltipla e Logística","heading":"8.4.2 Modelando a probabilidade de um evento","text":"Notação para um modelo de regressão logística: variável de resultado para um MLG é denotada por \\(Y_i\\), onde o índice \\(\\) é usado para representar observação \\(\\). aplicativo de e-mail, \\(Y_i\\) será usado para representar se o e-mail \\(\\) é spam (\\(Y_i=1\\)) ou não (\\(Y_i=0\\)).variáveis preditoras são representadas da seguinte forma: \\(x_{1,}\\) é o valor da variável 1 para observação \\(\\), \\(x_{2,}\\) é o valor da variável 2 para observação \\(\\) e assim por diante.regressão logística é um modelo linear generalizado em que o resultado é uma variável categórica de dois níveis. O resultado, \\(Y_i\\), recebe o valor 1 (em nosso aplicativo, isso representa uma mensagem de spam) com probabilidade \\(p_i\\) e o valor 0 com probabilidade \\(1-p_i\\). É probabilidade \\(p_i\\) que modelamos em relação às variáveis preditoras.O modelo de regressão logística relaciona probabilidade de um e-mail ser spam (\\(p_i\\)) aos preditores \\(x_{1,}, x_{2,}, \\dots, x_{k,}\\) através de um quadro muito parecido com o de regressão múltipla:\\[\\begin{align}\r\ntransformação(p_{}) = \\beta_0 + \\beta_1x_{1,} + \\beta_2 x_{2,} + \\cdots \\beta_k x_{k,}\r\n\\tag{8.3}\r\n\\end{align}\\]Queremos escolher uma transformação na Equação (8.3) que faz sentido prático e matemático. Por exemplo, queremos uma transformação que faça o leque de possibilidades lado esquerdo da Equação @ref9EQ:linkTransformationEquation) igual ao intervalo de possibilidades para o lado direito; se não houvesse transformação para essa equação, o lado esquerdo só poderia ter valores entre 0 e 1, mas o lado direito poderia obter valores fora desse intervalo. Uma transformação comum para \\(p_i\\) é o transformação logit, que pode ser escrito como\\[\\begin{align*}\r\nlogit(p_i) = \\log_{e}\\left( \\frac{p_i}{1-p_i} \\right)\r\n\\end{align*}\\]transformação logit é mostrada na Figura 8.6. Abaixo, nós reescrevemos Equação (8.3) usando transformação logit de \\(p_i\\):\\[\\begin{align*}\r\n\\log_{e}\\left( \\frac{p_i}{1-p_i} \\right)\r\n    = \\beta_0 + \\beta_1 x_{1,} + \\beta_2 x_{2,} + \\cdots + \\beta_k x_{k,}\r\n\\end{align*}\\]nosso exemplo de spam, existem 10 variáveis preditoras, então \\(k=10\\). Este modelo não é muito intuitivo, mas ainda tem alguma semelhança com regressão múltipla, e podemos ajustar este modelo usando software. De fato, uma vez que examinamos os resultados software, começaremos sentir que estamos de volta à regressão múltipla, mesmo que interpretação dos coeficientes seja mais complexa.\r\nFigura 8.6: Valores de pi contra valores de logit(pi)\r\n\\[\\begin{align*}\r\n\\log\\left( \\frac{p_i}{1-p_i} \\right) = -2.12 - 1.81\\times\\text{\\_múltiplos}\r\n\\end{align*}\\]Se um email selecionado aleatoriamente e tiver apenas um endereço campo, qual é probabilidade de ser spam? E se mais de um endereço estiver listado campo?Se houver apenas um e-mail campo de destinatários, a_multiplicar toma o valor 0 e o lado direito da equação modelo é igual -2,12. Resolvendo para \\(p_i\\): \\(\\frac{e^{-2.12}}{1 + e^{-2.12}} = 0.11\\). Assim como rotulamos um valor ajustado de \\(y_i\\) com um “chapéu” em uma variável simples e em uma regressão múltipla, faremos o mesmo para essa probabilidade: \\(\\hat{p}_i = 0.11\\).Se houver mais de um endereço listado campo de destinatários, o lado direito da equação modelo será \\(-2.12 - 1.81\\times1 = -3.93\\), que corresponde uma probabilidade \\(\\hat{p}_i = 0.02\\).Observe que podemos examinar -2,12 e -3,93 na Figura 8.6 para estimar probabilidade antes de calcular formalmente o valor.Para converter de valores na escala de regressão (por exemplo, -2,12 e -3,93 Exemplo 8.6), use seguinte fórmula, que é o resultado da resolução de \\(p_i\\) modelo de regressão:\\[\\begin{align*}\r\np_i\r\n    = \\frac{e^{\\beta_0 + \\beta_1 x_{1,}+\\cdots+\\beta_k x_{k,}}}\r\n        {\\ 1\\ \\ +\\ \\ e^{\\beta_0 + \\beta_1 x_{1,}+\\cdots+\\beta_k x_{k,}}\\ }\r\n\\end{align*}\\]Tal como acontece com maioria dos problemas de dados aplicados, substituímos estimativas pontuais dos parâmetros (o \\(\\beta_i\\)) para que possamos fazer uso desta fórmula. Exemplo 8.6, probabilidades foram calculadas como\\[\\begin{align*}\r\n&\\frac{\\ e^{-2.12}\\ }{\\ 1\\ +\\ e^{-2.12}\\ } = 0.11 && \\frac{\\ e^{-2.12 - 1.81}\\ }{\\ 1\\ +\\ e^{-2.12 - 1.81}\\ } = 0.02\r\n\\end{align*}\\]Embora informações sobre se o e-mail é endereçado várias pessoas seja um começo útil na classificação de e-mails como spam ou não, probabilidades de 11% e 2% não são drasticamente diferentes, e nenhuma delas fornece evidências muito fortes sobre quais mensagens de e-mail específicas são spam. Para obter estimativas mais precisas, precisaremos incluir muito mais variáveis modelo.Usamos software estatístico para ajustar o modelo de regressão logística com todos os dez preditores descritos na Tabela 8.7. Como regressão múltipla, o resultado pode ser apresentado em uma tabela de resumo, que é mostrada na Tabela 8.8. estrutura desta tabela é quase idêntica à da regressão múltipla; única diferença notável é que os p-valores são calculados usando distribuição normal em vez da distribuição-\\(t\\).Tabela 8.8: Tabela de resumo para o modelo de regressão logística completa para o exemplo de filtro de spam.Assim como regressão múltipla, poderíamos cortar algumas variáveis modelo usando o p-valor. Usando eliminação regressiva com um ponto de corte de p-valor de 0,05 (comece com o modelo completo e apare os preditores com valores de p maiores que 0,05), acabamos por eliminar os preditores exclamação_asun, dólar, herdar, e cc. O restante desta seção contará com este modelo menor, que é resumido na Tabela 8.9.Tabela 8.9: Tabela de resumo para o modelo de regressão logística para o filtro de spam, onde seleção de variáveis foi executada.estimativas pontuais geralmente mudam um pouco – e muitas vezes – dependendo de quais outras variáveis estão incluídas modelo. Isso geralmente é devido à colinearidade nas variáveis preditoras. Anteriormente, vimos isso exemplo leilão Ebay quando comparamos o coeficiente de condição em um modelo de variável única e o coeficiente correspondente modelo de regressão múltipla que usou três variáveis adicionais.O coeficiente estimado de ganhador é positivo (1,7250). Um coeficiente estimado positivo na regressão logística, assim como na regressão múltipla, corresponde uma associação positiva entre o preditor e variáveis de resposta ao considerar demais variáveis modelo. Como variável de resposta assume valor 1 se um email é spam e 0 caso contrário, o coeficiente positivo indica que presença de “vencedor”\" em um email aumenta probabilidade de que mensagem seja spam.Como HTML corresponde um valor de 1 na variável formatação e o coeficiente dessa variável é negativo (-1,5569), isso reduziria estimativa de probabilidade proveniente modelo.","code":"\np  <- seq(0.0001, 0.9999, 0.0002)\nlp <- log(p/(1-p))\n\npts  <- seq(0.01, 0.99, length.out = 25)\nR    <- c(-6,6)\nadj  <- 0.07\nadj1 <- 0.02\n\n#-------------------------------------------------------------------------------\nthis <- which.min(abs(p - 0.2))\nLP <- c(seq(6, -5, -1))\nP <- exp(LP) / (1 + exp(LP))\nPOS <- c(3, 1, 3, 1, 2, 2, 2, 2, 4, 3, 1, 3)\nxOFF <- c()\nRound <- c(3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3)\n\nt1 <- t2 <- labs <- vector()\n\nfor (i in 1:length(LP)) {\n  t1[i]   <- format(round(c(LP, 0.9), Round[i]))[i]\n  t2[i]   <- format(round(P, Round[i]))[i]\n  \n  labs[i] <- paste0(\"(\", t1[i], \", \", t2[i], \")\")\n}\n\nggplot() + \n  geom_line(aes(lp, p)) + \n  labs(x = expression(logit(p[i])), y = expression(p[i])) + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_hline(yintercept = 0:1, linetype = 'dashed', color = 'skyblue3') + \n  geom_point(aes(LP, P), color = 'red') + \n  annotate(geom = \"text\", x = as.numeric(t1), y = as.numeric(t2), size = 3, label = paste0(labs))\naux$ganhador <- ifelse(aux$ganhador == 'yes', 1, 0)\nmd <- glm(spam ~ . , data = aux, family = binomial)\n\ntable8 <- data.frame(summary(md)$coefficients)\ncolnames(table8) <- c('Estimativa', 'Erro Padrão', 'Valor Z', 'Pr(>|z|)')\n\nknitr::kable(table8, digits = 3, caption = 'Tabela de resumo para o modelo de regressão logística completa para o exemplo de filtro de spam.')\nmd2 <- glm(spam ~ a_multiplos + ganhador + formatacao + re_assun + \n            anexo + senha, data = aux, family = binomial)\n\ntable9 <- data.frame(summary(md2)$coefficients)\ncolnames(table9) <- c('Estimativa', 'Erro Padrão', 'Valor Z', 'Pr(>|z|)')\n\nknitr::kable(table9, digits = 3 , caption = 'Tabela de resumo para o modelo de regressão logística para o filtro de spam, onde a seleção de variáveis foi executada.')"},{"path":"ch8-reg-mult-log.html","id":"practicalDecisionsOnEMailApp","chapter":"8 Regressão Múltipla e Logística","heading":"8.4.3 Decisões práticas no aplicativo de e-mail","text":"Examplos 8.7 e 8.8 destacaram uma característica fundamental da regressão logística e múltipla. exemplo filtro de spam, algumas características e-mail empurram classificação de um e-mail na direção spam, enquanto outras características o empurram na direção oposta.Se implementássemos um filtro de spam usando o modelo adequado, cada e-mail futuro analisado se encaixaria em uma das três categorias com base nas características e-mail:características e-mail geralmente indicam que o e-mail não é spam e, portanto, probabilidade resultante de que o e-mail é spam é bastante baixa, digamos, abaixo de 0,05.características e-mail geralmente indicam que o e-mail não é spam e, portanto, probabilidade resultante de que o e-mail é spam é bastante baixa, digamos, abaixo de 0,05.características geralmente indicam que o email é spam e, portanto, probabilidade resultante de o email ser spam é muito grande, digamos, acima de 0,95.características geralmente indicam que o email é spam e, portanto, probabilidade resultante de o email ser spam é muito grande, digamos, acima de 0,95.características se equilibram umas às outras em termos de evidência favor e contra mensagem sendo classificada como spam. Sua probabilidade cai intervalo restante, ou seja, o e-mail não pode ser classificado adequadamente como spam ou não spam.características se equilibram umas às outras em termos de evidência favor e contra mensagem sendo classificada como spam. Sua probabilidade cai intervalo restante, ou seja, o e-mail não pode ser classificado adequadamente como spam ou não spam.Se estivéssemos gerenciando um serviço de e-mail, teríamos que pensar sobre o que deveria ser feito em cada uma dessas três instâncias. Em um aplicativo de email, geralmente há apenas duas possibilidades: filtrar o email da caixa de entrada normal e colocá-lo em um “spambox,” ou deixar que o email vá para caixa de entrada normal.Quase qualquer classificador terá algum erro. Nas diretrizes filtro de spam acima, decidimos que não há problema em permitir que até 5% das mensagens na caixa de spam sejam mensagens reais. Se quiséssemos dificultar um pouco classificação de mensagens como spam, poderíamos usar um limite de 0,99. Isso teria dois efeitos. Por elevar o padrão que pode ser classificado como spam, reduz o número de bons emails classificados como spam. entanto, ele também não classificará corretamente uma fração aumentada de mensagens spam. Não importa complexidade e confiança que possamos ter em nosso modelo, essas considerações práticas são absolutamente cruciais para criar um filtro de spam útil. Sem eles, poderíamos fazer mais mal que bem usando nosso modelo estatístico.","code":""},{"path":"ch8-reg-mult-log.html","id":"diagnosticsForTheEmailSorter","chapter":"8 Regressão Múltipla e Logística","heading":"8.4.4 Diagnóstico para o classificador de e-mail","text":"Condições de regressão logística: Existem duas condições chave para ajustar um modelo de regressão logística:Cada preditor \\(x_i\\) está linearmente relacionado logit\\((p_i)\\) se todos os outros preditores forem mantidos constantes.Cada preditor \\(x_i\\) está linearmente relacionado logit\\((p_i)\\) se todos os outros preditores forem mantidos constantes.O modelo que relaciona o parâmetro \\(p_i\\) com os preditores \\(x_{1,}, x_{2,}, \\dots, x_{k,}\\) assemelha-se muito à verdadeira relação entre o parâmetro e os preditores.O modelo que relaciona o parâmetro \\(p_i\\) com os preditores \\(x_{1,}, x_{2,}, \\dots, x_{k,}\\) assemelha-se muito à verdadeira relação entre o parâmetro e os preditores.Cada resultado \\(Y_i\\) é independente dos outros resultados.Cada resultado \\(Y_i\\) é independente dos outros resultados.primeira condição modelo de regressão logística não é facilmente verificada sem uma quantidade razoavelmente grande de dados. Felizmente, temos 3.921 e-mails em nosso conjunto de dados! Vamos primeiro visualizar esses dados traçando classificação real dos e-mails em relação às probabilidades ajustadas modelo, como mostrado na Figura~ 8.7. grande maioria dos emails (spam ou não) ainda tem probabilidades abaixo de 0,5.\r\nFigura 8.7: probabilidade prevista de que cada um dos 3.912 e-mails seja spam é classificada por seu agrupamento, spam ou não. Ruídos (pequenos deslocamentos verticais aleatórios) foram adicionados cada ponto para que os pontos com valores quase idênticos não sejam representados exatamente um em cima outro. Isto torna possível ver mais observações.\r\nprincípio, isso pode parecer muito desanimador: ajustamos um modelo logístico para criar um filtro de spam, mas nenhum e-mail tem uma probabilidade ajustada de ser spam acima de 0,75. Não se desespere; Vamos discutir maneiras de melhorar o modelo através uso de melhores variáveis na Seção 8.4.5.Gostaríamos de avaliar qualidade nosso modelo. Por exemplo, podemos perguntar: se olharmos para os e-mails que modelamos como tendo 10% de chance de ser spam, descobrimos que cerca de 10% deles são realmente spam? Para nos ajudar, emprestamos um método estatístico avançado chamado splines naturais que estima probabilidade local sobre região de 0,00 0,75 (maior probabilidade prevista foi de 0,73, portanto evitamos extrapolar). Tudo o que você precisa saber sobre splines naturais para entender o que estamos fazendo é que eles são usados para encaixar linhas flexíveis em vez de linhas retas.O ajuste da curva usando splines naturais é mostrado na Figura 8.8 como uma linha preta sólida. Se o modelo logístico se ajustar bem, curva deve seguir de perto linha tracejada \\(y=x\\). Adicionamos sombreamento para representar o limite de confiança da linha curva para esclarecer quais flutuações podem ser plausivelmente devido ao acaso. Mesmo com essa confiança, há pontos fracos na suposição primeiro modelo. curva sólida e sua margem de confiança mergulham abaixo da linha tracejada em cerca de 0,1 0,3, e depois flutuam acima da linha tracejada em cerca de 0,35 0,55. Esses desvios indicam que o modelo que relaciona o parâmetro aos preditores não se parece muito com o relacionamento verdadeiro.\r\nFigura 8.8: linha preta sólida fornece estimativa empírica da probabilidade de observações com base em suas probabilidades previstas (limites de confiança também são mostrados para essa linha), que é ajustada usando splines naturais. Uma pequena quantidade de ruído foi adicionada às observações na parcela para permitir que mais observações fossem vistas.\r\nPudemos avaliar o segundo pressuposto modelo de regressão logística – independência dos desfechos – utilizando os resíduos modelo. Os resíduos de um modelo de regressão logística são calculados da mesma forma que na regressão múltipla: o resultado observado menos o resultado esperado. Para regressão logística, o valor esperado resultado é probabilidade ajustada para observação, e o resíduo pode ser escrito como\\[\\begin{align*}\r\ne_i = Y_i - \\hat{p}_i\r\n\\end{align*}\\]Poderíamos plotar esses resíduos contra uma variedade de variáveis ou em sua ordem de coleta, como fizemos com os resíduos em regressão múltipla. entanto, como o modelo precisará ser revisado para classificar efetivamente o spam e já foi visto gráficos residuais semelhantes, nós não vamos investigar os resíduos aqui.","code":"\nlibrary(splines)\ndata(email)\ne <- email\ne$cc       <- ifelse(email$cc > 0, 1, 0)\ne$attach   <- ifelse(email$attach > 0, 1, 0)\ne$dollar   <- ifelse(email$dollar > 0, 1, 0)\ne$inherit  <- ifelse(email$inherit > 0, 1, 0)\ne$password <- ifelse(email$password > 0, 1, 0)\ng <- glm(spam ~ to_multiple + winner + format + \n                re_subj + exclaim_subj +\n                attach + dollar +\n                inherit + password, # +\n                #num_char + line_breaks + exclaim_mess,\n                data = e, family = binomial)\n# summary(g)\np  <- predict(g, type = \"response\")\np. <- p\n\n# logisticModelPredict\nset.seed(1)\nnoise <- rnorm(nrow(e), sd = 0.08)\nggplot() + \n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1)) + \n  geom_point(aes(p, e$spam + noise), color = 'skyblue3') + \n  labs(x = 'Probabilidade Predita', y = NULL) + \n  xlim(0, 1) + \n  scale_y_continuous(breaks = seq(0, 1, by = 1), labels = c('0 \\n(Não é Spam)', '1 \\n(Spam)')) + \n  theme(axis.text.y = element_text(angle = 90, hjust = .5))\nlibrary(splines)\ndata(email)\ne <- email\n\ne$cc       <- ifelse(email$cc > 0, 1, 0)\ne$attach   <- ifelse(email$attach > 0, 1, 0)\ne$dollar   <- ifelse(email$dollar > 0, 1, 0)\ne$inherit  <- ifelse(email$inherit > 0, 1, 0)\ne$password <- ifelse(email$password > 0, 1, 0)\n\ng <- glm(spam ~ to_multiple + winner + format + \n           re_subj + exclaim_subj +\n           attach + dollar +\n           inherit + password, # +\n         #num_char + line_breaks + exclaim_mess,\n         data = e, family = binomial)\n# summary(g)\np  <- predict(g, type = \"response\")\np. <- p\nq <- p\n\nset.seed(1)\nnoise <- rnorm(nrow(e), sd = 0.08)\n\n# parte do poligono \nns1 <- 7\ng1 <- lm(e$spam ~ ns(p, ns1))\np  <- seq(0, max(p), length.out = 200)\nY  <- predict(g1,\n              data.frame(ns(p, ns1)),\n              se.fit = TRUE)\nyb <- Y$fit - 1.96 * Y$se.fit\nyt <- rev(Y$fit + 1.96 * Y$se.fit)\n\n\nggplot() + \n  geom_point(aes(q, e$spam+noise/5), color = 'skyblue3') + \n  geom_line(aes(0:1, 0:1), linetype = 'dashed') +   xlim(0, 1) +\n  geom_polygon(aes(c(p, rev(p)), c(yb, yt)), fill = 'gold2', alpha = 0.5) +\n  geom_line(aes(p, Y$fit)) +\n  theme(panel.border = element_rect(colour = \"black\", fill = NA, size = 1), \n        axis.text.y = element_text(angle = 90, hjust = .5)) +\n  geom_segment(aes(x = 0.83, y = 0.57, xend = 0.8, yend = 0.785), \n               arrow = arrow(length = unit(0.2, \"cm\"))) + \n  geom_segment(aes(x = 0.36, y = 0.54, xend = 0.45, yend = 0.52), \n               arrow = arrow(length = unit(0.2, \"cm\"))) + \n  geom_segment(aes(x = 0.6, y = 0.36, xend = 0.7, yend = 0.61), \n               arrow = arrow(length = unit(0.2, \"cm\"))) + \n  annotate(geom = \"text\", x = 0.88, y = 0.48, size = 3, \n           label = \"O que esperamos \\nse o modelo logístico \\né razoável\") + \n  annotate(geom = \"text\", x = 0.25, y = 0.6, size = 3, \n           label = \"Probabilidades localmente \\nestimadas com \\nlimites de confiança\") + \n  annotate(geom = \"text\", x = 0.6, y = 0.27, size = 3, \n           label = \"Os limites se tornam \\namplos porque não \\nsão encontrados muitos \\ndados até o momento\") + \n  labs(x = 'Probabilidade Predita', y = 'Spam') + \n  scale_y_continuous(breaks = seq(0, 1, by = 0.2), labels = c('0 \\n(Não é Spam)', '0.2', '0.4', '0.6', '0.8', '1 \\n(Spam)'))  \np  <- p."},{"path":"ch8-reg-mult-log.html","id":"improvingTheSetOfVariablesForASpamFilter","chapter":"8 Regressão Múltipla e Logística","heading":"8.4.5 Melhorando o conjunto de variáveis para um filtro de spam","text":"Se estivéssemos criando um filtro de spam para um serviço de e-mail que gerenciava muitas contas (por exemplo, Gmail ou Hotmail), gastaríamos muito mais tempo pensando em variáveis adicionais que poderiam ser úteis para classificar e-mails como spam ou não. Também usaríamos transformações ou outras técnicas que nos ajudariam incluir variáveis numéricas fortemente distorcidas como preditores.Reserve alguns minutos para pensar em variáveis adicionais que podem ser úteis na identificação de spam. Abaixo está uma lista de variáveis que achamos que podem ser úteis:(1) Uma variável indicadora pode ser usada para representar se houve correspondência bidirecional prévia com o remetente de uma mensagem. Por exemplo, se você enviou uma mensagem para joao@exemplo.com e, em seguida, João enviou um e-mail para você, essa variável levaria o valor 1 para o e-mail que João enviou. Se você nunca tivesse enviado um e-mail para John, variável seria definida como 0.(1) Uma variável indicadora pode ser usada para representar se houve correspondência bidirecional prévia com o remetente de uma mensagem. Por exemplo, se você enviou uma mensagem para joao@exemplo.com e, em seguida, João enviou um e-mail para você, essa variável levaria o valor 1 para o e-mail que João enviou. Se você nunca tivesse enviado um e-mail para John, variável seria definida como 0.(2) Uma segunda variável indicadora poderia utilizar informações de sinalização de spam anteriores da conta. variável pode ter valor 1 se o remetente da mensagem já enviou mensagens marcadas como spam.(2) Uma segunda variável indicadora poderia utilizar informações de sinalização de spam anteriores da conta. variável pode ter valor 1 se o remetente da mensagem já enviou mensagens marcadas como spam.(3) Uma terceira variável indicadora pode sinalizar emails que contêm links incluídos em mensagens de spam anteriores. Se tal link encontrado, defina variável como 1 para o email. Caso contrário, defina-como 0.(3) Uma terceira variável indicadora pode sinalizar emails que contêm links incluídos em mensagens de spam anteriores. Se tal link encontrado, defina variável como 1 para o email. Caso contrário, defina-como 0.variáveis descritas acima adotam uma das duas abordagens. variável (1) é especialmente projetada para aproveitar o fato de que o spam raramente é enviado entre indivíduos que possuem comunicação bidirecional. Variáveis (2) e (3) são especialmente projetadas para sinalizar spammers (quem envia muito spam) comuns ou spams comuns. Enquanto nós teríamos que verificar usando os dados que cada uma das variáveis é efetiva, estas parecem ser idéias promissoras.Tabela 8.10 mostra uma tabela de contingência para spam e também para nova variável descrita em (1) acima. Se olharmos para os 1.090 e-mails em que houve correspondência com o remetente nos últimos 30 dias, nenhuma dessas mensagens foi spam. Isso sugere que variável (1) seria muito eficaz para classificar com precisão algumas mensagens como não spam. Com essa variável única, poderíamos enviar cerca de 28% de mensagens para caixa de entrada com confiança de que quase nenhuma é spam.Tabela 8.10: Uma tabela de contingência para spam e uma nova variável que representa se houve correspondência com o remetente nos últimos 30 dias.variáveis descritas em (2) e (3) forneceriam uma excelente base para distinguir mensagens provenientes de spammers conhecidos ou mensagens que recebam uma forma conhecida de spam. Para utilizar essas variáveis, precisaríamos criar bancos de dados: um contendo endereços de e-mail de spammers conhecidos e um contendo URLs encontrados em mensagens de spam conhecidas. Nosso acesso essas informações é limitado, por isso não podemos implementar essas duas variáveis neste livro. entanto, se formos contratados por um serviço de e-mail para criar um filtro de spam, esses serão os próximos passos importantes.Além de encontrar mais e melhores preditores, precisaríamos criar um modelo de regressão logística personalizado para cada conta de e-mail. Isso pode soar como uma tarefa intimidadora, mas sua complexidade não é tão assustadora quanto parece à primeira vista. Salvaremos os detalhes de um curso de estatística em que programação de computadores desempenha um papel mais central.Para tarefa extremamente desafiadora de classificar mensagens de spam, fizemos muito progresso. Vimos que variáveis simples de e-mail, como o formato, inclusão de certas palavras e outras características circunstanciais, fornecem informações úteis para classificação de spam. Muitos desafios permanecem, desde melhor compreensão da regressão logística até realização da programação de computadores necessária, mas conclusão de tal tarefa está quase ao seu alcance.","code":"\ntable10 <- rbind(c(367, 0, 367), c(2464, 1090, 3554), c(2831, 1090, 3921))\ncolnames(table10) <- c('troca de emails prévia (não)', 'troca de emails prévia (sim)', 'Total')\nrownames(table10) <- c('spam', 'não spam', 'total')\n\nknitr::kable(table10, align = 'c', \n             caption = 'Uma tabela de contingência para spam e uma nova variável que representa se houve correspondência com o remetente nos últimos 30 dias.')"}]
